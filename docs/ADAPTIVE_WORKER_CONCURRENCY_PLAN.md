# План: авто-расчёт параллелизма воркера (CPU/память, MLX+Ollama, тяжёлые/лёгкие модели)

**Статус внедрения (2026-02-01):** реализовано. Модуль `knowledge_os/app/adaptive_concurrency.py` (get_effective_concurrent, is_model_heavy); интеграция в `smart_worker_autonomous.py`: SMART_WORKER_ADAPTIVE_CONCURRENCY, effective_N, семафор, лимиты тяжёлых (ADAPTIVE_MAX_HEAVY_MLX/OLLAMA), чередование блоков (SMART_WORKER_INTERLEAVE_BLOCKS). По умолчанию адаптив выключен (false); для включения — env SMART_WORKER_ADAPTIVE_CONCURRENCY=true. Верификация: пункты 22–24 в [VERIFICATION_CHECKLIST_OPTIMIZATIONS.md](VERIFICATION_CHECKLIST_OPTIMIZATIONS.md).

Документ описывает, как сделан **автоматический расчёт** числа задач «в работе» одновременно: по CPU/памяти, с учётом одновременной обработки в Ollama и MLX, комбинации тяжёлых и лёгких моделей и чередования. Согласовано с рекомендациями специалистов (Backend, SRE, Performance) и мировыми практиками; с постоянной проверкой результата и исправлением причин сбоев.

**Связанные документы:** [VERIFICATION_CHECKLIST_OPTIMIZATIONS.md](VERIFICATION_CHECKLIST_OPTIMIZATIONS.md) (разделы 3–5), [WORKER_THROUGHPUT_AND_STUCK_TASKS.md](WORKER_THROUGHPUT_AND_STUCK_TASKS.md), [CURRENT_STATE_WORKER_AND_LLM.md](CURRENT_STATE_WORKER_AND_LLM.md), [MASTER_REFERENCE.md](MASTER_REFERENCE.md).

---

## 1. Цели

1. **Авто-расчёт «сколько задач одновременно»** — не фиксированный `SMART_WORKER_MAX_CONCURRENT`, а значение, зависящее от:
   - загрузки хоста (CPU, память);
   - загрузки MLX API Server (active_requests, max_concurrent, память);
   - загрузки Ollama (активные процессы, CPU/память).
2. **Учёт одновременной работы MLX и Ollama** — оба бэкенда могут обрабатывать задачи параллельно; лимит не должен приводить к перегрузке ни одного из них.
3. **Учёт «тяжёлых» и «лёгких» моделей** — комбинировать: на одном бэкенде тяжёлая модель, на другом — лёгкая; чередовать и ограничивать число тяжёлых запросов одновременно (чтобы не OOM).
4. **Проверка результата и исправление причин** — метрики, логи, чеклист; при сбоях — снижать параллелизм и устранять корневые причины (см. раздел 3 чеклиста).

---

## 2. Специалисты и чеклист (с кем сверяться)

| Роль | Эксперт | Что проверять |
|------|---------|----------------|
| **Backend** | Игорь | Пул БД достаточен при динамическом N; семафор/очередь не дают утечек; нет блокирующего I/O в event loop. |
| **SRE / Monitor** | Елена | Heartbeat и stuck reset работают при изменяющемся N; метрики (effective_concurrent, cpu, ram, mlx/ollama utilization); алерты при падении N ниже порога или OOM. |
| **Performance** | Ольга | Latency и throughput не деградируют; при перегрузке — backpressure (снижение N), а не каскад таймаутов. |
| **QA** | Анна | Тесты: граничные случаи (MLX недоступен, Ollama перегружен, память 95%); регрессия при отключении адаптива. |

**Чеклист после внедрения** (добавить в [VERIFICATION_CHECKLIST_OPTIMIZATIONS.md](VERIFICATION_CHECKLIST_OPTIMIZATIONS.md)):

- [ ] Адаптивный параллелизм: при росте CPU/RAM или перегрузке MLX/Ollama значение N снижается; при разгрузке — повышается в пределах floor/ceiling.
- [ ] Пул БД: `max_size = max(15, effective_concurrent + 8)` (или аналог), чтобы хватало на задачи и heartbeats.
- [ ] Логи/метрики: раз в цикл или раз в K секунд выводить/экспортировать `effective_concurrent`, `mlx_active`, `ollama_active`, `host_cpu`, `host_ram`.
- [ ] При ошибках (OOM, таймауты): снижать N на шаг, не увеличивать до стабилизации; причины фиксировать и устранять (раздел 3 чеклиста).

---

## 3. Мировые практики (учёт)

- **Adaptive concurrency (Uber Cinnamon, Netflix concurrency-limits):** лимит подстраивается под реальную пропускную способность и задержки; при перегрузке — уменьшение, при разгрузке — осторожное увеличение.
- **Resource-based slot supplier (Temporal и др.):** число слотов зависит от целевой утилизации CPU/памяти (например, не превышать 80% CPU, 85% RAM).
- **Backpressure:** при исчерпании ресурсов — отказ в приёме новой работы или снижение параллелизма, а не неограниченная очередь.
- **Ограниченные очереди и таймауты:** семафор, heartbeat и stuck reset уже есть; при адаптивном N сохранять эти механизмы и не допускать «взрыва» горутин/соединений.

Источники: Uber Cinnamon Auto-Tuner, Temporal Worker performance (resource-based slots), Go Concurrency in Production (backpressure, cancellation).

---

## 4. Входные данные для расчёта N

| Источник | Данные | Где брать |
|----------|--------|------------|
| **Хост** | CPU %, RAM % (и при необходимости диск) | `resource_monitor.get_system_resources()` (уже есть); воркер в Docker может опрашивать хост через MLX/Ollama health или отдельный endpoint. |
| **MLX API Server** | active_requests, max_concurrent, memory (used_percent) | `resource_monitor.get_mlx_health()` или `GET /health` (уже используется в local_router). |
| **Ollama** | активные процессы, системные CPU/RAM | `resource_monitor.get_ollama_health()` или `GET /api/ps` + системные метрики. |
| **Модели (тяжёлые/лёгкие)** | категория задачи → модель (reasoning/70b = тяжёлая, fast/3.8b = лёгкая) | Уже есть: `available_models_scanner` (MLX_PRIORITY_BY_CATEGORY, OLLAMA_PRIORITY_BY_CATEGORY); воркер знает preferred_model и preferred_source. |

Классификация «тяжёлая/лёгкая» по имени модели (пример):

- **Тяжёлые:** 70b, 104b, 32b для reasoning/coding (например deepseek-r1-distill-llama:70b, command-r-plus:104b, qwen2.5-coder:32b).
- **Лёгкие:** 3.8b, 3b, tiny (phi3.5:3.8b, qwen2.5:3b, tinyllama).

Использовать конфигурируемый список или правила по паттерну имени (например `:70b`, `:104b` → heavy).

---

## 5. Алгоритм авто-расчёта N (предлагаемый)

### 5.1. Ограничения по ресурсам

- **Хост (CPU):** целевая утилизация, например 80%. Оценка: `cpu_cap = max(1, floor(cpu_count * 0.8 / cpu_per_task_estimate))` или упрощённо: при CPU > 85% снижать N, при CPU < 70% — разрешать повышение.
- **Хост (память):** при RAM > 85% — снижать N; при RAM > 90% — не добавлять тяжёлые задачи; при RAM > 95% — агрессивно снижать (уже есть в mlx_api_server и resource_monitor).
- **MLX:** свободных слотов `mlx_free = max(0, max_concurrent - active_requests)`; при перегрузке (should_throttle_mlx) не направлять новые задачи в MLX (уже есть в local_router); для воркера: не брать в работу больше, чем «сколько ещё можно отправить в MLX + Ollama без перегрузки».
- **Ollama:** аналогично — активные процессы и системные CPU/RAM; при is_overloaded — не нагружать дальше.

### 5.2. Формула эффективного N (одновременно «в работе»)

1. **База:** `N_min = 1`, `N_max = SMART_WORKER_MAX_CONCURRENT` (например 20) — потолок из конфига.
2. **По хосту:**  
   - если `ram_used_percent > 90` → `N_cap_host = max(1, current_N - 2)` (или формула по свободной памяти);  
   - если `cpu_percent > 85` → уменьшать N;  
   - иначе при `ram < 80` и `cpu < 70` — можно осторожно увеличивать N (например +1 раз в 30 сек).
3. **По MLX:** `mlx_free = mlx_max_concurrent - mlx_active`; если воркер отправляет часть задач в MLX, то «слотов под MLX» не больше `mlx_free` (остальное — Ollama или ожидание).
4. **По Ollama:** аналогично — не превышать разумное число одновременных запросов к Ollama (например по числу активных процессов или по эмпирическому лимиту на процесс).
5. **Итоговый N на цикл:**  
   `N = min(N_max, N_cap_host, N_cap_mlx + N_cap_ollama)` с учётом, что одна задача идёт только в один бэкенд.  
   Упрощение: `N = min(N_max, N_cap_host, mlx_free + ollama_cap)` и распределять задачи по источникам (mlx/ollama) как сейчас (preferred_source + чередование блоков).

### 5.3. Учёт тяжёлых/лёгких моделей (комбинация и чередование)

- **Ограничение тяжёлых одновременно:** например не более 2 тяжёлых на MLX и не более 2 тяжёлых на Ollama в один момент (конфиг: `ADAPTIVE_MAX_HEAVY_MLX`, `ADAPTIVE_MAX_HEAVY_OLLAMA`). Остальные слоты — лёгкие или «средние».
- **Чередование:** уже есть SMART_WORKER_INTERLEAVE_BLOCKS — чередуем блоки MLX/Ollama; внутри блока можно упорядочивать так: тяжёлая на MLX + лёгкая на Ollama, затем наоборот, чтобы не грузить оба бэкенда только тяжёлыми.
- **Вес задачи:** при расчёте «сколько ещё можно взять» считать тяжёлую задачу как 2 слота, лёгкую как 1 (или по факту памяти модели). Тогда эффективный лимит: `effective_slots = N`, но «тяжёлых слотов» не больше заданного (например 4 суммарно).

Реализационно: перед запуском батча для каждой задачи известны preferred_source и preferred_model → помечаем heavy/light; при наборе в «текущие в работе» не превышать лимиты по тяжёлым на MLX и на Ollama.

---

## 6. Реализация (этапы)

### Этап 1: Модуль расчёта N (AdaptiveConcurrencyCalculator)

- **Входы:** `get_system_resources()`, `get_mlx_health()`, `get_ollama_health()` (через resource_monitor); опционально текущее N и последние ошибки (OOM/таймаут).
- **Выход:** рекомендуемое `effective_concurrent` (int), а также метки «mlx_overloaded», «ollama_overloaded», «host_stressed».
- **Логика:**  
  - пороги RAM/CPU как в resource_monitor (85%, 90%);  
  - mlx_free, ollama_cap;  
  - N = min(N_max, N_host, mlx_free + ollama_cap); floor 1, не превышать N_max.
- **Кэш:** обновлять не чаще раз в 10–15 секунд, чтобы не дёргать health на каждый цикл воркера.
- **Тесты:** мок health (низкая/высокая загрузка) → проверка, что N уменьшается/увеличивается в ожидаемых пределах.

### Этап 2: Интеграция в Smart Worker

- В главном цикле воркера перед выборкой pending-задач вызывать `get_effective_concurrent()`; использовать это значение вместо фиксированного `SMART_WORKER_MAX_CONCURRENT` для семафора на этот цикл.
- Пул БД: `max_size = max(15, effective_concurrent + 8)` уже по текущему N; при динамическом N либо пересчитывать при старте цикла (консервативно — брать max за последние циклы), либо задать max_size с запасом от N_max.
- Логирование: раз в цикл или раз в 30 сек выводить в лог: `effective_concurrent`, `host_cpu`, `host_ram`, `mlx_active/max`, `ollama_active` (или аналог).

### Этап 3: Лимиты по тяжёлым/лёгким

- Классификатор моделей: по имени (или по категории) heavy/light (конфиг или константы в available_models_scanner).
- При формировании очереди задач (all_tasks_to_process) и при взятии в семафор: считать текущее число «тяжёлых на MLX» и «тяжёлых на Ollama»; не запускать новую тяжёлую задачу, если лимит по соответствующему бэкенду уже достигнут (тогда брать следующую лёгкую или ждать).
- Опционально: «вес» задачи (1 или 2) и лимит по сумме весов (например не более 6 «тяжёлых слотов» всего).

### Этап 4: Метрики и обработка сбоев

- Экспорт метрик (Prometheus или лог для Grafana): `worker_effective_concurrent`, `worker_mlx_active`, `worker_ollama_active`, `worker_host_cpu_percent`, `worker_host_ram_percent`.
- При обнаружении OOM или серии таймаутов (например в process_task): уменьшить N на 1–2 и не повышать 1–2 минуты; записать причину в лог/метаданные.
- В разделе 3 чеклиста добавить строки: «OOM при адаптивном N» → причина (завышен N, тяжёлые модели без лимита) → решение (снизить N_max, ввести лимиты тяжёлых).

---

## 7. Конфигурация (env)

| Переменная | По умолчанию | Описание |
|------------|--------------|----------|
| SMART_WORKER_ADAPTIVE_CONCURRENCY | false | Включить авто-расчёт N (true) или использовать фиксированный SMART_WORKER_MAX_CONCURRENT. |
| SMART_WORKER_MAX_CONCURRENT | 10 | Потолок для N при адаптивном режиме; при фиксированном — значение N. |
| ADAPTIVE_HOST_RAM_THRESHOLD | 0.85 | При RAM > 85% снижать N. |
| ADAPTIVE_HOST_CPU_THRESHOLD | 0.85 | При CPU > 85% снижать N. |
| ADAPTIVE_MAX_HEAVY_MLX | 2 | Макс. тяжёлых задач одновременно на MLX. |
| ADAPTIVE_MAX_HEAVY_OLLAMA | 2 | Макс. тяжёлых задач одновременно на Ollama. |
| ADAPTIVE_CALC_INTERVAL_SEC | 15 | Интервал пересчёта N (секунды). |

---

## 8. Проверка результата и исправление ошибок

1. **После каждого этапа:** прогнать тесты (QA); проверить логи воркера и метрики (SRE); убедиться, что при искусственной перегрузке MLX/Ollama или хоста N снижается (Performance).
2. **В проде:** следить за алертами (OOM, таймауты); при повторении — анализировать причину (раздел 3 чеклиста) и править пороги или лимиты тяжёлых.
3. **Документация:** обновить MASTER_REFERENCE.md и CURRENT_STATE_WORKER_AND_LLM.md: как устроен адаптивный параллелизм, откуда берутся данные, кто отвечает за проверку (Backend, SRE, Performance).

---

## 9. Краткое резюме

- **Авто-расчёт N** по CPU/памяти хоста и по загрузке MLX и Ollama, с floor/ceiling и кэшем.
- **Одновременно MLX и Ollama** учитываются через mlx_free и ollama_cap при расчёте N и через существующее чередование блоков.
- **Тяжёлые/лёгкие модели** — лимиты на число тяжёлых на каждый бэкенд и чередование «тяжёлая на одном — лёгкая на другом».
- **Специалисты и чеклист** — Backend, SRE, Performance, QA; новые пункты в VERIFICATION_CHECKLIST; при сбоях — исправлять причины (раздел 3).
- **Мировые практики** — адаптивный лимит, backpressure, ресурсные пороги, ограниченные очереди.

Дальнейший шаг: реализовать Этап 1 (AdaptiveConcurrencyCalculator + тесты), затем согласовать интерфейс с главным циклом воркера и ввести интеграцию (Этап 2).
