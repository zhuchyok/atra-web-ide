# Пропускная способность воркера и зависшие задачи

Документ согласован с рекомендациями Backend (Игорь), QA (Анна), SRE (Елена), Performance (Ольга). Чеклист верификации: [VERIFICATION_CHECKLIST_OPTIMIZATIONS.md](VERIFICATION_CHECKLIST_OPTIMIZATIONS.md) (пункты 14–19).

## Почему задачи зависают (причины)

### 1. Блокировка event loop синхронным I/O

**Файловый enricher** (`file_context_enricher.py`) вызывался из `process_task` **синхронно**: `enricher.enrich_task_with_file_context(...)` и `enrich_task_with_multiple_files(...)` делают обычное `open()`/`read()` без `run_in_executor`. Пока одна задача читает файл с диска, **весь event loop блокируется**:

- не выполняются другие задачи;
- **не выполняются heartbeats** — `updated_at` не обновляется;
- через 15 минут задача считается зависшей, хотя воркер «занят» синхронным чтением.

**Исправление:** вызов enricher перенесён в `loop.run_in_executor(None, ...)`, чтобы чтение файлов шло в потоке и не блокировало цикл. Heartbeats продолжают обновлять `updated_at`.

### 2. Нехватка соединений в пуле БД

Пул воркера был **max_size=5** при **MAX_CONCURRENT_TASKS=10**. Одновременно работают:

- до 10 вызовов `process_task` (каждый при необходимости делает `pool.acquire()`);
- до 10 heartbeats (каждые 15 сек каждый делает `pool.acquire()` для `UPDATE tasks SET updated_at`).

При 5 соединениях часть heartbeats подолгу ждёт `acquire()`. Пока heartbeat ждёт, он не обновляет `updated_at` → задача выглядит зависшей.

**Исправление:** размер пула задаётся как `max(15, SMART_WORKER_MAX_CONCURRENT + 8)`, чтобы хватало и на обработку, и на heartbeats.

### 3. Поздний сброс зависших (ранее 1 час)

Описано ниже: зависшие возвращались в `pending` только через 1 час, из‑за чего «5 задач за час». Сейчас по умолчанию 15 минут (`SMART_WORKER_STUCK_MINUTES`).

### 4. Неверные URL Ollama/MLX (Docker vs хост)

**Проблема:** В Docker контейнере `LocalAIRouter` раньше **игнорировал** переменные `OLLAMA_API_URL` и `MLX_API_URL`: всегда подставлял `host.docker.internal:11434` / `11435`. Сканер моделей (`_refresh_available_models`) при этом брал URL из env. В итоге: сканер мог ходить на один хост (из env), а запросы к LLM — на другой (hardcode). Либо при нестандартной схеме (Ollama/MLX в другом контейнере) env не учитывался и запросы шли не туда → таймауты, зависания, пустые ответы.

**Исправление:** В `LocalAIRouter.__init__` узлы `self.nodes` формируются из `OLLAMA_API_URL` / `OLLAMA_BASE_URL` и `MLX_API_URL`; если не заданы — в Docker используется `host.docker.internal`, локально — `localhost`. Сканер по умолчанию (`scan_and_select_models` без аргументов) тоже использует env и ту же логику Docker/локально.

### 5. Эхо ответа (Victoria возвращает ваш же текст)

**Проблема:** Модель или сервер иногда возвращает промпт пользователя как ответ (эхо). В Telegram пользователь видит свой же запрос как «ответ» Виктории.

**Исправление:** В `local_router.run_local_llm` добавлена проверка `_is_echo_response(result, prompt)`: если ответ совпадает с промптом или является его началом (короткий ответ) — такой ответ не считается успешным, запрос переключается на следующий узел (Ollama/MLX) или возвращается `None` (fallback в облако/ошибка).

Подробнее по точкам подключения к Ollama/MLX и чеклисту: [OLLAMA_MLX_CONNECTION_AND_ECHO.md](OLLAMA_MLX_CONNECTION_AND_ECHO.md).

---

## Почему было «5 задач за час, 10 в работе»

Типичная картина:

1. **10 задач** остаются в статусе `in_progress` (зависли: воркер упал, таймаут не сработал, LLM не ответил).
2. Раньше сброс зависших выполнялся раз в **1 час** (`SMART_WORKER_STUCK_HOURS=1`).
3. Воркер берёт только задачи со статусом **`pending`**. Пока 10 слотов заняты «зависшими» `in_progress`, в очереди было только **5 pending**.
4. Воркер обработал эти 5, перевёл их в `completed`/`failed`, после чего **pending = 0**.
5. Следующие 55 минут воркер крутится в цикле: «No pending tasks», sleep 5 сек — до сброса зависших через 1 час.
6. Итог: **~5 задач за час** при 10 «в работе» (фактически зависших).

## Что сделано

### 1. Интервал сброса зависших: 1 ч → 15 мин

- **Раньше:** `SMART_WORKER_STUCK_HOURS=1` — задачи в `in_progress` без обновления `updated_at` более 1 часа возвращались в `pending`.
- **Сейчас:** по умолчанию **15 минут** — переменная `SMART_WORKER_STUCK_MINUTES` (по умолчанию `15`).
- Зависшие задачи быстрее возвращаются в очередь, слоты не блокируются на час.

В коде:

- В главном цикле: `UPDATE tasks SET status = 'pending' ... WHERE status = 'in_progress' AND updated_at < NOW() - make_interval(mins => $1)`.
- В `process_task`: та же логика при взятии задачи — можно перевести в `in_progress` задачу, которая уже `in_progress`, но не обновлялась больше `STUCK_MINUTES` (та же величина).

### 2. Непрерывная обработка (семафор вместо батча)

- **Раньше:** воркер брал до `BATCH_SIZE` pending, делил на батчи по `MAX_CONCURRENT_TASKS`, ждал завершения **всего батча**, потом запускал следующий батч. Одна долгая задача в батче задерживала старт следующих.
- **Сейчас:** используется **семафор** на `MAX_CONCURRENT_TASKS`. Запускаются до N задач параллельно; как только одна завершилась, сразу стартует следующая из списка. Ожидание всего «батча» убрано — пропускная способность выше при разном времени выполнения задач.

### 3. Согласованность порога в process_task

В `process_task` при переводе задачи в `in_progress` используется тот же порог «зависшая»: `SMART_WORKER_STUCK_MINUTES`. Иначе часть логики считала бы задачу «зависшей» через 15 мин, а другая — только через 1 ч.

## Сколько задач обрабатываются одновременно и учёт загрузки Mac Studio

- **Параллелизм:** одновременно обрабатывается до **`SMART_WORKER_MAX_CONCURRENT`** задач (по умолчанию **10**). Ограничение через семафор; как только одна задача завершилась, сразу стартует следующая.
- **Учёт загрузки Mac Studio:**
  - **MLX:** в `local_router.run_local_llm` перед запросом к MLX вызываются `resource_monitor.get_mlx_health()` и `should_throttle_mlx()` — при перегрузке (все слоты заняты, RAM > 85%, CPU > 85% или температура > 80°C) MLX-узел пропускается, пробуем Ollama.
  - **Очередь MLX:** `_is_mlx_overloaded()` проверяет очередь запросов (active_requests >= max_concurrent или queue_size > 0); при перегрузке приоритет отдаётся Ollama.
  - **Ollama:** аналогично проверяется через `get_ollama_health()` (RAM/CPU > 90% → перегрузка).
- **Выгрузка/загрузка моделей:** MLX API Server держит в кэше до **`MLX_MAX_CACHED_MODELS`** (по умолчанию 2) моделей; при переключении на другую модель возможна выгрузка по LRU. Чтобы реже переключать модели, включён **батчинг по модели** (см. ниже).

## Батчи по модели (меньше load/unload)

Чтобы не выгружать и не загружать модели на каждый запрос, воркер:

1. **Сканирует доступные модели** (Ollama и MLX) через `available_models_scanner.get_available_models()`. **Модели — только из сканера**; оркестратор решает тип задачи, воркер выбирает модель из актуальных.
2. **Назначает каждой задаче** `preferred_model` по категории (reasoning/coding/fast/default) и источнику (mlx/ollama) — `pick_mlx_for_category` / `pick_ollama_for_category`.
3. **Группирует задачи** по паре `(preferred_source, preferred_model)`.
4. **Обрабатывает блоки** в порядке убывания размера группы (сначала самый большой блок — дольше держим одну модель) или **чередованием** (INTERLEAVE_BLOCKS=true — MLX и Ollama одновременно).
5. Передаёт в роутер **`_preferred_model`**; `local_router.run_local_llm` использует его как `initial_model` для узла.

**Важно: время загрузки модели.** При смене модели (новый блок) Ollama/MLX загружают модель при первом запросе. Тяжёлые модели (glm-4.7:30GB, qwen2.5-coder:32b) — 30–90 сек. Запросы, отправленные до готовности модели, дают ReadTimeout и зависание. Нужен **буфер** (MODEL_LOAD_BUFFER_SEC) или проверка готовности модели перед первым запросом блока. См. VERIFICATION_CHECKLIST_OPTIMIZATIONS.md, раздел 3.

Включено по умолчанию; отключить: `SMART_WORKER_BATCH_BY_MODEL=false`.

---

## Настройки (env)

| Переменная | По умолчанию | Описание |
|------------|--------------|----------|
| `SMART_WORKER_STUCK_MINUTES` | `15` | Через сколько минут задача в `in_progress` без обновления `updated_at` считается зависшей и возвращается в `pending`. |
| `SMART_WORKER_MAX_CONCURRENT` | `10` | Сколько задач обрабатываются параллельно (семафор). |
| `SMART_WORKER_BATCH_SIZE` | `50` | Сколько pending задач за один проход цикла выбирается из БД (до лимита). |
| `SMART_WORKER_BATCH_BY_MODEL` | `true` | Батчировать задачи по (source, model) по сканеру — меньше load/unload моделей на MLX/Ollama. |
| `SMART_WORKER_LLM_TIMEOUT` | `300` | Таймаут одной задачи (сек). В `process_task`: `asyncio.wait_for(..., timeout=llm_timeout)`. |
| `SMART_WORKER_HEAVY_MODEL_TIMEOUT_MULTIPLIER` | `1.5` | Для тяжёлых моделей (70b, 104b, 32b) — множитель таймаута. Учитывает время загрузки модели (30–90 сек). |

## Проверка после изменений

1. Перезапустить контейнер воркера:  
   `docker compose -f knowledge_os/docker-compose.yml restart knowledge_os_worker`
2. Смотреть логи: зависшие должны сбрасываться с сообщением вида  
   `Вернуто в очередь зависших задач (>15 мин): N`
3. **Проверить, что задачи обрабатываются:** в логах воркера — `Found N pending tasks`, `Батчи по модели: M блоков`, `Completed: N tasks processed`. По БД: `SELECT status, COUNT(*) FROM tasks GROUP BY status` — должны появляться/расти `completed`, уменьшаться `pending`/`in_progress` (при отсутствии новых поступлений).
4. Ожидаемый эффект: при тех же 10 зависших и 5 pending — через ~15 мин эти 10 станут снова `pending`, воркер подхватит до 10 (или все 15) и обработает их параллельно; «5 задач за час» не должно повторяться при нормальной работе LLM/сети.

## Если пропускная способность всё ещё низкая

- Увеличить `SMART_WORKER_MAX_CONCURRENT` (осторожно: нагрузка на LLM и БД).
- Убедиться, что задачи не зависают: heartbeat обновляет `updated_at` каждые 15 сек; таймаут 5 мин должен обрывать долгие вызовы.
- Проверить логи на частые `Main loop error` и `sleep(30)` — частые исключения снижают эффективность цикла.

## Если задачи снова зависают

- Убедиться, что в цепочке вызовов нет другого **синхронного I/O** (например, в `scout_task_processor`, `simulator`): любой блокирующий вызов в async-коде блокирует event loop и heartbeats.
- Проверить логи воркера на `Heartbeat error` — если heartbeat часто падает, `updated_at` не обновляется.
- Убедиться, что пул БД не перегружен: при большом `SMART_WORKER_MAX_CONCURRENT` размер пула задаётся как `max(15, SMART_WORKER_MAX_CONCURRENT + 8)`; при необходимости увеличить вручную в `get_pool()`.

---

## Мировые практики (закреплённые)

- **Не блокировать event loop в async-воркере** (Python asyncio, Node.js event loop): синхронный I/O (файлы, тяжёлые вычисления) выполнять через `run_in_executor` / worker threads; иначе heartbeats и другие задачи не выполняются.
- **Пул соединений ≥ конкурентность + служебные корутины**: если N задач и у каждой свой heartbeat, пул БД должен позволять и обработку, и heartbeat-запросы без длительного ожидания `acquire()`.
- **Heartbeat + таймаут для длинных задач** (SRE-практика): задача в «in progress» должна периодически обновлять `updated_at` (heartbeat); плюс жёсткий таймаут на вызов внешнего сервиса (LLM), чтобы не висеть бесконечно.
- **Сброс зависших по времени** (stuck detection): задачи в `in_progress` без обновления `updated_at` дольше N минут возвращать в очередь (pending) с метаданными; N выбирать так, чтобы не сбрасывать нормально долгие задачи (например 15–30 мин).
- **Непрерывная обработка вместо батчей**: использовать семафор и запускать следующую задачу сразу по завершении одной, а не ждать завершения всего батча — так пропускная способность выше при разном времени выполнения задач.
