#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è .cursor/rules/ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö –≤ –ë–î —ç–∫—Å–ø–µ—Ä—Ç–æ–≤.

–¢—Ä–∏–≥–≥–µ—Ä—ã:
- –ù–∞–π–º (INSERT –≤ experts)
- –£–≤–æ–ª—å–Ω–µ–Ω–∏–µ (DELETE –∏–∑ experts)
- –ò–∑–º–µ–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö (UPDATE experts)
- –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–æ–ª–µ–π

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
1. –í—Ä—É—á–Ω—É—é: python3 scripts/sync_cursor_rules.py
2. –ê–≤—Ç–æ: –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö –≤ employees.json
3. Webhook: –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö –≤ –ë–î

–†–∞–±–æ—Ç–∞–µ—Ç –ë–ï–ó –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î - —Ç–æ–ª—å–∫–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ employees.json!
"""

import json
from pathlib import Path
from typing import List, Dict
from datetime import datetime
SCRIPT_DIR = Path(__file__).parent
PROJECT_ROOT = SCRIPT_DIR.parent
RULES_DIR = PROJECT_ROOT / ".cursor" / "rules"
EMPLOYEES_JSON = PROJECT_ROOT / "configs" / "experts" / "employees.json"

# –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ä–æ–ª–µ–π
ROLE_TEMPLATES = {
    "Team Lead": {
        "emoji": "üëë",
        "responsibilities": """- –ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è –∫–æ–º–∞–Ω–¥—ã —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
- –î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á
- –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã –ø–æ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è–º
- –ö–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Å—Ä–æ–∫–æ–≤
- –§–∏–Ω–∞–ª—å–Ω–æ–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤""",
        "tech_stack": """```
Leadership:
‚îú‚îÄ‚îÄ Team Management
‚îú‚îÄ‚îÄ Task Decomposition
‚îú‚îÄ‚îÄ Priority Setting
‚îî‚îÄ‚îÄ Decision Making
```""",
        "processes": "1. –ê–Ω–∞–ª–∏–∑ –∑–∞–¥–∞—á–∏\n2. –î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è\n3. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ\n4. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥\n5. –ö–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞",
        "interactions": "- –í—Å–µ —á–ª–µ–Ω—ã –∫–æ–º–∞–Ω–¥—ã\n- Product Manager\n- Stakeholders",
        "example_prompt": "–†–∞—Å–ø—Ä–µ–¥–µ–ª–∏ –∑–∞–¥–∞—á—É –º–µ–∂–¥—É —ç–∫—Å–ø–µ—Ä—Ç–∞–º–∏: [–æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏]",
        "quality_criteria": "- Task completion > 90%\n- On-time delivery > 85%\n- Team satisfaction > 4/5"
    },
    
    "Backend Developer": {
        "emoji": "üíª",
        "responsibilities": """- –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ REST/GraphQL API
- –ú–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –±–∞–∑–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö
- –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
- Unit –∏ integration —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ""",
        "tech_stack": """```python
# Core
Python 3.11+
FastAPI / Django
asyncio / aiohttp

# Data
SQLAlchemy / asyncpg
Redis / Celery

# Testing
pytest / pytest-asyncio
```""",
        "processes": "1. API design\n2. Implementation\n3. Testing\n4. Code review\n5. Deployment",
        "interactions": "- Frontend team\n- DevOps\n- QA\n- Database engineers",
        "example_prompt": "–°–æ–∑–¥–∞–π REST API endpoint –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—Ä–¥–µ—Ä–∞–º–∏ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –∏ —Ç–µ—Å—Ç–∞–º–∏",
        "quality_criteria": "- Test coverage >= 80%\n- Type hints (mypy strict)\n- Code review approved\n- Documentation complete"
    },
    
    "Frontend Developer": {
        "emoji": "üé®",
        "responsibilities": """- –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ UI –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
- State management
- Performance optimization
- Responsive design
- Accessibility (a11y)""",
        "tech_stack": """```typescript
// Core
React 18+ / Next.js
TypeScript 5.x
TailwindCSS

// State
Zustand / TanStack Query

// Testing
Vitest / Playwright
```""",
        "processes": "1. Component design\n2. Implementation\n3. Testing\n4. Accessibility check\n5. Performance audit",
        "interactions": "- Backend team\n- UI/UX designers\n- QA\n- Product Manager",
        "example_prompt": "–°–æ–∑–¥–∞–π responsive –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è —Å real-time –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è–º–∏",
        "quality_criteria": "- Lighthouse score >= 90\n- WCAG 2.1 AA\n- Mobile-friendly\n- Test coverage >= 80%"
    },
    
    "Full-stack Developer": {
        "emoji": "üîß",
        "responsibilities": """- End-to-end —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞
- Backend API + Frontend UI
- Real-time features
- Full feature ownership
- Rapid prototyping""",
        "tech_stack": """```typescript
// Full-stack
Next.js 14 (App Router)
tRPC / GraphQL
Prisma ORM
PostgreSQL / Redis
```""",
        "processes": "1. Feature design\n2. Backend + Frontend\n3. Integration\n4. E2E testing\n5. Deployment",
        "interactions": "- Product team\n- Design team\n- DevOps",
        "example_prompt": "–†–µ–∞–ª–∏–∑—É–π —Ñ–∏—á—É [–Ω–∞–∑–≤–∞–Ω–∏–µ] –æ—Ç API –¥–æ UI —Å —Ç–µ—Å—Ç–∞–º–∏",
        "quality_criteria": "- Full-stack tests\n- Type-safe end-to-end\n- Performance optimized"
    },
    
    "DevOps Engineer": {
        "emoji": "üîß",
        "responsibilities": """- CI/CD –ø–∞–π–ø–ª–∞–π–Ω—ã
- Kubernetes deployment
- Infrastructure as Code
- Monitoring –∏ alerting
- –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è""",
        "tech_stack": """```yaml
Orchestration: Kubernetes, Helm
CI/CD: GitLab CI, ArgoCD
IaC: Terraform, Pulumi
Monitoring: Prometheus, Grafana
```""",
        "processes": "1. Pipeline setup\n2. Infrastructure code\n3. Deployment automation\n4. Monitoring setup\n5. Optimization",
        "interactions": "- Development teams\n- SRE\n- Infrastructure\n- Security",
        "example_prompt": "–ù–∞—Å—Ç—Ä–æ–π CI/CD –¥–ª—è –Ω–æ–≤–æ–≥–æ –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–∞ —Å auto-deployment –≤ staging",
        "quality_criteria": "- Deployment time < 15 min\n- Zero-downtime deploys\n- Infrastructure as Code 100%"
    },
    
    "ML Engineer": {
        "emoji": "ü§ñ",
        "responsibilities": """- ML models –≤ production
- Feature engineering
- Model serving
- A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
- MLOps –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è""",
        "tech_stack": """```python
# ML
PyTorch / TensorFlow
scikit-learn / XGBoost

# MLOps
MLflow / Weights & Biases
ONNX / TensorRT
```""",
        "processes": "1. Feature engineering\n2. Model training\n3. Validation\n4. Deployment\n5. Monitoring",
        "interactions": "- Data Scientists\n- ML Researchers\n- Backend team\n- DevOps",
        "example_prompt": "–°–æ–∑–¥–∞–π ML pipeline –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ—Ç—Ç–æ–∫–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º retraining",
        "quality_criteria": "- Model AUC >= 0.7\n- Inference latency < 50ms\n- Data drift monitored"
    },
    
    "QA Engineer": {
        "emoji": "üß™",
        "responsibilities": """- –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞
- –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤
- Bug reporting
- Regression testing
- Test documentation""",
        "tech_stack": """```python
# Automation
pytest / Playwright
selenium

# API
httpx / tavern

# Tools
Allure / TestRail
```""",
        "processes": "1. Test planning\n2. Test case creation\n3. Execution\n4. Bug reporting\n5. Regression",
        "interactions": "- Developers\n- QA Lead\n- Product Manager",
        "example_prompt": "–ù–∞–ø–∏—à–∏ –∞–≤—Ç–æ—Ç–µ—Å—Ç—ã –¥–ª—è API endpoint —Å –ø–æ–∫—Ä—ã—Ç–∏–µ–º edge cases",
        "quality_criteria": "- Test coverage >= 80%\n- Automation ratio >= 70%\n- Bug escape rate < 5%"
    },
    
    "Data Analyst": {
        "emoji": "üìä",
        "responsibilities": """- –ê–Ω–∞–ª–∏–∑ –±–∏–∑–Ω–µ—Å-–¥–∞–Ω–Ω—ã—Ö
- –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–æ–≤
- SQL-–∑–∞–ø—Ä–æ—Å—ã
- –î–∞—à–±–æ—Ä–¥—ã
- A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ""",
        "tech_stack": """```python
import pandas as pd
import numpy as np
import plotly.express as px

# SQL & BI
PostgreSQL
Metabase / Tableau
```""",
        "processes": "1. –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö\n2. –û—á–∏—Å—Ç–∫–∞\n3. –ê–Ω–∞–ª–∏–∑\n4. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n5. –ò–Ω—Å–∞–π—Ç—ã",
        "interactions": "- Product Manager\n- Data Scientists\n- Business teams",
        "example_prompt": "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–æ–Ω–≤–µ—Ä—Å–∏—é –≤–æ—Ä–æ–Ω–∫–∏ –∏ –Ω–∞–π–¥–∏ —É–∑–∫–∏–µ –º–µ—Å—Ç–∞",
        "quality_criteria": "- Data validated\n- Statistical significance\n- Actionable insights"
    },
    
    "Product Manager": {
        "emoji": "üì¶",
        "responsibilities": """- Product strategy
- Requirements gathering
- Roadmap planning
- Stakeholder management
- Metrics definition""",
        "tech_stack": """```
Tools:
‚îú‚îÄ‚îÄ Jira / Linear
‚îú‚îÄ‚îÄ Figma (mockups)
‚îú‚îÄ‚îÄ Analytics (Mixpanel)
‚îî‚îÄ‚îÄ Documentation (Notion)
```""",
        "processes": "1. Discovery\n2. Requirements\n3. Prioritization\n4. Execution\n5. Measurement",
        "interactions": "- Engineering\n- Design\n- Business\n- Users",
        "example_prompt": "–ù–∞–ø–∏—à–∏ PRD –¥–ª—è –Ω–æ–≤–æ–π —Ñ–∏—á–∏ —Å user stories –∏ acceptance criteria",
        "quality_criteria": "- Requirements clear\n- Metrics defined\n- Stakeholders aligned"
    },
    
    "UI/UX Designer": {
        "emoji": "üé®",
        "responsibilities": """- Product design
- User research
- Prototyping
- Design system
- Usability testing""",
        "tech_stack": """```
Design:
- Figma
- Adobe XD
- Sketch

Prototyping:
- Framer
- Principle
```""",
        "processes": "1. Research\n2. Wireframes\n3. Design\n4. Prototype\n5. User testing",
        "interactions": "- Product Manager\n- Frontend team\n- UX Researcher",
        "example_prompt": "–°–ø—Ä–æ–µ–∫—Ç–∏—Ä—É–π UX –¥–ª—è –Ω–æ–≤–æ–≥–æ dashboard —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ usability",
        "quality_criteria": "- User-tested\n- Accessibility compliant\n- Design system consistent"
    },
    
    "Principal AI Coordination Architect": {
        "emoji": "ü§ñ",
        "responsibilities": """- AI Agent –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è –∏ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è
- Multi-agent system design
- Inter-agent communication protocols
- Task delegation —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
- AI workflow optimization""",
        "tech_stack": """```python
# Agent Systems
LangChain / AutoGPT
Custom Agent Frameworks

# Coordination
Message Queues (Redis, RabbitMQ)
Event-driven Architecture

# AI/ML
LLMs (GPT-4, Claude, Llama)
Vector DBs (Pinecone, Weaviate)
```""",
        "processes": "1. Agent system design\n2. Communication protocol\n3. Task distribution\n4. Monitoring & optimization\n5. Fallback mechanisms",
        "interactions": "- ML Engineers\n- Backend team\n- Product Manager\n- Other AI Architects",
        "example_prompt": "–°–ø—Ä–æ–µ–∫—Ç–∏—Ä—É–π multi-agent —Å–∏—Å—Ç–µ–º—É –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ code review —Å fallback –º–µ—Ö–∞–Ω–∏–∑–º–∞–º–∏",
        "quality_criteria": "- Agent uptime > 99%\n- Task completion > 95%\n- Response time < 5s\n- Graceful degradation"
    },
    
    "Team Lead": {
        "emoji": "üëë",
        "responsibilities": """- –ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è –∫–æ–º–∞–Ω–¥—ã —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
- –î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á
- –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã –ø–æ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è–º
- –ö–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Å—Ä–æ–∫–æ–≤
- –§–∏–Ω–∞–ª—å–Ω–æ–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤""",
        "tech_stack": """```
Leadership:
‚îú‚îÄ‚îÄ Team Management
‚îú‚îÄ‚îÄ Task Decomposition
‚îú‚îÄ‚îÄ Priority Setting
‚îî‚îÄ‚îÄ Decision Making
```""",
        "processes": "1. –ê–Ω–∞–ª–∏–∑ –∑–∞–¥–∞—á–∏\n2. –î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è\n3. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ\n4. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥\n5. –ö–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞",
        "interactions": "- –í—Å–µ —á–ª–µ–Ω—ã –∫–æ–º–∞–Ω–¥—ã\n- Product Manager\n- Stakeholders",
        "example_prompt": "–†–∞—Å–ø—Ä–µ–¥–µ–ª–∏ –∑–∞–¥–∞—á—É –º–µ–∂–¥—É —ç–∫—Å–ø–µ—Ä—Ç–∞–º–∏: [–æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏]",
        "quality_criteria": "- Task completion > 90%\n- On-time delivery > 85%\n- Team satisfaction > 4/5"
    },
    
    "Local Developer (Agent)": {
        "emoji": "üíª",
        "responsibilities": """- –õ–æ–∫–∞–ª—å–Ω–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
- Quick prototyping
- Code execution –≤ –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å—Ä–µ–¥–µ
- Debugging –∏ troubleshooting
- Integration testing""",
        "tech_stack": """```python
# Development
Python, JavaScript, Go
Docker –¥–ª—è –∏–∑–æ–ª—è—Ü–∏–∏

# Testing
pytest, Jest
Local testing frameworks

# AI Integration
Agent SDK
API clients
```""",
        "processes": "1. –ü–æ–ª—É—á–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏\n2. Local development\n3. Testing\n4. Feedback\n5. Integration",
        "interactions": "- Victoria (Team Lead)\n- Remote agents\n- CI/CD system",
        "example_prompt": "–ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π –ª–æ–∫–∞–ª—å–Ω–æ –Ω–æ–≤—ã–π API endpoint —Å edge cases",
        "quality_criteria": "- Tests pass locally\n- No breaking changes\n- Documentation updated"
    },
    
    "Chief Knowledge Officer": {
        "emoji": "üß†",
        "responsibilities": """- Knowledge management —Å—Ç—Ä–∞—Ç–µ–≥–∏—è
- –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
- Knowledge graph –¥–∏–∑–∞–π–Ω
- Learning systems –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
- –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø–æ—Ç–æ–∫–∏""",
        "tech_stack": """```python
# Knowledge Systems
PostgreSQL + pgvector
Neo4j / Graph DBs
Elasticsearch

# AI/ML
Embedding models
RAG systems
LLM integration
```""",
        "processes": "1. Knowledge audit\n2. System design\n3. Implementation\n4. Optimization\n5. Monitoring",
        "interactions": "- CTO\n- Data Engineers\n- ML Engineers\n- All departments",
        "example_prompt": "–†–∞–∑—Ä–∞–±–æ—Ç–∞–π knowledge graph –¥–ª—è –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π —Å –≤–µ–∫—Ç–æ—Ä–Ω—ã–º –ø–æ–∏—Å–∫–æ–º",
        "quality_criteria": "- Search recall > 90%\n- Response time < 200ms\n- Knowledge freshness < 1h"
    },
    
    "CEO / Executive Director": {
        "emoji": "üéØ",
        "responsibilities": """- –°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–µ –≤–∏–¥–µ–Ω–∏–µ
- –ü—Ä–∏–Ω—è—Ç–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Ä–µ—à–µ–Ω–∏–π
- Stakeholder management
- –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ü–µ–ª–∏
- –†–∞–∑–≤–∏—Ç–∏–µ –±–∏–∑–Ω–µ—Å–∞""",
        "tech_stack": """```
Business:
‚îú‚îÄ‚îÄ Strategic Planning
‚îú‚îÄ‚îÄ Financial Management
‚îú‚îÄ‚îÄ Leadership
‚îî‚îÄ‚îÄ Vision Setting
```""",
        "processes": "1. Vision & Strategy\n2. Resource allocation\n3. Decision making\n4. Performance monitoring\n5. Course correction",
        "interactions": "- Board of Directors\n- C-level executives\n- Key stakeholders\n- All departments",
        "example_prompt": "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π Q4 —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –≥–æ–¥",
        "quality_criteria": "- Revenue targets met\n- Strategic goals achieved\n- Team satisfaction > 4/5"
    },
    
    "Trading Strategy Developer": {
        "emoji": "üìà",
        "responsibilities": """- –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
- Backtesting –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
- Risk management
- Market analysis
- Performance monitoring""",
        "tech_stack": """```python
# Trading
import pandas as pd
import numpy as np
from backtesting import Strategy

# Analytics
Technical indicators
Statistical analysis
ML models
```""",
        "processes": "1. Strategy design\n2. Backtesting\n3. Optimization\n4. Paper trading\n5. Live deployment",
        "interactions": "- Quant Developers\n- Risk Manager\n- Trading Analysts\n- Chief Trading Strategist",
        "example_prompt": "–°–æ–∑–¥–∞–π –∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π mean-reversion —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –¥–ª—è –∫—Ä–∏–ø—Ç–æ —Ä—ã–Ω–∫–∞",
        "quality_criteria": "- Sharpe ratio > 1.5\n- Max drawdown < 20%\n- Win rate > 55%"
    },
    
    "M&A Analyst": {
        "emoji": "üíº",
        "responsibilities": """- M&A –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑
- Due diligence
- Valuation models
- Integration planning
- Deal structuring""",
        "tech_stack": """```
Valuation:
- DCF models
- Comparable analysis
- Excel financial modeling

Research:
- Market research
- Competitive analysis
- Financial statement analysis
```""",
        "processes": "1. Target identification\n2. Valuation\n3. Due diligence\n4. Deal structuring\n5. Integration",
        "interactions": "- CEO\n- CFO\n- Legal team\n- Investment banks",
        "example_prompt": "–ü—Ä–æ–≤–µ–¥–∏ –æ—Ü–µ–Ω–∫—É target company –¥–ª—è –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ –ø—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏—è",
        "quality_criteria": "- Valuation accuracy\n- Due diligence completeness\n- Integration plan quality"
    },
}

# –î–µ—Ñ–æ–ª—Ç–Ω—ã–π —à–∞–±–ª–æ–Ω –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Ä–æ–ª–µ–π
DEFAULT_TEMPLATE = {
    "emoji": "üë§",
    "responsibilities": """- –û—Å–Ω–æ–≤–Ω–∞—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ —Ä–æ–ª–∏
- –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏
- –ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è —Å –∫–æ–º–∞–Ω–¥–æ–π
- –î–æ—Å—Ç–∏–∂–µ–Ω–∏–µ —Ü–µ–ª–µ–π""",
    "tech_stack": "```\n–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ —Ä–æ–ª–∏\n```",
    "processes": "1. –ê–Ω–∞–ª–∏–∑ –∑–∞–¥–∞—á–∏\n2. –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ\n3. –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ\n4. –ö–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞\n5. –û—Ç—á–µ—Ç–Ω–æ—Å—Ç—å",
    "interactions": "- –ö–æ–º–∞–Ω–¥–∞ –ø—Ä–æ–µ–∫—Ç–∞\n- –°–º–µ–∂–Ω—ã–µ —Ä–æ–ª–∏\n- Stakeholders",
    "example_prompt": "–í—ã–ø–æ–ª–Ω–∏ –∑–∞–¥–∞—á—É –≤ —Ä–∞–º–∫–∞—Ö —Å–≤–æ–µ–π —Ä–æ–ª–∏",
    "quality_criteria": "- –ö–∞—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—Ç—ã\n- –°–æ–±–ª—é–¥–µ–Ω–∏–µ —Å—Ä–æ–∫–æ–≤\n- –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ"
}


TEMPLATE = """---
description: "{name} - {role}"
alwaysApply: true
priority: {priority}
---

# {emoji} {name_upper} - {role_upper}

## üéØ –û–°–ù–û–í–ù–´–ï –û–ë–Ø–ó–ê–ù–ù–û–°–¢–ò
{responsibilities}

## üîß –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ô –°–¢–ï–ö / –ö–û–ú–ü–ï–¢–ï–ù–¶–ò–ò
{tech_stack}

## üìã –ö–õ–Æ–ß–ï–í–´–ï –ü–†–û–¶–ï–°–°–´
{processes}

## üé™ –í–ó–ê–ò–ú–û–î–ï–ô–°–¢–í–ò–ï –° –î–†–£–ì–ò–ú–ò –†–û–õ–Ø–ú–ò
{interactions}

## üí° –ü–†–ò–ú–ï–†–´ –ü–†–û–ú–ü–¢–û–í

```
@{name} {example_prompt}
```

## ‚úÖ –ö–†–ò–¢–ï–†–ò–ò –ö–ê–ß–ï–°–¢–í–ê
```
{quality_criteria}
```

---
*–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: {timestamp}*
*–ò—Å—Ç–æ—á–Ω–∏–∫: employees.json*
"""


def normalize_filename(name: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –∏–º—è –¥–ª—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞."""
    translit = {
        '–∞': 'a', '–±': 'b', '–≤': 'v', '–≥': 'g', '–¥': 'd', '–µ': 'e', '—ë': 'e',
        '–∂': 'zh', '–∑': 'z', '–∏': 'i', '–π': 'y', '–∫': 'k', '–ª': 'l', '–º': 'm',
        '–Ω': 'n', '–æ': 'o', '–ø': 'p', '—Ä': 'r', '—Å': 's', '—Ç': 't', '—É': 'u',
        '—Ñ': 'f', '—Ö': 'h', '—Ü': 'ts', '—á': 'ch', '—à': 'sh', '—â': 'sch',
        '—ä': '', '—ã': 'y', '—å': '', '—ç': 'e', '—é': 'yu', '—è': 'ya'
    }
    
    normalized = name.lower()
    for ru, en in translit.items():
        normalized = normalized.replace(ru, en)
    
    # –ó–∞–º–µ–Ω—è–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã
    normalized = normalized.replace(" ", "_").replace("/", "_").replace("&", "and")
    
    # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ underscore
    while "__" in normalized:
        normalized = normalized.replace("__", "_")
    
    return normalized.strip("_")


def load_employees_json() -> List[Dict]:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∏–∑ employees.json."""
    if EMPLOYEES_JSON.exists():
        with open(EMPLOYEES_JSON) as f:
            data = json.load(f)
            return data.get("employees", [])
    return []


def get_template_for_role(role: str) -> Dict:
    """–ü–æ–ª—É—á–∏—Ç—å —à–∞–±–ª–æ–Ω –¥–ª—è —Ä–æ–ª–∏."""
    # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
    if role in ROLE_TEMPLATES:
        return ROLE_TEMPLATES[role]
    
    # –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
    for template_role, template in ROLE_TEMPLATES.items():
        if template_role.lower() in role.lower() or role.lower() in template_role.lower():
            return template
    
    return DEFAULT_TEMPLATE


def generate_file_content(employee: Dict, priority: int) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ –¥–ª—è —ç–∫—Å–ø–µ—Ä—Ç–∞."""
    name = employee["name"]
    role = employee["role"]
    
    template_data = get_template_for_role(role)
    
    content = TEMPLATE.format(
        name=name,
        name_upper=name.upper(),
        role=role,
        role_upper=role.upper(),
        priority=priority,
        emoji=template_data["emoji"],
        responsibilities=template_data["responsibilities"],
        tech_stack=template_data["tech_stack"],
        processes=template_data["processes"],
        interactions=template_data["interactions"],
        example_prompt=template_data["example_prompt"],
        quality_criteria=template_data["quality_criteria"],
        timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    )
    
    return content


def sync_cursor_rules():
    """–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å .cursor/rules/ —Å employees.json."""
    
    print("=" * 60)
    print("üîÑ –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–Ø .cursor/rules/")
    print("=" * 60)
    print(f"üìÇ –ü—Ä–æ–µ–∫—Ç: {PROJECT_ROOT}")
    print(f"üìÑ –ò—Å—Ç–æ—á–Ω–∏–∫: {EMPLOYEES_JSON}")
    print(f"üìÅ –¶–µ–ª—å: {RULES_DIR}")
    
    # 1. –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ç–µ–∫—É—â–∏–π —Å–ø–∏—Å–æ–∫ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤
    print("\nüìã –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    employees = load_employees_json()
    
    if not employees:
        print("‚ùå –§–∞–π–ª employees.json –ø—É—Å—Ç –∏–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤: {len(employees)}")
    
    # 2. –°–æ–∑–¥–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
    RULES_DIR.mkdir(parents=True, exist_ok=True)
    
    # 3. –°–æ–±—Ä–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã
    existing_files = {f for f in RULES_DIR.glob("*.md") if f.name != "atra.mdc"}
    existing_names = {f.stem.split("_", 1)[1] if "_" in f.stem else f.stem: f for f in existing_files}
    
    # 4. –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∫–∞–∂–¥–æ–≥–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞
    current_files = set()
    stats = {"created": 0, "updated": 0, "skipped": 0}
    
    for idx, employee in enumerate(employees, start=1):
        name = employee["name"]
        role = employee["role"]
        normalized_name = normalize_filename(name)
        
        filename = f"{idx:02d}_{normalized_name}.md"
        filepath = RULES_DIR / filename
        current_files.add(filepath)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
        content = generate_file_content(employee, priority=idx)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ
        if filepath.exists():
            # –ß–∏—Ç–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π
            existing_content = filepath.read_text(encoding="utf-8")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏–∑–º–µ–Ω–∏–ª–∞—Å—å –ª–∏ —Ä–æ–ª—å –∏–ª–∏ –∏–º—è (–Ω–µ timestamp)
            existing_core = existing_content.split("*–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")[0].strip() if "*–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏" in existing_content else existing_content
            new_core = content.split("*–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")[0].strip()
            
            if existing_core != new_core:
                filepath.write_text(content, encoding="utf-8")
                print(f"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω  {filename} - {name} ({role})")
                stats["updated"] += 1
            else:
                print(f"‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω  {filename} - –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π")
                stats["skipped"] += 1
        else:
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Ñ–∞–π–ª
            filepath.write_text(content, encoding="utf-8")
            print(f"‚úÖ –°–æ–∑–¥–∞–Ω    {filename} - {name} ({role})")
            stats["created"] += 1
    
    # 5. –ù–∞–π—Ç–∏ —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ —Ñ–∞–π–ª—ã (—É–≤–æ–ª–µ–Ω–Ω—ã–µ), –Ω–µ —Ç—Ä–æ–≥–∞—Ç—å —Å–ª—É–∂–µ–±–Ω—ã–µ
    KEEP_FILES = {"README.md", "atra.mdc"}
    obsolete_files = existing_files - current_files - {RULES_DIR / name for name in KEEP_FILES}
    
    if obsolete_files:
        print(f"\n‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö —Ñ–∞–π–ª–æ–≤: {len(obsolete_files)}")
        for file in sorted(obsolete_files):
            print(f"   üóëÔ∏è  {file.name}")
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–¥–∞–ª—è–µ–º (–∏–ª–∏ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ)
        for file in obsolete_files:
            file.unlink()
            print(f"   ‚úÖ –£–¥–∞–ª–µ–Ω {file.name}")
        stats["deleted"] = len(obsolete_files)
    
    # 6. –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n" + "=" * 60)
    print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–ò")
    print("=" * 60)
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ:    {stats['created']}")
    print(f"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–æ:  {stats['updated']}")
    print(f"‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ:  {stats['skipped']}")
    if "deleted" in stats:
        print(f"üóëÔ∏è  –£–¥–∞–ª–µ–Ω–æ:    {stats['deleted']}")
    print(f"\nüìÅ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {len(current_files)}")
    print(f"üìÇ –ü–∞–ø–∫–∞: {RULES_DIR}")
    print("=" * 60)


def main():
    """Entry point."""
    try:
        sync_cursor_rules()
        return 0
    except Exception as e:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main())
