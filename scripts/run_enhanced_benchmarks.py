#!/usr/bin/env python3
"""
Benchmark —Ç–µ—Å—Ç—ã –¥–ª—è –∏–∑–º–µ—Ä–µ–Ω–∏—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞
–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç Enhanced —Ä–µ–∂–∏–º vs Standard —Ä–µ–∂–∏–º
"""

import asyncio
import time
import json
import sys
import os
from typing import Dict, List, Any
from datetime import datetime, timezone
import statistics

sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../knowledge_os'))

from app.victoria_enhanced import VictoriaEnhanced

class EnhancedBenchmark:
    """Benchmark –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è Enhanced vs Standard"""
    
    def __init__(self):
        self.enhanced = None
        self.benchmark_tasks = [
            {
                "id": "math_reasoning",
                "task": "–†–µ—à–∏ —Å–ª–æ–∂–Ω—É—é –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫—É—é –∑–∞–¥–∞—á—É: –ù–∞–π–¥–∏ —Å—É–º–º—É –≤—Å–µ—Ö –ø—Ä–æ—Å—Ç—ã—Ö —á–∏—Å–µ–ª –æ—Ç 1 –¥–æ 100",
                "category": "reasoning",
                "expected_method": "extended_thinking"
            },
            {
                "id": "planning",
                "task": "–°–ø–ª–∞–Ω–∏—Ä—É–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫—É –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è —Å –Ω—É–ª—è: –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, —ç—Ç–∞–ø—ã",
                "category": "planning",
                "expected_method": "tree_of_thoughts"
            },
            {
                "id": "complex_problem",
                "task": "–ù–∞–π–¥–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è –∑–∞–¥–∞—á–∏: –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–æ–∏–º–æ—Å—Ç—å —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–º –∫–∞—á–µ—Å—Ç–≤–µ",
                "category": "complex",
                "expected_method": "swarm"
            },
            {
                "id": "execution",
                "task": "–í—ã–ø–æ–ª–Ω–∏ –∑–∞–¥–∞—á—É: —Å–æ–∑–¥–∞–π –ø–ª–∞–Ω —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è API —Å–µ—Ä–≤–∏—Å–∞",
                "category": "execution",
                "expected_method": "react"
            },
        ]
    
    async def setup(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è"""
        print("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è benchmark...")
        try:
            self.enhanced = VictoriaEnhanced()
            print("‚úÖ VictoriaEnhanced –≥–æ—Ç–æ–≤")
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            return False
    
    async def benchmark_task(self, task: Dict, use_enhanced: bool, iterations: int = 3) -> Dict[str, Any]:
        """Benchmark –æ–¥–Ω–æ–π –∑–∞–¥–∞—á–∏"""
        times = []
        results = []
        
        for i in range(iterations):
            start_time = time.time()
            try:
                result = await self.enhanced.solve(
                    task["task"],
                    use_enhancements=use_enhanced
                )
                elapsed = time.time() - start_time
                times.append(elapsed)
                results.append({
                    "iteration": i + 1,
                    "time": elapsed,
                    "method": result.get("method", "unknown"),
                    "success": result.get("result") is not None
                })
            except Exception as e:
                elapsed = time.time() - start_time
                times.append(elapsed)
                results.append({
                    "iteration": i + 1,
                    "time": elapsed,
                    "error": str(e),
                    "success": False
                })
        
        return {
            "task_id": task["id"],
            "category": task["category"],
            "use_enhanced": use_enhanced,
            "iterations": iterations,
            "avg_time": statistics.mean(times),
            "min_time": min(times),
            "max_time": max(times),
            "std_dev": statistics.stdev(times) if len(times) > 1 else 0,
            "success_rate": sum(1 for r in results if r.get("success", False)) / iterations,
            "results": results
        }
    
    async def run_benchmarks(self):
        """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö benchmark —Ç–µ—Å—Ç–æ–≤"""
        print("=" * 60)
        print("üìä BENCHMARK TESTS - Enhanced vs Standard")
        print("=" * 60)
        
        if not await self.setup():
            return
        
        all_results = []
        
        for task in self.benchmark_tasks:
            print(f"\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: {task['id']} ({task['category']})")
            
            # Standard —Ä–µ–∂–∏–º
            print("  ‚è≥ Standard —Ä–µ–∂–∏–º...")
            standard_result = await self.benchmark_task(task, use_enhanced=False)
            all_results.append(standard_result)
            
            # Enhanced —Ä–µ–∂–∏–º
            print("  ‚è≥ Enhanced —Ä–µ–∂–∏–º...")
            enhanced_result = await self.benchmark_task(task, use_enhanced=True)
            all_results.append(enhanced_result)
            
            # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ
            improvement = ((standard_result["avg_time"] - enhanced_result["avg_time"]) / standard_result["avg_time"]) * 100
            print(f"  üìà –£–ª—É—á—à–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏: {improvement:.1f}%")
            print(f"  ‚úÖ Success rate: Standard={standard_result['success_rate']*100:.1f}%, Enhanced={enhanced_result['success_rate']*100:.1f}%")
        
        # –í—ã–≤–æ–¥ —Å–≤–æ–¥–∫–∏
        self.print_summary(all_results)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.save_results(all_results)
    
    def print_summary(self, results: List[Dict]):
        """–í—ã–≤–æ–¥ —Å–≤–æ–¥–∫–∏"""
        print("\n" + "=" * 60)
        print("üìä –°–í–û–î–ö–ê BENCHMARK")
        print("=" * 60)
        
        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –∑–∞–¥–∞—á–∞–º
        tasks = {}
        for result in results:
            task_id = result["task_id"]
            if task_id not in tasks:
                tasks[task_id] = {}
            mode = "enhanced" if result["use_enhanced"] else "standard"
            tasks[task_id][mode] = result
        
        for task_id, modes in tasks.items():
            standard = modes.get("standard", {})
            enhanced = modes.get("enhanced", {})
            
            if standard and enhanced:
                time_improvement = ((standard["avg_time"] - enhanced["avg_time"]) / standard["avg_time"]) * 100
                success_improvement = (enhanced["success_rate"] - standard["success_rate"]) * 100
                
                print(f"\nüìã {task_id}:")
                print(f"  –í—Ä–µ–º—è: {standard['avg_time']:.2f}s ‚Üí {enhanced['avg_time']:.2f}s ({time_improvement:+.1f}%)")
                print(f"  Success rate: {standard['success_rate']*100:.1f}% ‚Üí {enhanced['success_rate']*100:.1f}% ({success_improvement:+.1f}%)")
                print(f"  –ú–µ—Ç–æ–¥: {enhanced.get('results', [{}])[0].get('method', 'unknown')}")
    
    def save_results(self, results: List[Dict]):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        timestamp = datetime.now(timezone.utc).isoformat()
        output = {
            "timestamp": timestamp,
            "benchmark_results": results,
            "summary": self._calculate_summary(results)
        }
        
        os.makedirs("docs/mac-studio/test_results", exist_ok=True)
        filename = f"docs/mac-studio/test_results/benchmark_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(output, f, indent=2, ensure_ascii=False)
        
        print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {filename}")
    
    def _calculate_summary(self, results: List[Dict]) -> Dict:
        """–†–∞—Å—á–µ—Ç —Å–≤–æ–¥–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        standard_results = [r for r in results if not r["use_enhanced"]]
        enhanced_results = [r for r in results if r["use_enhanced"]]
        
        avg_time_standard = statistics.mean([r["avg_time"] for r in standard_results]) if standard_results else 0
        avg_time_enhanced = statistics.mean([r["avg_time"] for r in enhanced_results]) if enhanced_results else 0
        
        avg_success_standard = statistics.mean([r["success_rate"] for r in standard_results]) if standard_results else 0
        avg_success_enhanced = statistics.mean([r["success_rate"] for r in enhanced_results]) if enhanced_results else 0
        
        return {
            "avg_time_improvement": ((avg_time_standard - avg_time_enhanced) / avg_time_standard * 100) if avg_time_standard > 0 else 0,
            "avg_success_improvement": (avg_success_enhanced - avg_success_standard) * 100,
            "total_tasks": len(set(r["task_id"] for r in results))
        }

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    benchmark = EnhancedBenchmark()
    await benchmark.run_benchmarks()

if __name__ == "__main__":
    asyncio.run(main())
