#!/usr/bin/env python3
"""
–°–±–æ—Ä —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑ production –ª–æ–≥–æ–≤ –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è validation set.
–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ Data Engineer: –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è, –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ –∫–ª—é—á—É, –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö.
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python3 scripts/collect_real_queries.py --days 7 --limit 100
"""
import argparse
import json
import re
import sys
from pathlib import Path
from datetime import datetime, timedelta
from collections import Counter
from typing import Optional

REPO_ROOT = Path(__file__).resolve().parent.parent

# –ö–ª—é—á–∏ –≤ JSON-–ª–æ–≥–∞—Ö, –æ—Ç–∫—É–¥–∞ –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ (backend/API, —á–∞—Ç)
QUERY_KEYS = ("query", "goal", "message", "content", "text", "user_message")

def normalize_query(text: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏: –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä, —Å–∂–∞—Ç–∏–µ –ø—Ä–æ–±–µ–ª–æ–≤ (Data Engineer)."""
    if not text or not isinstance(text, str):
        return ""
    t = " ".join(text.split()).strip()
    return t.lower() if len(t) >= 2 else t

def extract_query_from_line(line: str) -> Optional[str]:
    """–ü—ã—Ç–∞–µ—Ç—Å—è –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –∏–∑ JSON-—Å—Ç—Ä–æ–∫–∏ –ª–æ–≥–∞."""
    line = line.strip()
    if not line:
        return None
    # –ü–æ–ø—ã—Ç–∫–∞ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ JSON (—Ü–µ–ª–∏–∫–æ–º –∏–ª–∏ –≤ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫–∏)
    for candidate in (line, line.split("\t")[-1], line.split(" - ")[-1]):
        try:
            obj = json.loads(candidate)
            if isinstance(obj, dict):
                for key in QUERY_KEYS:
                    val = obj.get(key)
                    if isinstance(val, str) and len(val) >= 2:
                        return normalize_query(val)
            elif isinstance(obj, str) and len(obj) >= 2:
                return normalize_query(obj)
        except (json.JSONDecodeError, TypeError):
            continue
    # Fallback: –≤—ã—Ç–∞—â–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ "query": "..." –∏–ª–∏ goal": "
    for pat in (r'"query"\s*:\s*"([^"]+)"', r'"goal"\s*:\s*"([^"]+)"', r'"message"\s*:\s*"([^"]+)"'):
        m = re.search(pat, line)
        if m:
            return normalize_query(m.group(1))
    return None

def collect_from_logs(log_dir: Path, days: int, limit: int):
    """–°–æ–±–∏—Ä–∞–µ—Ç –∑–∞–ø—Ä–æ—Å—ã –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∏ JSON –ª–æ–≥–æ–≤ —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π."""
    raw_queries = []
    
    if not log_dir.exists():
        print(f"‚ö†Ô∏è –ö–∞—Ç–∞–ª–æ–≥ –ª–æ–≥–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {log_dir}")
        return []
    
    for log_file in list(log_dir.glob("**/*.log")) + list(log_dir.glob("**/chat*.json")):
        try:
            with open(log_file, "r", encoding="utf-8", errors="ignore") as f:
                for line in f:
                    extracted = extract_query_from_line(line)
                    if extracted and len(extracted) >= 3:
                        raw_queries.append(extracted)
                    elif any(x in line for x in ('"query":', 'User query:', 'goal":', 'message":')):
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ fallback
                        norm = normalize_query(line)
                        if len(norm) >= 5:
                            raw_queries.append(norm[:500])
        except Exception:
            continue
    
    freq = Counter(raw_queries)
    top_queries = [{"query": q, "frequency": c, "source": "logs"} for q, c in freq.most_common(limit)]
    return top_queries

def main():
    parser = argparse.ArgumentParser(description="Collect real production queries")
    parser.add_argument("--days", type=int, default=7, help="Days to collect")
    parser.add_argument("--limit", type=int, default=100, help="Max queries")
    parser.add_argument("--output", default="data/real_queries.json")
    args = parser.parse_args()

    log_dir = REPO_ROOT / "logs"
    queries = collect_from_logs(log_dir, args.days, args.limit)
    
    print(f"üìä –°–æ–±—Ä–∞–Ω–æ {len(queries)} –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑ –ª–æ–≥–æ–≤ –∑–∞ {args.days} –¥–Ω–µ–π")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    output = Path(args.output)
    if not output.is_absolute():
        output = REPO_ROOT / output
    
    output.parent.mkdir(parents=True, exist_ok=True)
    with open(output, "w", encoding="utf-8") as f:
        json.dump({"queries": queries, "collected_at": datetime.now().isoformat()}, f, indent=2, ensure_ascii=False)
    
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {output}")
    print("\nüí° –°–æ–≤–µ—Ç (QA): –¥–æ–±–∞–≤—å—Ç–µ —Ç–æ–ø –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ validation set: python3 scripts/augment_validation_set.py --real data/real_queries.json --add 10")
    print("   –ó–∞—Ç–µ–º –∑–∞–ø–æ–ª–Ω–∏—Ç–µ reference –æ—Ç–≤–µ—Ç—ã –¥–ª—è –Ω–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ data/validation_queries.json.")
    return 0

if __name__ == "__main__":
    sys.exit(main())
