#!/usr/bin/env python3
"""
–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ validation set —Å –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–µ–π.
–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ Data Engineer: –µ–¥–∏–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫, –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ –∫–ª—é—á—É, –ø–æ–ª–Ω–æ—Ç–∞ –¥–∞–Ω–Ω—ã—Ö.
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
  python3 scripts/merge_validation_sources.py
  python3 scripts/merge_validation_sources.py --synthetic data/synthetic_query_variations.json --add 20
"""
import argparse
import json
import sys
from pathlib import Path
from typing import Any, Dict, List, Set, Tuple

REPO_ROOT = Path(__file__).resolve().parent.parent


def normalize_key(q: str) -> str:
    """–ö–ª—é—á –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏: –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä, —Å–∂–∞—Ç–∏–µ –ø—Ä–æ–±–µ–ª–æ–≤ (Data Engineer)."""
    return " ".join((q or "").lower().split()).strip()


def load_queries(path: Path) -> List[Dict[str, Any]]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑ JSON (validation –∏–ª–∏ real/synthetic)."""
    if not path.exists():
        return []
    with open(path, "r", encoding="utf-8") as f:
        data = json.load(f)
    return data.get("queries", data) if isinstance(data, dict) else data


def merge_with_dedupe(
    base_queries: List[Dict[str, Any]],
    extra_sources: List[Tuple[Path, int]],
) -> List[Dict[str, Any]]:
    """
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç base + –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Å –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–µ–π –ø–æ normalize_key(query).
    extra_sources: —Å–ø–∏—Å–æ–∫ (path, max_add) ‚Äî –∏–∑ –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞ –¥–æ–±–∞–≤–∏—Ç—å –Ω–µ –±–æ–ª–µ–µ max_add –Ω–æ–≤—ã—Ö.
    """
    seen: Set[str] = set()
    result: List[Dict[str, Any]] = []
    for item in base_queries:
        q = item.get("query")
        if q:
            key = normalize_key(q)
            if key not in seen:
                seen.add(key)
                result.append(dict(item))
    for path, max_add in extra_sources:
        extra = load_queries(path)
        added_here = 0
        for item in extra:
            if added_here >= max_add:
                break
            q = item.get("query")
            if not q or len(q) < 3:
                continue
            key = normalize_key(q)
            if key in seen:
                continue
            seen.add(key)
            # –ü—Ä–∏–≤–µ—Å—Ç–∏ –∫ —Ñ–æ—Ä–º–∞—Ç—É validation (id, query, reference, context_expected)
            entry = {
                "id": item.get("id", f"merged_{len(result)+1}"),
                "query": q,
                "reference": item.get("reference"),
                "context_expected": item.get("context_expected", []),
            }
            if item.get("source"):
                entry["source"] = item["source"]
            if item.get("frequency"):
                entry["frequency"] = item["frequency"]
            result.append(entry)
            added_here += 1
    return result


def main() -> int:
    parser = argparse.ArgumentParser(
        description="Merge validation sources with deduplication (Data Engineer)"
    )
    parser.add_argument(
        "--validation",
        default="data/validation_queries.json",
        help="Base validation set",
    )
    parser.add_argument(
        "--output",
        default=None,
        help="Output path (default: overwrite --validation)",
    )
    parser.add_argument(
        "--real",
        default="data/real_queries.json",
        help="Real queries from logs",
    )
    parser.add_argument(
        "--add-real",
        type=int,
        default=15,
        help="Max real queries to add",
    )
    parser.add_argument(
        "--synthetic",
        default="data/synthetic_query_variations.json",
        help="Synthetic variations",
    )
    parser.add_argument(
        "--add-synthetic",
        type=int,
        default=50,
        help="Max synthetic variations to add",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Only print counts, do not write",
    )
    args = parser.parse_args()

    base_path = REPO_ROOT / args.validation
    if not base_path.exists():
        print(f"‚ùå Validation set not found: {base_path}", file=sys.stderr)
        return 1

    base_queries = load_queries(base_path)
    extra_sources: List[Tuple[Path, int]] = []
    if (REPO_ROOT / args.real).exists():
        extra_sources.append((REPO_ROOT / args.real, args.add_real))
    if (REPO_ROOT / args.synthetic).exists():
        extra_sources.append((REPO_ROOT / args.synthetic, args.add_synthetic))

    merged = merge_with_dedupe(base_queries, extra_sources)
    print(f"üìä –ë–∞–∑–æ–≤—ã–π set: {len(base_queries)} –∑–∞–ø—Ä–æ—Å–æ–≤")
    print(f"   –ü–æ—Å–ª–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏: {len(merged)} –∑–∞–ø—Ä–æ—Å–æ–≤")

    if args.dry_run:
        print("   (dry-run: —Ñ–∞–π–ª –Ω–µ –∏–∑–º–µ–Ω—ë–Ω)")
        return 0

    out_path = REPO_ROOT / (args.output or args.validation)
    out_path.parent.mkdir(parents=True, exist_ok=True)
    payload = {
        "_comment": "Validation set –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ RAG (–§–∞–∑–∞ 4). reference = —ç—Ç–∞–ª–æ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç.",
        "version": "1.0",
        "updated": __import__("datetime").datetime.now().strftime("%Y-%m-%d"),
        "queries": merged,
    }
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(payload, f, indent=2, ensure_ascii=False)
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {out_path}")
    print("üí° –ó–∞–ø–æ–ª–Ω–∏—Ç–µ reference –¥–ª—è –∑–∞–ø–∏—Å–µ–π —Å source=production –∏–ª–∏ source=synthetic_variation (–µ—Å–ª–∏ –ø—É—Å—Ç–æ).")
    return 0


if __name__ == "__main__":
    sys.exit(main())
