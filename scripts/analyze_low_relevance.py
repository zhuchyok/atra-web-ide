#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –Ω–∏–∑–∫–∏–º relevance (–§–∞–∑–∞ 4.1).
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python scripts/analyze_low_relevance.py
"""
import json
import sys
from pathlib import Path
from collections import defaultdict

REPO_ROOT = Path(__file__).resolve().parent.parent


def analyze_problematic_queries(
    report_path: str = "backend/validation_report.json",
    threshold: float = 0.8,
):
    """–ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –Ω–∏–∑–∫–∏–º relevance."""
    path = REPO_ROOT / report_path
    if not path.exists():
        print(f"‚ùå –û—Ç—á—ë—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")
        return []

    with open(path, "r", encoding="utf-8") as f:
        data = json.load(f)

    problematic = []
    for result in data.get("results", []):
        m = result.get("metrics", {})
        rel = m.get("relevance", 1.0)
        if rel < threshold:
            problematic.append({
                "query": result["query"],
                "relevance": rel,
                "faithfulness": m.get("faithfulness", 0),
                "coherence": m.get("coherence", 0),
                "bleu": m.get("bleu", 0),
                "rouge": m.get("rouge", 0),
            })

    print(f"üìä –ê–Ω–∞–ª–∏–∑ –æ—Ç—á—ë—Ç–∞: {path.name}")
    print(f"   –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {len(data.get('results', []))}")
    print(f"   –ü—Ä–æ–±–ª–µ–º–Ω—ã—Ö (relevance < {threshold:.0%}): {len(problematic)}")
    print("=" * 60)

    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø–∞–º
    patterns = defaultdict(list)
    for item in problematic:
        q = item["query"].lower()
        words = len(q.split())
        if item["relevance"] == 0:
            patterns["–∫—Ä–∏—Ç–∏—á–Ω—ã–µ_0_relevance"].append(item)
        elif words <= 3:
            patterns["–∫–æ—Ä–æ—Ç–∫–∏–µ"].append(item)
        elif any(w in q for w in ["–∫–∞–∫", "–ø–æ—á–µ–º—É", "–∑–∞—á–µ–º"]):
            patterns["–º–Ω–æ–≥–æ—à–∞–≥–æ–≤—ã–µ"].append(item)
        elif any(w in q for w in ["–ª—É—á—à–µ", "—Å—Ä–∞–≤–Ω–∏", "—Ä–µ–∫–æ–º–µ–Ω–¥—É–π"]):
            patterns["–∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–µ"].append(item)
        else:
            patterns["–ø—Ä–æ—á–∏–µ"].append(item)

    for pattern, items in sorted(patterns.items()):
        if items:
            avg_rel = sum(i["relevance"] for i in items) / len(items)
            print(f"\nüîç {pattern}: {len(items)} –∑–∞–ø—Ä–æ—Å–æ–≤, avg relevance: {avg_rel:.1%}")
            for i in items[:5]:
                print(f"   ‚Ä¢ '{i['query']}' ‚Üí rel={i['relevance']:.2f} faith={i['faithfulness']:.2f} coh={i['coherence']:.2f}")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    out_path = REPO_ROOT / "problematic_queries_analysis.json"
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump({
            "threshold": threshold,
            "total_problematic": len(problematic),
            "patterns": {k: v for k, v in patterns.items() if v},
            "all": problematic,
        }, f, indent=2, ensure_ascii=False)
    print(f"\n‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {out_path}")

    return problematic


def main():
    threshold = 0.8
    if len(sys.argv) > 1:
        try:
            threshold = float(sys.argv[1])
        except ValueError:
            pass
    analyze_problematic_queries(threshold=threshold)
    return 0


if __name__ == "__main__":
    sys.exit(main())
