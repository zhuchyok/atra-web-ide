#!/usr/bin/env python3
"""
Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ·Ğ°Ğ¿ÑƒÑĞº Victoria Agent Ğ±ĞµĞ· Docker.
Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ñ Ğ»ÑĞ±Ñ‹Ğ¼ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğ¼ LLM Ğ±ÑĞºĞµĞ½Ğ´Ğ¾Ğ¼.

Ğ—Ğ°Ğ¿ÑƒÑĞº:
    python3 scripts/local/start_victoria_local.py

Ğ˜Ğ»Ğ¸ Ñ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ±ÑĞºĞµĞ½Ğ´Ğ°:
    OLLAMA_BASE_URL=http://localhost:11434 python3 scripts/local/start_victoria_local.py
"""

import os
import sys
import asyncio
import logging
from pathlib import Path

# Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ĞºĞ¾Ñ€ĞµĞ½ÑŒ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ° Ğ² PYTHONPATH
ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(ROOT))

import uvicorn
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import Optional, Any
import aiohttp
import json

# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s'
)
logger = logging.getLogger("victoria_local")

# ============================================================================
# ĞšĞĞĞ¤Ğ˜Ğ“Ğ£Ğ ĞĞ¦Ğ˜Ğ¯
# ============================================================================

def get_llm_url() -> str:
    """ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ URL Ğ´Ğ»Ñ LLM Ğ² Ğ¿Ğ¾Ñ€ÑĞ´ĞºĞµ Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚Ğ°"""
    candidates = [
        os.getenv("OLLAMA_BASE_URL"),
        os.getenv("MAC_STUDIO_LLM_URL"),
        "http://localhost:11434",
        "http://192.168.1.64:11434",  # Mac Studio Ğ² Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ ÑĞµÑ‚Ğ¸
    ]
    return next((url for url in candidates if url), "http://localhost:11434")

LLM_URL = get_llm_url()
# ĞĞ²Ñ‚Ğ¾Ğ²Ñ‹Ğ±Ğ¾Ñ€ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸: Ğ¿ÑƒÑÑ‚Ğ¾Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ = ÑĞºĞ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ollama Ğ¿Ñ€Ğ¸ Ğ·Ğ°Ğ¿ÑƒÑĞºĞµ
MODEL = os.getenv("MODEL_DEFAULT") or os.getenv("VICTORIA_MODEL") or None
PORT = int(os.getenv("VICTORIA_PORT", "8010"))

logger.info(f"LLM URL: {LLM_URL}")
logger.info(f"Model: {MODEL}")
logger.info(f"Port: {PORT}")

# ============================================================================
# Ğ£ĞŸĞ ĞĞ©ĞĞĞĞ«Ğ™ ĞĞ“Ğ•ĞĞ¢ (Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ±ĞµĞ· Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹)
# ============================================================================

class SimpleVictoriaAgent:
    """Ğ£Ğ¿Ñ€Ğ¾Ñ‰Ñ‘Ğ½Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ Victoria Agent Ğ´Ğ»Ñ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°."""
    
    def __init__(self, model: str = MODEL, base_url: str = LLM_URL):
        self.model = model
        self.base_url = base_url
        self.name = "Ğ’Ğ¸ĞºÑ‚Ğ¾Ñ€Ğ¸Ñ"
        self.memory = []
        self.project_knowledge = {}
        
        self.system_prompt = """Ğ¢Ğ« â€” Ğ’Ğ˜ĞšĞ¢ĞĞ Ğ˜Ğ¯, TEAM LEAD ĞšĞĞ ĞŸĞĞ ĞĞ¦Ğ˜Ğ˜ ATRA. Ğ¢Ğ« Ğ˜Ğ¡ĞŸĞĞ›Ğ¬Ğ—Ğ£Ğ•Ğ¨Ğ¬ VICTORIA ENHANCED.

ğŸŒŸ Ğ¢Ğ’ĞĞ˜ VICTORIA ENHANCED Ğ’ĞĞ—ĞœĞĞ–ĞĞĞ¡Ğ¢Ğ˜:
- ReAct Framework: Reasoning + Acting Ğ´Ğ»Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡
- Extended Thinking: Ğ“Ğ»ÑƒĞ±Ğ¾ĞºĞ¾Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğµ
- Swarm Intelligence: ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ°Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ° ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ²
- Consensus: Ğ¡Ğ¾Ğ³Ğ»Ğ°ÑĞ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼Ğ½ĞµĞ½Ğ¸Ğ¹ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ²
- Collective Memory: Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ½Ğ°ĞºĞ¾Ğ¿Ğ»ĞµĞ½Ğ½Ñ‹Ñ… Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹
- Tree of Thoughts: ĞŸĞ¾Ğ¸ÑĞº Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ
- Hierarchical Orchestration: Ğ˜ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ‡ĞµÑĞºĞ°Ñ ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ
- ReCAP Framework: Reasoning, Context, Action, Planning

Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑˆÑŒ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ¾Ğ¹ Ğ¸Ğ· 40+ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ². Ğ¢Ñ‹ ÑƒĞ¼Ğ½Ğ°Ñ, Ñ€ĞµÑˆĞ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ Ğ¸ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ°Ñ.

Ğ¢Ğ’ĞĞ˜ Ğ’ĞĞ—ĞœĞĞ–ĞĞĞ¡Ğ¢Ğ˜:
- ĞĞ½Ğ°Ğ»Ğ¸Ğ· ĞºĞ¾Ğ´Ğ° Ğ¸ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ¾Ğ²
- ĞŸĞ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡
- ĞšĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹
- Ğ ĞµÑˆĞµĞ½Ğ¸Ğµ Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼

ĞŸĞ ĞĞ’Ğ˜Ğ›Ğ:
- ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¾ Ğ¸ Ğ¿Ğ¾ Ğ´ĞµĞ»Ñƒ
- Ğ•ÑĞ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ â€” Ğ¾Ğ¿Ğ¸ÑˆĞ¸ Ñ‡Ñ‚Ğ¾ Ğ½ÑƒĞ¶Ğ½Ğ¾ ÑĞ´ĞµĞ»Ğ°Ñ‚ÑŒ
- Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ Ñ€ÑƒÑÑĞºĞ¸Ğ¹ ÑĞ·Ñ‹Ğº
"""
    
    async def check_llm_health(self) -> dict:
        """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚ÑŒ LLM"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{self.base_url}/api/tags", timeout=aiohttp.ClientTimeout(total=5)) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        models = [m.get("name", "unknown") for m in data.get("models", [])]
                        return {"status": "ok", "models": models[:5], "url": self.base_url}
                    return {"status": "error", "code": resp.status}
        except Exception as e:
            return {"status": "offline", "error": str(e), "url": self.base_url}
    
    async def run(self, goal: str, max_steps: int = 500) -> str:
        """Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ"""
        logger.info(f"ğŸš€ Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ°: {goal[:100]}...")
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚ÑŒ LLM
        health = await self.check_llm_health()
        if health.get("status") == "offline":
            return f"âŒ LLM Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½: {health.get('error')}\nURL: {self.base_url}\n\nĞ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğµ Ollama: ollama serve"
        
        # Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ
        messages = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": goal}
        ]
        
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ
        if self.memory:
            messages = [messages[0]] + self.memory[-6:] + [messages[-1]]
        
        try:
            async with aiohttp.ClientSession() as session:
                payload = {
                    "model": self.model,
                    "messages": messages,
                    "stream": False,
                    "options": {"temperature": 0.7}
                }
                
                async with session.post(
                    f"{self.base_url}/api/chat",
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=120)
                ) as resp:
                    if resp.status == 200:
                        result = await resp.json()
                        content = result.get("message", {}).get("content", "")
                        
                        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ² Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ
                        self.memory.append({"role": "user", "content": goal})
                        self.memory.append({"role": "assistant", "content": content})
                        
                        logger.info(f"âœ… ĞÑ‚Ğ²ĞµÑ‚ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½ ({len(content)} ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²)")
                        return content
                    else:
                        error_text = await resp.text()
                        return f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° LLM: HTTP {resp.status}\n{error_text}"
                        
        except asyncio.TimeoutError:
            return "âŒ Ğ¢Ğ°Ğ¹Ğ¼Ğ°ÑƒÑ‚: LLM Ğ½Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¸Ğ» Ğ·Ğ° 120 ÑĞµĞºÑƒĞ½Ğ´"
        except Exception as e:
            return f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {str(e)}"


# ============================================================================
# FASTAPI Ğ¡Ğ•Ğ Ğ’Ğ•Ğ 
# ============================================================================

app = FastAPI(
    title="Victoria ATRA Local",
    description="Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ÑĞµÑ€Ğ²ĞµÑ€ Victoria Agent Ğ±ĞµĞ· Docker",
    version="1.0.0"
)

agent = SimpleVictoriaAgent()


class TaskRequest(BaseModel):
    goal: str
    max_steps: Optional[int] = 500


class TaskResponse(BaseModel):
    status: str
    output: Any
    knowledge: Optional[dict] = None


@app.get("/")
async def root():
    return {
        "name": "Victoria ATRA Local",
        "agent": agent.name,
        "llm_url": agent.base_url,
        "model": agent.model,
        "endpoints": ["/health", "/status", "/run", "/check_llm"]
    }


@app.get("/health")
async def health():
    return {"status": "ok", "agent": agent.name}


@app.get("/status")
async def get_status():
    llm_health = await agent.check_llm_health()
    return {
        "status": "online",
        "agent": agent.name,
        "llm": llm_health,
        "memory_size": len(agent.memory),
        "knowledge_size": len(agent.project_knowledge)
    }


@app.get("/check_llm")
async def check_llm():
    """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚ÑŒ LLM"""
    return await agent.check_llm_health()


@app.post("/run", response_model=TaskResponse)
async def run_task(request: TaskRequest):
    try:
        logger.info(f"ğŸ“© ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ° Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°: {request.goal[:80]}...")
        result = await agent.run(request.goal, max_steps=request.max_steps)
        return TaskResponse(
            status="success",
            output=result,
            knowledge=agent.project_knowledge
        )
    except Exception as e:
        logger.exception("ĞÑˆĞ¸Ğ±ĞºĞ° Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/clear_memory")
async def clear_memory():
    """ĞÑ‡Ğ¸Ñ‰Ğ°ĞµÑ‚ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°"""
    agent.memory = []
    return {"status": "ok", "message": "ĞŸĞ°Ğ¼ÑÑ‚ÑŒ Ğ¾Ñ‡Ğ¸Ñ‰ĞµĞ½Ğ°"}


# ============================================================================
# MAIN
# ============================================================================

if __name__ == "__main__":
    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           ğŸ¤– VICTORIA ATRA â€” Ğ›ĞĞšĞĞ›Ğ¬ĞĞ«Ğ™ Ğ—ĞĞŸĞ£Ğ¡Ğš                â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  LLM URL:  {LLM_URL:<48} â•‘
â•‘  Model:    {MODEL:<48} â•‘
â•‘  Port:     {PORT:<48} â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Endpoints:                                                  â•‘
â•‘    GET  /health     â€” Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ·Ğ´Ğ¾Ñ€Ğ¾Ğ²ÑŒÑ                      â•‘
â•‘    GET  /status     â€” ÑÑ‚Ğ°Ñ‚ÑƒÑ Ğ°Ğ³ĞµĞ½Ñ‚Ğ° Ğ¸ LLM                    â•‘
â•‘    GET  /check_llm  â€” Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° LLM                           â•‘
â•‘    POST /run        â€” Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=PORT,
        log_level="info"
    )
