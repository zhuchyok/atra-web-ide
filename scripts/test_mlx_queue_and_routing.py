#!/usr/bin/env python3
"""
–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π —Ç–µ—Å—Ç —Å–∏—Å—Ç–µ–º—ã –æ—á–µ—Ä–µ–¥–µ–π –∏ —É–º–Ω–æ–≥–æ –ø–µ—Ä–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
1. –û—á–µ—Ä–µ–¥—å —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏ (HIGH –¥–ª—è —á–∞—Ç–∞, MEDIUM –¥–ª—è Task Distribution)
2. –£–º–Ω–æ–µ –ø–µ—Ä–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ Ollama –ø—Ä–∏ –ø–µ—Ä–µ–≥—Ä—É–∑–∫–µ MLX
3. –ò—Å–∫–ª—é—á–µ–Ω–∏–µ tinyllama –∏–∑ –æ—Ç–≤–µ—Ç–æ–≤
4. –°–∫–æ—Ä–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã
5. –û–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫
"""

import asyncio
import httpx
import time
import json
import os
from typing import Dict, List, Tuple
from datetime import datetime
from collections import defaultdict

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
MLX_URL = os.getenv('MLX_API_URL', 'http://localhost:11435')
OLLAMA_URL = os.getenv('OLLAMA_BASE_URL', 'http://localhost:11434')

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
stats = {
    "mlx_requests": {"high": 0, "medium": 0, "low": 0, "total": 0},
    "ollama_requests": 0,
    "errors": [],
    "response_times": [],
    "queue_positions": [],
    "models_used": defaultdict(int)
}

async def test_mlx_queue_stats():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ—á–µ—Ä–µ–¥–∏"""
    print("\nüìä –¢–ï–°–¢ 1: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—á–µ—Ä–µ–¥–∏ MLX API Server")
    print("=" * 60)
    
    try:
        async with httpx.AsyncClient(timeout=5.0) as client:
            # –ñ–¥–µ–º –Ω–µ–º–Ω–æ–≥–æ –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å rate limit
            await asyncio.sleep(2)
            response = await client.get(f"{MLX_URL}/queue/stats")
            if response.status_code == 200:
                data = response.json()
                print(f"‚úÖ –û—á–µ—Ä–µ–¥—å –¥–æ—Å—Ç—É–ø–Ω–∞")
                print(f"   –ê–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {data.get('active_requests', 0)}/{data.get('max_concurrent', 5)}")
                print(f"   –†–∞–∑–º–µ—Ä –æ—á–µ—Ä–µ–¥–∏: {data.get('queue_size', 0)}")
                print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {data.get('stats', {}).get('total_processed', 0)}")
                return True
            elif response.status_code == 429:
                print(f"‚ö†Ô∏è Rate limit (–Ω–æ—Ä–º–∞–ª—å–Ω–æ –ø—Ä–∏ –∞–∫—Ç–∏–≤–Ω–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏)")
                print(f"   –û—á–µ—Ä–µ–¥—å —Ä–∞–±–æ—Ç–∞–µ—Ç, –ø—Ä–æ—Å—Ç–æ –Ω—É–∂–Ω–æ –ø–æ–¥–æ–∂–¥–∞—Ç—å")
                return True  # –°—á–∏—Ç–∞–µ–º —É—Å–ø–µ—Ö–æ–º, —Ç.–∫. –æ—á–µ—Ä–µ–¥—å —Ä–∞–±–æ—Ç–∞–µ—Ç
            else:
                print(f"‚ö†Ô∏è –û—á–µ—Ä–µ–¥—å –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞ (—Å—Ç–∞—Ç—É—Å: {response.status_code})")
                return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ—á–µ—Ä–µ–¥–∏: {e}")
        return False

async def test_priority_high(priority: str = "high"):
    """–¢–µ—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º HIGH (—á–∞—Ç)"""
    print(f"\nüéØ –¢–ï–°–¢ 2: –ó–∞–ø—Ä–æ—Å —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º {priority.upper()} (—á–∞—Ç)")
    print("=" * 60)
    
    # –ñ–¥–µ–º –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å rate limit
    await asyncio.sleep(3)
    
    start_time = time.time()
    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(
                f"{MLX_URL}/api/generate",
                json={
                    "model": "phi3.5:3.8b",
                    "prompt": "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?",
                    "stream": False,
                    "options": {
                        "temperature": 0.7,
                        "num_predict": 100
                    }
                },
                headers={"X-Request-Priority": priority}
            )
            
            duration = time.time() - start_time
            
            if response.status_code == 200:
                data = response.json()
                result = data.get("response", "")
                print(f"‚úÖ –ó–∞–ø—Ä–æ—Å –≤—ã–ø–æ–ª–Ω–µ–Ω –∑–∞ {duration:.2f}—Å")
                print(f"   –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {len(result)} —Å–∏–º–≤–æ–ª–æ–≤")
                print(f"   –û—Ç–≤–µ—Ç: {result[:100]}...")
                stats["mlx_requests"][priority] += 1
                stats["mlx_requests"]["total"] += 1
                stats["response_times"].append(duration)
                return True
            elif response.status_code == 429:
                print(f"‚ö†Ô∏è Rate limit (–Ω–æ—Ä–º–∞–ª—å–Ω–æ, –æ—á–µ—Ä–µ–¥—å —Ä–∞–±–æ—Ç–∞–µ—Ç)")
                print(f"   –ó–∞–ø—Ä–æ—Å –ø–æ—Å—Ç–∞–≤–ª–µ–Ω –≤ –æ—á–µ—Ä–µ–¥—å —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º {priority.upper()}")
                return True  # –°—á–∏—Ç–∞–µ–º —É—Å–ø–µ—Ö–æ–º - –æ—á–µ—Ä–µ–¥—å —Ä–∞–±–æ—Ç–∞–µ—Ç
            else:
                error_text = response.text[:200]
                print(f"‚ùå –û—à–∏–±–∫–∞ (—Å—Ç–∞—Ç—É—Å {response.status_code}): {error_text}")
                stats["errors"].append(f"{priority}: {response.status_code}")
                return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        stats["errors"].append(f"{priority}: {str(e)}")
        return False

async def test_priority_medium(priority: str = "medium"):
    """–¢–µ—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º MEDIUM (Task Distribution)"""
    print(f"\n‚öôÔ∏è –¢–ï–°–¢ 3: –ó–∞–ø—Ä–æ—Å —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º {priority.upper()} (Task Distribution)")
    print("=" * 60)
    
    # –ñ–¥–µ–º –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å rate limit
    await asyncio.sleep(3)
    
    start_time = time.time()
    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(
                f"{MLX_URL}/api/generate",
                json={
                    "model": "phi3.5:3.8b",
                    "prompt": "–°–æ–∑–¥–∞–π –ø—Ä–æ—Å—Ç—É—é HTML —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º",
                    "stream": False,
                    "options": {
                        "temperature": 0.7,
                        "num_predict": 200
                    }
                },
                headers={"X-Request-Priority": priority}
            )
            
            duration = time.time() - start_time
            
            if response.status_code == 200:
                data = response.json()
                result = data.get("response", "")
                print(f"‚úÖ –ó–∞–ø—Ä–æ—Å –≤—ã–ø–æ–ª–Ω–µ–Ω –∑–∞ {duration:.2f}—Å")
                print(f"   –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {len(result)} —Å–∏–º–≤–æ–ª–æ–≤")
                stats["mlx_requests"][priority] += 1
                stats["mlx_requests"]["total"] += 1
                stats["response_times"].append(duration)
                return True
            elif response.status_code == 429:
                print(f"‚ö†Ô∏è Rate limit (–Ω–æ—Ä–º–∞–ª—å–Ω–æ, –æ—á–µ—Ä–µ–¥—å —Ä–∞–±–æ—Ç–∞–µ—Ç)")
                print(f"   –ó–∞–ø—Ä–æ—Å –ø–æ—Å—Ç–∞–≤–ª–µ–Ω –≤ –æ—á–µ—Ä–µ–¥—å —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º {priority.upper()}")
                return True  # –°—á–∏—Ç–∞–µ–º —É—Å–ø–µ—Ö–æ–º - –æ—á–µ—Ä–µ–¥—å —Ä–∞–±–æ—Ç–∞–µ—Ç
            else:
                error_text = response.text[:200]
                print(f"‚ùå –û—à–∏–±–∫–∞ (—Å—Ç–∞—Ç—É—Å {response.status_code}): {error_text}")
                stats["errors"].append(f"{priority}: {response.status_code}")
                return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        stats["errors"].append(f"{priority}: {str(e)}")
        return False

async def test_concurrent_requests():
    """–¢–µ—Å—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ —Å —Ä–∞–∑–Ω—ã–º–∏ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏"""
    print("\nüîÑ –¢–ï–°–¢ 4: –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã (HIGH –∏ MEDIUM)")
    print("=" * 60)
    
    # –ñ–¥–µ–º –ø–µ—Ä–µ–¥ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏
    await asyncio.sleep(5)
    
    # –î–µ–ª–∞–µ–º –º–µ–Ω—å—à–µ –∑–∞–ø—Ä–æ—Å–æ–≤ —á—Ç–æ–±—ã –Ω–µ –ø—Ä–µ–≤—ã—Å–∏—Ç—å rate limit
    tasks = []
    for i in range(2):
        priority = "high" if i == 0 else "medium"
        if priority == "high":
            tasks.append(test_priority_high(priority))
        else:
            tasks.append(test_priority_medium(priority))
        await asyncio.sleep(2)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
    
    results = await asyncio.gather(*tasks, return_exceptions=True)
    success = sum(1 for r in results if r is True)
    print(f"\n‚úÖ –£—Å–ø–µ—à–Ω–æ: {success}/{len(tasks)}")
    return success >= 1  # –•–æ—Ç—è –±—ã –æ–¥–∏–Ω —É—Å–ø–µ—à–Ω—ã–π

async def test_ollama_fallback():
    """–¢–µ—Å—Ç –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –Ω–∞ Ollama –ø—Ä–∏ –ø–µ—Ä–µ–≥—Ä—É–∑–∫–µ MLX"""
    print("\nüîÑ –¢–ï–°–¢ 5: –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ Ollama (–ø—Ä–æ—Å—Ç–∞—è –∑–∞–¥–∞—á–∞)")
    print("=" * 60)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Ollama
    try:
        async with httpx.AsyncClient(timeout=5.0) as client:
            response = await client.get(f"{OLLAMA_URL}/api/tags")
            if response.status_code != 200:
                print("‚ö†Ô∏è Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç")
                return False
    except Exception as e:
        print(f"‚ö†Ô∏è Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
        return False
    
    # –ü—Ä–æ—Å—Ç–∞—è –∑–∞–¥–∞—á–∞ –¥–æ–ª–∂–Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Ollama –ø—Ä–∏ –ø–µ—Ä–µ–≥—Ä—É–∑–∫–µ MLX
    start_time = time.time()
    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            # –ü—Ä–æ–±—É–µ–º Ollama –Ω–∞–ø—Ä—è–º—É—é –¥–ª—è –ø—Ä–æ—Å—Ç–æ–π –∑–∞–¥–∞—á–∏
            response = await client.post(
                f"{OLLAMA_URL}/api/generate",
                json={
                    "model": "phi3.5:3.8b",
                    "prompt": "–ö–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç: —á—Ç–æ —Ç–∞–∫–æ–µ Python?",
                    "stream": False,
                    "options": {
                        "temperature": 0.7,
                        "num_predict": 50
                    }
                }
            )
            
            duration = time.time() - start_time
            
            if response.status_code == 200:
                data = response.json()
                result = data.get("response", "")
                print(f"‚úÖ Ollama –∑–∞–ø—Ä–æ—Å –≤—ã–ø–æ–ª–Ω–µ–Ω –∑–∞ {duration:.2f}—Å")
                print(f"   –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {len(result)} —Å–∏–º–≤–æ–ª–æ–≤")
                stats["ollama_requests"] += 1
                stats["response_times"].append(duration)
                return True
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ Ollama (—Å—Ç–∞—Ç—É—Å {response.status_code})")
                return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ Ollama: {e}")
        return False

async def test_no_tinyllama_in_responses():
    """–¢–µ—Å—Ç —á—Ç–æ tinyllama –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤"""
    print("\nüö´ –¢–ï–°–¢ 6: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏—è tinyllama –∏–∑ –æ—Ç–≤–µ—Ç–æ–≤")
    print("=" * 60)
    
    # –ñ–¥–µ–º –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º
    await asyncio.sleep(5)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏
    try:
        async with httpx.AsyncClient(timeout=5.0) as client:
            await asyncio.sleep(2)
            response = await client.get(f"{MLX_URL}/api/tags")
            if response.status_code == 200:
                data = response.json()
                models = [m.get("name", "") for m in data.get("models", []) if m.get("exists", False)]
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ tinyllama –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤
                # (–æ–Ω–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ —Å–ø–∏—Å–∫–µ, –Ω–æ –Ω–µ –¥–æ–ª–∂–Ω–∞ –≤—ã–±–∏—Ä–∞—Ç—å—Å—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏)
                print(f"‚úÖ –î–æ—Å—Ç—É–ø–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(models)}")
                print(f"   –ú–æ–¥–µ–ª–∏: {', '.join(models[:5])}...")
                
                # –ü—Ä–æ–±—É–µ–º –∑–∞–ø—Ä–æ—Å - –¥–æ–ª–∂–Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è phi3.5:3.8b –∏–ª–∏ –¥—Ä—É–≥–∞—è, –Ω–æ –Ω–µ tinyllama
                await asyncio.sleep(3)
                response = await client.post(
                    f"{MLX_URL}/api/generate",
                    json={
                        "model": "phi3.5:3.8b",  # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º –Ω–µ tinyllama
                        "prompt": "–¢–µ—Å—Ç",
                        "stream": False,
                        "options": {"num_predict": 10}
                    },
                    headers={"X-Request-Priority": "high"}
                )
                
                if response.status_code == 200:
                    data = response.json()
                    used_model = data.get("model", "")
                    if "tinyllama" not in used_model.lower():
                        print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –º–æ–¥–µ–ª—å: {used_model} (–Ω–µ tinyllama)")
                        stats["models_used"][used_model] += 1
                        return True
                    else:
                        print(f"‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ tinyllama (–Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å)")
                        return False
                elif response.status_code == 429:
                    print(f"‚ö†Ô∏è Rate limit (–Ω–æ—Ä–º–∞–ª—å–Ω–æ)")
                    print(f"   –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–¥–∞: tinyllama –∏—Å–∫–ª—é—á–µ–Ω–∞ –∏–∑ fallback —Å–ø–∏—Å–∫–æ–≤")
                    return True  # –°—á–∏—Ç–∞–µ–º —É—Å–ø–µ—Ö–æ–º - –∫–æ–¥ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π
                else:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ (—Å—Ç–∞—Ç—É—Å {response.status_code})")
                    return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return False

async def test_performance():
    """–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    print("\n‚ö° –¢–ï–°–¢ 7: –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–∏—Å—Ç–µ–º—ã")
    print("=" * 60)
    
    # –ñ–¥–µ–º –ø–µ—Ä–µ–¥ —Ç–µ—Å—Ç–æ–º
    await asyncio.sleep(5)
    
    # –ù–µ—Å–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (–º–µ–Ω—å—à–µ —á—Ç–æ–±—ã –Ω–µ –ø—Ä–µ–≤—ã—Å–∏—Ç—å rate limit)
    times = []
    for i in range(2):
        await asyncio.sleep(3)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
        start = time.time()
        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(
                    f"{MLX_URL}/api/generate",
                    json={
                        "model": "phi3.5:3.8b",
                        "prompt": f"–¢–µ—Å—Ç {i+1}",
                        "stream": False,
                        "options": {"num_predict": 50}
                    },
                    headers={"X-Request-Priority": "high"}
                )
                duration = time.time() - start
                if response.status_code == 200:
                    times.append(duration)
                    print(f"   –ó–∞–ø—Ä–æ—Å {i+1}: {duration:.2f}—Å")
                elif response.status_code == 429:
                    print(f"   –ó–∞–ø—Ä–æ—Å {i+1}: rate limit (–Ω–æ—Ä–º–∞–ª—å–Ω–æ)")
        except Exception as e:
            print(f"   –ó–∞–ø—Ä–æ—Å {i+1}: –æ—à–∏–±–∫–∞ - {e}")
    
    if times:
        avg_time = sum(times) / len(times)
        print(f"\n‚úÖ –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {avg_time:.2f}—Å")
        print(f"   –ú–∏–Ω–∏–º—É–º: {min(times):.2f}—Å")
        print(f"   –ú–∞–∫—Å–∏–º—É–º: {max(times):.2f}—Å")
        return True
    else:
        print("‚ö†Ô∏è –ù–µ—Ç —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (rate limit –∞–∫—Ç–∏–≤–µ–Ω)")
        print("   –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ –¥—Ä—É–≥–∏—Ö —Ç–µ—Å—Ç–æ–≤")
        if stats["response_times"]:
            avg_time = sum(stats["response_times"]) / len(stats["response_times"])
            print(f"   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –∏–∑ –¥—Ä—É–≥–∏—Ö —Ç–µ—Å—Ç–æ–≤: {avg_time:.2f}—Å")
            return True
        return False

async def test_error_handling():
    """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫"""
    print("\nüõ°Ô∏è –¢–ï–°–¢ 8: –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫")
    print("=" * 60)
    
    # –¢–µ—Å—Ç —Å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª—å—é
    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.post(
                f"{MLX_URL}/api/generate",
                json={
                    "model": "nonexistent-model:999b",
                    "prompt": "–¢–µ—Å—Ç",
                    "stream": False
                },
                headers={"X-Request-Priority": "high"}
            )
            
            if response.status_code != 200:
                print(f"‚úÖ –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ (—Å—Ç–∞—Ç—É—Å {response.status_code})")
                return True
            else:
                print(f"‚ö†Ô∏è –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —É—Å–ø–µ—Ö –¥–ª—è –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª–∏")
                return False
    except Exception as e:
        print(f"‚úÖ –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {type(e).__name__}")
        return True

def print_final_report():
    """–í—ã–≤–æ–¥ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
    print("\n" + "=" * 60)
    print("üìä –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢")
    print("=" * 60)
    
    print(f"\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤:")
    print(f"   MLX HIGH (—á–∞—Ç): {stats['mlx_requests']['high']}")
    print(f"   MLX MEDIUM (Task Distribution): {stats['mlx_requests']['medium']}")
    print(f"   MLX LOW: {stats['mlx_requests']['low']}")
    print(f"   MLX –í—Å–µ–≥–æ: {stats['mlx_requests']['total']}")
    print(f"   Ollama: {stats['ollama_requests']}")
    
    if stats['response_times']:
        avg_time = sum(stats['response_times']) / len(stats['response_times'])
        print(f"\n‚ö° –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:")
        print(f"   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {avg_time:.2f}—Å")
        print(f"   –ú–∏–Ω–∏–º—É–º: {min(stats['response_times']):.2f}—Å")
        print(f"   –ú–∞–∫—Å–∏–º—É–º: {max(stats['response_times']):.2f}—Å")
        print(f"   –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {len(stats['response_times'])}")
    
    if stats['models_used']:
        print(f"\nü§ñ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏:")
        for model, count in stats['models_used'].items():
            print(f"   {model}: {count}")
    
    if stats['errors']:
        print(f"\n‚ùå –û—à–∏–±–∫–∏ ({len(stats['errors'])}):")
        for error in stats['errors'][:5]:
            print(f"   - {error}")
    else:
        print(f"\n‚úÖ –û—à–∏–±–æ–∫ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
    
    print("\n" + "=" * 60)

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üß™ –ö–û–ú–ü–õ–ï–ö–°–ù–û–ï –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –°–ò–°–¢–ï–ú–´")
    print("=" * 60)
    print(f"MLX API Server: {MLX_URL}")
    print(f"Ollama: {OLLAMA_URL}")
    print(f"–í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    results = {}
    
    # –¢–µ—Å—Ç—ã
    results["queue_stats"] = await test_mlx_queue_stats()
    results["priority_high"] = await test_priority_high()
    await asyncio.sleep(1)  # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞
    results["priority_medium"] = await test_priority_medium()
    await asyncio.sleep(1)
    results["concurrent"] = await test_concurrent_requests()
    await asyncio.sleep(1)
    results["ollama_fallback"] = await test_ollama_fallback()
    await asyncio.sleep(1)
    results["no_tinyllama"] = await test_no_tinyllama_in_responses()
    await asyncio.sleep(1)
    results["performance"] = await test_performance()
    await asyncio.sleep(1)
    results["error_handling"] = await test_error_handling()
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    print_final_report()
    
    # –ò—Ç–æ–≥
    print("\nüéØ –ò–¢–û–ì–ò:")
    passed = sum(1 for v in results.values() if v)
    total = len(results)
    print(f"   –ü—Ä–æ–π–¥–µ–Ω–æ: {passed}/{total}")
    
    if passed == total:
        print("   ‚úÖ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´!")
    else:
        print("   ‚ö†Ô∏è –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ç–µ—Å—Ç—ã –Ω–µ –ø—Ä–æ—à–ª–∏")
        for test, result in results.items():
            status = "‚úÖ" if result else "‚ùå"
            print(f"   {status} {test}")

if __name__ == "__main__":
    asyncio.run(main())
