#!/bin/bash
# –°–∫—Ä–∏–ø—Ç —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ Mac Studio M4 Max

set -e

echo "üöÄ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–¥–µ–ª–µ–π –¥–ª—è Mac Studio M4 Max"
echo ""

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
echo "üì¶ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π..."
python3 -c "import mlx_lm" 2>/dev/null || {
    echo "‚ùå MLX –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!"
    echo "   –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install mlx mlx-lm"
    exit 1
}

# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –º–æ–¥–µ–ª–µ–π
mkdir -p ~/.mlx_models

echo "‚úÖ –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã"
echo ""

# –ó–∞–ø—É—Å–∫ Python —Å–∫—Ä–∏–ø—Ç–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏
echo "ü§ñ –ó–∞–ø—É—Å–∫ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –º–æ–¥–µ–ª–µ–π..."
python3 << 'PYTHON_SCRIPT'
import os
import subprocess
import sys
from pathlib import Path

# –ú–æ–¥–µ–ª–∏ –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏
MODELS = [
    {
        "name": "DeepSeek-R1-Distill-Llama-70B",
        "hf_id": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
        "mlx_path": "~/.mlx_models/DeepSeek-R1-Distill-Llama-70B-Q6",
        "q_bits": 6,
        "size_gb": 55,
        "category": "reasoning"
    },
    {
        "name": "Qwen2.5-Coder-32B-Instruct",
        "hf_id": "Qwen/Qwen2.5-Coder-32B-Instruct",
        "mlx_path": "~/.mlx_models/Qwen2.5-Coder-32B-Instruct-Q8",
        "q_bits": 8,
        "size_gb": 35,
        "category": "coding"
    },
    {
        "name": "Phi-3.5-Mini-Instruct",
        "hf_id": "microsoft/Phi-3.5-mini-instruct",
        "mlx_path": "~/.mlx_models/Phi-3.5-mini-instruct-Q4",
        "q_bits": 4,
        "size_gb": 2,
        "category": "fast"
    },
    {
        "name": "TinyLlama-1.1B-Chat",
        "hf_id": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
        "mlx_path": "~/.mlx_models/TinyLlama-1.1B-Chat-Q4",
        "q_bits": 4,
        "size_gb": 0.7,
        "category": "tiny"
    },
    {
        "name": "Qwen2.5-3B-Instruct",
        "hf_id": "Qwen/Qwen2.5-3B-Instruct",
        "mlx_path": "~/.mlx_models/Qwen2.5-3B-Instruct-Q4",
        "q_bits": 4,
        "size_gb": 2,
        "category": "fast"
    },
    {
        "name": "Phi-3-Mini-4K-Instruct",
        "hf_id": "microsoft/Phi-3-mini-4k-instruct",
        "mlx_path": "~/.mlx_models/Phi-3-mini-4k-instruct-Q4",
        "q_bits": 4,
        "size_gb": 2,
        "category": "fast"
    }
]

def install_model(model_config):
    """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –æ–¥–Ω—É –º–æ–¥–µ–ª—å"""
    mlx_path = os.path.expanduser(model_config['mlx_path'])
    
    if os.path.exists(mlx_path) and os.listdir(mlx_path):
        print(f"‚úÖ {model_config['name']} —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
        return True
    
    print(f"\nüîÑ –£—Å—Ç–∞–Ω–æ–≤–∫–∞: {model_config['name']}")
    print(f"   HuggingFace: {model_config['hf_id']}")
    print(f"   –†–∞–∑–º–µ—Ä: ~{model_config['size_gb']}GB")
    
    cmd = [
        sys.executable, "-m", "mlx_lm.convert",
        "--hf-path", model_config['hf_id'],
        "--q-bits", str(model_config['q_bits']),
        "-q",
        "--mlx-path", mlx_path
    ]
    
    try:
        subprocess.run(cmd, check=True)
        print(f"‚úÖ {model_config['name']} —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        return True
    except subprocess.CalledProcessError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ {model_config['name']}: {e}")
        return False

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–¥–µ–ª–µ–π
total_size = 0
for model in MODELS:
    if install_model(model):
        total_size += model['size_gb']

print(f"\n‚úÖ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
print(f"üìä –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: ~{total_size}GB")

PYTHON_SCRIPT

echo ""
echo "‚úÖ –ú–æ–¥–µ–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã!"
echo "üìÅ –†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ: ~/.mlx_models"

