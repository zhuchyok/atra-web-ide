#!/usr/bin/env python3
"""
–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –±–µ–∑ API –∑–∞–ø—Ä–æ—Å–æ–≤
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —á—Ç–æ tinyllama –∏—Å–∫–ª—é—á–µ–Ω–∞ –∏–∑ –≤—Å–µ—Ö —Å–ø–∏—Å–∫–æ–≤ –æ—Ç–≤–µ—Ç–æ–≤
"""

import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

def test_no_tinyllama_in_code():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ tinyllama –∏—Å–∫–ª—é—á–µ–Ω–∞ –∏–∑ –∫–æ–¥–∞"""
    print("üö´ –ü–†–û–í–ï–†–ö–ê: –ò—Å–∫–ª—é—á–µ–Ω–∏–µ tinyllama –∏–∑ –æ—Ç–≤–µ—Ç–æ–≤")
    print("=" * 60)
    
    files_to_check = [
        ("knowledge_os/app/react_agent.py", "fallback_models"),
        ("knowledge_os/app/extended_thinking.py", "fallback_models"),
        ("knowledge_os/app/victoria_enhanced.py", "model_priorities"),
        ("knowledge_os/app/mlx_api_server.py", "CATEGORY_TO_MODEL"),
        ("backend/app/routers/chat.py", "_select_model_for_chat")
    ]
    
    issues = []
    passed = 0
    
    for file_path, context in files_to_check:
        full_path = os.path.join(os.path.dirname(__file__), '..', file_path)
        if not os.path.exists(full_path):
            print(f"‚ö†Ô∏è –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
            continue
        
        with open(full_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ tinyllama –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤
        # (–º–æ–∂–µ—Ç –±—ã—Ç—å –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∞ –∏–ª–∏ –∏—Å–∫–ª—é—á–µ–Ω–∞)
        lines = content.split('\n')
        found_issues = []
        
        for i, line in enumerate(lines, 1):
            # –ò—â–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ tinyllama –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –æ—Ç–≤–µ—Ç–æ–≤
            if 'tinyllama' in line.lower() and 'tinyllama' in line:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –Ω–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∏ –Ω–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ
                stripped = line.strip()
                if not stripped.startswith('#') and '–∏—Å–∫–ª—é—á–µ–Ω–∞' not in line.lower() and '—Ç–æ–ª—å–∫–æ –¥–ª—è' not in line.lower():
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç - –Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤ —Å–ø–∏—Å–∫–∞—Ö –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤
                    if any(keyword in line.lower() for keyword in ['fallback', 'model', 'fast', 'default', 'return']):
                        found_issues.append((i, line.strip()[:80]))
        
        if found_issues:
            print(f"\n‚ùå {file_path}:")
            for line_num, line_content in found_issues[:3]:
                print(f"   –°—Ç—Ä–æ–∫–∞ {line_num}: {line_content}...")
            issues.extend([(file_path, i, l) for i, l in found_issues])
        else:
            print(f"‚úÖ {file_path}: tinyllama –∏—Å–∫–ª—é—á–µ–Ω–∞")
            passed += 1
    
    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç: {passed}/{len(files_to_check)} —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã")
    
    if issues:
        print(f"\n‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ {len(issues)} –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º")
        return False
    else:
        print("\n‚úÖ –í—Å–µ —Ñ–∞–π–ª—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã - tinyllama –∏—Å–∫–ª—é—á–µ–Ω–∞ –∏–∑ –æ—Ç–≤–µ—Ç–æ–≤")
        return True

def test_ollama_models_config():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ Ollama –º–æ–¥–µ–ª–µ–π"""
    print("\nüìã –ü–†–û–í–ï–†–ö–ê: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Ollama –º–æ–¥–µ–ª–µ–π")
    print("=" * 60)
    
    file_path = os.path.join(os.path.dirname(__file__), '..', 'knowledge_os/app/local_router.py')
    
    if not os.path.exists(file_path):
        print("‚ö†Ô∏è –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return False
    
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ OLLAMA_MODELS –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ
    if 'OLLAMA_MODELS' in content:
        print("‚úÖ OLLAMA_MODELS –Ω–∞–π–¥–µ–Ω—ã")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω—É–∂–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        required_models = ['phi3.5:3.8b', 'moondream', 'llava:7b']
        for model in required_models:
            if model in content:
                print(f"   ‚úÖ {model} –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
            else:
                print(f"   ‚ö†Ô∏è {model} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        return True
    else:
        print("‚ùå OLLAMA_MODELS –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return False

def test_queue_implementation():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –æ—á–µ—Ä–µ–¥–∏"""
    print("\nüîÑ –ü–†–û–í–ï–†–ö–ê: –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –æ—á–µ—Ä–µ–¥–∏")
    print("=" * 60)
    
    queue_file = os.path.join(os.path.dirname(__file__), '..', 'knowledge_os/app/mlx_request_queue.py')
    server_file = os.path.join(os.path.dirname(__file__), '..', 'knowledge_os/app/mlx_api_server.py')
    
    checks = []
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ mlx_request_queue.py
    if os.path.exists(queue_file):
        with open(queue_file, 'r', encoding='utf-8') as f:
            queue_content = f.read()
        
        if 'class MLXRequestQueue' in queue_content:
            checks.append(("MLXRequestQueue –∫–ª–∞—Å—Å", True))
        if 'RequestPriority' in queue_content:
            checks.append(("RequestPriority enum", True))
        if 'add_request' in queue_content:
            checks.append(("add_request –º–µ—Ç–æ–¥", True))
        if 'HIGH' in queue_content and 'MEDIUM' in queue_content:
            checks.append(("–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã HIGH/MEDIUM", True))
    else:
        checks.append(("mlx_request_queue.py —Ñ–∞–π–ª", False))
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ mlx_api_server.py
    if os.path.exists(server_file):
        with open(server_file, 'r', encoding='utf-8') as f:
            server_content = f.read()
        
        if 'X-Request-Priority' in server_content:
            checks.append(("–ü–æ–¥–¥–µ—Ä–∂–∫–∞ X-Request-Priority", True))
        if 'get_request_queue' in server_content:
            checks.append(("–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è get_request_queue", True))
        if '/queue/stats' in server_content:
            checks.append(("Endpoint /queue/stats", True))
    else:
        checks.append(("mlx_api_server.py —Ñ–∞–π–ª", False))
    
    for check_name, result in checks:
        status = "‚úÖ" if result else "‚ùå"
        print(f"   {status} {check_name}")
    
    return all(r for _, r in checks)

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üîç –ü–†–û–í–ï–†–ö–ê –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò –°–ò–°–¢–ï–ú–´")
    print("=" * 60)
    
    results = {}
    results["no_tinyllama"] = test_no_tinyllama_in_code()
    results["ollama_config"] = test_ollama_models_config()
    results["queue_impl"] = test_queue_implementation()
    
    print("\n" + "=" * 60)
    print("üìä –ò–¢–û–ì–ò –ü–†–û–í–ï–†–ö–ò –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò:")
    print("=" * 60)
    
    passed = sum(1 for v in results.values() if v)
    total = len(results)
    
    for test, result in results.items():
        status = "‚úÖ" if result else "‚ùå"
        print(f"   {status} {test}")
    
    print(f"\n‚úÖ –ü—Ä–æ–π–¥–µ–Ω–æ: {passed}/{total}")
    
    if passed == total:
        print("   ‚úÖ –í–°–ï –ü–†–û–í–ï–†–ö–ò –ü–†–û–ô–î–ï–ù–´!")
    else:
        print("   ‚ö†Ô∏è –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–µ –ø—Ä–æ—à–ª–∏")

if __name__ == "__main__":
    main()
