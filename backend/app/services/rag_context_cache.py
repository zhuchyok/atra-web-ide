"""
RAG Context Cache â€” ÐºÑÑˆ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð²ÐµÐºÑ‚Ð¾Ñ€Ð½Ð¾Ð³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ° (Ollama + MLX ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚).
Ð¡Ð½Ð¸Ð¶Ð°ÐµÑ‚ latency Ð¿Ñ€Ð¸ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð½Ñ‹Ñ… Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°Ñ…: embedding + Ð‘Ð” Ð½Ðµ Ð²Ñ‹Ð·Ñ‹Ð²Ð°ÑŽÑ‚ÑÑ.
"""
import hashlib
import json
import logging
import os
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

from app.config import get_settings

logger = logging.getLogger(__name__)

_redis_client = None
_cache_monitor: Optional["CacheMonitor"] = None


class CacheMonitor:
    """Ð¡Ñ‡Ñ‘Ñ‚Ñ‡Ð¸Ðº hits/misses Ð´Ð»Ñ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð° ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸ ÐºÑÑˆÐ°."""

    def __init__(self):
        self.hits = 0
        self.misses = 0
        self.hits_local = 0
        self.hits_redis = 0
        self.start_time = datetime.now()

    def record_hit(self, source: str = "local"):
        self.hits += 1
        if source == "redis":
            self.hits_redis += 1
        else:
            self.hits_local += 1

    def record_miss(self):
        self.misses += 1

    def get_stats(self) -> Dict[str, Any]:
        total = self.hits + self.misses
        hit_rate = (self.hits / total * 100) if total > 0 else 0.0
        return {
            "hit_rate_pct": round(hit_rate, 1),
            "hits": self.hits,
            "misses": self.misses,
            "hits_local": self.hits_local,
            "hits_redis": self.hits_redis,
            "total": total,
            "uptime_sec": (datetime.now() - self.start_time).total_seconds(),
        }


def _get_redis():
    global _redis_client
    if _redis_client is not None:
        return _redis_client
    try:
        import redis.asyncio as aioredis
        settings = get_settings()
        url = getattr(settings, "redis_url", None) or os.getenv("REDIS_URL")
        if url:
            _redis_client = aioredis.from_url(url, decode_responses=True)
            return _redis_client
    except Exception as e:
        logger.debug("Redis for RAG cache: %s", e)
    return None


def _generate_key(
    goal: str,
    user_id: Optional[str] = None,
    collection: str = "default",
    embedding_model: Optional[str] = None,
    limit: int = 3,
    threshold: float = 0.65,
) -> str:
    """Ð£Ð½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¹ ÐºÐ»ÑŽÑ‡ Ñ ÑƒÑ‡Ñ‘Ñ‚Ð¾Ð¼ Ð²ÑÐµÑ… Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð² Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°."""
    settings = get_settings()
    components = {
        "goal": (goal or "").strip().lower(),
        "user_id": user_id or "global",
        "collection": collection,
        "embedding_model": embedding_model or getattr(settings, "ollama_embed_model", "nomic-embed-text"),
        "limit": limit,
        "threshold": round(threshold, 2),
    }
    key_str = json.dumps(components, sort_keys=True)
    h = hashlib.sha256(key_str.encode()).hexdigest()[:24]
    return f"rag_ctx:{h}"


_rag_context_cache: Optional["RAGContextCache"] = None


def get_cache_monitor() -> "CacheMonitor":
    """Ð“Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€ ÐºÑÑˆÐ° Ð´Ð»Ñ API."""
    global _cache_monitor
    if _cache_monitor is None:
        _cache_monitor = CacheMonitor()
    return _cache_monitor


def get_rag_context_cache(ttl: int = 300, use_redis: bool = True) -> "RAGContextCache":
    """Singleton RAGContextCache Ð´Ð»Ñ Auto-Optimizer Ð¸ RAGLightService."""
    global _rag_context_cache
    if _rag_context_cache is None:
        _rag_context_cache = RAGContextCache(ttl=ttl, use_redis=use_redis)
    return _rag_context_cache


class RAGContextCache:
    """ÐšÑÑˆ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð° RAG (Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð²ÐµÐºÑ‚Ð¾Ñ€Ð½Ð¾Ð³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ°)."""

    def __init__(
        self,
        ttl: int = 300,
        use_redis: bool = True,
        local_maxsize: int = 200,
    ):
        self.ttl = ttl
        self.use_redis = use_redis
        self._local: Dict[str, Tuple[List[Tuple[str, float]], float]] = {}
        self._local_max = local_maxsize
        self.monitor = get_cache_monitor()
        self._min_ttl = 60
        self._max_ttl = 600

    def get_current_ttl(self) -> int:
        """Ð¢ÐµÐºÑƒÑ‰Ð¸Ð¹ TTL Ð² ÑÐµÐºÑƒÐ½Ð´Ð°Ñ… (Ð´Ð»Ñ Auto-Optimizer)."""
        return self.ttl

    def set_ttl(self, ttl: int) -> None:
        """Ð”Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ðµ TTL (Ð´Ð»Ñ Auto-Optimizer)."""
        self.ttl = max(self._min_ttl, min(ttl, self._max_ttl))

    async def get_context(
        self,
        goal: str,
        user_id: Optional[str] = None,
        limit: int = 3,
        threshold: float = 0.65,
    ) -> Optional[List[Tuple[str, float]]]:
        """ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÐºÑÑˆÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ [(content, score), ...]."""
        key = _generate_key(goal, user_id, limit=limit, threshold=threshold)

        if key in self._local:
            chunks, _ = self._local[key]
            self.monitor.record_hit("local")
            logger.info("âœ… RAG cache hit (local): %s...", (goal or "")[:40])
            return chunks

        if self.use_redis:
            r = _get_redis()
            if r:
                try:
                    raw = await r.get(key)
                    if raw:
                        data = json.loads(raw)
                        chunks = [tuple(c) for c in data.get("chunks", [])]
                        self.monitor.record_hit("redis")
                        logger.info("âœ… RAG cache hit (redis): %s...", (goal or "")[:40])
                        return chunks
                except Exception as e:
                    logger.debug("RAG cache redis get: %s", e)

        self.monitor.record_miss()
        logger.debug("ðŸ”„ RAG cache miss: %s...", (goal or "")[:40])
        return None

    async def save_context(
        self,
        goal: str,
        chunks: List[Tuple[str, float]],
        user_id: Optional[str] = None,
        limit: int = 3,
        threshold: float = 0.65,
    ) -> None:
        """Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð² ÐºÑÑˆ."""
        if not chunks:
            return
        key = _generate_key(goal, user_id, limit=limit, threshold=threshold)
        data = {"chunks": list(chunks)}

        while len(self._local) >= self._local_max and self._local:
            self._local.pop(next(iter(self._local)))
        self._local[key] = (chunks, 0.0)

        if self.use_redis:
            r = _get_redis()
            if r:
                try:
                    await r.setex(key, self.ttl, json.dumps(data, ensure_ascii=False))
                except Exception as e:
                    logger.debug("RAG cache redis set: %s", e)
