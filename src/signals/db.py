"""
–ú–æ–¥—É–ª—å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö —Ç–æ—Ä–≥–æ–≤–æ–≥–æ –±–æ—Ç–∞ ATRA.

–°–æ–¥–µ—Ä–∂–∏—Ç –∫–ª–∞—Å—Å Database –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è SQLite –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö,
–≤–∫–ª—é—á–∞—è –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å —Å–∏–≥–Ω–∞–ª–∞–º–∏, –ø–æ–∑–∏—Ü–∏—è–º–∏, –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏,
–Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –∏ –¥—Ä—É–≥–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ —Å–∏—Å—Ç–µ–º—ã.
"""

# pylint: disable=too-many-lines
import sqlite3
import logging
import shutil
import os
import time
import re
import json
import threading
import random
import ast
import asyncio
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Tuple, Optional
from src.shared.utils.datetime_utils import get_utc_now
from src.database.fetch_optimizer import fetch_all_optimized
from config import (
    DATABASE,
    RETENTION_QUOTES_DAYS,
    RETENTION_SIGNALS_DAYS,
    RETENTION_SIGNALS_LOG_DAYS,
    RETENTION_ACCUM_EVENTS_DAYS,
    RETENTION_APP_CACHE_DAYS,
    RETENTION_ENABLE_WEEKLY_VACUUM,
    # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    ADAPTIVE_ENGINE_ENABLED,
    METRICS_FEEDER_ENABLED,
    METRICS_FEEDER_INTERVAL_SEC,
    METRICS_CACHE_TTL_SEC,
    PERFORMANCE_LOOKBACK_DAYS,
    ADAPTIVE_ENTRY_ADJ_ENABLED,
    ADAPTIVE_ENTRY_MAX_ADJUST_PCT,
    DYNAMIC_MODE_SWITCH_ENABLED,
    CORRELATION_COOLDOWN_ENABLED,
    CORRELATION_LOOKBACK_HOURS,
    CORRELATION_MAX_PAIRWISE,
    CORRELATION_COOLDOWN_SEC,
    SOFT_BLOCKLIST_ENABLED,
    SOFT_BLOCKLIST_HYSTERESIS,
    SOFT_BLOCK_COOLDOWN_HOURS,
    MIN_ACTIVE_COINS,
    BLOCKLIST_CHURN_FRAC,
    DYNAMIC_CALC_INTERVAL,
    DYNAMIC_TP_ENABLED,
    VOLUME_BLOCKS_ENABLED,
)

logger = logging.getLogger(__name__)


def _safe_float(value: Any) -> Optional[float]:
    try:
        return float(value)
    except (TypeError, ValueError):
        return None


# –î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è
def profile(func):
    """–î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–π"""
    def wrapper(*args, **kwargs):
        start = time.perf_counter()
        result = func(*args, **kwargs)
        elapsed = time.perf_counter() - start
        logging.info("%s –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –∑–∞ %.3f —Å–µ–∫", func.__name__, elapsed)
        return result

    return wrapper


BACKUP_DIR = "backups"


def backup_file(filepath, backup_dir=BACKUP_DIR):
    """–°–æ–∑–¥–∞–µ—Ç —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é —Ñ–∞–π–ª–∞ —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π"""
    os.makedirs(backup_dir, exist_ok=True)
    source = Path(filepath)
    if not source.is_file():
        logging.warning("–ë—ç–∫–∞–ø –ø—Ä–æ–ø—É—â–µ–Ω: —Ñ–∞–π–ª %s –Ω–µ –Ω–∞–π–¥–µ–Ω", filepath)
        return None

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_path = Path(backup_dir) / f"{source.name}_{timestamp}"

    try:
        source_uri = f"file:{source.resolve()}?mode=ro"
        with sqlite3.connect(source_uri, uri=True) as src_conn:
            with sqlite3.connect(str(backup_path)) as dst_conn:
                src_conn.backup(dst_conn)
        logging.info("SQLite backup %s -> %s", source, backup_path)
    except sqlite3.Error as exc:
        # –§–æ–ª–±—ç–∫ –Ω–∞ –ø—Ä—è–º–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ (–Ω–∞ —Å–ª—É—á–∞–π —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π sqlite)
        shutil.copy(str(source), str(backup_path))
        logging.warning(
            "SQLite backup API –æ—à–∏–±–∫–∞ (%s), –≤—ã–ø–æ–ª–Ω–µ–Ω–æ –ø—Ä—è–º–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ %s -> %s",
            exc,
            source,
            backup_path,
        )

    return str(backup_path)


class Database:
    """PiuX_Trade: –ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –∏ —Å–¥–µ–ª–æ–∫."""

    _instance = None
    _instance_lock = threading.Lock()
    _db_usage_logged_once = False
    _readonly_instance = None

    def __new__(cls, *args, **kwargs):
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç—Å—è –ª–∏ read-only —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
        readonly = kwargs.get('readonly', False)

        with cls._instance_lock:
            if readonly:
                # –î–ª—è read-only —Å–æ–∑–¥–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
                if cls._readonly_instance is None:
                    cls._readonly_instance = super(Database, cls).__new__(cls)
                    cls._readonly_instance._initialized = False
                    cls._readonly_instance._is_readonly = True
                return cls._readonly_instance
            else:
                # –î–ª—è –∑–∞–ø–∏—Å–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º singleton
                if cls._instance is None:
                    cls._instance = super(Database, cls).__new__(cls)
                    cls._instance._initialized = False
                    cls._instance._is_readonly = False
                return cls._instance

    def __init__(self, db_path=DATABASE, use_connection_pool: bool = False, readonly: bool = False):
        """
        Args:
            db_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –ë–î
            use_connection_pool: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å connection pool (–û–¢–ö–õ–Æ–ß–ï–ù–û)
            readonly: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å read-only —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ (–¥–ª—è —Ä–∏–¥–µ—Ä–æ–≤)
        """
        if getattr(self, '_initialized', False):
            return

        self.db_path = db_path
        self._is_readonly = getattr(self, '_is_readonly', readonly)
        # üîß –ò–°–ü–†–ê–í–õ–ï–ù–û: –≤—Å–µ–≥–¥–∞ –æ—Ç–∫–ª—é—á–∞–µ–º connection_pool
        self.use_connection_pool = False
        self._pool = None
        self._use_pool = False

        # –ü—Ä—è–º–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ (fallback –∏–ª–∏ –µ—Å–ª–∏ pool –æ—Ç–∫–ª—é—á–µ–Ω)
        if not self._use_pool:
            # –†–∞–∑—Ä–µ—à–∞–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –∏–∑ —Ä–∞–∑–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤
            # –í–∞–∂–Ω–æ: –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—é –∑–∞–ø–∏—Å–µ–π —á–µ—Ä–µ–∑ lock
            if self._is_readonly:
                # Read-only —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–∑ URI
                db_uri = f"file:{os.path.abspath(db_path)}?mode=ro"
                self.conn = sqlite3.connect(db_uri, uri=True, check_same_thread=False, timeout=60.0)
                logging.info("‚úÖ [DB] –°–æ–∑–¥–∞–Ω–æ read-only —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ: %s", db_path)
            else:
                self.conn = sqlite3.connect(db_path, check_same_thread=False, timeout=60.0)
                # –í–∫–ª—é—á–∞–µ–º WAL –∏ –¥—Ä—É–≥–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å—Ä–∞–∑—É –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
                try:
                    self.conn.execute("PRAGMA journal_mode=WAL;")
                    self.conn.execute("PRAGMA synchronous=NORMAL;")
                    self.conn.execute("PRAGMA busy_timeout=60000;")
                except sqlite3.Error as e:
                    logging.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–º–µ–Ω–∏—Ç—å PRAGMA –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: %s", e)
            self.cursor = self.conn.cursor()
        else:
            # –ü—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ pool —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–æ–ª—É—á–∞–µ–º –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏
            self.conn = None
            self.cursor = None

        self._lock = threading.RLock()
        # –ü–æ–ø—ã—Ç–∫–∞ –∞–≤—Ç–æ-—Ä–µ–º–æ–Ω—Ç–∞, –µ—Å–ª–∏ —Å—Ö–µ–º–∞ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∞
        # (e.g., "malformed database schema (ETHUSDT)")
        # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –ø—Ä—è–º–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ (–Ω–µ pool)
        if not self._use_pool and self.conn is not None:
            self._try_repair_malformed_schema()
            # –†–µ–∂–∏–º WAL –∏ busy_timeout –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –∫–æ–Ω–∫—É—Ä—Ä–µ–Ω—Ç–Ω–æ—Å—Ç–∏
            try:
                with self._lock:
                    self.conn.execute("PRAGMA journal_mode=WAL;")
                    self.conn.execute("PRAGMA synchronous=NORMAL;")
                    self.conn.execute("PRAGMA busy_timeout=60000;")  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–æ 60s
                    # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è cache_size: –∏—Å–ø–æ–ª—å–∑—É–µ–º 64MB –∏–ª–∏ 25% –æ—Ç RAM (–º–∏–Ω 64MB)
                    import psutil
                    try:
                        available_ram_mb = psutil.virtual_memory().total / (1024 * 1024)
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º 25% –æ—Ç RAM, –Ω–æ –º–∏–Ω–∏–º—É–º 64MB –∏ –º–∞–∫—Å–∏–º—É–º 512MB
                        optimal_cache_mb = max(64, min(512, int(available_ram_mb * 0.25)))
                        cache_size_kb = -optimal_cache_mb * 1024  # –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ = KB
                        self.conn.execute(f"PRAGMA cache_size={cache_size_kb};")
                        logging.info("‚úÖ [DB] PRAGMA cache_size —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: %dMB", optimal_cache_mb)
                    except Exception:
                        # Fallback –Ω–∞ 64MB –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å RAM
                        self.conn.execute("PRAGMA cache_size=-64000;")  # 64MB cache
                    self.conn.execute("PRAGMA mmap_size=268435456;")  # 256MB mmap
                    self.conn.execute("PRAGMA temp_store=MEMORY;")
                    self.conn.execute("PRAGMA foreign_keys=ON;")  # –í–∫–ª—é—á–∏—Ç—å FK
            except sqlite3.Error as e:
                logging.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–º–µ–Ω–∏—Ç—å PRAGMA –¥–ª—è –ë–î: %s", e)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–∞–±–ª–∏—Ü
        self._initialize_tables_on_init()
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π (–¢–û–õ–¨–ö–û –µ—Å–ª–∏ —è–≤–Ω–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–æ —á–µ—Ä–µ–∑ ENV)
        try:
            if os.getenv('AUTO_APPLY_OPTIMIZATIONS', 'false').lower() == 'true':
                from src.database.optimization_manager import DatabaseOptimizationManager
                opt_manager = DatabaseOptimizationManager(self)
                opt_manager.apply_all_optimizations()
                logging.debug("‚úÖ [DB] –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã")
        except Exception as e:
            logging.debug("‚ö†Ô∏è [DB] –û—à–∏–±–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π: %s", e)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è write queue (–ª–µ–Ω–∏–≤–∞—è, –ø—Ä–∏ –ø–µ—Ä–≤–æ–º async –≤—ã–∑–æ–≤–µ)
        self._write_queue: Optional[Any] = None
        self._write_queue_initialized = False
        
        # Prepared statements cache –¥–ª—è –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–ª–∞–Ω–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤
        self._prepared_statements: Dict[str, Any] = {}
        
        # Query cache –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤
        self._query_cache_enabled = True
        try:
            from src.database.query_cache import get_query_cache
            self._query_cache = get_query_cache()
        except ImportError:
            self._query_cache = None
            self._query_cache_enabled = False
        
        self._initialized = True

    def _get_db_executor(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏—é-–∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –¥–ª—è write queue"""
        def db_executor(query: str, params: Any = (), is_write: bool = True, executemany: bool = False):
            """–°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –¥–ª—è write queue"""
            with self._lock:
                if executemany:
                    self.cursor.executemany(query, params)
                else:
                    self.cursor.execute(query, params)
                if is_write:
                    self.conn.commit()
                return fetch_all_optimized(self.cursor) if not is_write else True
        return db_executor

    async def _ensure_write_queue(self):
        """–û–±–µ—Å–ø–µ—á–∏—Ç—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é write queue"""
        if not self._write_queue_initialized:
            try:
                from src.database.write_queue import get_write_queue
                self._write_queue = await get_write_queue(
                    db_executor=self._get_db_executor(),
                    max_retries=5,
                    initial_retry_delay=0.5,
                    max_queue_size=1000,
                    enable_metrics=True,
                )
                self._write_queue_initialized = True
                logging.info("‚úÖ [DB] Write queue –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            except Exception as e:
                logging.warning("‚ö†Ô∏è [DB] –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å write queue: %s", e)
                self._write_queue = None

    async def execute_with_retry_async(
        self,
        query: str,
        params: tuple = (),
        is_write: bool = True,
        max_retries: int = 5,
        use_queue: bool = True,
    ):
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ SQL –∑–∞–ø—Ä–æ—Å–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º write queue

        Args:
            query: SQL –∑–∞–ø—Ä–æ—Å
            params: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
            is_write: –Ø–≤–ª—è–µ—Ç—Å—è –ª–∏ –æ–ø–µ—Ä–∞—Ü–∏—è –∑–∞–ø–∏—Å—å—é
            max_retries: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª-–≤–æ –ø–æ–ø—ã—Ç–æ–∫ (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
            use_queue: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å write queue (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é True)

        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞
        """
        # –ï—Å–ª–∏ write queue –æ—Ç–∫–ª—é—á–µ–Ω –∏–ª–∏ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥
        if not use_queue or self._write_queue is None:
            await self._ensure_write_queue()

        if use_queue and self._write_queue is not None:
            try:
                from src.database.write_queue import WriteOperationType
                result = await self._write_queue.execute(
                    query=query,
                    params=params,
                    is_write=is_write,
                    operation_type=WriteOperationType.EXECUTE,
                )
                return result
            except Exception as e:
                logging.warning(
                    "‚ö†Ô∏è [DB] –û—à–∏–±–∫–∞ –≤ write queue, fallback –Ω–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥: %s", e
                )

        # Fallback –Ω–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ —á–µ—Ä–µ–∑ asyncio.to_thread
        return await asyncio.to_thread(
            self.execute_with_retry,
            query,
            params,
            is_write,
            max_retries
        )

    def _get_prepared_statement(self, query: str):
        """
        –ü–æ–ª—É—á–∞–µ—Ç –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç prepared statement –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
        –£—Å–∫–æ—Ä—è–µ—Ç –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –∑–∞–ø—Ä–æ—Å—ã –Ω–∞ 10-20%
        """
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∫–ª—é—á (—É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã, –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É)
        query_key = ' '.join(query.strip().split()).lower()
        
        if query_key not in self._prepared_statements:
            # SQLite –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∫—ç—à–∏—Ä—É–µ—Ç prepared statements, –Ω–æ –º—ã –º–æ–∂–µ–º
            # —è–≤–Ω–æ –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            self._prepared_statements[query_key] = query
        
        return self._prepared_statements[query_key]
    
    def _serialize_quality_meta(self, quality_meta: Any) -> Optional[str]:
        """
        –ë—ã—Å—Ç—Ä–∞—è —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è quality_meta —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º MessagePack
        –£—Å–∫–æ—Ä—è–µ—Ç —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—é –Ω–∞ 2-3x
        """
        if not isinstance(quality_meta, dict):
            return None
        
        try:
            from src.data.serialization import serialize_fast
            import base64
            data_serialized = serialize_fast(quality_meta)
            return base64.b64encode(data_serialized).decode('utf-8')
        except (ImportError, Exception):
            # Fallback –Ω–∞ JSON
            return json.dumps(quality_meta, ensure_ascii=False)

    def execute_with_retry(
        self,
        query: str,
        params: tuple = (),
        is_write: bool = True,
        max_retries: int = 5,
        use_prepared: bool = True,
        use_cache: bool = True,
        cache_ttl: int = 300
    ):
        """
        SQL –∑–∞–ø—Ä–æ—Å —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ –ø—Ä–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–µ.
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç prepared statements –∏ Redis –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è.
        
        Args:
            query: SQL –∑–∞–ø—Ä–æ—Å
            params: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
            is_write: –Ø–≤–ª—è–µ—Ç—Å—è –ª–∏ –∑–∞–ø—Ä–æ—Å –∑–∞–ø–∏—Å—å—é
            max_retries: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫
            use_prepared: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å prepared statements
            use_cache: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Redis –∫—ç—à –¥–ª—è read-only –∑–∞–ø—Ä–æ—Å–æ–≤
            cache_ttl: –í—Ä–µ–º—è –∂–∏–∑–Ω–∏ –∫—ç—à–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        """
        # –î–ª—è read-only –∑–∞–ø—Ä–æ—Å–æ–≤ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        if not is_write and use_cache:
            try:
                from src.database.redis_cache import get_from_cache
                cached_result = get_from_cache(query, params, ttl=cache_ttl)
                if cached_result is not None:
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ –∫–æ—Ä—Ç–µ–∂–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                    if isinstance(cached_result, list) and cached_result:
                        if isinstance(cached_result[0], list):
                            return [tuple(row) for row in cached_result]
                    return cached_result
            except Exception as e:
                logging.debug("‚ö†Ô∏è [DB] –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫—ç—à–∞: %s", e)
        
        retry_delay = 0.5
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º prepared statement –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ –∏ –∑–∞–ø—Ä–æ—Å –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–π—Å—è
        if use_prepared and not is_write:
            query = self._get_prepared_statement(query)
        
        for attempt in range(max_retries):
            try:
                with self._lock:
                    self.cursor.execute(query, params)
                    if is_write:
                        self.conn.commit()
                    return fetch_all_optimized(self.cursor) if not is_write else True
            except sqlite3.OperationalError as e:
                if "locked" in str(e).lower() and attempt < max_retries - 1:
                    logging.warning(
                        "‚ö†Ô∏è –ë–î –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞ (–ø–æ–ø—ã—Ç–∫–∞ %d/%d), –∂–¥–µ–º %.1f—Å...", 
                        attempt + 1, max_retries, retry_delay
                    )
                    time.sleep(retry_delay)
                    retry_delay *= 2
                    continue
                logging.error("‚ùå –û—à–∏–±–∫–∞ –ë–î –ø–æ—Å–ª–µ %d –ø–æ–ø—ã—Ç–æ–∫: %s", max_retries, e)
                raise e
            except Exception as e:
                logging.error("‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ë–î: %s", e)
                raise e
        return False

    def execute_batch(self, queries: List[Tuple[str, tuple]], is_write: bool = True, max_retries: int = 5) -> bool:
        """
        –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ batch –æ–ø–µ—Ä–∞—Ü–∏–π –≤ –æ–¥–Ω–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
        –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è –º–∞—Å—Å–æ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π (50-90% —É—Å–∫–æ—Ä–µ–Ω–∏–µ)
        
        Args:
            queries: –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (query, params)
            is_write: –Ø–≤–ª—è—é—Ç—Å—è –ª–∏ –æ–ø–µ—Ä–∞—Ü–∏–∏ –∑–∞–ø–∏—Å—è–º–∏
            max_retries: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫
            
        Returns:
            True –ø—Ä–∏ —É—Å–ø–µ—Ö–µ, False –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        retry_delay = 0.5
        
        for attempt in range(max_retries):
            try:
                with self._lock:
                    self.conn.execute("BEGIN TRANSACTION")
                    try:
                        for query, params in queries:
                            self.cursor.execute(query, params)
                        if is_write:
                            self.conn.commit()
                        else:
                            self.conn.rollback()
                        return True
                    except Exception as e:
                        self.conn.rollback()
                        raise e
            except sqlite3.OperationalError as e:
                if "locked" in str(e).lower() and attempt < max_retries - 1:
                    logging.warning("‚ö†Ô∏è –ë–î –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞ –ø—Ä–∏ batch –æ–ø–µ—Ä–∞—Ü–∏–∏ (–ø–æ–ø—ã—Ç–∫–∞ %d/%d), –∂–¥–µ–º %.1f—Å...", 
                                    attempt + 1, max_retries, retry_delay)
                    time.sleep(retry_delay)
                    retry_delay *= 2
                    continue
                logging.error("‚ùå –û—à–∏–±–∫–∞ batch –æ–ø–µ—Ä–∞—Ü–∏–∏ –ø–æ—Å–ª–µ %d –ø–æ–ø—ã—Ç–æ–∫: %s", max_retries, e)
                return False
            except Exception as e:
                logging.error("‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ batch –æ–ø–µ—Ä–∞—Ü–∏–∏: %s", e)
                return False
        return False

    def _get_table_indexes(self, table_name: str) -> List[Tuple[str, str]]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã
        
        Args:
            table_name: –ò–º—è —Ç–∞–±–ª–∏—Ü—ã
            
        Returns:
            –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (index_name, create_sql)
        """
        indexes = []
        try:
            with self._lock:
                # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã
                cursor = self.conn.execute("""
                    SELECT name, sql FROM sqlite_master 
                    WHERE type='index' AND tbl_name=? AND sql IS NOT NULL
                """, (table_name,))
                indexes = [(row[0], row[1]) for row in fetch_all_optimized(cursor)]
        except Exception as e:
            logging.warning("‚ö†Ô∏è [DB] –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è %s: %s", table_name, e)
        return indexes

    def _disable_indexes_for_table(self, table_name: str) -> List[Tuple[str, str]]:
        """
        –í—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–∞–µ—Ç –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã (—É–¥–∞–ª—è–µ—Ç –∏—Ö)
        
        Args:
            table_name: –ò–º—è —Ç–∞–±–ª–∏—Ü—ã
            
        Returns:
            –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (index_name, create_sql) –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
        """
        indexes = self._get_table_indexes(table_name)
        if not indexes:
            return []
        
        disabled_indexes = []
        try:
            with self._lock:
                for index_name, create_sql in indexes:
                    try:
                        # –£–¥–∞–ª—è–µ–º –∏–Ω–¥–µ–∫—Å
                        self.conn.execute(f"DROP INDEX IF EXISTS {index_name}")
                        disabled_indexes.append((index_name, create_sql))
                        logging.debug("‚úÖ [DB] –í—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω –∏–Ω–¥–µ–∫—Å: %s", index_name)
                    except Exception as e:
                        logging.warning("‚ö†Ô∏è [DB] –û—à–∏–±–∫–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞ %s: %s", index_name, e)
        except Exception as e:
            logging.warning("‚ö†Ô∏è [DB] –û—à–∏–±–∫–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è %s: %s", table_name, e)
        
        return disabled_indexes

    def _restore_indexes(self, disabled_indexes: List[Tuple[str, str]]) -> bool:
        """
        –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ä–∞–Ω–µ–µ –æ—Ç–∫–ª—é—á–µ–Ω–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã
        
        Args:
            disabled_indexes: –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (index_name, create_sql)
            
        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –≤—Å–µ –∏–Ω–¥–µ–∫—Å—ã
        """
        if not disabled_indexes:
            return True
        
        success_count = 0
        try:
            with self._lock:
                for index_name, create_sql in disabled_indexes:
                    try:
                        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å
                        self.conn.execute(create_sql)
                        success_count += 1
                        logging.debug("‚úÖ [DB] –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–Ω–¥–µ–∫—Å: %s", index_name)
                    except Exception as e:
                        logging.warning("‚ö†Ô∏è [DB] –û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞ %s: %s", index_name, e)
        except Exception as e:
            logging.warning("‚ö†Ô∏è [DB] –û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤: %s", e)
        
        return success_count == len(disabled_indexes)

    def executemany_optimized(
        self, 
        query: str, 
        params_list: List[tuple], 
        max_retries: int = 5,
        disable_indexes: bool = True
    ) -> bool:
        """
        –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π executemany —Å –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ–º –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è –º–∞—Å—Å–æ–≤–æ–π –≤—Å—Ç–∞–≤–∫–∏
        –£—Å–∫–æ—Ä–µ–Ω–∏–µ –Ω–∞ 50-90% –¥–ª—è –º–∞—Å—Å–æ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
        
        Args:
            query: SQL –∑–∞–ø—Ä–æ—Å
            params_list: –°–ø–∏—Å–æ–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è executemany
            max_retries: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫
            disable_indexes: –û—Ç–∫–ª—é—á–∞—Ç—å –ª–∏ –∏–Ω–¥–µ–∫—Å—ã –ø–µ—Ä–µ–¥ –≤—Å—Ç–∞–≤–∫–æ–π (—É—Å–∫–æ—Ä–µ–Ω–∏–µ 50-90%)
            
        Returns:
            True –ø—Ä–∏ —É—Å–ø–µ—Ö–µ, False –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è —Ç–∞–±–ª–∏—Ü—ã –∏–∑ INSERT –∑–∞–ø—Ä–æ—Å–∞
        table_name = None
        disabled_indexes = []
        
        if disable_indexes and query.strip().upper().startswith('INSERT'):
            try:
                # –ü–∞—Ä—Å–∏–º –∏–º—è —Ç–∞–±–ª–∏—Ü—ã –∏–∑ INSERT –∑–∞–ø—Ä–æ—Å–∞
                match = re.search(r'INSERT\s+INTO\s+(\w+)', query, re.IGNORECASE)
                if match:
                    table_name = match.group(1)
                    # –û—Ç–∫–ª—é—á–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –ø–µ—Ä–µ–¥ –º–∞—Å—Å–æ–≤–æ–π –≤—Å—Ç–∞–≤–∫–æ–π
                    disabled_indexes = self._disable_indexes_for_table(table_name)
                    if disabled_indexes:
                        logging.info("‚úÖ [DB] –û—Ç–∫–ª—é—á–µ–Ω–æ %d –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è –º–∞—Å—Å–æ–≤–æ–π –≤—Å—Ç–∞–≤–∫–∏ –≤ %s", 
                                   len(disabled_indexes), table_name)
            except Exception as e:
                logging.warning("‚ö†Ô∏è [DB] –û—à–∏–±–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è –æ—Ç–∫–ª—é—á–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤: %s", e)
        
        retry_delay = 0.5
        
        try:
            for attempt in range(max_retries):
                try:
                    with self._lock:
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
                        old_synchronous = self.conn.execute("PRAGMA synchronous").fetchone()[0]
                        
                        try:
                            # –û—Ç–∫–ª—é—á–∞–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –º–∞—Å—Å–æ–≤–æ–π –≤—Å—Ç–∞–≤–∫–∏
                            self.conn.execute("PRAGMA synchronous=OFF")
                            self.conn.execute("BEGIN TRANSACTION")
                            
                            self.cursor.executemany(query, params_list)
                            self.conn.commit()
                            
                            # –í–∫–ª—é—á–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ
                            self.conn.execute(f"PRAGMA synchronous={old_synchronous}")
                            
                            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –≤—Å—Ç–∞–≤–∫–∏
                            if disabled_indexes:
                                self._restore_indexes(disabled_indexes)
                                logging.info("‚úÖ [DB] –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ %d –∏–Ω–¥–µ–∫—Å–æ–≤ –ø–æ—Å–ª–µ –º–∞—Å—Å–æ–≤–æ–π –≤—Å—Ç–∞–≤–∫–∏", 
                                           len(disabled_indexes))
                            
                            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–ø–æ–ª–Ω—è–µ–º ANALYZE –ø–æ—Å–ª–µ –º–∞—Å—Å–æ–≤–æ–π –≤—Å—Ç–∞–≤–∫–∏ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                            try:
                                self.conn.execute("ANALYZE")
                                logging.debug("‚úÖ [DB] ANALYZE –≤—ã–ø–æ–ª–Ω–µ–Ω –ø–æ—Å–ª–µ –º–∞—Å—Å–æ–≤–æ–π –≤—Å—Ç–∞–≤–∫–∏")
                            except Exception as e:
                                logging.debug("‚ö†Ô∏è [DB] –û—à–∏–±–∫–∞ ANALYZE –ø–æ—Å–ª–µ –º–∞—Å—Å–æ–≤–æ–π –≤—Å—Ç–∞–≤–∫–∏: %s", e)
                            
                            return True
                        except Exception as e:
                            self.conn.rollback()
                            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ
                            self.conn.execute(f"PRAGMA synchronous={old_synchronous}")
                            raise e
                except sqlite3.OperationalError as e:
                    if "locked" in str(e).lower() and attempt < max_retries - 1:
                        logging.warning("‚ö†Ô∏è –ë–î –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞ –ø—Ä–∏ executemany (–ø–æ–ø—ã—Ç–∫–∞ %d/%d), –∂–¥–µ–º %.1f—Å...", 
                                        attempt + 1, max_retries, retry_delay)
                        time.sleep(retry_delay)
                        retry_delay *= 2
                        continue
                    logging.error("‚ùå –û—à–∏–±–∫–∞ executemany –ø–æ—Å–ª–µ %d –ø–æ–ø—ã—Ç–æ–∫: %s", max_retries, e)
                    return False
                except Exception as e:
                    logging.error("‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ executemany: %s", e)
                    return False
        finally:
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ
            if disabled_indexes:
                try:
                    self._restore_indexes(disabled_indexes)
                except Exception as e:
                    logging.error("‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤: %s", e)
        
        return False

    def _initialize_tables_on_init(self):
        """–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç–∞–±–ª–∏—Ü –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏"""
        try:
            # üîß –ò–°–ü–†–ê–í–õ–ï–ù–û: connection_pool –æ—Ç–∫–ª—é—á–µ–Ω
            if self.conn is not None:
                self._init_tables()
            else:
                logging.warning("‚ö†Ô∏è [DB] –ù–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î")
        except sqlite3.DatabaseError as e:
            # –§–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–æ–ª–±—ç–∫: –µ—Å–ª–∏ —Å—Ö–µ–º–∞ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∞ ‚Äî —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π —Ñ–∞–π–ª –ë–î.
            if "malformed database schema" in str(e).lower():
                logging.error(
                    "–°—Ö–µ–º–∞ –ë–î –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∞. –ü–µ—Ä–µ—Å–æ–∑–¥–∞—é –ë–î (–±—ç–∫–∞–ø –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω)‚Ä¶"
                )
                self._reset_database_preserving_backup()
            else:
                raise
        if not Database._db_usage_logged_once:
            print(f"[PiuX_Trade][DB] –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {self.db_path}")
            Database._db_usage_logged_once = True
        # –§–∞–π–ª —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –±–æ—Ç–∞ (–≤ JSON)
        self.user_data_file = "user_data.json"

    def is_connected(self):
        """–ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î."""
        try:
            # üîß –ò–°–ü–†–ê–í–õ–ï–ù–û: –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä—è–º–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
            if self.conn is None:
                return False
            with self._lock:
                self.conn.execute("SELECT 1")
            return True
        except (sqlite3.Error, ValueError, AttributeError, RuntimeError) as e:
            logging.debug("is_connected check failed: %s", e)
            return False

    def get_lock(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –ë–î."""
        return self._lock

    def _try_repair_malformed_schema(self):
        """
        –£—Å—Ç—Ä–∞–Ω—è–µ—Ç –∑–∞–ø–∏—Å–∏ —Å –ø–æ–≤—Ä–µ–∂–¥—ë–Ω–Ω–æ–π —Å—Ö–µ–º–æ–π –≤ sqlite_master
        (—Ç–∏–ø–∏—á–Ω—ã–π –∫–µ–π—Å: —Å—Ç–∞—Ä—ã–µ —Ç–∞–±–ª–∏—Ü—ã —Å –∏–º–µ–Ω–∞–º–∏ —Å–∏–º–≤–æ–ª–æ–≤).

        –õ–æ–≥–∏–∫–∞:
        - –ü—ã—Ç–∞–µ–º—Å—è —É–¥–∞–ª–∏—Ç—å –æ–±—ä–µ–∫—Ç –æ–±—ã—á–Ω—ã–º–∏ DROP-–∫–æ–º–∞–Ω–¥–∞–º–∏.
        - –ï—Å–ª–∏ –Ω–µ —É–¥–∞—ë—Ç—Å—è ‚Äî —É–¥–∞–ª—è–µ–º –Ω–∞–ø—Ä—è–º—É—é —á–µ—Ä–µ–∑ writable_schema.
        """
        # –ï—Å–ª–∏ –Ω–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è, –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º
        if self.conn is None:
            return

        max_attempts = 10
        for _ in range(max_attempts):
            try:
                with self._lock:
                    # –ü—Ä–æ—Å—Ç–∞—è –∫–æ–º–∞–Ω–¥–∞, –∫–æ—Ç–æ—Ä–∞—è —Ç—Ä–∏–≥–≥–µ—Ä–∏—Ç –ø–∞—Ä—Å–∏–Ω–≥ —Å—Ö–µ–º—ã
                    self.conn.execute("PRAGMA user_version;")
                # –£—Å–ø–µ—Ö ‚Äî –Ω–∏—á–µ–≥–æ —á–∏–Ω–∏—Ç—å –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è
                break
            except sqlite3.DatabaseError as e:
                msg = str(e)
                m = re.search(
                    r"malformed database schema \(([^)]+)\)", msg, flags=re.IGNORECASE
                )
                if not m:
                    logging.warning("DB init error: %s", e)
                    return
                bad_object = m.group(1)
                try:
                    logging.warning(
                        "–û–±–Ω–∞—Ä—É–∂–µ–Ω –ø–æ–≤—Ä–µ–∂–¥—ë–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç '%s'. –£–¥–∞–ª—è–µ–º‚Ä¶", bad_object
                    )
                    with self._lock:
                        # –ü—ã—Ç–∞–µ–º—Å—è –æ–±—ã—á–Ω—ã–º–∏ —Å–ø–æ—Å–æ–±–∞–º–∏
                        for drop_type in ["TABLE", "INDEX", "VIEW", "TRIGGER"]:
                            try:
                                self.conn.execute(
                                    f"DROP {drop_type} IF EXISTS \"{bad_object}\""
                                )
                            except sqlite3.Error:
                                pass
                        self.conn.commit()
                except sqlite3.Error:
                    pass

                # –ï—Å–ª–∏ –ø–æ-–ø—Ä–µ–∂–Ω–µ–º—É –ª–æ–º–∞–µ—Ç—Å—è ‚Äî —á–∏—Å—Ç–∏–º sqlite_master –Ω–∞–ø—Ä—è–º—É—é
                try:
                    with self._lock:
                        self.conn.execute("PRAGMA writable_schema=ON;")
                        self.conn.execute(
                            "DELETE FROM sqlite_master WHERE name=?", (bad_object,)
                        )
                        self.conn.execute("PRAGMA writable_schema=OFF;")
                        self.conn.commit()
                        try:
                            self.conn.execute("VACUUM;")
                        except sqlite3.Error:
                            pass
                except sqlite3.Error as e2:
                    logging.error(
                        "–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –æ–±—ä–µ–∫—Ç '%s': %s", bad_object, e2
                    )
                    return
                continue
        # –ü—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏–∫–∞: —É–¥–∞–ª–∏–º –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, ETHUSDT)
        try:
            with self._lock:
                cur = self.conn.execute(
                    "SELECT name, type FROM sqlite_master WHERE name GLOB '[A-Z0-9]*USDT' "
                    "OR name GLOB '[A-Z0-9]*BTC' OR name GLOB '[A-Z0-9]*ETH'"
                )
                rows = fetch_all_optimized(cur) or []
        except sqlite3.Error:
            rows = []
        for name, obj_type in rows:
            # –°–∏—Å—Ç–µ–º–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã
            known = {
                'fees','quotes','arbitrage_events','pairs','manual_trades',
                'active_signals','signals','signals_log','users_data',
                'signal_accum_events','app_cache','backtest_results',
                'telemetry_cycles','telemetry_api'
            }
            if name in known:
                continue
            try:
                with self._lock:
                    if obj_type in ['table', 'index', 'view', 'trigger']:
                        self.conn.execute(f"DROP {obj_type.upper()} IF EXISTS \"{name}\"")
                    self.conn.commit()
                    logging.warning(
                        "–£–¥–∞–ª—ë–Ω –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–π –æ–±—ä–µ–∫—Ç: %s (%s)", name, obj_type
                    )
            except sqlite3.Error:
                # –ñ—ë—Å—Ç–∫–∞—è —á–∏—Å—Ç–∫–∞, –µ—Å–ª–∏ –æ–±—ã—á–Ω—ã–π DROP –Ω–µ –ø–æ–º–æ–≥–∞–µ—Ç
                try:
                    with self._lock:
                        self.conn.execute("PRAGMA writable_schema=ON;")
                        self.conn.execute("DELETE FROM sqlite_master WHERE name=?", (name,))
                        self.conn.execute("PRAGMA writable_schema=OFF;")
                        self.conn.commit()
                        try:
                            self.conn.execute("VACUUM;")
                        except sqlite3.Error:
                            pass
                    logging.warning("–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —É–¥–∞–ª—ë–Ω –æ–±—ä–µ–∫—Ç —Å—Ö–µ–º—ã —á–µ—Ä–µ–∑ writable_schema: %s", name)
                except sqlite3.Error as e3:
                    logging.error("–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –æ–±—ä–µ–∫—Ç —Å—Ö–µ–º—ã '%s': %s", name, e3)
                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º, —á—Ç–æ–±—ã –ø–æ–ø—ã—Ç–∞—Ç—å—Å—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ

        # –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏
        try:
            with self._lock:
                cur = self.conn.execute("PRAGMA integrity_check;")
                res = cur.fetchone()
                if res and str(res[0]).lower() != 'ok':
                    logging.warning("PRAGMA integrity_check –≤–µ—Ä–Ω—É–ª: %s", res[0])
        except sqlite3.Error:
            pass

    def _reset_database_preserving_backup(self):
        """
        –°–æ–∑–¥–∞—ë—Ç —á–∏—Å—Ç—ã–π —Ñ–∞–π–ª –ë–î, —Å–æ—Ö—Ä–∞–Ω–∏–≤ –±—ç–∫–∞–ø —Å—Ç–∞—Ä–æ–≥–æ.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–º –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–∏ —Å—Ö–µ–º—ã.
        """
        try:
            # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
            try:
                self.conn.close()
            except sqlite3.Error:
                pass
            # –ë—ç–∫–∞–ø–∏–º –∏—Å—Ö–æ–¥–Ω—É—é –ë–î
            try:
                backup_file(self.db_path)
            except (OSError, IOError):
                logging.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –±—ç–∫–∞–ø –ø–µ—Ä–µ–¥ —Å–±—Ä–æ—Å–æ–º –ë–î")
            # –£–¥–∞–ª—è–µ–º –ø–æ–≤—Ä–µ–∂–¥—ë–Ω–Ω—ã–π —Ñ–∞–π–ª –∏ —Å–æ–∑–¥–∞—ë–º –∑–∞–Ω–æ–≤–æ
            try:
                if os.path.exists(self.db_path):
                    os.remove(self.db_path)
            except OSError as e:
                logging.error("–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª –ë–î: %s", e)
            # –ù–æ–≤–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
            self.conn = sqlite3.connect(
                self.db_path, check_same_thread=False, timeout=30.0
            )
            self.cursor = self.conn.cursor()
            # –ü—Ä–∏–º–µ–Ω—è–µ–º PRAGMA
            try:
                with self._lock:
                    self.conn.execute("PRAGMA journal_mode=WAL;")
                    self.conn.execute("PRAGMA synchronous=NORMAL;")
                    self.conn.execute("PRAGMA busy_timeout=60000;")
                    # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è cache_size
                    import psutil
                    try:
                        available_ram_mb = psutil.virtual_memory().total / (1024 * 1024)
                        optimal_cache_mb = max(
                            64, min(512, int(available_ram_mb * 0.25))
                        )
                        cache_size_kb = -optimal_cache_mb * 1024
                        self.conn.execute(f"PRAGMA cache_size={cache_size_kb};")
                    except Exception:
                        self.conn.execute("PRAGMA cache_size=-64000;")
                    self.conn.execute("PRAGMA mmap_size=268435456;")
                    self.conn.execute("PRAGMA temp_store=MEMORY;")
                    self.conn.execute("PRAGMA foreign_keys=ON;")
            except sqlite3.Error:
                pass
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–∞–±–ª–∏—Ü
            self._init_tables()
            logging.error("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∞. –°—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è –≤ –±—ç–∫–∞–ø–∞—Ö.")
        except sqlite3.Error as e:
            logging.critical("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–∏ –ë–î: %s", e)
            raise

    def _init_tables(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ç–∞–±–ª–∏—Ü –ë–î"""
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
        if self.conn is None or self.cursor is None:
            logging.warning("‚ö†Ô∏è [DB] –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–∞–±–ª–∏—Ü—ã: conn/cursor None")
            return

        # –ó–∞—â–∏—Ç–∞ –æ—Ç –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫
        try:
            with self._lock:
                self.conn.execute("PRAGMA busy_timeout=30000;")
        except sqlite3.Error:
            pass

        self.cursor.execute(
            """
        CREATE TABLE IF NOT EXISTS fees (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            exchange TEXT,
            symbol TEXT,
            maker_fee REAL,
            taker_fee REAL,
            withdraw_fee REAL,
            network TEXT,
            last_updated DATETIME DEFAULT CURRENT_TIMESTAMP
        )"""
        )
        self.cursor.execute(
            """
        CREATE TABLE IF NOT EXISTS quotes (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            ts TEXT,
            exchange TEXT,
            symbol TEXT,
            bid REAL CHECK (bid > 0),
            ask REAL CHECK (ask > 0 AND ask >= bid)
        )"""
        )
        self.cursor.execute(
            """
        CREATE TABLE IF NOT EXISTS arbitrage_events (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            ts TEXT,
            symbol TEXT,
            buy_exchange TEXT,
            sell_exchange TEXT,
            buy_price REAL,
            sell_price REAL,
            amount REAL,
            net_profit REAL,
            net_profit_pct REAL
        )"""
        )
        self.cursor.execute(
            """
        CREATE TABLE IF NOT EXISTS pairs (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            exchange TEXT,
            symbol TEXT,
            base_asset TEXT,
            quote_asset TEXT,
            status TEXT,
            min_qty REAL,
            max_qty REAL,
            step_size REAL,
            min_price REAL,
            max_price REAL,
            price_tick REAL,
            maker_commission REAL,
            taker_commission REAL,
            is_spot_allowed INTEGER,
            is_margin_allowed INTEGER,
            last_updated DATETIME DEFAULT CURRENT_TIMESTAMP
        )"""
        )
        self.cursor.execute(
            """
        CREATE TABLE IF NOT EXISTS manual_trades (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            ts TEXT,
            symbol TEXT,
            buy_exchange TEXT,
            sell_exchange TEXT,
            buy_price REAL,
            sell_price REAL,
            amount REAL,
            notified_profit REAL,
            notified_profit_pct REAL,
            withdraw_fee REAL,
            final_profit REAL,
            final_profit_pct REAL,
            status TEXT,
            real_buy_price REAL,
            real_sell_price REAL,
            real_amount REAL,
            real_profit REAL,
            real_profit_pct REAL,
            trade_completed INTEGER DEFAULT 0
        )"""
        )
        self.cursor.execute(
            """
        CREATE TABLE IF NOT EXISTS active_signals (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            signal_key TEXT UNIQUE,
            status TEXT,
            ts DATETIME DEFAULT CURRENT_TIMESTAMP
        )"""
        )
        # –ú–∏–≥—Ä–∞—Ü–∏–∏ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤: –¥–æ–±–∞–≤–ª—è–µ–º expiry_time –∏ entry_time –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏
        try:
            with self._lock:
                self.conn.execute("ALTER TABLE active_signals ADD COLUMN expiry_time TEXT")
        except sqlite3.Error:
            pass
        try:
            with self._lock:
                self.conn.execute("ALTER TABLE active_signals ADD COLUMN symbol TEXT")
        except sqlite3.Error:
            pass
        try:
            with self._lock:
                self.conn.execute("ALTER TABLE active_signals ADD COLUMN entry_time TEXT")
        except sqlite3.Error:
            pass
        try:
            with self._lock:
                self.conn.execute("ALTER TABLE active_signals ADD COLUMN chat_id INTEGER")
        except sqlite3.Error:
            pass
        try:
            with self._lock:
                self.conn.execute("ALTER TABLE active_signals ADD COLUMN message_id INTEGER")
        except sqlite3.Error:
            pass
        self.cursor.execute(
            """
        CREATE TABLE IF NOT EXISTS signals (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            ts TEXT,
            exchange TEXT,
            symbol TEXT,
            rsi REAL,
            ema_fast REAL,
            ema_slow REAL,
            price REAL
        )"""
        )
        # –ù–æ–≤—ã–µ —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è –ø–æ–ª–Ω–æ–π –ë–î-–ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
        self.cursor.execute(
            """
        CREATE TABLE IF NOT EXISTS signals_log (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            symbol TEXT,
            entry REAL CHECK (entry IS NULL OR entry > 0),
            stop REAL CHECK (stop IS NULL OR stop > 0),
            tp1 REAL CHECK (tp1 IS NULL OR tp1 > 0),
            tp2 REAL CHECK (tp2 IS NULL OR tp2 > 0),
            entry_time TEXT,
            exit_time TEXT,
            result TEXT,
            net_profit REAL,
            qty_added REAL CHECK (qty_added IS NULL OR qty_added >= 0),
            qty_closed REAL CHECK (qty_closed IS NULL OR qty_closed >= 0),
            leverage_used INTEGER CHECK (leverage_used IS NULL OR leverage_used > 0),
            risk_pct_used REAL CHECK (risk_pct_used IS NULL OR (risk_pct_used >= 0 AND risk_pct_used <= 100)),
            entry_amount_usd REAL CHECK (entry_amount_usd IS NULL OR entry_amount_usd >= 0),
            trade_mode TEXT,
            funding_rate REAL,
            quote24h_usd REAL CHECK (quote24h_usd IS NULL OR quote24h_usd >= 0),
            depth_usd REAL CHECK (depth_usd IS NULL OR depth_usd >= 0),
            spread_pct REAL CHECK (spread_pct IS NULL OR spread_pct >= 0),
            exposure_pct REAL CHECK (exposure_pct IS NULL OR (exposure_pct >= 0 AND exposure_pct <= 100)),
            mtf_score REAL,
            sector TEXT,
            expected_cost_usd REAL CHECK (expected_cost_usd IS NULL OR expected_cost_usd >= 0),
            impact_bp REAL,
            quality_score REAL CHECK (quality_score IS NULL OR (quality_score >= 0 AND quality_score <= 100)),
            quality_meta TEXT,
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )
        """
        )
        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è —Å–∏–≥–Ω–∞–ª–æ–≤
        self.cursor.execute(
            "CREATE INDEX IF NOT EXISTS idx_signals_log_sym_time "
            "ON signals_log(symbol, entry_time)"
        )
        self.cursor.execute(
            "CREATE INDEX IF NOT EXISTS idx_signals_log_created_at "
            "ON signals_log(created_at)"
        )
        self.cursor.execute(
            "CREATE INDEX IF NOT EXISTS idx_signals_log_result_on "
            "ON signals_log(result)"
        )
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        try:
            self.cursor.execute(
                """
                DELETE FROM signals_log
                WHERE rowid NOT IN (
                    SELECT MIN(rowid)
                    FROM signals_log
                    GROUP BY symbol, entry_time, exit_time, net_profit, result
                )
                """
            )
        except sqlite3.Error as cleanup_err:
            logger.debug("‚ö†Ô∏è [DB] –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ signals_log: %s", cleanup_err)
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø–æ–≤—Ç–æ—Ä–Ω—ã–µ –∑–∞–ø–∏—Å–∏
        self.cursor.execute(
            "CREATE UNIQUE INDEX IF NOT EXISTS idx_signals_log_unique_event "
            "ON signals_log(symbol, entry_time, exit_time, net_profit, result)"
        )
        # –¢–∞–±–ª–∏—Ü–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è TradeTracker)
        self.cursor.execute(
            """
        CREATE TABLE IF NOT EXISTS trades (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            symbol TEXT NOT NULL,
            direction TEXT NOT NULL CHECK (direction IN ('LONG', 'SHORT')),
            entry_price REAL NOT NULL CHECK (entry_price > 0),
            exit_price REAL CHECK (exit_price IS NULL OR exit_price > 0),
            entry_time DATETIME NOT NULL,
            exit_time DATETIME,
            duration_minutes REAL CHECK (duration_minutes IS NULL OR duration_minutes >= 0),
            quantity REAL NOT NULL CHECK (quantity > 0),
            position_size_usdt REAL NOT NULL CHECK (position_size_usdt > 0),
            leverage REAL DEFAULT 1.0 CHECK (leverage > 0 AND leverage <= 125),
            risk_percent REAL CHECK (risk_percent IS NULL OR (risk_percent >= 0 AND risk_percent <= 100)),
            pnl_usd REAL,
            pnl_percent REAL,
            fees_usd REAL DEFAULT 0.0 CHECK (fees_usd >= 0),
            net_pnl_usd REAL,
            exit_reason TEXT,
            tp1_price REAL CHECK (tp1_price IS NULL OR tp1_price > 0),
            tp2_price REAL CHECK (tp2_price IS NULL OR tp2_price > 0),
            sl_price REAL CHECK (sl_price IS NULL OR sl_price > 0),
            tp1_hit INTEGER DEFAULT 0 CHECK (tp1_hit IN (0, 1)),
            tp2_hit INTEGER DEFAULT 0 CHECK (tp2_hit IN (0, 1)),
            sl_hit INTEGER DEFAULT 0 CHECK (sl_hit IN (0, 1)),
            signal_key TEXT,
            user_id TEXT,
            trade_mode TEXT DEFAULT 'futures' CHECK (trade_mode IN ('spot', 'futures', 'margin')),
            filter_mode TEXT DEFAULT 'strict',
            confidence REAL CHECK (confidence IS NULL OR (confidence >= 0 AND confidence <= 100)),
            dca_count INTEGER DEFAULT 0 CHECK (dca_count >= 0),
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )
        """
        )
        self.cursor.execute("CREATE INDEX IF NOT EXISTS idx_trades_symbol ON trades(symbol)")
        self.cursor.execute("CREATE INDEX IF NOT EXISTS idx_trades_exit_time ON trades(exit_time)")
        self.cursor.execute("CREATE INDEX IF NOT EXISTS idx_trades_user_id ON trades(user_id)")
        self.cursor.execute("CREATE INDEX IF NOT EXISTS idx_trades_exit_reason ON trades(exit_reason)")
        
        # –ß–∞—Å—Ç–∏—á–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ (—É—Å–∫–æ—Ä–µ–Ω–∏–µ –Ω–∞ 30-50%)
        self._create_partial_indexes()
        
        # –î–æ–±–∞–≤–ª—è–µ–º CHECK constraints –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ç–∞–±–ª–∏—Ü —á–µ—Ä–µ–∑ —Ç—Ä–∏–≥–≥–µ—Ä—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        # (SQLite –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç ALTER TABLE ADD CONSTRAINT, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç—Ä–∏–≥–≥–µ—Ä—ã)
        self._add_validation_triggers()
        
        # –ú–∏–≥—Ä–∞—Ü–∏–∏ –¥–ª—è signals_log: –¥–æ–±–∞–≤–ª—è–µ–º user_id
        try:
            with self._lock:
                self.conn.execute("ALTER TABLE signals_log ADD COLUMN user_id INTEGER")
        except sqlite3.Error:
            pass
        
        # –ú–∏–≥—Ä–∞—Ü–∏–∏: –¥–æ–±–∞–≤–ª—è–µ–º —Å—É—Ä—Ä–æ–≥–∞—Ç–Ω—ã–µ –∫–ª—é—á–∏ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ (—É—Å–∫–æ—Ä–µ–Ω–∏–µ –Ω–∞ 20-40%)
        self._add_surrogate_time_keys()
        # –ú–∏–≥—Ä–∞—Ü–∏–∏: –¥–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ (–µ—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç)
        for attempt, col_def in enumerate([
            ("leverage_used", "INTEGER"),
            ("risk_pct_used", "REAL"),
            ("entry_amount_usd", "REAL"),
            ("trade_mode", "TEXT"),
            ("funding_rate", "REAL"),
            ("quote24h_usd", "REAL"),
            ("depth_usd", "REAL"),
            ("spread_pct", "REAL"),
            ("exposure_pct", "REAL"),
            ("mtf_score", "REAL"),
            ("sector", "TEXT"),
            ("expected_cost_usd", "REAL"),
            ("impact_bp", "REAL"),
        ]):
            try:
                with self._lock:
                    self.conn.execute(
                        f"ALTER TABLE signals_log ADD COLUMN {col_def[0]} {col_def[1]}"
                    )
            except sqlite3.OperationalError as e:
                if "database is locked" in str(e):
                    # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π backoff
                    wait_time = 0.1 * (2 ** attempt) + random.uniform(0, 0.1)
                    time.sleep(wait_time)
                    try:
                        with self._lock:
                            self.conn.execute(
                                f"ALTER TABLE signals_log ADD COLUMN {col_def[0]} {col_def[1]}"
                            )
                    except sqlite3.Error:
                        pass
                elif "duplicate column name" in str(e).lower():
                    pass
                else:
                    pass
            except sqlite3.Error:
                pass
        # –°–æ–∑–¥–∞—ë–º –∏–Ω–¥–µ–∫—Å –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å—Ç–æ–ª–±—Ü–∞
        try:
            self.cursor.execute(
                "CREATE INDEX IF NOT EXISTS idx_signals_log_user_sym_time "
                "ON signals_log(user_id, symbol, entry_time)"
            )
        except sqlite3.Error:
            pass
        
        # –î–æ–±–∞–≤–ª—è–µ–º CHECK constraints –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ç–∞–±–ª–∏—Ü —á–µ—Ä–µ–∑ —Ç—Ä–∏–≥–≥–µ—Ä—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        # (SQLite –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç ALTER TABLE ADD CONSTRAINT, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç—Ä–∏–≥–≥–µ—Ä—ã)
        self._add_validation_triggers()
        
        self.cursor.execute(
            """
        CREATE TABLE IF NOT EXISTS users_data (
            user_id TEXT PRIMARY KEY,
            data TEXT NOT NULL,
            updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )
        """
        )
        # –ù–∞–∫–æ–ø–∏—Ç–µ–ª—å —Å–∏–≥–Ω–∞–ª–æ–≤: —Å–æ–±—ã—Ç–∏—è
        self.cursor.execute(
            """
        CREATE TABLE IF NOT EXISTS signal_accum_events (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            ts INTEGER,
            symbol TEXT,
            event TEXT,
            weight REAL,
            ttl_sec INTEGER,
            meta TEXT
        )"""
        )
        self.cursor.execute(
            """
        CREATE INDEX IF NOT EXISTS idx_accum_symbol_ts ON signal_accum_events(symbol, ts)
        """
        )
        # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∫—ç—à (DB-—É—Ä–æ–≤–µ–Ω—å)
        self.cursor.execute(
            """
        CREATE TABLE IF NOT EXISTS app_cache (
            cache_type TEXT,
            cache_key TEXT,
            payload TEXT,
            expires_at INTEGER,
            PRIMARY KEY(cache_type, cache_key)
        )
        """
        )
        self.cursor.execute("CREATE INDEX IF NOT EXISTS idx_app_cache_expires_at ON app_cache(expires_at)")

        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫ (–∞–¥–∞–ø—Ç–∏–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞)
        self.cursor.execute(
            """
        CREATE TABLE IF NOT EXISTS system_settings (
            key TEXT PRIMARY KEY,
            value TEXT NOT NULL,
            updated_at TEXT DEFAULT CURRENT_TIMESTAMP
        )
        """
        )

        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏ —Å–Ω–∏–º–∫–æ–≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (Rollback System)
        self.cursor.execute(
            """
        CREATE TABLE IF NOT EXISTS system_config_history (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            config_json TEXT NOT NULL,
            win_rate REAL,
            pnl_pct REAL,
            is_stable INTEGER DEFAULT 0,
            created_at TEXT DEFAULT CURRENT_TIMESTAMP
        )
        """
        )

        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –±–ª–æ–∫–ª–∏—Å—Ç–∞ –º–æ–Ω–µ—Ç —Å –Ω–∏–∑–∫–æ–π –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–µ–π
        self.cursor.execute(
            """
        CREATE TABLE IF NOT EXISTS market_cap_blacklist (
            symbol TEXT PRIMARY KEY,
            market_cap REAL,
            blacklisted_at TEXT DEFAULT CURRENT_TIMESTAMP,
            last_checked TEXT DEFAULT CURRENT_TIMESTAMP,
            unfreeze_date TEXT,
            reason TEXT DEFAULT 'low_market_cap'
        )
        """
        )

        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–≤–µ—Ä–æ–∫ —Ñ–∏–ª—å—Ç—Ä–æ–≤
        self.cursor.execute(
            """
        CREATE TABLE IF NOT EXISTS filter_checks (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            symbol TEXT,
            filter_type TEXT,
            passed INTEGER DEFAULT 0,
            reason TEXT,
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )
        """
        )
        # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ created_at
        self.cursor.execute(
            "CREATE INDEX IF NOT EXISTS idx_filter_checks_created_at ON filter_checks(created_at)"
        )
        # –°–æ–±—ã—Ç–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –ª–æ–∂–Ω—ã—Ö –ø—Ä–æ–±–æ–µ–≤ (–¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ pass-rate)
        self.cursor.execute(
            """
        CREATE TABLE IF NOT EXISTS false_breakout_events (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            symbol TEXT NOT NULL,
            direction TEXT NOT NULL,
            confidence REAL,
            threshold REAL,
            passed INTEGER,
            regime TEXT,
            regime_confidence REAL,
            volatility_pct REAL,
            volume_confidence REAL,
            momentum_confidence REAL,
            level_confidence REAL,
            recent_pass_rate REAL,
            test_run INTEGER DEFAULT 0
        )
        """
        )
        self.cursor.execute(
            "CREATE INDEX IF NOT EXISTS idx_false_brk_sym_time "
            "ON false_breakout_events(symbol, created_at)"
        )
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ MTF-–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–π
        self.cursor.execute(
            """
        CREATE TABLE IF NOT EXISTS mtf_confirmation_events (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            symbol TEXT NOT NULL,
            direction TEXT NOT NULL,
            confirmed INTEGER,
            error TEXT,
            regime TEXT,
            regime_confidence REAL
        )
        """
        )
        self.cursor.execute(
            "CREATE INDEX IF NOT EXISTS idx_mtf_conf_sym_time "
            "ON mtf_confirmation_events(symbol, created_at)"
        )

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–≥–æ —Å–∞–π–∑–∏–Ω–≥–∞
        self.cursor.execute(
            """
        CREATE TABLE IF NOT EXISTS position_sizing_events (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            symbol TEXT NOT NULL,
            direction TEXT,
            entry_time TEXT NOT NULL,
            signal_token TEXT,
            user_id TEXT,
            trade_mode TEXT,
            signal_price REAL,
            baseline_amount_usd REAL,
            ai_amount_usd REAL,
            regime_multiplier REAL,
            after_regime_amount_usd REAL,
            correlation_multiplier REAL,
            after_correlation_amount_usd REAL,
            adaptive_multiplier REAL,
            after_adaptive_amount_usd REAL,
            risk_adjustment_multiplier REAL,
            final_amount_usd REAL,
            base_risk_pct REAL,
            ai_risk_pct REAL,
            leverage REAL,
            regime TEXT,
            regime_confidence REAL,
            quality_score REAL,
            composite_score REAL,
            pattern_confidence REAL,
            adaptive_reason TEXT,
            adaptive_components TEXT
        )
            """
        )
        self.cursor.execute(
            "CREATE INDEX IF NOT EXISTS idx_pos_size_sym_time "
            "ON position_sizing_events(symbol, entry_time)"
        )
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Ç–∞–±–ª–∏—Ü—ã
        for column_def in [
            ("adaptive_reason", "TEXT"),
            ("adaptive_components", "TEXT"),
        ]:
            try:
                self.cursor.execute(f"ALTER TABLE position_sizing_events ADD COLUMN {column_def[0]} {column_def[1]}")
            except sqlite3.OperationalError:
                pass

        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É test_run –¥–ª—è mtf_confirmation_events (–µ—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç)
        try:
            self.cursor.execute(
                "ALTER TABLE mtf_confirmation_events ADD COLUMN test_run INTEGER DEFAULT 0"
            )
        except sqlite3.OperationalError:
            # –ö–æ–ª–æ–Ω–∫–∞ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            pass
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—ç–∫—Ç–µ—Å—Ç–∞ (—Ä–µ–ø–ª–µ–π –Ω–∞—à–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏)
        self.cursor.execute(
            """
        CREATE TABLE IF NOT EXISTS backtest_results (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            symbol TEXT,
            interval TEXT,
            since_days INTEGER,
            bars INTEGER,
            signals INTEGER,
            tp1 INTEGER,
            tp2 INTEGER,
            sl INTEGER,
            pnl REAL,
            mae_avg_pct REAL,
            mfe_avg_pct REAL,
            avg_duration_sec REAL,
            started_at TEXT,
            ended_at TEXT,
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )
        """
        )
        self.conn.commit()
        self.periodic_backup()

    # –ü—Ä–æ—Å—Ç–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –±—ç–∫–∞–ø–æ–≤ (–≤—ã–∑–æ–≤–æ–º –ø–æ —Ç–∞–π–º–µ—Ä—É –∏–∑ –≤–Ω–µ—à–Ω–µ–≥–æ —Ü–∏–∫–ª–∞)
    _last_backup_ts = 0
    def periodic_backup(self, min_interval_sec: int = 600):
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        now = time.time()
        if now - Database._last_backup_ts >= min_interval_sec:
            backup_file(self.db_path)
            Database._last_backup_ts = now

    def save_quote(self, exchange, symbol, bid, ask):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–æ—Ç–∏—Ä–æ–≤–∫—É –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        self.cursor.execute(
            "INSERT INTO quotes (ts, exchange, symbol, bid, ask) VALUES (?, ?, ?, ?, ?)",
            (get_utc_now().isoformat(), exchange, symbol, bid, ask),
        )
        self.conn.commit()
        self.periodic_backup()

    def save_arbitrage_event(
        self,
        symbol,
        buy_exchange,
        sell_exchange,
        buy_price,
        sell_price,
        amount,
        net_profit,
        net_profit_pct,
    ):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–æ–±—ã—Ç–∏–µ –∞—Ä–±–∏—Ç—Ä–∞–∂–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.

        Args:
            symbol (str): –°–∏–º–≤–æ–ª —Ç–æ—Ä–≥–æ–≤–æ–π –ø–∞—Ä—ã
            buy_exchange (str): –ë–∏—Ä–∂–∞ –¥–ª—è –ø–æ–∫—É–ø–∫–∏
            sell_exchange (str): –ë–∏—Ä–∂–∞ –¥–ª—è –ø—Ä–æ–¥–∞–∂–∏
            buy_price (float): –¶–µ–Ω–∞ –ø–æ–∫—É–ø–∫–∏
            sell_price (float): –¶–µ–Ω–∞ –ø—Ä–æ–¥–∞–∂–∏
            amount (float): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ
            net_profit (float): –ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å
            net_profit_pct (float): –ü—Ä–æ—Ü–µ–Ω—Ç —á–∏—Å—Ç–æ–π –ø—Ä–∏–±—ã–ª–∏
        """
        self.cursor.execute(
            "INSERT INTO arbitrage_events (ts, symbol, buy_exchange, sell_exchange, buy_price, "
            "sell_price, amount, net_profit, net_profit_pct) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)",
            (
                get_utc_now().isoformat(),
                symbol,
                buy_exchange,
                sell_exchange,
                buy_price,
                sell_price,
                amount,
                net_profit,
                net_profit_pct,
            ),
        )
        self.conn.commit()
        self.periodic_backup()

    def insert_fees_for_pairs(
        self,
        exchange,
        pairs,
        default_maker_fee,
        default_taker_fee,
        default_withdraw_fee=None,
        network=None,
    ):
        """
        –í—Å—Ç–∞–≤–ª—è–µ—Ç –∫–æ–º–∏—Å—Å–∏–∏ –¥–ª—è —Ç–æ—Ä–≥–æ–≤—ã—Ö –ø–∞—Ä.

        Args:
            exchange (str): –ù–∞–∑–≤–∞–Ω–∏–µ –±–∏—Ä–∂–∏
            pairs (list): –°–ø–∏—Å–æ–∫ —Ç–æ—Ä–≥–æ–≤—ã—Ö –ø–∞—Ä
            default_maker_fee (float): –ö–æ–º–∏—Å—Å–∏—è –º–µ–π–∫–µ—Ä–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            default_taker_fee (float): –ö–æ–º–∏—Å—Å–∏—è —Ç–µ–π–∫–µ—Ä–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            default_withdraw_fee (float, optional): –ö–æ–º–∏—Å—Å–∏—è –∑–∞ –≤—ã–≤–æ–¥ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            network (str, optional): –°–µ—Ç—å –¥–ª—è –≤—ã–≤–æ–¥–∞ —Å—Ä–µ–¥—Å—Ç–≤
        """
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: —Å–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ fees –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º
        existing_fees = set()
        with self._lock:
            cur = self.conn.execute(
                "SELECT symbol FROM fees WHERE exchange=?", (exchange,)
            )
            existing_fees = {row[0] for row in fetch_all_optimized(cur)}
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –∏—Å–ø–æ–ª—å–∑—É–µ–º batch –æ–ø–µ—Ä–∞—Ü–∏—é –≤–º–µ—Å—Ç–æ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö INSERT
        to_insert = [
            (
                exchange,
                pair["symbol"] if isinstance(pair, dict) else pair,
                default_maker_fee,
                default_taker_fee,
                default_withdraw_fee,
                network,
            )
            for pair in pairs
            if (pair["symbol"] if isinstance(pair, dict) else pair) not in existing_fees
        ]
        
        if to_insert:
            query = """
                INSERT INTO fees (exchange, symbol, maker_fee, taker_fee, withdraw_fee, network)
                VALUES (?, ?, ?, ?, ?, ?)
            """
            self.executemany_optimized(query, to_insert)
        self.periodic_backup()

    def save_system_setting(self, key, value):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫—É —Å–∏—Å—Ç–µ–º—ã"""
        try:
            self.cursor.execute(
                "INSERT OR REPLACE INTO system_settings (key, value, updated_at) VALUES (?, ?, ?)",
                (key, value, get_utc_now().isoformat())
            )
            self.conn.commit()
            self.periodic_backup()
            return True
        except Exception as e:
            logging.error("‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ %s: %s", key, e)
            return False

# –°—Ç–∞—Ä—ã–µ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã —É–¥–∞–ª–µ–Ω—ã - –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –Ω–æ–≤—ã–µ –≤–µ—Ä—Å–∏–∏ –Ω–∏–∂–µ

    def save_backtest_result(
        self, symbol, interval, since_days, bars, signals, tp1, tp2, sl, pnl,
        mae_avg_pct, mfe_avg_pct, avg_duration_sec, started_at, ended_at
    ):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –±—ç–∫—Ç–µ—Å—Ç–∞"""
        try:
            self.cursor.execute(
                """INSERT INTO backtest_results
                (symbol, interval, since_days, bars, signals, tp1, tp2, sl, pnl,
                 mae_avg_pct, mfe_avg_pct, avg_duration_sec, 
                 started_at, ended_at, created_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
                (symbol, interval, since_days, bars, signals, tp1, tp2, sl, pnl,
                 mae_avg_pct, mfe_avg_pct, avg_duration_sec, started_at, ended_at,
                 datetime.now().isoformat())
            )
            self.conn.commit()
            self.periodic_backup()
            return True
        except Exception as e:
            logging.error("‚ùå –û—à–∏–±–∫–∞ –±—ç–∫—Ç–µ—Å—Ç–∞ %s: %s", symbol, e)
            return False

    def get_backtest_results(self, symbol=None, limit=10):
        """–ü–æ–ª—É—á–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—ç–∫—Ç–µ—Å—Ç–æ–≤"""
        try:
            if symbol:
                self.cursor.execute(
                    "SELECT * FROM backtest_results WHERE symbol = ? "
                    "ORDER BY created_at DESC LIMIT ?",
                    (symbol, limit)
                )
            else:
                self.cursor.execute(
                    "SELECT * FROM backtest_results ORDER BY created_at DESC LIMIT ?", 
                    (limit,)
                )
            return fetch_all_optimized(self.cursor)
        except Exception as e:
            logging.error("‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –±—ç–∫—Ç–µ—Å—Ç–æ–≤: %s", e)
            return []

    def update_withdraw_fee(self, exchange, symbol, withdraw_fee, network=None):
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç –∫–æ–º–∏—Å—Å–∏—é –∑–∞ –≤—ã–≤–æ–¥.
        """
        self.cursor.execute(
            "UPDATE fees SET withdraw_fee=?, network=?, "
            "last_updated=CURRENT_TIMESTAMP WHERE exchange=? AND symbol=?",
            (withdraw_fee, network, exchange, symbol),
        )
        self.conn.commit()
        self.periodic_backup()

    def update_maker_fee(self, exchange, symbol, maker_fee):
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç –∫–æ–º–∏—Å—Å–∏—é –º–µ–π–∫–µ—Ä–∞ –¥–ª—è —Ç–æ—Ä–≥–æ–≤–æ–π –ø–∞—Ä—ã.

        Args:
            exchange (str): –ù–∞–∑–≤–∞–Ω–∏–µ –±–∏—Ä–∂–∏
            symbol (str): –°–∏–º–≤–æ–ª —Ç–æ—Ä–≥–æ–≤–æ–π –ø–∞—Ä—ã
            maker_fee (float): –ö–æ–º–∏—Å—Å–∏—è –º–µ–π–∫–µ—Ä–∞
        """
        self.cursor.execute(
            "UPDATE fees SET maker_fee=?, last_updated=CURRENT_TIMESTAMP WHERE exchange=? AND symbol=?",
            (maker_fee, exchange, symbol),
        )
        self.conn.commit()
        self.periodic_backup()

    def update_taker_fee(self, exchange, symbol, taker_fee):
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç –∫–æ–º–∏—Å—Å–∏—é —Ç–µ–π–∫–µ—Ä–∞ –¥–ª—è —Ç–æ—Ä–≥–æ–≤–æ–π –ø–∞—Ä—ã.

        Args:
            exchange (str): –ù–∞–∑–≤–∞–Ω–∏–µ –±–∏—Ä–∂–∏
            symbol (str): –°–∏–º–≤–æ–ª —Ç–æ—Ä–≥–æ–≤–æ–π –ø–∞—Ä—ã
            taker_fee (float): –ö–æ–º–∏—Å—Å–∏—è —Ç–µ–π–∫–µ—Ä–∞
        """
        self.cursor.execute(
            "UPDATE fees SET taker_fee=?, last_updated=CURRENT_TIMESTAMP WHERE exchange=? AND symbol=?",
            (taker_fee, exchange, symbol),
        )
        self.conn.commit()
        self.periodic_backup()

    def get_fees(self, exchange, symbol):
        """
        –ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–º–∏—Å—Å–∏—è—Ö –¥–ª—è —Ç–æ—Ä–≥–æ–≤–æ–π –ø–∞—Ä—ã.
        """
        self.cursor.execute(
            "SELECT maker_fee, taker_fee, withdraw_fee, network "
            "FROM fees WHERE exchange=? AND symbol=?",
            (exchange, symbol),
        )
        row = self.cursor.fetchone()
        if row:
            return {
                "maker_fee": row[0],
                "taker_fee": row[1],
                "withdraw_fee": row[2],
                "network": row[3],
            }
        return None

    def update_pair_info(self, exchange, symbol, **kwargs):
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ—Ä–≥–æ–≤–æ–π –ø–∞—Ä–µ.
        """
        columns = ", ".join(f"{k}=?" for k in kwargs)
        values = list(kwargs.values())
        values.extend([exchange, symbol])
        self.cursor.execute(
            f"UPDATE pairs SET {columns}, last_updated=CURRENT_TIMESTAMP "
            "WHERE exchange=? AND symbol=?",
            values,
        )
        self.conn.commit()
        self.periodic_backup()

    def insert_pairs_for_exchange(self, exchange, pairs):
        """
        –í—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ—Ä–≥–æ–≤—ã–µ –ø–∞—Ä—ã –¥–ª—è –±–∏—Ä–∂–∏.

        Args:
            exchange (str): –ù–∞–∑–≤–∞–Ω–∏–µ –±–∏—Ä–∂–∏
            pairs (list): –°–ø–∏—Å–æ–∫ —Ç–æ—Ä–≥–æ–≤—ã—Ö –ø–∞—Ä
        """
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: —Å–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø–∞—Ä—ã –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º
        existing_pairs = set()
        with self._lock:
            cur = self.conn.execute(
                "SELECT symbol FROM pairs WHERE exchange=?", (exchange,)
            )
            existing_pairs = {row[0] for row in fetch_all_optimized(cur)}
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –∏—Å–ø–æ–ª—å–∑—É–µ–º list comprehension –≤–º–µ—Å—Ç–æ —Ü–∏–∫–ª–∞ —Å append
        to_insert = [
            (
                exchange,
                pair["symbol"],
                pair.get("base_asset"),
                pair.get("quote_asset"),
                pair.get("status"),
                pair.get("min_qty"),
                pair.get("max_qty"),
                pair.get("step_size"),
                pair.get("min_price"),
                pair.get("max_price"),
                pair.get("price_tick"),
                pair.get("maker_commission"),
                pair.get("taker_commission"),
                int(pair.get("is_spot_allowed", False)),
                int(pair.get("is_margin_allowed", False)),
            )
            for pair in pairs
            if pair["symbol"] not in existing_pairs
        ]
        if to_insert:
            # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –∏—Å–ø–æ–ª—å–∑—É–µ–º executemany_optimized –¥–ª—è –º–∞—Å—Å–æ–≤–æ–π –≤—Å—Ç–∞–≤–∫–∏
            query = """
                INSERT INTO pairs (
                    exchange, symbol, base_asset, quote_asset, status,
                    min_qty, max_qty, step_size, min_price, max_price, price_tick,
                    maker_commission, taker_commission,
                    is_spot_allowed, is_margin_allowed
                )
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """
            self.executemany_optimized(query, to_insert)
        self.periodic_backup()

    def mass_update_fees(
        self, exchange, maker_fee=None, taker_fee=None, withdraw_fee=None, network=None
    ):
        """
        –ú–∞—Å—Å–æ–≤–æ –æ–±–Ω–æ–≤–∏—Ç—å –∫–æ–º–∏—Å—Å–∏–∏ –¥–ª—è –≤—Å–µ—Ö –ø–∞—Ä –±–∏—Ä–∂–∏.
        –õ—é–±–æ–π –∏–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–∂–Ω–æ –Ω–µ —É–∫–∞–∑—ã–≤–∞—Ç—å (—Ç–æ–≥–¥–∞ –Ω–µ –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è).
        """
        set_clauses = []
        values = []
        if maker_fee is not None:
            set_clauses.append("maker_fee=?")
            values.append(maker_fee)
        if taker_fee is not None:
            set_clauses.append("taker_fee=?")
            values.append(taker_fee)
        if withdraw_fee is not None:
            set_clauses.append("withdraw_fee=?")
            values.append(withdraw_fee)
        if network is not None:
            set_clauses.append("network=?")
            values.append(network)
        if not set_clauses:
            return  # –Ω–∏—á–µ–≥–æ –Ω–µ –æ–±–Ω–æ–≤–ª—è—Ç—å
        set_sql = ", ".join(set_clauses) + ", last_updated=CURRENT_TIMESTAMP"
        sql = f"UPDATE fees SET {set_sql} WHERE exchange=?"
        values.append(exchange)
        self.cursor.execute(sql, values)
        self.conn.commit()
        self.periodic_backup()

    def add_active_signal(self, signal_key, status):
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã–π —Å–∏–≥–Ω–∞–ª –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.
        """
        self.cursor.execute(
            "INSERT OR REPLACE INTO active_signals (signal_key, status, ts) "
            "VALUES (?, ?, datetime('now'))",
            (signal_key, status),
        )
        self.conn.commit()
        self.periodic_backup()

    def remove_active_signal(self, signal_key):
        """
        –£–¥–∞–ª—è–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã–π —Å–∏–≥–Ω–∞–ª –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.

        Args:
            signal_key (str): –ö–ª—é—á —Å–∏–≥–Ω–∞–ª–∞
        """
        self.cursor.execute(
            "DELETE FROM active_signals WHERE signal_key=?",
            (signal_key,),
        )
        self.conn.commit()
        self.periodic_backup()

    # --- –ê–∫—Ç–∏–≤–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã —Å –∏—Å—Ç–µ—á–µ–Ω–∏–µ–º ---
    def add_active_signal_with_expiry(
        self,
        signal_key: str,
        status: str,
        expiry_time: str,
        entry_time: str = None,
        chat_id: int = None,
        message_id: int = None,
        symbol: str = None
    ):
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã–π —Å–∏–≥–Ω–∞–ª —Å –≤—Ä–µ–º–µ–Ω–µ–º –∏—Å—Ç–µ—á–µ–Ω–∏—è.

        Args:
            signal_key (str): –ö–ª—é—á —Å–∏–≥–Ω–∞–ª–∞
            status (str): –°—Ç–∞—Ç—É—Å —Å–∏–≥–Ω–∞–ª–∞
            expiry_time (str): –í—Ä–µ–º—è –∏—Å—Ç–µ—á–µ–Ω–∏—è —Å–∏–≥–Ω–∞–ª–∞
            entry_time (str, optional): –í—Ä–µ–º—è –≤—Ö–æ–¥–∞
            chat_id (int, optional): ID —á–∞—Ç–∞
            message_id (int, optional): ID —Å–æ–æ–±—â–µ–Ω–∏—è
            symbol (str, optional): –°–∏–º–≤–æ–ª —Ç–æ—Ä–≥–æ–≤–æ–π –ø–∞—Ä—ã
        """
        try:
            with self._lock:
                self.conn.execute(
                    """
                    INSERT INTO active_signals(signal_key, status, ts, expiry_time, symbol,
                                              entry_time, chat_id, message_id)
                    VALUES(?, ?, datetime('now'), ?, ?, ?, ?, ?)
                    ON CONFLICT(signal_key) DO UPDATE SET
                        status=excluded.status, ts=excluded.ts, expiry_time=excluded.expiry_time,
                        symbol=excluded.symbol, entry_time=excluded.entry_time,
                        chat_id=excluded.chat_id, message_id=excluded.message_id
                    """,
                    (signal_key, status, expiry_time, symbol, entry_time, chat_id, message_id),
                )
                self.conn.commit()
        except sqlite3.Error as e:
            logging.warning("add_active_signal_with_expiry error: %s", e)

    def get_active_signal_info(self, signal_key: str):
        """
        –ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∞–∫—Ç–∏–≤–Ω–æ–º —Å–∏–≥–Ω–∞–ª–µ.

        Args:
            signal_key (str): –ö–ª—é—á —Å–∏–≥–Ω–∞–ª–∞

        Returns:
            dict: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏–≥–Ω–∞–ª–µ –∏–ª–∏ None, –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω
        """
        try:
            with self._lock:
                cur = self.conn.execute(
                    "SELECT status, ts, expiry_time, entry_time FROM active_signals WHERE signal_key=?",
                    (signal_key,),
                )
                row = cur.fetchone()
            if not row:
                return None
            return {"status": row[0], "ts": row[1], "expiry_time": row[2], "entry_time": row[3]}
        except sqlite3.Error as e:
            logging.warning("get_active_signal_info error: %s", e)
            return None

    def mark_signal_expired(self, signal_key: str) -> bool:
        """
        –û—Ç–º–µ—á–∞–µ—Ç —Å–∏–≥–Ω–∞–ª –∫–∞–∫ –∏—Å—Ç–µ–∫—à–∏–π.

        Args:
            signal_key (str): –ö–ª—é—á —Å–∏–≥–Ω–∞–ª–∞

        Returns:
            bool: True –µ—Å–ª–∏ —Å–∏–≥–Ω–∞–ª –±—ã–ª –æ–±–Ω–æ–≤–ª–µ–Ω, False –≤ –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ
        """
        try:
            with self._lock:
                self.conn.execute(
                    "UPDATE active_signals SET status='expired', ts=datetime('now') WHERE signal_key=?",
                    (signal_key,),
                )
                self.conn.commit()
            return True
        except sqlite3.Error as e:
            logging.warning("mark_signal_expired error: %s", e)
            return False

    def is_signal_active_or_recent(self, signal_key, recent_minutes=60):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∞–∫—Ç–∏–≤–µ–Ω –ª–∏ —Å–∏–≥–Ω–∞–ª –∏–ª–∏ –±—ã–ª –Ω–µ–¥–∞–≤–Ω–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω.

        Args:
            signal_key (str): –ö–ª—é—á —Å–∏–≥–Ω–∞–ª–∞
            recent_minutes (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–∏–Ω—É—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–µ–¥–∞–≤–Ω–æ—Å—Ç–∏

        Returns:
            bool: True –µ—Å–ª–∏ —Å–∏–≥–Ω–∞–ª –∞–∫—Ç–∏–≤–µ–Ω –∏–ª–∏ –±—ã–ª –Ω–µ–¥–∞–≤–Ω–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω
        """
        self.cursor.execute(
            "SELECT status, ts FROM active_signals WHERE signal_key=?",
            (signal_key,),
        )
        row = self.cursor.fetchone()
        if not row:
            return False
        status, ts = row
        if status == "active":
            return True
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è
        try:
            ts_dt = datetime.strptime(ts, "%Y-%m-%d %H:%M:%S")
        except (ValueError, TypeError):
            ts_dt = datetime.fromisoformat(ts)
        if status == "declined" and (datetime.now() - ts_dt).total_seconds() < recent_minutes * 60:
            return True
        return False

    # ===== –ù–∞–∫–æ–ø–∏—Ç–µ–ª—å —Å–∏–≥–Ω–∞–ª–æ–≤ =====
    def add_accum_event(self, symbol: str, event: str, weight: float, ttl_sec: int, meta: Optional[dict] = None):
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç —Å–æ–±—ã—Ç–∏–µ –≤ –Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å —Å–∏–≥–Ω–∞–ª–æ–≤.

        Args:
            symbol (str): –°–∏–º–≤–æ–ª —Ç–æ—Ä–≥–æ–≤–æ–π –ø–∞—Ä—ã
            event (str): –¢–∏–ø —Å–æ–±—ã—Ç–∏—è
            weight (float): –í–µ—Å —Å–æ–±—ã—Ç–∏—è
            ttl_sec (int): –í—Ä–µ–º—è –∂–∏–∑–Ω–∏ —Å–æ–±—ã—Ç–∏—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            meta (dict, optional): –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        """
        ts = int(time.time())
        meta_json = json.dumps(meta or {}, ensure_ascii=False)
        try:
            with self._lock:
                self.cursor.execute(
                    "INSERT INTO signal_accum_events(ts, symbol, event, weight, ttl_sec, meta) VALUES(?,?,?,?,?,?)",
                    (ts, symbol, event, float(weight), int(ttl_sec), meta_json),
                )
                self.conn.commit()
        except (sqlite3.Error, ValueError, TypeError) as e:
            logging.warning("[AccumDB] add_accum_event error: %s", e)

    def get_accum_events(self, symbol: str, window_sec: int) -> List[Tuple]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Å–æ–±—ã—Ç–∏—è –∏–∑ –Ω–∞–∫–æ–ø–∏—Ç–µ–ª—è —Å–∏–≥–Ω–∞–ª–æ–≤ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥.

        Args:
            symbol (str): –°–∏–º–≤–æ–ª —Ç–æ—Ä–≥–æ–≤–æ–π –ø–∞—Ä—ã
            window_sec (int): –û–∫–Ω–æ –≤—Ä–µ–º–µ–Ω–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö

        Returns:
            List[Tuple]: –°–ø–∏—Å–æ–∫ —Å–æ–±—ã—Ç–∏–π
        """
        now_ts = int(time.time())
        min_ts = max(0, now_ts - int(window_sec))
        try:
            with self._lock:
                self.cursor.execute(
                    """SELECT ts, event, weight, ttl_sec, meta
                    FROM signal_accum_events
                    WHERE symbol=? AND ts>=?
                    ORDER BY ts ASC""",
                    (symbol, min_ts),
                )
                rows = fetch_all_optimized(self.cursor)
                return rows or []
        except (sqlite3.Error, ValueError, TypeError) as e:
            logging.warning("[AccumDB] get_accum_events error: %s", e)
            return []

    def update_signal_status(self, signal_key, status):
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç—É—Å —Å–∏–≥–Ω–∞–ª–∞.

        Args:
            signal_key (str): –ö–ª—é—á —Å–∏–≥–Ω–∞–ª–∞
            status (str): –ù–æ–≤—ã–π —Å—Ç–∞—Ç—É—Å —Å–∏–≥–Ω–∞–ª–∞
        """
        self.cursor.execute(
            "UPDATE active_signals SET status=?, ts=datetime('now') WHERE signal_key=?",
            (status, signal_key),
        )
        self.conn.commit()
        self.periodic_backup()

    @profile
    def get_daily_stats(self, date_str=None):
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∑–∞ –¥–µ–Ω—å"""
        if date_str is None:
            date_str = datetime.now().strftime("%Y-%m-%d")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∞—Ä–±–∏—Ç—Ä–∞–∂–Ω—ã–º —Å–æ–±—ã—Ç–∏—è–º
        self.cursor.execute(
            """
            SELECT
                COUNT(*) as total_signals,
                SUM(net_profit) as total_profit,
                AVG(net_profit_pct) as avg_profit_pct,
                MIN(net_profit_pct) as min_profit_pct,
                MAX(net_profit_pct) as max_profit_pct,
                SUM(amount) as total_volume
            FROM arbitrage_events
            WHERE DATE(ts) = ?
        """,
            (date_str,),
        )

        arbitrage_stats = self.cursor.fetchone()

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ä—É—á–Ω—ã–º —Å–¥–µ–ª–∫–∞–º
        self.cursor.execute(
            """
            SELECT
                COUNT(*) as total_trades,
                SUM(CASE WHEN trade_completed = 1 THEN real_profit ELSE final_profit END) as total_profit,
                AVG(CASE WHEN trade_completed = 1 THEN real_profit_pct ELSE final_profit_pct END) as avg_profit_pct,
                COUNT(CASE WHEN (CASE WHEN trade_completed = 1 THEN real_profit
                    ELSE final_profit END) > 0 THEN 1 END) as profitable_trades,
                COUNT(CASE WHEN (CASE WHEN trade_completed = 1 THEN real_profit
                    ELSE final_profit END) < 0 THEN 1 END) as losing_trades,
                COUNT(CASE WHEN trade_completed = 1 THEN 1 END) as completed_trades
            FROM manual_trades
            WHERE DATE(ts) = ?
        """,
            (date_str,),
        )

        trade_stats = self.cursor.fetchone()

        return {
            "date": date_str,
            "arbitrage": {
                "total_signals": arbitrage_stats[0] or 0,
                "total_profit": arbitrage_stats[1] or 0,
                "avg_profit_pct": arbitrage_stats[2] or 0,
                "min_profit_pct": arbitrage_stats[3] or 0,
                "max_profit_pct": arbitrage_stats[4] or 0,
                "total_volume": arbitrage_stats[5] or 0,
            },
            "trades": {
                "total_trades": trade_stats[0] or 0,
                "total_profit": trade_stats[1] or 0,
                "avg_profit_pct": trade_stats[2] or 0,
                "profitable_trades": trade_stats[3] or 0,
                "losing_trades": trade_stats[4] or 0,
                "completed_trades": trade_stats[5] or 0,
            },
        }

    def get_weekly_stats(self, week_start=None):
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∑–∞ –Ω–µ–¥–µ–ª—é"""
        if week_start is None:
            # –ù–∞—Ö–æ–¥–∏–º –Ω–∞—á–∞–ª–æ —Ç–µ–∫—É—â–µ–π –Ω–µ–¥–µ–ª–∏ (–ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫)
            today = get_utc_now()
            days_since_monday = today.weekday()
            week_start = (today - timedelta(days=days_since_monday)).strftime("%Y-%m-%d")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∞—Ä–±–∏—Ç—Ä–∞–∂–Ω—ã–º —Å–æ–±—ã—Ç–∏—è–º –∑–∞ –Ω–µ–¥–µ–ª—é
        self.cursor.execute(
            """
            SELECT
                COUNT(*) as total_signals,
                SUM(net_profit) as total_profit,
                AVG(net_profit_pct) as avg_profit_pct,
                MIN(net_profit_pct) as min_profit_pct,
                MAX(net_profit_pct) as max_profit_pct,
                SUM(amount) as total_volume,
                COUNT(DISTINCT DATE(ts)) as trading_days
            FROM arbitrage_events
            WHERE DATE(ts) >= ? AND DATE(ts) <= DATE(?, '+6 days')
        """,
            (week_start, week_start),
        )

        arbitrage_stats = self.cursor.fetchone()

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ä—É—á–Ω—ã–º —Å–¥–µ–ª–∫–∞–º –∑–∞ –Ω–µ–¥–µ–ª—é
        self.cursor.execute(
            """
            SELECT
                COUNT(*) as total_trades,
                SUM(CASE WHEN trade_completed = 1 THEN real_profit ELSE final_profit END) as total_profit,
                AVG(CASE WHEN trade_completed = 1 THEN real_profit_pct ELSE final_profit_pct END) as avg_profit_pct,
                COUNT(CASE WHEN (CASE WHEN trade_completed = 1 THEN real_profit
                    ELSE final_profit END) > 0 THEN 1 END) as profitable_trades,
                COUNT(CASE WHEN (CASE WHEN trade_completed = 1 THEN real_profit
                    ELSE final_profit END) < 0 THEN 1 END) as losing_trades,
                COUNT(DISTINCT DATE(ts)) as trading_days,
                COUNT(CASE WHEN trade_completed = 1 THEN 1 END) as completed_trades
            FROM manual_trades
            WHERE DATE(ts) >= ? AND DATE(ts) <= DATE(?, '+6 days')
        """,
            (week_start, week_start),
        )

        trade_stats = self.cursor.fetchone()

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏
        self.cursor.execute(
            """
            SELECT
                DATE(ts) as day,
                COUNT(*) as signals,
                SUM(net_profit) as profit
            FROM arbitrage_events
            WHERE DATE(ts) >= ? AND DATE(ts) <= DATE(?, '+6 days')
            GROUP BY DATE(ts)
            ORDER BY day
        """,
            (week_start, week_start),
        )

        daily_stats = fetch_all_optimized(self.cursor)

        return {
            "week_start": week_start,
            "arbitrage": {
                "total_signals": arbitrage_stats[0] or 0,
                "total_profit": arbitrage_stats[1] or 0,
                "avg_profit_pct": arbitrage_stats[2] or 0,
                "min_profit_pct": arbitrage_stats[3] or 0,
                "max_profit_pct": arbitrage_stats[4] or 0,
                "total_volume": arbitrage_stats[5] or 0,
                "trading_days": arbitrage_stats[6] or 0,
            },
            "trades": {
                "total_trades": trade_stats[0] or 0,
                "total_profit": trade_stats[1] or 0,
                "avg_profit_pct": trade_stats[2] or 0,
                "profitable_trades": trade_stats[3] or 0,
                "losing_trades": trade_stats[4] or 0,
                "trading_days": trade_stats[5] or 0,
                "completed_trades": trade_stats[6] or 0,
            },
            "daily_stats": [
                {"day": day, "signals": signals, "profit": profit or 0}
                for day, signals, profit in daily_stats
            ],
        }

    def get_pending_trades(self):
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö —Å–¥–µ–ª–æ–∫"""
        self.cursor.execute(
            """
            SELECT id, ts, symbol, buy_exchange, sell_exchange, buy_price, sell_price, amount,
                   notified_profit, notified_profit_pct, withdraw_fee, final_profit, final_profit_pct
            FROM manual_trades
            WHERE trade_completed = 0 AND status = 'finished'
            ORDER BY ts DESC
        """
        )
        return fetch_all_optimized(self.cursor)

    def update_trade_result(
        self,
        trade_id,
        real_buy_price,
        real_sell_price,
        real_amount,
        real_profit,
        real_profit_pct,
    ):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–¥–µ–ª–∫–∏"""
        self.cursor.execute(
            """
            UPDATE manual_trades
            SET real_buy_price = ?, real_sell_price = ?, real_amount = ?,
                real_profit = ?, real_profit_pct = ?, trade_completed = 1
            WHERE id = ?
        """,
            (
                real_buy_price,
                real_sell_price,
                real_amount,
                real_profit,
                real_profit_pct,
                trade_id,
            ),
        )
        self.conn.commit()
        self.periodic_backup()

    def get_trade_by_id(self, trade_id):
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–¥–µ–ª–∫—É –ø–æ ID"""
        self.cursor.execute(
            """
            SELECT id, ts, symbol, buy_exchange, sell_exchange, buy_price, sell_price, amount,
                   notified_profit, notified_profit_pct, withdraw_fee, final_profit, final_profit_pct,
                   real_buy_price, real_sell_price, real_amount, real_profit, real_profit_pct, trade_completed
            FROM manual_trades
            WHERE id = ?
        """,
            (trade_id,),
        )
        row = self.cursor.fetchone()
        if row:
            return {
                "id": row[0],
                "ts": row[1],
                "symbol": row[2],
                "buy_exchange": row[3],
                "sell_exchange": row[4],
                "buy_price": row[5],
                "sell_price": row[6],
                "amount": row[7],
                "notified_profit": row[8],
                "notified_profit_pct": row[9],
                "withdraw_fee": row[10],
                "final_profit": row[11],
                "final_profit_pct": row[12],
                "real_buy_price": row[13],
                "real_sell_price": row[14],
                "real_amount": row[15],
                "real_profit": row[16],
                "real_profit_pct": row[17],
                "trade_completed": row[18],
            }
        return None

    def insert_signal(self, signal):
        """
        –í—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π —Å–∏–≥–Ω–∞–ª –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.

        Args:
            signal (dict): –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ —Å–∏–≥–Ω–∞–ª–∞
        """
        self.cursor.execute(
            "INSERT INTO signals (ts, exchange, symbol, rsi, ema_fast, ema_slow, price) VALUES (?, ?, ?, ?, ?, ?, ?)",
            (
                get_utc_now().isoformat(),
                signal["exchange"],
                signal["symbol"],
                signal["rsi"],
                signal["ema_fast"],
                signal["ema_slow"],
                signal["price"],
            ),
        )
        self.conn.commit()
        print(f"[PiuX_Trade][DB] –°–∏–≥–Ω–∞–ª –¥–æ–±–∞–≤–ª–µ–Ω: {signal}")
        backup_file(self.db_path)

    # ====== Signals log API ======
    def insert_signal_log_entry(self, row: dict):
        columns = [
            "symbol",
            "entry",
            "stop",
            "tp1",
            "tp2",
            "entry_time",
            "exit_time",
            "result",
            "net_profit",
            "qty_added",
            "qty_closed",
            "user_id",
            "direction",
        ]
        values = [row.get(c) for c in columns]

        # –î–æ–±–∞–≤–ª—è–µ–º quality_score –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
        if "quality_score" in row and row.get("quality_score") is not None:
            columns.append("quality_score")
            values.append(float(row["quality_score"]))

        # –î–æ–±–∞–≤–ª—è–µ–º quality_meta –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
        if "quality_meta" in row and row.get("quality_meta") is not None:
            columns.append("quality_meta")
            quality_meta = row["quality_meta"]
            if isinstance(quality_meta, dict):
                # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –∏—Å–ø–æ–ª—å–∑—É–µ–º –±—ã—Å—Ç—Ä—É—é —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—é
                values.append(self._serialize_quality_meta(quality_meta))
            else:
                values.append(str(quality_meta))
        symbol = row.get("symbol")
        entry_time = row.get("entry_time")
        exit_time = row.get("exit_time")
        net_profit = row.get("net_profit")
        result = row.get("result")

        # üîß –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ conn –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω
        if self.conn is None:
            logger.error("‚ùå [DB] self.conn is None –≤ insert_signal_log_entry, –ø—ã—Ç–∞–µ–º—Å—è –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å")
            try:
                # –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
                self.conn = sqlite3.connect(self.db_path, check_same_thread=False, timeout=30.0)
                self.cursor = self.conn.cursor()
                with self._lock:
                    self.conn.execute("PRAGMA journal_mode=WAL;")
                    self.conn.execute("PRAGMA synchronous=NORMAL;")
                    self.conn.execute("PRAGMA busy_timeout=60000;")  # 60s –¥–ª—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ—Å—Ç–∏
                    # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è cache_size
                    import psutil
                    try:
                        available_ram_mb = psutil.virtual_memory().total / (1024 * 1024)
                        optimal_cache_mb = max(64, min(512, int(available_ram_mb * 0.25)))
                        cache_size_kb = -optimal_cache_mb * 1024
                        self.conn.execute(f"PRAGMA cache_size={cache_size_kb};")
                    except Exception:
                        self.conn.execute("PRAGMA cache_size=-64000;")  # 64MB fallback
                    self.conn.execute("PRAGMA mmap_size=268435456;")  # 256MB mmap
                    self.conn.execute("PRAGMA temp_store=MEMORY;")
                    self.conn.execute("PRAGMA foreign_keys=ON;")
                logger.info("‚úÖ [DB] –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —É—Å–ø–µ—à–Ω–æ")
            except Exception as e:
                logger.error("‚ùå [DB] –ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ: %s", e)
                return False

        with self._lock:
            try:
                duplicate = self.conn.execute(
                    """
                    SELECT id
                    FROM signals_log
                    WHERE symbol = ?
                      AND entry_time = ?
                      AND COALESCE(exit_time, '') = COALESCE(?, '')
                      AND COALESCE(net_profit, 0) = COALESCE(?, 0)
                      AND COALESCE(result, '') = COALESCE(?, '')
                    """,
                    (
                        symbol,
                        entry_time,
                        exit_time,
                        net_profit,
                        result,
                    ),
                ).fetchone()
            except sqlite3.Error as dup_err:
                logger.debug("‚ö†Ô∏è [DB] –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ signals_log –Ω–µ —É–¥–∞–ª–∞—Å—å: %s", dup_err)
                duplicate = None

            if duplicate:
                logger.debug(
                    "‚Ü©Ô∏è [DB] signals_log –¥—É–±–ª–∏–∫–∞—Ç –ø—Ä–æ–ø—É—â–µ–Ω: symbol=%s entry_time=%s result=%s",
                    symbol,
                    entry_time,
                    result,
                )
                return duplicate[0]

            self.conn.execute(
                f"INSERT INTO signals_log ({', '.join(columns)}) VALUES ({', '.join(['?']*len(columns))})",
                values,
            )
            self.conn.commit()
        self.periodic_backup()

    def update_signal_close_db(self, symbol: str, entry_time: str, exit_time: str, result: str, net_profit: float):
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ –∑–∞–∫—Ä—ã—Ç–∏–∏ —Å–∏–≥–Ω–∞–ª–∞ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.

        Args:
            symbol (str): –°–∏–º–≤–æ–ª —Ç–æ—Ä–≥–æ–≤–æ–π –ø–∞—Ä—ã
            entry_time (str): –í—Ä–µ–º—è –≤—Ö–æ–¥–∞
            exit_time (str): –í—Ä–µ–º—è –≤—ã—Ö–æ–¥–∞
            result (str): –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–¥–µ–ª–∫–∏
            net_profit (float): –ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å
        """
        self.cursor.execute(
            """
            UPDATE signals_log
            SET exit_time = ?, result = ?, net_profit = ?
            WHERE symbol = ? AND entry_time = ?
        """,
            (exit_time, result, net_profit, symbol, entry_time),
        )
        self.conn.commit()
        self.periodic_backup()

    def get_last_signal_log(self, user_id=None):
        """–ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–∏–≥–Ω–∞–ª –∏–∑ –ë–î (—Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π connection pool)"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º created_at (UTC, –±–µ–∑ —Ç–∞–π–º–∑–æ–Ω—ã) –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
            # üîß –ò–°–ü–†–ê–í–õ–ï–ù–û: connection_pool –æ—Ç–∫–ª—é—á–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
            if self.conn is not None:
                cur = self.cursor
                if user_id is not None:
                    cur.execute(
                        """
                        SELECT symbol, entry, tp1, tp2, entry_time, result
                        FROM signals_log
                        WHERE user_id = ?
                        ORDER BY datetime(created_at) DESC
                        LIMIT 1
                    """,
                        (user_id,)
                    )
                else:
                    cur.execute(
                        """
                        SELECT symbol, entry, tp1, tp2, entry_time, result
                        FROM signals_log
                        ORDER BY datetime(created_at) DESC
                        LIMIT 1
                    """
                    )
                    row = cur.fetchone()
                    if not row:
                        return None
                    return {
                        "symbol": row[0],
                        "entry": row[1],
                        "tp1": row[2],
                        "tp2": row[3],
                        "entry_time": row[4],
                        "result": row[5],
                    }
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
                if self.cursor is None:
                    logging.warning("get_last_signal_log: cursor is None")
                    return None
                with self._lock:
                    if user_id is not None:
                        self.cursor.execute(
                            """
                            SELECT symbol, entry, tp1, tp2, entry_time, result
                            FROM signals_log
                            WHERE user_id = ?
                            ORDER BY datetime(created_at) DESC
                            LIMIT 1
                        """,
                            (user_id,)
                        )
                    else:
                        self.cursor.execute(
                            """
                            SELECT symbol, entry, tp1, tp2, entry_time, result
                            FROM signals_log
                            ORDER BY datetime(created_at) DESC
                            LIMIT 1
                        """
                        )
                    row = self.cursor.fetchone()
                    if not row:
                        return None
                    return {
                        "symbol": row[0],
                        "entry": row[1],
                        "tp1": row[2],
                        "tp2": row[3],
                        "entry_time": row[4],
                        "result": row[5],
                    }
        except (sqlite3.Error, ValueError, AttributeError, RuntimeError) as e:
            logging.warning("get_last_signal_log error: %s", e)
            return None

    # --- Backtest results API ---
    def insert_backtest_result(self, result: dict) -> bool:
        """
        –í—Å—Ç–∞–≤–ª—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –±—ç–∫—Ç–µ—Å—Ç–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.

        Args:
            result (dict): –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –±—ç–∫—Ç–µ—Å—Ç–∞

        Returns:
            bool: True –µ—Å–ª–∏ –≤—Å—Ç–∞–≤–∫–∞ –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ, False –≤ –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ
        """
        try:
            with self._lock:
                self.conn.execute(
                    """
                    INSERT INTO backtest_results(
                        symbol, interval, since_days, bars, signals, tp1, tp2, sl, pnl,
                        mae_avg_pct, mfe_avg_pct, avg_duration_sec, started_at, ended_at
                    ) VALUES(?,?,?,?,?,?,?,?,?,?,?,?,?,?)
                    """,
                    (
                        result.get("symbol"),
                        result.get("interval"),
                        int(result.get("since_days", 0) or 0),
                        int(result.get("bars", 0) or 0),
                        int(result.get("signals", 0) or 0),
                        int(result.get("tp1", 0) or 0),
                        int(result.get("tp2", 0) or 0),
                        int(result.get("sl", 0) or 0),
                        float(result.get("pnl", 0.0) or 0.0),
                        float(result.get("mae_avg_pct", 0.0) or 0.0),
                        float(result.get("mfe_avg_pct", 0.0) or 0.0),
                        float(result.get("avg_duration_sec", 0.0) or 0.0),
                        result.get("start"),
                        result.get("end"),
                    ),
                )
                self.conn.commit()
            return True
        except (sqlite3.Error, ValueError, TypeError) as e:
            logging.warning("insert_backtest_result error: %s", e)
            return False

    def get_recent_backtests(self, limit: int = 10):
        """
        –ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—ç–∫—Ç–µ—Å—Ç–æ–≤.

        Args:
            limit (int): –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

        Returns:
            list: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±—ç–∫—Ç–µ—Å—Ç–æ–≤
        """
        try:
            with self._lock:
                cur = self.conn.execute(
                    """
                    SELECT symbol, interval, since_days, bars, signals, tp1, tp2, sl, pnl,
                           mae_avg_pct, mfe_avg_pct, avg_duration_sec, started_at, ended_at, created_at
                    FROM backtest_results
                    ORDER BY datetime(created_at) DESC
                    LIMIT ?
                    """,
                    (int(limit),),
                )
                rows = fetch_all_optimized(cur) or []
            # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –∏—Å–ø–æ–ª—å–∑—É–µ–º list comprehension –≤–º–µ—Å—Ç–æ —Ü–∏–∫–ª–∞ —Å append
            return [
                {
                    "symbol": r[0], "interval": r[1], "since_days": r[2], "bars": r[3], "signals": r[4],
                    "tp1": r[5], "tp2": r[6], "sl": r[7], "pnl": r[8],
                    "mae_avg_pct": r[9], "mfe_avg_pct": r[10], "avg_duration_sec": r[11],
                    "start": r[12], "end": r[13], "created_at": r[14],
                }
                for r in rows
            ]
        except (sqlite3.Error, ValueError, TypeError) as e:
            logging.warning("get_recent_backtests error: %s", e)
            return []

    def get_false_breakout_summary(self, hours: int = 24) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –ª–æ–∂–Ω—ã—Ö –ø—Ä–æ–±–æ–µ–≤ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —á–∞—Å–æ–≤."""
        summary: Dict[str, Any] = {
            'window_hours': hours,
            'total_events': 0,
            'pass_rate': None,
            'avg_confidence': None,
            'avg_threshold': None,
            'avg_volatility_pct': None,
            'avg_recent_pass_rate': None,
            'regime_breakdown': []
        }
        try:
            window_clause = f"-{int(hours)} hours"
            with self._lock:
                cur = self.conn.execute(
                    """
                    SELECT
                        COUNT(*),
                        SUM(passed),
                        AVG(confidence),
                        AVG(threshold),
                        AVG(volatility_pct),
                        AVG(recent_pass_rate)
                    FROM false_breakout_events
                    WHERE created_at >= datetime('now', ?)
                      AND COALESCE(test_run, 0) = 0
                    """,
                    (window_clause,),
                )
                row = cur.fetchone()
                if row:
                    total, passed, avg_conf, avg_threshold, avg_vol, avg_recent = row
                    summary['total_events'] = int(total or 0)
                    if total:
                        summary['pass_rate'] = (passed or 0) / total
                    summary['avg_confidence'] = avg_conf
                    summary['avg_threshold'] = avg_threshold
                    summary['avg_volatility_pct'] = avg_vol
                    summary['avg_recent_pass_rate'] = avg_recent

                cur = self.conn.execute(
                    """
                    SELECT
                        COALESCE(regime, 'UNKNOWN') AS regime,
                        COUNT(*) AS total,
                        SUM(passed) AS passed
                    FROM false_breakout_events
                    WHERE created_at >= datetime('now', ?)
                      AND COALESCE(test_run, 0) = 0
                    GROUP BY regime
                    ORDER BY total DESC
                    """,
                    (window_clause,),
                )
                summary['regime_breakdown'] = [
                    {
                        'regime': regime,
                        'total': int(total or 0),
                        'pass_rate': (passed or 0) / total if total else None,
                    }
                    for regime, total, passed in fetch_all_optimized(cur)
                ]
        except sqlite3.Error as e:
            logging.warning("get_false_breakout_summary error: %s", e)
        return summary

    def get_mtf_confirmation_summary(self, hours: int = 24) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É MTF-–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —á–∞—Å–æ–≤."""
        summary: Dict[str, Any] = {
            'window_hours': hours,
            'total_events': 0,
            'confirmation_rate': None,
            'error_rate': None,
            'regime_breakdown': []
        }
        try:
            window_clause = f"-{int(hours)} hours"
            with self._lock:
                cur = self.conn.execute(
                    """
                    SELECT
                        COUNT(*),
                        SUM(confirmed),
                        SUM(CASE WHEN error IS NOT NULL AND error <> '' THEN 1 ELSE 0 END)
                    FROM mtf_confirmation_events
                    WHERE created_at >= datetime('now', ?)
                    """,
                    (window_clause,),
                )
                row = cur.fetchone()
                if row:
                    total, confirmed, errors = row
                    summary['total_events'] = int(total or 0)
                    if total:
                        summary['confirmation_rate'] = (confirmed or 0) / total
                        summary['error_rate'] = (errors or 0) / total

                cur = self.conn.execute(
                    """
                    SELECT
                        COALESCE(regime, 'UNKNOWN') AS regime,
                        COUNT(*) AS total,
                        SUM(confirmed) AS confirmed
                    FROM mtf_confirmation_events
                    WHERE created_at >= datetime('now', ?)
                    GROUP BY regime
                    ORDER BY total DESC
                    """,
                    (window_clause,),
                )
                summary['regime_breakdown'] = [
                    {
                        'regime': regime,
                        'total': int(total or 0),
                        'confirmation_rate': (confirmed or 0) / total if total else None,
                    }
                    for regime, total, confirmed in fetch_all_optimized(cur)
                ]
        except sqlite3.Error as e:
            logging.warning("get_mtf_confirmation_summary error: %s", e)
        return summary

    # --- –ü–µ—Ä—Ñ–æ–º–∞–Ω—Å –ø–æ —Å–∏–º–≤–æ–ª–∞–º (–§–∞–∑–∞ 2) ---
    def get_symbol_performance(self, since_days: int = 7) -> dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å {symbol: {total, tp2, tp1, sl, net_profit_sum, winrate}} –∑–∞ –ø–µ—Ä–∏–æ–¥."""
        try:
            with self._lock:
                cur = self.conn.execute(
                    """
                    SELECT symbol,
                           COUNT(*) as total,
                           SUM(CASE WHEN result LIKE 'TP2%' THEN 1 ELSE 0 END) as tp2,
                           SUM(CASE WHEN result LIKE 'TP1%' THEN 1 ELSE 0 END) as tp1,
                           SUM(CASE WHEN UPPER(result) LIKE 'SL%' THEN 1 ELSE 0 END) as sl,
                           IFNULL(SUM(net_profit),0.0) as net_profit_sum
                    FROM signals_log
                    WHERE datetime(created_at) >= datetime('now', ?)
                    GROUP BY symbol
                    """,
                    (f"-{int(since_days)} days",),
                )
                rows = fetch_all_optimized(cur) or []
            out = {}
            for s, total, tp2, tp1, sl, netp in rows:
                total = int(total or 0)
                tp_all = int(tp2 or 0) + int(tp1 or 0)
                winrate = (tp_all / total) if total > 0 else 0.0
                out[str(s)] = {
                    "total": total,
                    "tp2": int(tp2 or 0),
                    "tp1": int(tp1 or 0),
                    "sl": int(sl or 0),
                    "net_profit_sum": float(netp or 0.0),
                    "winrate": float(winrate),
                }
            return out
        except (sqlite3.Error, ValueError, TypeError) as e:
            logging.warning("get_symbol_performance error: %s", e)
            return {}

    # --- –ê—É–¥–∏—Ç –∏ –∞–ª–µ—Ä—Ç—ã (—Ç–∞–±–ª–∏—Ü—ã –∏ –º–µ—Ç–æ–¥—ã) ---
    def _ensure_audit_tables(self):
        try:
            with self._lock:
                self.conn.execute(
                    """
                    CREATE TABLE IF NOT EXISTS audit_dynamic_params (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        ts TEXT,
                        scope TEXT,
                        param TEXT,
                        old_value TEXT,
                        new_value TEXT,
                        note TEXT
                    )
                    """
                )
                self.conn.execute(
                    """
                    CREATE TABLE IF NOT EXISTS audit_strategy_pauses (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        ts TEXT,
                        action TEXT,
                        reason TEXT,
                        window_hours INTEGER,
                        sl_count INTEGER,
                        net_profit_sum REAL
                    )
                    """
                )
                self.conn.execute(
                    """
                    CREATE TABLE IF NOT EXISTS audit_soft_blocklist (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        ts TEXT,
                        action TEXT,
                        symbol TEXT,
                        votes INTEGER,
                        reason TEXT
                    )
                    """
                )
                self.conn.execute(
                    """
                    CREATE TABLE IF NOT EXISTS audit_active_coins (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        ts TEXT,
                        action TEXT,
                        symbol TEXT,
                        note TEXT
                    )
                    """
                )
                self.conn.commit()
        except sqlite3.Error as e:
            logging.warning("ensure_audit_tables error: %s", e)

    def audit_dynamic_param(self, scope: str, param: str, old_value, new_value, note: str = None):
        """
        –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –≤ –∞—É–¥–∏—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–µ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞.

        Args:
            scope (str): –û–±–ª–∞—Å—Ç—å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞
            param (str): –ù–∞–∑–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞
            old_value: –°—Ç–∞—Ä–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            new_value: –ù–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            note (str, optional): –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–º–µ—Ç–∫–∞
        """
        try:
            self._ensure_audit_tables()
            with self._lock:
                self.conn.execute(
                    "INSERT INTO audit_dynamic_params(ts, scope, param, old_value, new_value, note) "
                    "VALUES(datetime('now'),?,?,?,?,?)",
                    (
                        scope, param,
                        json.dumps(old_value, ensure_ascii=False),
                        json.dumps(new_value, ensure_ascii=False),
                        note
                    ),
                )
                self.conn.commit()
        except (sqlite3.Error, TypeError, ValueError) as e:
            logging.warning("audit_dynamic_param error: %s", e)

    def audit_soft_block(self, action: str, symbol: str, votes: int = None, reason: str = None):
        """
        –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –≤ –∞—É–¥–∏—Ç –¥–µ–π—Å—Ç–≤–∏–µ —Å –º—è–≥–∫–∏–º –±–ª–æ–∫–ª–∏—Å—Ç–æ–º.

        Args:
            action (str): –î–µ–π—Å—Ç–≤–∏–µ (add/remove)
            symbol (str): –°–∏–º–≤–æ–ª —Ç–æ—Ä–≥–æ–≤–æ–π –ø–∞—Ä—ã
            votes (int, optional): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–æ–ª–æ—Å–æ–≤
            reason (str, optional): –ü—Ä–∏—á–∏–Ω–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
        """
        try:
            self._ensure_audit_tables()
            with self._lock:
                self.conn.execute(
                    "INSERT INTO audit_soft_blocklist(ts, action, symbol, votes, reason) "
                    "VALUES(datetime('now'),?,?,?,?)",
                    (action, symbol, int(votes) if votes is not None else None, reason),
                )
                self.conn.commit()
        except (sqlite3.Error, TypeError, ValueError) as e:
            logging.warning("audit_soft_block error: %s", e)

    def select_signals_for_backtest(self, symbol: str, since_iso: str):
        """
        –ü—É–±–ª–∏—á–Ω—ã–π —Å–µ–ª–µ–∫—Ç–æ—Ä –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∞: –≤—ã–±–∏—Ä–∞–µ—Ç —Å–∏–≥–Ω–∞–ª—ã –ø–æ —Å–∏–º–≤–æ–ª—É –ø–æ—Å–ª–µ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (entry, stop, tp1, tp2, entry_time).
        """
        try:
            with self._lock:
                cur = self.conn.execute(
                    """
                    SELECT entry, stop, tp1, tp2, entry_time
                    FROM signals_log
                    WHERE symbol = ? AND datetime(entry_time) >= datetime(?)
                    ORDER BY datetime(entry_time) ASC
                    """,
                    (symbol, since_iso),
                )
                return fetch_all_optimized(cur) or []
        except sqlite3.Error as e:
            logging.warning("select_signals_for_backtest error: %s", e)
            return []

    def insert_signal_log(self, symbol: str, entry: float, stop: float, tp1: float, tp2: float,
                           entry_time: str, quality_score: Optional[float] = None,
                           quality_meta: Optional[dict] = None,
                           leverage_used: Optional[float] = None,
                           risk_pct_used: Optional[float] = None,
                           entry_amount_usd: Optional[float] = None,
                           trade_mode: Optional[str] = None,
                           funding_rate: Optional[float] = None,
                           quote24h_usd: Optional[float] = None,
                           depth_usd: Optional[float] = None,
                           spread_pct: Optional[float] = None,
                           exposure_pct: Optional[float] = None,
                           mtf_score: Optional[float] = None,
                           sector: Optional[str] = None,
                           expected_cost_usd: Optional[float] = None,
                           impact_bp: Optional[float] = None,
                           user_id: Optional[int] = None,
                           direction: Optional[str] = None):
        """
        –í—Å—Ç–∞–≤–ª—è–µ—Ç –∑–∞–ø–∏—Å—å –æ —Å–∏–≥–Ω–∞–ª–µ –≤ –ª–æ–≥ —Å–∏–≥–Ω–∞–ª–æ–≤.

        Args:
            symbol (str): –°–∏–º–≤–æ–ª —Ç–æ—Ä–≥–æ–≤–æ–π –ø–∞—Ä—ã
            entry (float): –¶–µ–Ω–∞ –≤—Ö–æ–¥–∞
            stop (float): –¶–µ–Ω–∞ —Å—Ç–æ–ø-–ª–æ—Å—Å–∞
            tp1 (float): –ü–µ—Ä–≤—ã–π —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç
            tp2 (float): –í—Ç–æ—Ä–æ–π —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç
            entry_time (str): –í—Ä–µ–º—è –≤—Ö–æ–¥–∞
            quality_score (float, optional): –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–∏–≥–Ω–∞–ª–∞
            quality_meta (dict, optional): –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∫–∞—á–µ—Å—Ç–≤–∞
            leverage_used (float, optional): –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–æ–µ –ø–ª–µ—á–æ
            risk_pct_used (float, optional): –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç —Ä–∏—Å–∫–∞
            entry_amount_usd (float, optional): –°—É–º–º–∞ –≤—Ö–æ–¥–∞ –≤ USD
            trade_mode (str, optional): –†–µ–∂–∏–º —Ç–æ—Ä–≥–æ–≤–ª–∏ ('spot'/'futures')
            funding_rate (float, optional): –°—Ç–∞–≤–∫–∞ —Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏—è
            quote24h_usd (float, optional): –û–±—ä–µ–º —Ç–æ—Ä–≥–æ–≤ –∑–∞ 24—á –≤ USD
            depth_usd (float, optional): –ì–ª—É–±–∏–Ω–∞ —Ä—ã–Ω–∫–∞ –≤ USD
            spread_pct (float, optional): –°–ø—Ä–µ–¥ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
            exposure_pct (float, optional): –ü—Ä–æ—Ü–µ–Ω—Ç —ç–∫—Å–ø–æ–∑–∏—Ü–∏–∏
            mtf_score (float, optional): –û—Ü–µ–Ω–∫–∞ –º—É–ª—å—Ç–∏—Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
            sector (str, optional): –°–µ–∫—Ç–æ—Ä
            expected_cost_usd (float, optional): –û–∂–∏–¥–∞–µ–º–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –≤ USD
            impact_bp (float, optional): –í–ª–∏—è–Ω–∏–µ –≤ –±–∞–∑–∏—Å–Ω—ã—Ö –ø—É–Ω–∫—Ç–∞—Ö
            user_id (int, optional): ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            direction (str, optional): –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ ('BUY'/'SELL')
        """
        try:
            # üõ°Ô∏è –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–Ø –°–ò–ú–í–û–õ–ê: –ü—Ä–∏–≤–æ–¥–∏–º –∫ –µ–¥–∏–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤ –ë–î
            user_trade_mode = 'spot'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
            if user_id is not None:
                try:
                    user_data_temp = self.get_user_data(str(user_id)) or {}
                    user_trade_mode = user_data_temp.get('trade_mode', 'spot')
                except Exception:
                    pass  # –ò—Å–ø–æ–ª—å–∑—É–µ–º 'spot' –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–∏–º–≤–æ–ª
            try:
                from src.utils.shared_utils import normalize_symbol_for_db
                symbol_normalized = normalize_symbol_for_db(symbol, user_trade_mode)
                if symbol_normalized != symbol:
                    logging.getLogger(__name__).debug("üîÑ [DB] –°–∏–º–≤–æ–ª –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω –≤ signals_log: %s ‚Üí %s (—Ä–µ–∂–∏–º: %s)", symbol, symbol_normalized, user_trade_mode)
                symbol = symbol_normalized
            except Exception as e:
                logging.getLogger(__name__).warning("‚ö†Ô∏è [DB] –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å —Å–∏–º–≤–æ–ª %s –≤ signals_log: %s. –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –µ—Å—Ç—å", symbol, e)

            with self._lock:
                self.conn.execute(
                    """
                    INSERT INTO signals_log(symbol, entry, stop, tp1, tp2, entry_time, result, net_profit,
                                             qty_added, qty_closed, trade_mode,
                                             leverage_used, risk_pct_used, entry_amount_usd,
                                             funding_rate, quote24h_usd, depth_usd, spread_pct, exposure_pct,
                                             mtf_score, sector, expected_cost_usd, impact_bp,
                                             quality_score, quality_meta, user_id, direction)
                    VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """,
                    (
                        symbol, float(entry), float(stop), float(tp1), float(tp2), entry_time,
                        "PENDING", None, None, 0.0, trade_mode.lower() if isinstance(trade_mode, str) else None,
                        float(leverage_used) if leverage_used is not None else None,
                        float(risk_pct_used) if risk_pct_used is not None else None,
                        float(entry_amount_usd) if entry_amount_usd is not None else None,
                        float(funding_rate) if funding_rate is not None else None,
                        float(quote24h_usd) if quote24h_usd is not None else None,
                        float(depth_usd) if depth_usd is not None else None,
                        float(spread_pct) if spread_pct is not None else None,
                        float(exposure_pct) if exposure_pct is not None else None,
                        float(mtf_score) if mtf_score is not None else None,
                        sector if sector is not None else None,
                        float(expected_cost_usd) if expected_cost_usd is not None else None,
                        float(impact_bp) if impact_bp is not None else None,
                        float(quality_score) if quality_score is not None else None,
                        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –∏—Å–ø–æ–ª—å–∑—É–µ–º –±—ã—Å—Ç—Ä—É—é —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—é
                        self._serialize_quality_meta(quality_meta),
                        int(user_id) if user_id is not None else None,
                        direction
                    ),
                )
                self.conn.commit()
            backup_file(self.db_path)
            return True
        except (sqlite3.Error, ValueError, TypeError) as e:
            logging.warning("insert_signal_log error: %s", e)
            return False

    def audit_strategy_pause(
        self, action: str, reason: str, window_hours: int, sl_count: int, net_profit_sum: float
    ) -> None:
        """
        –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –≤ –∞—É–¥–∏—Ç –ø–∞—É–∑—É —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏.

        Args:
            action (str): –î–µ–π—Å—Ç–≤–∏–µ (pause/resume)
            reason (str): –ü—Ä–∏—á–∏–Ω–∞ –ø–∞—É–∑—ã
            window_hours (int): –û–∫–Ω–æ –≤—Ä–µ–º–µ–Ω–∏ –≤ —á–∞—Å–∞—Ö
            sl_count (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ø-–ª–æ—Å—Å–æ–≤
            net_profit_sum (float): –°—É–º–º–∞—Ä–Ω–∞—è —á–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å
        """
        try:
            self._ensure_audit_tables()
            with self._lock:
                self.conn.execute(
                    "INSERT INTO audit_strategy_pauses(ts, action, reason, window_hours, "
                    "sl_count, net_profit_sum) VALUES(datetime('now'),?,?,?,?,?)",
                    (action, reason, int(window_hours), int(sl_count), float(net_profit_sum))
                )
                self.conn.commit()
        except sqlite3.Error as e:
            logging.warning("audit_strategy_pause error: %s", e)

    def insert_position_sizing_event(self, event: Dict[str, Any]) -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–µ—Ç–∞–ª–∏ —Ä–∞—Å—á—ë—Ç–∞ —Ä–∞–∑–º–µ—Ä–∞ –ø–æ–∑–∏—Ü–∏–∏ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞."""
        if not event:
            return

        try:
            with self._lock:
                query = """
                    INSERT INTO position_sizing_events (
                        symbol, direction, entry_time, signal_token, user_id, trade_mode,
                        signal_price, baseline_amount_usd, ai_amount_usd, regime_multiplier,
                        after_regime_amount_usd, correlation_multiplier, after_correlation_amount_usd,
                        adaptive_multiplier, after_adaptive_amount_usd, risk_adjustment_multiplier,
                        final_amount_usd, base_risk_pct, ai_risk_pct, leverage, regime,
                        regime_confidence, quality_score, composite_score, pattern_confidence,
                        adaptive_reason, adaptive_components
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """
                params = (
                    event.get("symbol"),
                    event.get("direction"),
                    event.get("entry_time"),
                    event.get("signal_token"),
                    str(event.get("user_id")) if event.get("user_id") is not None else None,
                    event.get("trade_mode"),
                    _safe_float(event.get("signal_price")),
                    _safe_float(event.get("baseline_amount_usd")),
                    _safe_float(event.get("ai_amount_usd")),
                    _safe_float(event.get("regime_multiplier")),
                    _safe_float(event.get("after_regime_amount_usd")),
                    _safe_float(event.get("correlation_multiplier")),
                    _safe_float(event.get("after_correlation_amount_usd")),
                    _safe_float(event.get("adaptive_multiplier")),
                    _safe_float(event.get("after_adaptive_amount_usd")),
                    _safe_float(event.get("risk_adjustment_multiplier")),
                    _safe_float(event.get("final_amount_usd")),
                    _safe_float(event.get("base_risk_pct")),
                    _safe_float(event.get("ai_risk_pct")),
                    _safe_float(event.get("leverage")),
                    event.get("regime"),
                    _safe_float(event.get("regime_confidence")),
                    _safe_float(event.get("quality_score")),
                    _safe_float(event.get("composite_score")),
                    _safe_float(event.get("pattern_confidence")),
                    event.get("adaptive_reason"),
                    json.dumps(event.get("adaptive_components"), ensure_ascii=False) if event.get("adaptive_components") is not None else None,
                )
                self.conn.execute(query, params)
                self.conn.commit()
        except sqlite3.Error as e:
            logging.warning("insert_position_sizing_event error: %s", e)

    # --- DB Cache helpers ---
    def cache_set(self, cache_type: str, cache_key: str, payload: dict, ttl_seconds: int) -> bool:
        """
        –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –∫—ç—à –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.

        Args:
            cache_type (str): –¢–∏–ø –∫—ç—à–∞
            cache_key (str): –ö–ª—é—á –∫—ç—à–∞
            payload (dict): –î–∞–Ω–Ω—ã–µ –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
            ttl_seconds (int): –í—Ä–µ–º—è –∂–∏–∑–Ω–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö

        Returns:
            bool: True –µ—Å–ª–∏ –∫—ç—à —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —É—Å–ø–µ—à–Ω–æ, False –≤ –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ
        """
        try:
            expires_at = int(time.time()) + int(ttl_seconds)
            payload_json = json.dumps(payload, ensure_ascii=False)

            # üîß –ò–°–ü–†–ê–í–õ–ï–ù–û: connection_pool –æ—Ç–∫–ª—é—á–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
            if self.conn is not None:
                with self._lock:
                    self.conn.execute(
                        """
                        INSERT INTO app_cache(cache_type, cache_key, payload, expires_at)
                        VALUES(?, ?, ?, ?)
                        ON CONFLICT(cache_type, cache_key) DO UPDATE SET
                            payload=excluded.payload,
                            expires_at=excluded.expires_at
                        """,
                        (cache_type, cache_key, payload_json, expires_at),
                    )
                    self.conn.commit()
            else:
                logging.warning("cache_set: conn is None")
                return False
            return True
        except (sqlite3.Error, ValueError, TypeError) as e:
            logging.warning("cache_set error: %s", e)
            return False

    def cache_get(self, cache_type: str, cache_key: str):
        """
        –ü–æ–ª—É—á–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –∫—ç—à–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.

        Args:
            cache_type (str): –¢–∏–ø –∫—ç—à–∞
            cache_key (str): –ö–ª—é—á –∫—ç—à–∞

        Returns:
            dict: –î–∞–Ω–Ω—ã–µ –∏–∑ –∫—ç—à–∞ –∏–ª–∏ None, –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –∏—Å—Ç–µ–∫–ª–∏
        """
        try:
            now_ts = int(time.time())

            if self.conn is not None:
                with self._lock:
                    cur = self.conn.execute(
                        "SELECT payload, expires_at FROM app_cache "
                        "WHERE cache_type=? AND cache_key=?",
                        (cache_type, cache_key),
                    )
                    row = cur.fetchone()
                
                if not row:
                    return None
                
                payload_json, expires_at = row
                if expires_at and int(expires_at) > now_ts:
                    try:
                        return json.loads(payload_json)
                    except json.JSONDecodeError:
                        return None
                else:
                    # –∏—Å—Ç—ë–∫ ‚Äî —É–¥–∞–ª–∏–º –ª–µ–Ω–∏–≤–æ
                    with self._lock:
                        self.conn.execute(
                            "DELETE FROM app_cache WHERE cache_type=? AND cache_key=?",
                            (cache_type, cache_key),
                        )
                        self.conn.commit()
                    return None
            else:
                logging.warning("cache_get: conn is None")
                return None
        except (sqlite3.Error, ValueError, TypeError) as e:
            logging.warning("cache_get error: %s", e)
            return None

    def cache_purge_expired(self) -> int:
        """–£–¥–∞–ª—è–µ—Ç –ø—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ –∏–∑ app_cache. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —á–∏—Å–ª–æ —É–¥–∞–ª—ë–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫.

        –ü—É–±–ª–∏—á–Ω—ã–π –º–µ—Ç–æ–¥, –∏–Ω–∫–∞–ø—Å—É–ª–∏—Ä—É—é—â–∏–π –¥–æ—Å—Ç—É–ø –∫ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–º—É lock/conn.
        """
        try:
            now_ts = int(time.time())
            with self._lock:
                cur = self.conn.execute(
                    "DELETE FROM app_cache WHERE IFNULL(expires_at,0) > 0 AND expires_at < ?",
                    (now_ts,),
                )
                self.conn.commit()
                return cur.rowcount if cur is not None else 0
        except (sqlite3.Error, ValueError, TypeError) as e:
            logging.warning("cache_purge_expired error: %s", e)
            return 0

    # --- –ü–µ—Ä—Ñ–æ–º–∞–Ω—Å-–º–µ—Ç—Ä–∏–∫–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥ ---
    def get_performance_summary(self, since_days: int = 7) -> dict:
        """
        –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ signals_log –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π.
        –í–∫–ª—é—á–∞–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –∫–≤–∞–Ω—Ç–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ (Sharpe, Sortino, MaxDD).
        """
        days = max(1, int(since_days))
        summary = {
            "since_days": days,
            "total_events": 0,
            "distinct_positions": 0,
            "tp2_count": 0,
            "tp1_partial_count": 0,
            "sl_count": 0,
            "net_profit_sum": 0.0,
            "net_profit_avg": 0.0,
            "winrate": 0.0,
            "sharpe_ratio": 0.0,
            "sortino_ratio": 0.0,
            "max_drawdown_pct": 0.0,
            "recent": [],
        }
        try:
            with self._lock:
                # ... (–±–∞–∑–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
                cur = self.conn.execute(
                    "SELECT COUNT(*) FROM signals_log WHERE datetime(created_at) >= datetime('now', ?)",
                    (f"-{days} days",),
                )
                summary["total_events"] = int(cur.fetchone()[0] or 0)

                cur = self.conn.execute(
                    "SELECT COUNT(DISTINCT symbol || '|' || IFNULL(entry_time,'')) "
                    "FROM signals_log WHERE datetime(created_at) >= datetime('now', ?)",
                    (f"-{days} days",),
                )
                summary["distinct_positions"] = int(cur.fetchone()[0] or 0)

                cur = self.conn.execute(
                    """
                    SELECT
                      SUM(CASE WHEN result LIKE 'TP2%' THEN 1 ELSE 0 END),
                      SUM(CASE WHEN result LIKE 'TP1%' THEN 1 ELSE 0 END),
                      SUM(CASE WHEN UPPER(result) LIKE 'SL%' THEN 1 ELSE 0 END)
                    FROM signals_log
                    WHERE datetime(created_at) >= datetime('now', ?)
                    """,
                    (f"-{days} days",),
                )
                row = cur.fetchone() or (0, 0, 0)
                summary["tp2_count"] = int(row[0] or 0)
                summary["tp1_partial_count"] = int(row[1] or 0)
                summary["sl_count"] = int(row[2] or 0)

                cur = self.conn.execute(
                    "SELECT IFNULL(SUM(net_profit),0.0), IFNULL(AVG(net_profit),0.0) "
                    "FROM signals_log WHERE datetime(created_at) >= datetime('now', ?)",
                    (f"-{days} days",),
                )
                agg = cur.fetchone() or (0.0, 0.0)
                summary["net_profit_sum"] = float(agg[0] or 0.0)
                summary["net_profit_avg"] = float(agg[1] or 0.0)

                total_trades = summary["tp2_count"] + summary["tp1_partial_count"] + summary["sl_count"]
                if total_trades > 0:
                    successful_trades = summary["tp2_count"] + summary["tp1_partial_count"]
                    summary["winrate"] = (successful_trades / total_trades) * 100.0

                # --- ADVANCED QUANT METRICS (Sharpe, Sortino, MaxDD) ---
                # –ü–æ–ª—É—á–∞–µ–º –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏
                cur = self.conn.execute(
                    """
                    SELECT date(created_at) as trade_date, SUM(net_profit)
                    FROM signals_log
                    WHERE datetime(created_at) >= datetime('now', ?)
                    GROUP BY trade_date
                    ORDER BY trade_date ASC
                    """,
                    (f"-{days} days",),
                )
                daily_profits = [row[1] for row in cur.fetchall() if row[1] is not None]
                
                if len(daily_profits) >= 2:
                    import numpy as np
                    profits_arr = np.array(daily_profits, dtype=float)
                    
                    # Sharpe (–∞–Ω–Ω—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π sqrt(365) –¥–ª—è –∫—Ä–∏–ø—Ç–æ)
                    mean_p = np.mean(profits_arr)
                    std_p = np.std(profits_arr)
                    if std_p > 0:
                        summary["sharpe_ratio"] = float((mean_p / std_p) * np.sqrt(365))
                    
                    # Sortino (Downside risk)
                    downside_returns = profits_arr[profits_arr < 0]
                    if len(downside_returns) > 0:
                        downside_std = np.sqrt(np.mean(downside_returns**2))
                        if downside_std > 0:
                            summary["sortino_ratio"] = float((mean_p / downside_std) * np.sqrt(365))
                    else:
                        summary["sortino_ratio"] = 100.0 # –û—à–∏–±–æ–∫ –Ω–µ—Ç
                    
                    # Max Drawdown
                    cumulative = np.cumsum(profits_arr)
                    peak = np.maximum.accumulate(cumulative)
                    # –ï—Å–ª–∏ –±–∞–ª–∞–Ω—Å –Ω–µ –∏–∑–≤–µ—Å—Ç–µ–Ω, —Å—á–∏—Ç–∞–µ–º DD –≤ –µ–¥–∏–Ω–∏—Ü–∞—Ö –ø—Ä–æ—Ñ–∏—Ç–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ø–∏–∫–∞
                    drawdown = peak - cumulative
                    # –ï—Å–ª–∏ –ø–∏–∫ –±–æ–ª—å—à–µ 0, –º–æ–∂–µ–º –æ—Ü–µ–Ω–∏—Ç—å % (—É–ø—Ä–æ—â–µ–Ω–Ω–æ)
                    summary["max_drawdown_units"] = float(np.max(drawdown))

                # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å–¥–µ–ª–æ–∫
                cur = self.conn.execute(
                    """
                    SELECT symbol, result, net_profit, created_at
                    FROM signals_log
                    WHERE datetime(created_at) >= datetime('now', ?)
                    ORDER BY datetime(created_at) DESC
                    LIMIT 10
                    """,
                    (f"-{days} days",),
                )
                rows = fetch_all_optimized(cur) or []
                summary["recent"] = [
                    {
                        "symbol": s,
                        "result": r,
                        "net_profit": float(np_val) if np_val is not None else None,
                        "created_at": ts,
                    }
                    for s, r, np_val, ts in rows
                ]

            return summary
        except (sqlite3.Error, ValueError, TypeError) as e:
            logging.warning("get_performance_summary error: %s", e)
            return summary

    # --- –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏: —Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ç–∞–±–ª–∏—Ü–µ users_data –≤–º–µ—Å—Ç–æ JSON ---
    def get_all_users(self):
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö user_id –∏–∑ –ë–î (—Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º)"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à –¥–ª—è —á–∞—Å—Ç–æ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º–æ–≥–æ —Å–ø–∏—Å–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        if self._query_cache_enabled and self._query_cache:
            cached = self._query_cache.get("SELECT user_id FROM users_data", ())
            if cached is not None:
                return cached
        
        with self._lock:
            if self.conn:
                cur = self.conn.execute("SELECT user_id FROM users_data")
                rows = fetch_all_optimized(cur)
                result = [r[0] for r in rows]
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à –Ω–∞ 5 –º–∏–Ω—É—Ç (—Å–ø–∏—Å–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –º–µ–Ω—è–µ—Ç—Å—è —Ä–µ–¥–∫–æ)
                if self._query_cache_enabled and self._query_cache:
                    self._query_cache.set("SELECT user_id FROM users_data", (), result, ttl=300.0)
                
                return result
            else:
                logger.error("‚ùå –ë–î –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ (conn=None)")
                return []

    def get_user_data(self, user_id):
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –ë–î"""
        with self._lock:
            if self.conn:
                cur = self.conn.execute("SELECT data FROM users_data WHERE user_id=?", (str(user_id),))
                row = cur.fetchone()
            else:
                logger.error("‚ùå –ë–î –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ (conn=None)")
                return {}

        if row and row[0]:
            try:
                # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±—ã—Å—Ç—Ä—É—é —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—é (MessagePack), fallback –Ω–∞ JSON
                try:
                    from src.data.serialization import deserialize_fast
                    import base64
                    # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ base64 (MessagePack)
                    if isinstance(row[0], str) and len(row[0]) > 0:
                        try:
                            decoded = base64.b64decode(row[0])
                            parsed_data = deserialize_fast(decoded)
                        except (ValueError, Exception):
                            # Fallback –Ω–∞ JSON
                            parsed_data = json.loads(row[0])
                    else:
                        parsed_data = json.loads(row[0])
                except (ImportError, Exception):
                    # Fallback –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π JSON
                    parsed_data = json.loads(row[0])
                
                if not isinstance(parsed_data, dict):
                    logger.warning("‚ö†Ô∏è –î–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è %s –Ω–µ —è–≤–ª—è—é—Ç—Å—è dict: %s", user_id, type(parsed_data))
                    return None
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à –Ω–∞ 30 —Å–µ–∫—É–Ω–¥ (–¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –º–æ–≥—É—Ç —á–∞—Å—Ç–æ –∑–∞–ø—Ä–∞—à–∏–≤–∞—Ç—å—Å—è)
                if self._query_cache_enabled and self._query_cache:
                    self._query_cache.set("SELECT data FROM users_data WHERE user_id=?", (str(user_id),), parsed_data, ttl=30.0)
                
                return parsed_data
            except (json.JSONDecodeError, TypeError) as e:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è %s: %s (–¥–∞–Ω–Ω—ã–µ: %s)", user_id, e, str(row[0])[:100] if row[0] else "None")
                return None
        logger.debug("‚ö†Ô∏è –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å %s –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ë–î –∏–ª–∏ –¥–∞–Ω–Ω—ã–µ –ø—É—Å—Ç—ã", user_id)
        return None

    def save_user_data(self, user_id, data):
        try:
            # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±—ã—Å—Ç—Ä—É—é —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—é (MessagePack), fallback –Ω–∞ JSON
            try:
                from src.data.serialization import serialize_fast
                data_serialized = serialize_fast(data)
                # MessagePack –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç bytes, –Ω–æ SQLite TEXT —Ç—Ä–µ–±—É–µ—Ç —Å—Ç—Ä–æ–∫—É
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º base64 –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è bytes –≤ TEXT –ø–æ–ª–µ
                import base64
                data_json = base64.b64encode(data_serialized).decode('utf-8')
            except (ImportError, Exception):
                # Fallback –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π JSON
                data_json = json.dumps(data, ensure_ascii=False)
        except (TypeError, ValueError) as e:
            logging.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞—Ç—å user_data –¥–ª—è %s: %s", user_id, e)
            return False

        try:
            # üîß –ò–°–ü–†–ê–í–õ–ï–ù–û: connection_pool –æ—Ç–∫–ª—é—á–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
            if self.conn is None:
                logging.warning("save_user_data: conn is None")
                return False
            with self._lock:
                self.conn.execute(
                    """
                    INSERT INTO users_data (user_id, data, updated_at)
                    VALUES (?, ?, CURRENT_TIMESTAMP)
                    ON CONFLICT(user_id) DO UPDATE SET data=excluded.data, updated_at=CURRENT_TIMESTAMP
                """,
                    (str(user_id), data_json),
                )
                self.conn.commit()
            self.periodic_backup()
            return True
        except (sqlite3.Error, ValueError, TypeError, AttributeError) as e:
            logging.warning("save_user_data error –¥–ª—è %s: %s", user_id, e)
            return False

    def delete_user_data(self, user_id):
        try:
            # üîß –ò–°–ü–†–ê–í–õ–ï–ù–û: connection_pool –æ—Ç–∫–ª—é—á–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
            if self.conn is None:
                logging.warning("delete_user_data: conn is None")
                return False
            with self._lock:
                self.conn.execute("DELETE FROM users_data WHERE user_id=?", (str(user_id),))
                self.conn.commit()
            self.periodic_backup()
            return True
        except (sqlite3.Error, ValueError, TypeError, AttributeError) as e:
            logging.warning("delete_user_data error –¥–ª—è %s: %s", user_id, e)
            return False

    def log_cycle_metrics(self, cycle_num: int, duration_sec: float):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –æ–¥–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ —Ä–∞–±–æ—Ç—ã —Å–∏—Å—Ç–µ–º—ã."""
        try:
            if self.conn is None:
                logging.warning("log_cycle_metrics: conn is None")
                return
            with self._lock:
                self.conn.execute(
                    """
                    CREATE TABLE IF NOT EXISTS telemetry_cycles (
                        ts TEXT,
                        cycle_num INTEGER,
                        duration_sec REAL
                    )
                    """
                )
                self.conn.execute(
                    "INSERT INTO telemetry_cycles(ts, cycle_num, duration_sec) VALUES(?, ?, ?)",
                    (get_utc_now().isoformat(), int(cycle_num), float(duration_sec)),
                )
                self.conn.commit()
        except (sqlite3.Error, ValueError, TypeError, AttributeError) as e:
            logging.warning("log_cycle_metrics error: %s", e)

    def log_api_latency(self, name: str, latency_ms: int, ok: bool):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –∑–∞–¥–µ—Ä–∂–∫—É API –≤—ã–∑–æ–≤–æ–≤."""
        try:
            if self.conn is None:
                logging.warning("log_api_latency: conn is None")
                return
            with self._lock:
                self.conn.execute(
                    """
                    CREATE TABLE IF NOT EXISTS telemetry_api (
                        ts TEXT,
                        name TEXT,
                        latency_ms INTEGER,
                        ok INTEGER
                    )
                    """
                )
                self.conn.execute(
                    "INSERT INTO telemetry_api(ts, name, latency_ms, ok) VALUES(?, ?, ?, ?)",
                    (get_utc_now().isoformat(), name, int(latency_ms), 1 if ok else 0),
                )
                self.conn.commit()
        except (sqlite3.Error, ValueError, TypeError, AttributeError) as e:
            logging.warning("log_api_latency error: %s", e)

    def get_admin_ids(self):
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ ID –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–≤ –∏–∑ users_data (role=='admin' –∏–ª–∏ is_admin==True),
        –∏–Ω–∞—á–µ —Ñ–æ–ª–±—ç–∫ –Ω–∞ ADMIN_IDS –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è.
        """
        admins = []
        try:
            with self._lock:
                cur = self.conn.execute("SELECT user_id, data FROM users_data")
                rows = fetch_all_optimized(cur) or []
            # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –∏—Å–ø–æ–ª—å–∑—É–µ–º list comprehension —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∏—Å–∫–ª—é—á–µ–Ω–∏–π
            for uid, j in rows:
                try:
                    data = json.loads(j) if isinstance(j, str) else (j or {})
                    if isinstance(data, dict) and (
                        str(data.get("role", "")).lower() == "admin" or bool(data.get("is_admin"))
                    ):
                        admins.append(int(uid))
                except (ValueError, TypeError):
                    continue
        except sqlite3.Error:
            pass

        if not admins:
            try:
                raw = os.getenv("ADMIN_IDS", "").strip()
                if raw:
                    if raw.startswith("["):
                        admins = [int(x) for x in ast.literal_eval(raw)]
                    else:
                        admins = [int(x) for x in raw.split(",") if x.strip()]
            except (ValueError, SyntaxError, TypeError):
                admins = []
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –∏—Å–ø–æ–ª—å–∑—É–µ–º set –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ (O(1) –≤–º–µ—Å—Ç–æ O(n))
        dedup = list(set(admins))
        dedup.sort(key=lambda x: (not str(x).startswith("556"), x))
        return dedup

    # --- –†–µ—Ç–µ–Ω—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö ---
    def _days_ago_iso(self, days: int) -> str:
        try:
            d = max(0, int(days))
        except (TypeError, ValueError):
            d = 0
        return (get_utc_now() - timedelta(days=d)).isoformat()

    def cleanup_old_data(self) -> dict:
        """
        –£–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ —Å–æ–≥–ª–∞—Å–Ω–æ –ø–æ–ª–∏—Ç–∏–∫–µ —Ä–µ—Ç–µ–Ω—Ü–∏–∏ –∏–∑ config.py.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —É–¥–∞–ª—ë–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫ –ø–æ —Ç–∞–±–ª–∏—Ü–∞–º.
        """
        stats = {
            "quotes": 0,
            "arbitrage_events": 0,
            "signals": 0,
            "signals_log": 0,
            "signal_accum_events": 0,
            "app_cache": 0,
        }
        try:
            with self._lock:
                # quotes: –ø–æ ts ISO
                if RETENTION_QUOTES_DAYS >= 0:
                    cutoff = self._days_ago_iso(RETENTION_QUOTES_DAYS)
                    try:
                        cur = self.conn.execute(
                            "DELETE FROM quotes WHERE datetime(ts) < datetime(?)",
                            (cutoff,),
                        )
                        stats["quotes"] = cur.rowcount if cur is not None else 0
                    except sqlite3.OperationalError as e:
                        if "no such column: ts" in str(e):
                            # –ü—Ä–æ–±—É–µ–º –ø–æ created_at
                            try:
                                cur = self.conn.execute(
                                    "DELETE FROM quotes WHERE created_at < datetime('now', ?)",
                                    (f"-{int(RETENTION_QUOTES_DAYS)} days",),
                                )
                                stats["quotes"] = cur.rowcount if cur is not None else 0
                            except sqlite3.OperationalError:
                                pass
                        else:
                            raise

                # arbitrage_events: –ø–æ ts ISO
                if RETENTION_SIGNALS_DAYS >= 0:
                    cutoff = self._days_ago_iso(RETENTION_SIGNALS_DAYS)
                    try:
                        cur = self.conn.execute(
                            "DELETE FROM arbitrage_events WHERE datetime(ts) < datetime(?)",
                            (cutoff,),
                        )
                        stats["arbitrage_events"] = cur.rowcount if cur is not None else 0
                    except sqlite3.OperationalError as e:
                        if "no such column: ts" in str(e):
                            try:
                                cur = self.conn.execute(
                                    "DELETE FROM arbitrage_events WHERE created_at < datetime('now', ?)",
                                    (f"-{int(RETENTION_SIGNALS_DAYS)} days",),
                                )
                                stats["arbitrage_events"] = cur.rowcount if cur is not None else 0
                            except sqlite3.OperationalError:
                                pass
                        else:
                            raise

                # signals: –ø–æ ts ISO
                if RETENTION_SIGNALS_DAYS >= 0:
                    cutoff = self._days_ago_iso(RETENTION_SIGNALS_DAYS)
                    try:
                        cur = self.conn.execute(
                            "DELETE FROM signals WHERE datetime(ts) < datetime(?)",
                            (cutoff,),
                        )
                        stats["signals"] = cur.rowcount if cur is not None else 0
                    except sqlite3.OperationalError as e:
                        if "no such column: ts" in str(e):
                            try:
                                cur = self.conn.execute(
                                    "DELETE FROM signals WHERE created_at < datetime('now', ?)",
                                    (f"-{int(RETENTION_SIGNALS_DAYS)} days",),
                                )
                                stats["signals"] = cur.rowcount if cur is not None else 0
                            except sqlite3.OperationalError:
                                pass
                        else:
                            raise

                # signals_log: –ø–æ created_at (datetime DEFAULT CURRENT_TIMESTAMP)
                if RETENTION_SIGNALS_LOG_DAYS >= 0:
                    # üöÄ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø (–ï–ª–µ–Ω–∞): –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–Ω–¥–µ–∫—Å –Ω–∞–ø—Ä—è–º—É—é –±–µ–∑ datetime()
                    cur = self.conn.execute(
                        "DELETE FROM signals_log WHERE created_at < datetime('now', ?)",
                        (f"-{int(RETENTION_SIGNALS_LOG_DAYS)} days",),
                    )
                    stats["signals_log"] = cur.rowcount if cur is not None else 0

                # signal_accum_events: –ø–æ ts unix + ttl_sec (—Å–Ω–∞—á–∞–ª–∞ —É–¥–∞–ª–∏–º —è–≤–Ω–æ –ø—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω—ã–µ, –∑–∞—Ç–µ–º –¥–∞–≤–Ω–µ–µ –æ–∫–Ω–æ)
                now_ts = int(time.time())
                # —è–≤–Ω—ã–µ TTL
                cur = self.conn.execute(
                    "DELETE FROM signal_accum_events WHERE (ts + IFNULL(ttl_sec,0)) < ?",
                    (now_ts,),
                )
                removed_ttl = cur.rowcount if cur is not None else 0
                # –æ–∫–Ω–æ –ø–æ –¥–Ω—è–º –¥–ª—è –æ—Å—Ç–∞—Ç–∫–∞
                if RETENTION_ACCUM_EVENTS_DAYS >= 0:
                    min_ts = max(0, now_ts - int(RETENTION_ACCUM_EVENTS_DAYS) * 86400)
                    cur = self.conn.execute(
                        "DELETE FROM signal_accum_events WHERE ts < ?",
                        (min_ts,),
                    )
                    removed_window = cur.rowcount if cur is not None else 0
                else:
                    removed_window = 0
                stats["signal_accum_events"] = int(removed_ttl or 0) + int(removed_window or 0)

                # app_cache: expires_at unix
                if RETENTION_APP_CACHE_DAYS >= 0:
                    min_exp = now_ts - int(RETENTION_APP_CACHE_DAYS) * 86400
                    cur = self.conn.execute(
                        "DELETE FROM app_cache WHERE IFNULL(expires_at,0) < ?",
                        (min_exp,),
                    )
                    stats["app_cache"] = cur.rowcount if cur is not None else 0

                self.conn.commit()
        except (sqlite3.Error, ValueError, TypeError) as e:
            logging.warning("cleanup_old_data error: %s", e)
        return stats

    def analyze_if_needed(self, force: bool = False) -> bool:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç ANALYZE –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ë–î
        –£–ª—É—á—à–∞–µ—Ç –ø–ª–∞–Ω—ã –∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–∞ 5-15%
        
        Args:
            force: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–∞–∂–µ –µ—Å–ª–∏ –Ω–µ–¥–∞–≤–Ω–æ –≤—ã–ø–æ–ª–Ω—è–ª–æ—Å—å
            
        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ
        """
        try:
            with self._lock:
                self.conn.execute("ANALYZE")
                logging.info("‚úÖ [DB] ANALYZE –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ")
                return True
        except Exception as e:
            logging.warning("‚ö†Ô∏è [DB] –û—à–∏–±–∫–∞ ANALYZE: %s", e)
            return False

    def vacuum_if_needed(self, force: bool = False) -> bool:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç VACUUM (–ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é –µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ –∏–ª–∏ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ).
        –ü–æ—Å–ª–µ VACUUM –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç ANALYZE –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –ø—Ä–∏ —É—Å–ø–µ—Ö–µ.
        """
        try:
            if not force and not RETENTION_ENABLE_WEEKLY_VACUUM:
                return False
            with self._lock:
                self.conn.execute("VACUUM;")
                # –ü–æ—Å–ª–µ VACUUM –≤—ã–ø–æ–ª–Ω—è–µ–º ANALYZE –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                self.conn.execute("ANALYZE;")
            logging.info("‚úÖ [DB] VACUUM –∏ ANALYZE –≤—ã–ø–æ–ª–Ω–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")
            return True
        except sqlite3.Error as e:
            logging.warning("VACUUM/ANALYZE error: %s", e)
            return False

    # --- –ú–µ—Ç—Ä–∏–∫–∏ –∏ –∞–≥—Ä–µ–≥–∞—Ç—ã (–§–∞–∑–∞ 1) ---
    def metrics_signals_open_last_24h(self) -> int:
        """–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–≥–Ω–∞–ª–æ–≤ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞."""
        try:
            with self._lock:
                cur = self.conn.execute(
                    """
                    SELECT COUNT(*)
                    FROM signals_log
                    WHERE datetime(created_at) >= datetime('now', '-24 hours')
                    AND (result IS NULL OR result = '' OR result LIKE 'OPEN%')
                    """
                )
                row = cur.fetchone()
                return int(row[0] or 0)
        except (sqlite3.Error, ValueError, TypeError) as e:
            logging.warning("metrics_signals_open_last_24h error: %s", e)
            return 0

    def metrics_signals_open_last_hours(self, hours: int) -> int:
        """–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–≥–Ω–∞–ª–æ–≤ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —á–∞—Å–æ–≤."""
        try:
            h = max(1, int(hours))
            with self._lock:
                cur = self.conn.execute(
                    """
                    SELECT COUNT(*)
                    FROM signals_log
                    WHERE datetime(created_at) >= datetime('now', ?)
                    AND (result IS NULL OR result = '' OR result LIKE 'OPEN%')
                    """,
                    (f'-{h} hours',),
                )
                row = cur.fetchone()
                return int((row or (0,))[0] or 0)
        except (sqlite3.Error, ValueError, TypeError) as e:
            logging.warning("metrics_signals_open_last_hours error: %s", e)
            return 0

    def metrics_chop_ratio_24h(self) -> float:
        """–û—Ü–µ–Ω–∫–∞ chop-—Ä–µ–∂–∏–º–∞: –¥–æ–ª—è —Å–æ–±—ã—Ç–∏–π 'bb_squeeze' —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö accum-—Å–æ–±—ã—Ç–∏–π –∑–∞ 24—á."""
        try:
            now_ts = int(time.time())
            min_ts = now_ts - 24 * 3600
            with self._lock:
                cur = self.conn.execute(
                    "SELECT COUNT(*) FROM signal_accum_events WHERE ts >= ?",
                    (min_ts,),
                )
                total = int((cur.fetchone() or (0,))[0] or 0)
                if total <= 0:
                    return 0.0
                cur = self.conn.execute(
                    "SELECT COUNT(*) FROM signal_accum_events WHERE ts >= ? AND event = ?",
                    (min_ts, 'bb_squeeze'),
                )
                squeezes = int((cur.fetchone() or (0,))[0] or 0)
                ratio = max(0.0, min(1.0, float(squeezes) / float(total)))
                return ratio
        except (sqlite3.Error, ValueError, TypeError) as e:
            logging.warning("metrics_chop_ratio_24h error: %s", e)
            return 0.0

    # --- –ü—Ä–æ—Ñ–∏–ª–∏ –º–æ–Ω–µ—Ç (symbol-aware overrides) ---
    def get_symbol_profile(self, symbol: str) -> dict:
        try:
            payload = self.cache_get("symbol_profile", str(symbol).upper()) or {}
            if isinstance(payload, dict):
                return payload
            return {}
        except (ValueError, TypeError):
            return {}

    def set_symbol_profile(self, symbol: str, profile_data: dict, ttl_seconds: int = 12 * 3600) -> bool:
        try:
            if not isinstance(profile_data, dict):
                return False
            return self.cache_set("symbol_profile", str(symbol).upper(), profile_data, ttl_seconds)
        except (ValueError, TypeError):
            return False

    def metrics_update_cache_hourly(self, ttl_seconds: int = 3600) -> bool:
        """–ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∏ –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –∏—Ö –≤ app_cache —Å TTL."""
        try:
            cnt_open_24h = self.metrics_signals_open_last_24h()
            self.cache_set("metrics", "signals_count_24h", {"value": cnt_open_24h}, ttl_seconds)
            chop = self.metrics_chop_ratio_24h()
            self.cache_set("metrics", "chop_ratio_24h", {"value": chop}, ttl_seconds)
            # –ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–æ–∫
            perf7 = self.get_performance_summary(since_days=7)
            self.cache_set("metrics", "perf_summary_7d", perf7, ttl_seconds)
            return True
        except (sqlite3.Error, ValueError, TypeError, RuntimeError) as e:
            logging.warning("metrics_update_cache_hourly error: %s", e)
            return False

    def set_user_admin(self, user_id: int, is_admin: bool = True) -> bool:
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞ –≤ users_data (is_admin –∏ role).
        """
        try:
            current = self.get_user_data(user_id) or {}
            if not isinstance(current, dict):
                current = {}
            current["is_admin"] = bool(is_admin)
            if is_admin:
                current["role"] = "admin"
            elif current.get("role") == "admin":
                current["role"] = "user"
            return self.save_user_data(user_id, current)
        except (ValueError, TypeError, RuntimeError):
            return False

    # ============================================================================
    # MTF-–í–ó–í–ï–®–ò–í–ê–ù–ò–ï (MULTI-TIMEFRAME)
    # ============================================================================

    def get_mtf_data(self, symbol: str, timeframe: str, limit: int = 100) -> Optional[dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç OHLC –¥–∞–Ω–Ω—ã–µ –¥–ª—è MTF –∞–Ω–∞–ª–∏–∑–∞."""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –ª–æ–≥–∏–∫—É –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
            # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–¥–µ—Å—å –±—É–¥–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ API –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
            _ = limit  # –ü–æ–∫–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –Ω–æ –º–æ–∂–µ—Ç –ø–æ–Ω–∞–¥–æ–±–∏—Ç—å—Å—è
            return {
                "symbol": symbol,
                "timeframe": timeframe,
                "data": [],  # –ó–∞–≥–ª—É—à–∫–∞ - –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –∑–¥–µ—Å—å –±—É–¥—É—Ç OHLC –¥–∞–Ω–Ω—ã–µ
                "timestamp": int(time.time())
            }
        except (ValueError, TypeError, RuntimeError) as e:
            logging.warning("get_mtf_data error for %s %s: %s", symbol, timeframe, e)
            return None

    def calculate_mtf_score(self, symbol: str, market_regime: str) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç MTF-—Å–∫–æ—Ä–∏–Ω–≥ –¥–ª—è —Å–∏–º–≤–æ–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ RSI, ADX, EMA –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞—Ö."""
        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
            try:
                import pandas as pd
                from src.utils.ohlc_utils import get_ohlc_binance_sync
            except ImportError as e:
                logging.debug("MTF —Å–∫–æ—Ä–∏–Ω–≥: –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã: %s", e)
                # Fallback –Ω–∞ –±–∞–∑–æ–≤—ã–π —Å–∫–æ—Ä–∏–Ω–≥
                base_score = 0.5
                if market_regime == "bull":
                    base_score += 0.1
                elif market_regime == "bear":
                    base_score -= 0.1
                return min(max(base_score, 0.0), 1.0)

            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ (1h, 4h)
            timeframes = ["1h", "4h"]
            tf_scores = []

            for tf in timeframes:
                try:
                    # –ü–æ–ª—É—á–∞–µ–º OHLC –¥–∞–Ω–Ω—ã–µ
                    ohlc = get_ohlc_binance_sync(symbol, interval=tf, limit=100)
                    if not ohlc or len(ohlc) < 50:
                        continue

                    # –°–æ–∑–¥–∞–µ–º DataFrame
                    df = pd.DataFrame(ohlc)
                    if 'timestamp' in df.columns:
                        df["open_time"] = pd.to_datetime(df["timestamp"], unit="ms")
                    elif 'open_time' in df.columns:
                        df["open_time"] = pd.to_datetime(df["open_time"])
                    else:
                        continue

                    df = df.set_index("open_time")

                    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —á–µ—Ä–µ–∑ —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –º–æ–¥—É–ª—å
                    from src.signals.indicators import add_technical_indicators
                    df = add_technical_indicators(df)

                    # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
                    if len(df) < 1:
                        continue

                    last_row = df.iloc[-1]
                    ema7_val = float(last_row.get("ema7", last_row["close"]))
                    ema25_val = float(last_row.get("ema25", last_row["close"]))
                    rsi_val = float(last_row.get("rsi", 50.0))
                    adx_val = float(last_row.get("adx", 25.0))

                    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º score –¥–ª—è —ç—Ç–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
                    tf_score = 0.5  # –ë–∞–∑–æ–≤—ã–π score

                    # –¢—Ä–µ–Ω–¥ (EMA7 vs EMA25)
                    if ema7_val > ema25_val:
                        tf_score += 0.15  # –ë—ã—á–∏–π —Ç—Ä–µ–Ω–¥
                    elif ema7_val < ema25_val:
                        tf_score -= 0.15  # –ú–µ–¥–≤–µ–∂–∏–π —Ç—Ä–µ–Ω–¥

                    # RSI –∞–Ω–∞–ª–∏–∑ (–ø–µ—Ä–µ–ø—Ä–æ–¥–∞–Ω–Ω–æ—Å—Ç—å/–ø–µ—Ä–µ–∫—É–ø–ª–µ–Ω–Ω–æ—Å—Ç—å)
                    if 30 < rsi_val < 70:  # –ó–¥–æ—Ä–æ–≤—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω
                        tf_score += 0.1
                    elif rsi_val < 30:  # –ü–µ—Ä–µ–ø—Ä–æ–¥–∞–Ω–Ω–æ—Å—Ç—å (–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª —Ä–æ—Å—Ç–∞)
                        tf_score += 0.05
                    elif rsi_val > 70:  # –ü–µ—Ä–µ–∫—É–ø–ª–µ–Ω–Ω–æ—Å—Ç—å (—Ä–∏—Å–∫ –ø–∞–¥–µ–Ω–∏—è)
                        tf_score -= 0.1

                    # ADX –∞–Ω–∞–ª–∏–∑ (—Å–∏–ª–∞ —Ç—Ä–µ–Ω–¥–∞)
                    if adx_val > 25:  # –°–∏–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–¥
                        tf_score += 0.1
                    elif adx_val < 20:  # –°–ª–∞–±—ã–π —Ç—Ä–µ–Ω–¥
                        tf_score -= 0.05

                    tf_scores.append(tf_score)

                except Exception as e:
                    logging.debug("MTF —Å–∫–æ—Ä–∏–Ω–≥: –æ—à–∏–±–∫–∞ –¥–ª—è %s %s: %s", symbol, tf, e)
                    continue

            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
            if not tf_scores:
                # Fallback –Ω–∞ —Ä–µ–∂–∏–º —Ä—ã–Ω–∫–∞
                base_score = 0.5
                if market_regime == "bull":
                    base_score += 0.1
                elif market_regime == "bear":
                    base_score -= 0.1
                return min(max(base_score, 0.0), 1.0)

            # –£—Å—Ä–µ–¥–Ω—è–µ–º scores –ø–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º (4h –∏–º–µ–µ—Ç –±–æ–ª—å—à–∏–π –≤–µ—Å)
            if len(tf_scores) == 2:
                # 1h - –≤–µ—Å 0.4, 4h - –≤–µ—Å 0.6
                final_score = tf_scores[0] * 0.4 + tf_scores[1] * 0.6
            else:
                final_score = sum(tf_scores) / len(tf_scores)

            # –ê–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ —Ä–µ–∂–∏–º—É —Ä—ã–Ω–∫–∞
            if market_regime == "bull":
                final_score += 0.1
            elif market_regime == "bear":
                final_score -= 0.1

            return min(max(final_score, 0.0), 1.0)

        except (ValueError, TypeError, RuntimeError) as e:
            logging.warning("calculate_mtf_score error for %s: %s", symbol, e)
            return 0.5

    # ============================================================================
    # ML-–°–ö–û–†–ò–ù–ì (MACHINE LEARNING)
    # ============================================================================

    def get_ml_training_data(self, limit: int = 1000) -> List[dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ML –º–æ–¥–µ–ª–∏."""
        try:
            # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è ML –¥–∞–Ω–Ω—ã—Ö
            # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–¥–µ—Å—å –±—É–¥–µ—Ç –≤—ã–±–æ—Ä–∫–∞ –∏–∑ signals_log —Å —Ñ–∏—á–∞–º–∏
            _ = limit  # –ü–æ–∫–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –Ω–æ –º–æ–∂–µ—Ç –ø–æ–Ω–∞–¥–æ–±–∏—Ç—å—Å—è
            return []
        except (ValueError, TypeError, RuntimeError) as e:
            logging.warning("get_ml_training_data error: %s", e)
            return []

    def calculate_ml_score(self, features: dict) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç ML-—Å–∫–æ—Ä–∏–Ω–≥ –¥–ª—è –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É—è LightGBM –º–æ–¥–µ–ª—å."""
        try:
            # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å LightGBM predictor –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
            try:
                from src.ai.lightgbm_predictor import get_lightgbm_predictor
                predictor = get_lightgbm_predictor()

                # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã
                if not predictor.is_trained:
                    if not predictor.load_models():
                        # –ú–æ–¥–µ–ª–∏ –Ω–µ –æ–±—É—á–µ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback
                        raise ImportError("ML models not trained")

                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º features dict –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è LightGBM
                # LightGBM predictor –æ–∂–∏–¥–∞–µ—Ç 3 –æ—Ç–¥–µ–ª—å–Ω—ã—Ö dict: market_conditions, indicators, signal_params

                # 1. Indicators dict
                indicators = {
                    'rsi': float(features.get("rsi", 50.0)),
                    'macd': float(features.get("macd", 0.0)),
                    'ema_fast': float(features.get("ema_fast", features.get("entry_price", 100.0) * 1.01)),
                    'ema_slow': float(features.get("ema_slow", features.get("entry_price", 100.0) * 0.99)),
                    'bb_upper': float(features.get("bb_upper", features.get("entry_price", 100.0) * 1.02)),
                    'bb_lower': float(features.get("bb_lower", features.get("entry_price", 100.0) * 0.98)),
                    'atr': float(features.get("atr", features.get("entry_price", 100.0) * 0.015)),
                }

                # 2. Market conditions dict
                market_conditions = {
                    'volume_ratio': float(features.get("volume_ratio", 1.0)),
                    'volatility': float(features.get("volatility", 0.02)),
                }

                # 3. Signal params dict
                entry_price = float(features.get("entry_price", 100.0))
                tp1 = float(features.get("tp1", entry_price * 1.025))
                tp2 = float(features.get("tp2", entry_price * 1.05))

                signal_params = {
                    'entry_price': entry_price,
                    'tp1': tp1,
                    'tp2': tp2,
                    'risk_pct': float(features.get("risk_pct", 2.0)),
                    'leverage': float(features.get("leverage", 1.0)),
                    'quality_score': float(features.get("quality_score", 0.5)),
                    'mtf_score': float(features.get("mtf_score", 0.5)),
                    'spread_pct': float(features.get("spread_pct", 0.0)),
                    'depth_usd': float(features.get("depth_usd", 0.0)),
                }

                # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ—Ç LightGBM
                prediction = predictor.predict(
                    market_conditions=market_conditions,
                    indicators=indicators,
                    signal_params=signal_params
                )

                # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict —Å 'success_probability'
                if isinstance(prediction, dict):
                    score = float(prediction.get('success_probability', 0.5))
                else:
                    score = float(prediction) if prediction is not None else 0.5

                return min(max(score, 0.0), 1.0)

            except (ImportError, AttributeError, Exception) as e:
                # Fallback –Ω–∞ —ç–≤—Ä–∏—Å—Ç–∏–∫—É –µ—Å–ª–∏ ML –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
                logging.debug("LightGBM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —ç–≤—Ä–∏—Å—Ç–∏–∫—É: %s", e)
                base_score = 0.5

                # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ñ–∏—á–µ–π
                rsi = features.get("rsi", 50)
                adx = features.get("adx", 25)
                volume_ratio = features.get("volume_ratio", 1.0)

                if rsi < 30 and adx > 25 and volume_ratio > 1.5:
                    base_score += 0.2
                elif rsi > 70 and adx > 25 and volume_ratio > 1.5:
                    base_score += 0.15

                return min(max(base_score, 0.0), 1.0)
        except (ValueError, TypeError, RuntimeError) as e:
            logging.warning("calculate_ml_score error: %s", e)
            return 0.5

    def save_ml_prediction(self, symbol: str, features: dict, prediction: float, timestamp: int) -> bool:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç ML –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –∞—É–¥–∏—Ç–∞."""
        try:
            # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–¥–µ—Å—å –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –æ—Ç–¥–µ–ª—å–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
            _ = features  # –ü–æ–∫–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –Ω–æ –º–æ–∂–µ—Ç –ø–æ–Ω–∞–¥–æ–±–∏—Ç—å—Å—è
            _ = timestamp  # –ü–æ–∫–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –Ω–æ –º–æ–∂–µ—Ç –ø–æ–Ω–∞–¥–æ–±–∏—Ç—å—Å—è
            logging.info("ML prediction saved: %s -> %.3f", symbol, prediction)
            return True
        except (ValueError, TypeError, RuntimeError) as e:
            logging.warning("save_ml_prediction error: %s", e)
            return False

    # ============================================================================
    # –ê–î–ú–ò–ù–ò–°–¢–†–ê–¢–û–†–´ –ò –£–í–ï–î–û–ú–õ–ï–ù–ò–Ø
    # ============================================================================

    def get_admin_users(self) -> List[int]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ ID –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–≤."""
        try:
            admin_users = []
            cursor = self.conn.execute("SELECT user_id, data FROM users_data")
            for row in fetch_all_optimized(cursor):
                user_id, data_json = row
                try:
                    data = json.loads(data_json) if data_json else {}
                    if (str(data.get("role", "")).lower() == "admin" or
                        bool(data.get("is_admin"))):
                        admin_users.append(int(user_id))
                except (json.JSONDecodeError, ValueError, TypeError):
                    continue
            return admin_users
        except (ValueError, TypeError, RuntimeError) as e:
            logging.warning("get_admin_users error: %s", e)
            return []

    # ============================================================================
    # –°–ò–°–¢–ï–ú–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò (–ê–î–ê–ü–¢–ò–í–ù–´–ï –ü–ê–†–ê–ú–ï–¢–†–´)
    # ============================================================================

    def get_system_setting(self, key: str, default_value=None):
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö."""
        try:
            with self._lock:
                cur = self.conn.execute(
                    "SELECT value FROM system_settings WHERE key = ?",
                    (key,)
                )
                row = cur.fetchone()
                if row:
                    value = row[0]
                    # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Ç–∏–ø
                    try:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –±—É–ª–µ–≤—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º
                        if value.lower() in ('true', 'false'):
                            return value.lower() == 'true'
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ —á–∏—Å–ª–æ–º
                        if '.' in value:
                            return float(value)
                        elif value.isdigit() or (value.startswith('-') and value[1:].isdigit()):
                            return int(value)
                        # –ò–Ω–∞—á–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ —Å—Ç—Ä–æ–∫—É
                        return value
                    except (ValueError, AttributeError):
                        return value
                return default_value
        except (sqlite3.Error, ValueError, TypeError) as e:
            logging.warning("get_system_setting error for key %s: %s", key, e)
            return default_value

    def set_system_setting(self, key: str, value) -> bool:
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö."""
        try:
            with self._lock:
                self.conn.execute(
                    """
                    INSERT INTO system_settings (key, value, updated_at)
                    VALUES (?, ?, CURRENT_TIMESTAMP)
                    ON CONFLICT(key) DO UPDATE SET
                        value = excluded.value,
                        updated_at = CURRENT_TIMESTAMP
                    """,
                    (key, str(value))
                )
                self.conn.commit()
            return True
        except (sqlite3.Error, ValueError, TypeError) as e:
            logging.warning("set_system_setting error for key %s: %s", key, e)
            return False

    def get_all_system_settings(self) -> dict:
        """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ —Å–∏—Å—Ç–µ–º–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö."""
        try:
            with self._lock:
                cur = self.conn.execute("SELECT key, value FROM system_settings")
                rows = fetch_all_optimized(cur)
                settings = {}
                for key, value in rows:
                    try:
                        # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Ç–∏–ø
                        if value.lower() in ('true', 'false'):
                            settings[key] = value.lower() == 'true'
                        elif '.' in value:
                            settings[key] = float(value)
                        elif value.isdigit() or (value.startswith('-') and value[1:].isdigit()):
                            settings[key] = int(value)
                        else:
                            settings[key] = value
                    except (ValueError, AttributeError):
                        settings[key] = value
                return settings
        except (sqlite3.Error, ValueError, TypeError) as e:
            logging.warning("get_all_system_settings error: %s", e)
            return {}

    def delete_system_setting(self, key: str) -> bool:
        """–£–¥–∞–ª—è–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö."""
        try:
            with self._lock:
                self.conn.execute("DELETE FROM system_settings WHERE key = ?", (key,))
                self.conn.commit()
            return True
        except (sqlite3.Error, ValueError, TypeError) as e:
            logging.warning("delete_system_setting error for key %s: %s", key, e)
            return False

    # --- Config Snapshots (Rollback System) ---

    def save_config_snapshot(self, config_dict: dict, win_rate: float, pnl_pct: float, is_stable: bool = False) -> bool:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–Ω–∏–º–æ–∫ —Ç–µ–∫—É—â–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏."""
        try:
            config_json = json.dumps(config_dict)
            with self._lock:
                self.conn.execute(
                    """
                    INSERT INTO system_config_history (config_json, win_rate, pnl_pct, is_stable)
                    VALUES (?, ?, ?, ?)
                    """,
                    (config_json, win_rate, pnl_pct, 1 if is_stable else 0)
                )
                self.conn.commit()
            return True
        except Exception as e:
            logging.error("‚ùå Error saving config snapshot: %s", e)
            return False

    def get_latest_stable_snapshot(self) -> Optional[dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å—Ç–∞–±–∏–ª—å–Ω—ã–π —Å–Ω–∏–º–æ–∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏."""
        try:
            with self._lock:
                cur = self.conn.execute(
                    "SELECT config_json FROM system_config_history WHERE is_stable = 1 ORDER BY created_at DESC LIMIT 1"
                )
                row = cur.fetchone()
                if row:
                    return json.loads(row[0])
            return None
        except Exception as e:
            logging.error("‚ùå Error getting latest stable snapshot: %s", e)
            return None

    def initialize_adaptive_settings(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ config.py."""
        try:
            # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –º–∏–≥—Ä–∞—Ü–∏–∏
            adaptive_params = {
                # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –¥–≤–∏–∂–æ–∫
                'ADAPTIVE_ENGINE_ENABLED': ADAPTIVE_ENGINE_ENABLED,
                'METRICS_FEEDER_ENABLED': METRICS_FEEDER_ENABLED,
                'METRICS_FEEDER_INTERVAL_SEC': METRICS_FEEDER_INTERVAL_SEC,
                'METRICS_CACHE_TTL_SEC': METRICS_CACHE_TTL_SEC,
                'PERFORMANCE_LOOKBACK_DAYS': PERFORMANCE_LOOKBACK_DAYS,

                # –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –ø–æ–¥—Å—Ç—Ä–æ–π–∫–∞ –ø–æ—Ä–æ–≥–æ–≤
                'ADAPTIVE_ENTRY_ADJ_ENABLED': ADAPTIVE_ENTRY_ADJ_ENABLED,
                'ADAPTIVE_ENTRY_MAX_ADJUST_PCT': ADAPTIVE_ENTRY_MAX_ADJUST_PCT,

                # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π —Å–≤–∏—Ç—á–µ—Ä —Ä–µ–∂–∏–º–æ–≤
                'DYNAMIC_MODE_SWITCH_ENABLED': DYNAMIC_MODE_SWITCH_ENABLED,

                # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∫—É–ª–¥–∞—É–Ω
                'CORRELATION_COOLDOWN_ENABLED': CORRELATION_COOLDOWN_ENABLED,
                'CORRELATION_LOOKBACK_HOURS': CORRELATION_LOOKBACK_HOURS,
                'CORRELATION_MAX_PAIRWISE': CORRELATION_MAX_PAIRWISE,
                'CORRELATION_COOLDOWN_SEC': CORRELATION_COOLDOWN_SEC,

                # –ú—è–≥–∫–∏–π –±–ª–æ–∫–ª–∏—Å—Ç
                'SOFT_BLOCKLIST_ENABLED': SOFT_BLOCKLIST_ENABLED,
                'SOFT_BLOCKLIST_HYSTERESIS': SOFT_BLOCKLIST_HYSTERESIS,
                'SOFT_BLOCK_COOLDOWN_HOURS': SOFT_BLOCK_COOLDOWN_HOURS,
                'MIN_ACTIVE_COINS': MIN_ACTIVE_COINS,
                'BLOCKLIST_CHURN_FRAC': BLOCKLIST_CHURN_FRAC,

                # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                'DYNAMIC_CALC_INTERVAL': DYNAMIC_CALC_INTERVAL,
                'DYNAMIC_TP_ENABLED': DYNAMIC_TP_ENABLED,
                'VOLUME_BLOCKS_ENABLED': VOLUME_BLOCKS_ENABLED,
            }

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
            for key, value in adaptive_params.items():
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –ë–î
                existing = self.get_system_setting(key)
                if existing is None:  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä –µ—â–µ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                    self.set_system_setting(key, value)
                    logging.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä %s = %s", key, value)

            logging.info("–ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö")
            return True

        except (AttributeError, ValueError, TypeError) as e:
            logging.warning("–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫: %s", e)
            return False

    # ============================================================================
    # –ë–õ–û–ö–õ–ò–°–¢ –ö–ê–ü–ò–¢–ê–õ–ò–ó–ê–¶–ò–ò (MARKET CAP BLACKLIST)
    # ============================================================================

    def add_to_market_cap_blacklist(self, symbol: str, market_cap: float, reason: str = "low_market_cap") -> bool:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –º–æ–Ω–µ—Ç—É –≤ –±–ª–æ–∫–ª–∏—Å—Ç –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–∏."""
        try:

            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–∞—Ç—É —Ä–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–Ω–∏—è –Ω–∞ –Ω–µ–¥–µ–ª—é –≤–ø–µ—Ä–µ–¥
            unfreeze_date = (datetime.now() + timedelta(days=7)).isoformat()

            with self._lock:
                self.conn.execute(
                    """
                    INSERT INTO market_cap_blacklist (symbol, market_cap, unfreeze_date, reason)
                    VALUES (?, ?, ?, ?)
                    ON CONFLICT(symbol) DO UPDATE SET
                        market_cap = excluded.market_cap,
                        blacklisted_at = CURRENT_TIMESTAMP,
                        unfreeze_date = excluded.unfreeze_date,
                        reason = excluded.reason
                    """,
                    (symbol, market_cap, unfreeze_date, reason)
                )
                self.conn.commit()
            logging.info("–ú–æ–Ω–µ—Ç–∞ %s –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ –±–ª–æ–∫–ª–∏—Å—Ç –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ (cap: $%.0fM)", symbol, market_cap / 1_000_000)
            return True
        except (sqlite3.Error, ValueError, TypeError) as e:
            logging.warning("–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ –±–ª–æ–∫–ª–∏—Å—Ç –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ %s: %s", symbol, e)
            return False

    def is_market_cap_blacklisted(self, symbol: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞ –ª–∏ –º–æ–Ω–µ—Ç–∞ –ø–æ –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–∏."""
        try:
            with self._lock:
                cur = self.conn.execute(
                    """
                    SELECT symbol FROM market_cap_blacklist
                    WHERE symbol = ? AND datetime(unfreeze_date) > datetime('now')
                    """,
                    (symbol,)
                )
                row = cur.fetchone()
            return row is not None
        except (sqlite3.Error, ValueError, TypeError) as e:
            logging.warning("–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –±–ª–æ–∫–ª–∏—Å—Ç–∞ –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ %s: %s", symbol, e)
            return False

    def get_market_cap_blacklist(self) -> List[dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–Ω–µ—Ç."""
        try:
            with self._lock:
                cur = self.conn.execute(
                    """
                    SELECT symbol, market_cap, blacklisted_at, unfreeze_date, reason
                    FROM market_cap_blacklist
                    WHERE datetime(unfreeze_date) > datetime('now')
                    ORDER BY blacklisted_at DESC
                    """
                )
                rows = fetch_all_optimized(cur)
            return [
                {
                    "symbol": row[0],
                    "market_cap": row[1],
                    "blacklisted_at": row[2],
                    "unfreeze_date": row[3],
                    "reason": row[4]
                }
                for row in rows
            ]
        except (sqlite3.Error, ValueError, TypeError) as e:
            logging.warning("–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –±–ª–æ–∫–ª–∏—Å—Ç–∞ –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–∏: %s", e)
            return []

    def unfreeze_market_cap_blacklist(self) -> int:
        """–†–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ—Ç –º–æ–Ω–µ—Ç—ã, —É –∫–æ—Ç–æ—Ä—ã—Ö –∏—Å—Ç–µ–∫ —Å—Ä–æ–∫ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏."""
        try:
            with self._lock:
                cur = self.conn.execute(
                    "DELETE FROM market_cap_blacklist "
                    "WHERE datetime(unfreeze_date) <= datetime('now')"
                )
                self.conn.commit()
                unfrozen_count = cur.rowcount
            if unfrozen_count > 0:
                logging.info("–†–∞–∑–º–æ—Ä–æ–∂–µ–Ω–æ %d –º–æ–Ω–µ—Ç –∏–∑ –±–ª–æ–∫–ª–∏—Å—Ç–∞", unfrozen_count)
            return unfrozen_count
        except (sqlite3.Error, ValueError, TypeError) as e:
            logging.warning("–û—à–∏–±–∫–∞ —Ä–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–Ω–∏—è –±–ª–æ–∫–ª–∏—Å—Ç–∞ –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–∏: %s", e)
            return 0

    def remove_from_market_cap_blacklist(self, symbol: str) -> bool:
        """–£–¥–∞–ª—è–µ—Ç –º–æ–Ω–µ—Ç—É –∏–∑ –±–ª–æ–∫–ª–∏—Å—Ç–∞ –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–∏."""
        try:
            with self._lock:
                self.conn.execute(
                    "DELETE FROM market_cap_blacklist WHERE symbol = ?",
                    (symbol,)
                )
                self.conn.commit()
            logging.info("–ú–æ–Ω–µ—Ç–∞ %s —É–¥–∞–ª–µ–Ω–∞ –∏–∑ –±–ª–æ–∫–ª–∏—Å—Ç–∞ –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–∏", symbol)
            return True
        except (sqlite3.Error, ValueError, TypeError) as e:
            logging.warning("–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –∏–∑ –±–ª–æ–∫–ª–∏—Å—Ç–∞ –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ %s: %s", symbol, e)
            return False

    def update_market_cap_blacklist_check(self, symbol: str) -> bool:
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –º–æ–Ω–µ—Ç—ã."""
        try:
            with self._lock:
                self.conn.execute(
                    "UPDATE market_cap_blacklist SET last_checked = CURRENT_TIMESTAMP WHERE symbol = ?",
                    (symbol,)
                )
                self.conn.commit()
            return True
        except (sqlite3.Error, ValueError, TypeError) as e:
            logging.warning("–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ %s: %s", symbol, e)
            return False

    def _add_validation_triggers(self):
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç —Ç—Ä–∏–≥–≥–µ—Ä—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ç–∞–±–ª–∏—Ü.
        SQLite –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç ALTER TABLE ADD CONSTRAINT, –ø–æ—ç—Ç–æ–º—É –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç—Ä–∏–≥–≥–µ—Ä—ã.
        """
        try:
            # –¢—Ä–∏–≥–≥–µ—Ä –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–ª—è quotes (bid, ask)
            self.cursor.execute("""
                CREATE TRIGGER IF NOT EXISTS validate_quotes_insert
                BEFORE INSERT ON quotes
                BEGIN
                    SELECT CASE
                        WHEN NEW.bid IS NOT NULL AND NEW.bid <= 0 THEN
                            RAISE(ABORT, 'bid must be > 0')
                        WHEN NEW.ask IS NOT NULL AND NEW.ask <= 0 THEN
                            RAISE(ABORT, 'ask must be > 0')
                        WHEN NEW.bid IS NOT NULL AND NEW.ask IS NOT NULL AND NEW.ask < NEW.bid THEN
                            RAISE(ABORT, 'ask must be >= bid')
                    END;
                END;
            """)
            
            self.cursor.execute("""
                CREATE TRIGGER IF NOT EXISTS validate_quotes_update
                BEFORE UPDATE ON quotes
                BEGIN
                    SELECT CASE
                        WHEN NEW.bid IS NOT NULL AND NEW.bid <= 0 THEN
                            RAISE(ABORT, 'bid must be > 0')
                        WHEN NEW.ask IS NOT NULL AND NEW.ask <= 0 THEN
                            RAISE(ABORT, 'ask must be > 0')
                        WHEN NEW.bid IS NOT NULL AND NEW.ask IS NOT NULL AND NEW.ask < NEW.bid THEN
                            RAISE(ABORT, 'ask must be >= bid')
                    END;
                END;
            """)
            
            # –¢—Ä–∏–≥–≥–µ—Ä –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–ª—è signals_log (entry, stop, tp1, tp2)
            self.cursor.execute("""
                CREATE TRIGGER IF NOT EXISTS validate_signals_log_insert
                BEFORE INSERT ON signals_log
                BEGIN
                    SELECT CASE
                        WHEN NEW.entry IS NOT NULL AND NEW.entry <= 0 THEN
                            RAISE(ABORT, 'entry must be > 0')
                        WHEN NEW.stop IS NOT NULL AND NEW.stop <= 0 THEN
                            RAISE(ABORT, 'stop must be > 0')
                        WHEN NEW.tp1 IS NOT NULL AND NEW.tp1 <= 0 THEN
                            RAISE(ABORT, 'tp1 must be > 0')
                        WHEN NEW.tp2 IS NOT NULL AND NEW.tp2 <= 0 THEN
                            RAISE(ABORT, 'tp2 must be > 0')
                        WHEN NEW.qty_added IS NOT NULL AND NEW.qty_added < 0 THEN
                            RAISE(ABORT, 'qty_added must be >= 0')
                        WHEN NEW.qty_closed IS NOT NULL AND NEW.qty_closed < 0 THEN
                            RAISE(ABORT, 'qty_closed must be >= 0')
                        WHEN NEW.risk_pct_used IS NOT NULL AND (NEW.risk_pct_used < 0 OR NEW.risk_pct_used > 100) THEN
                            RAISE(ABORT, 'risk_pct_used must be between 0 and 100')
                        WHEN NEW.quality_score IS NOT NULL AND (NEW.quality_score < 0 OR NEW.quality_score > 100) THEN
                            RAISE(ABORT, 'quality_score must be between 0 and 100')
                    END;
                END;
            """)
            
            # –¢—Ä–∏–≥–≥–µ—Ä –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–ª—è trades
            self.cursor.execute("""
                CREATE TRIGGER IF NOT EXISTS validate_trades_insert
                BEFORE INSERT ON trades
                BEGIN
                    SELECT CASE
                        WHEN NEW.entry_price <= 0 THEN
                            RAISE(ABORT, 'entry_price must be > 0')
                        WHEN NEW.exit_price IS NOT NULL AND NEW.exit_price <= 0 THEN
                            RAISE(ABORT, 'exit_price must be > 0')
                        WHEN NEW.quantity <= 0 THEN
                            RAISE(ABORT, 'quantity must be > 0')
                        WHEN NEW.position_size_usdt <= 0 THEN
                            RAISE(ABORT, 'position_size_usdt must be > 0')
                        WHEN NEW.leverage <= 0 OR NEW.leverage > 125 THEN
                            RAISE(ABORT, 'leverage must be between 0 and 125')
                        WHEN NEW.risk_percent IS NOT NULL AND (NEW.risk_percent < 0 OR NEW.risk_percent > 100) THEN
                            RAISE(ABORT, 'risk_percent must be between 0 and 100')
                        WHEN NEW.fees_usd < 0 THEN
                            RAISE(ABORT, 'fees_usd must be >= 0')
                        WHEN NEW.direction NOT IN ('LONG', 'SHORT') THEN
                            RAISE(ABORT, 'direction must be LONG or SHORT')
                        WHEN NEW.trade_mode NOT IN ('spot', 'futures', 'margin') THEN
                            RAISE(ABORT, 'trade_mode must be spot, futures, or margin')
                    END;
                END;
            """)
            
            self.conn.commit()
            logging.debug("‚úÖ [DB] –¢—Ä–∏–≥–≥–µ—Ä—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã")
        except sqlite3.Error as e:
            logging.warning("‚ö†Ô∏è [DB] –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç—Ä–∏–≥–≥–µ—Ä–æ–≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: %s", e)

    def _add_surrogate_time_keys(self):
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç —Å—É—Ä—Ä–æ–≥–∞—Ç–Ω—ã–µ –∫–ª—é—á–∏ (INTEGER) –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫.
        –£—Å–∫–æ—Ä–µ–Ω–∏–µ –Ω–∞ 20-40% –∑–∞ —Å—á–µ—Ç –º–µ–Ω—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –∏–Ω–¥–µ–∫—Å–æ–≤ –∏ –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä—ã—Ö —Å—Ä–∞–≤–Ω–µ–Ω–∏–π.
        """
        try:
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É time_surrogate –¥–ª—è signals_log
            try:
                with self._lock:
                    self.conn.execute("ALTER TABLE signals_log ADD COLUMN time_surrogate INTEGER")
            except sqlite3.Error:
                pass  # –ö–æ–ª–æ–Ω–∫–∞ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            
            # –ó–∞–ø–æ–ª–Ω—è–µ–º time_surrogate –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π
            try:
                with self._lock:
                    self.conn.execute("""
                        UPDATE signals_log 
                        SET time_surrogate = CAST(strftime('%s', entry_time) AS INTEGER)
                        WHERE time_surrogate IS NULL AND entry_time IS NOT NULL
                    """)
                    self.conn.commit()
            except sqlite3.Error as e:
                logging.debug("‚ö†Ô∏è [DB] –û—à–∏–±–∫–∞ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è time_surrogate –¥–ª—è signals_log: %s", e)
            
            # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å –Ω–∞ time_surrogate
            try:
                self.cursor.execute(
                    "CREATE INDEX IF NOT EXISTS idx_signals_log_time_surrogate "
                    "ON signals_log(time_surrogate)"
                )
            except sqlite3.Error:
                pass
            
            # –¢—Ä–∏–≥–≥–µ—Ä –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è time_surrogate –ø—Ä–∏ INSERT/UPDATE
            self.cursor.execute("""
                CREATE TRIGGER IF NOT EXISTS signals_log_time_surrogate_insert
                AFTER INSERT ON signals_log
                BEGIN
                    UPDATE signals_log 
                    SET time_surrogate = CAST(strftime('%s', entry_time) AS INTEGER)
                    WHERE id = NEW.id AND time_surrogate IS NULL AND entry_time IS NOT NULL;
                END;
            """)
            
            self.cursor.execute("""
                CREATE TRIGGER IF NOT EXISTS signals_log_time_surrogate_update
                AFTER UPDATE OF entry_time ON signals_log
                BEGIN
                    UPDATE signals_log 
                    SET time_surrogate = CAST(strftime('%s', NEW.entry_time) AS INTEGER)
                    WHERE id = NEW.id;
                END;
            """)
            
            # –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –¥–ª—è active_signals
            try:
                with self._lock:
                    self.conn.execute("ALTER TABLE active_signals ADD COLUMN time_surrogate INTEGER")
            except sqlite3.Error:
                pass
            
            try:
                with self._lock:
                    self.conn.execute("""
                        UPDATE active_signals 
                        SET time_surrogate = CAST(strftime('%s', ts) AS INTEGER)
                        WHERE time_surrogate IS NULL AND ts IS NOT NULL
                    """)
                    self.conn.commit()
            except sqlite3.Error:
                pass
            
            try:
                self.cursor.execute(
                    "CREATE INDEX IF NOT EXISTS idx_active_signals_time_surrogate "
                    "ON active_signals(time_surrogate)"
                )
            except sqlite3.Error:
                pass
            
            self.cursor.execute("""
                CREATE TRIGGER IF NOT EXISTS active_signals_time_surrogate_insert
                AFTER INSERT ON active_signals
                BEGIN
                    UPDATE active_signals 
                    SET time_surrogate = CAST(strftime('%s', ts) AS INTEGER)
                    WHERE id = NEW.id AND time_surrogate IS NULL AND ts IS NOT NULL;
                END;
            """)
            
            # –î–ª—è trades
            try:
                with self._lock:
                    self.conn.execute("ALTER TABLE trades ADD COLUMN entry_time_surrogate INTEGER")
                    self.conn.execute("ALTER TABLE trades ADD COLUMN exit_time_surrogate INTEGER")
            except sqlite3.Error:
                pass
            
            try:
                with self._lock:
                    self.conn.execute("""
                        UPDATE trades 
                        SET entry_time_surrogate = CAST(strftime('%s', entry_time) AS INTEGER)
                        WHERE entry_time_surrogate IS NULL AND entry_time IS NOT NULL
                    """)
                    self.conn.execute("""
                        UPDATE trades 
                        SET exit_time_surrogate = CAST(strftime('%s', exit_time) AS INTEGER)
                        WHERE exit_time_surrogate IS NULL AND exit_time IS NOT NULL
                    """)
                    self.conn.commit()
            except sqlite3.Error:
                pass
            
            try:
                self.cursor.execute(
                    "CREATE INDEX IF NOT EXISTS idx_trades_entry_time_surrogate "
                    "ON trades(entry_time_surrogate)"
                )
                self.cursor.execute(
                    "CREATE INDEX IF NOT EXISTS idx_trades_exit_time_surrogate "
                    "ON trades(exit_time_surrogate)"
                )
            except sqlite3.Error:
                pass
            
            self.cursor.execute("""
                CREATE TRIGGER IF NOT EXISTS trades_entry_time_surrogate_insert
                AFTER INSERT ON trades
                BEGIN
                    UPDATE trades 
                    SET entry_time_surrogate = CAST(strftime('%s', entry_time) AS INTEGER)
                    WHERE id = NEW.id AND entry_time_surrogate IS NULL AND entry_time IS NOT NULL;
                END;
            """)
            
            self.cursor.execute("""
                CREATE TRIGGER IF NOT EXISTS trades_exit_time_surrogate_update
                AFTER UPDATE OF exit_time ON trades
                BEGIN
                    UPDATE trades 
                    SET exit_time_surrogate = CAST(strftime('%s', NEW.exit_time) AS INTEGER)
                    WHERE id = NEW.id AND NEW.exit_time IS NOT NULL;
                END;
            """)
            
            self.conn.commit()
            logging.debug("‚úÖ [DB] –°—É—Ä—Ä–æ–≥–∞—Ç–Ω—ã–µ –∫–ª—é—á–∏ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ –¥–æ–±–∞–≤–ª–µ–Ω—ã")
        except sqlite3.Error as e:
            logging.warning("‚ö†Ô∏è [DB] –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å—É—Ä—Ä–æ–≥–∞—Ç–Ω—ã—Ö –∫–ª—é—á–µ–π: %s", e)

    def _create_partial_indexes(self):
        """
        –°–æ–∑–¥–∞–µ—Ç —á–∞—Å—Ç–∏—á–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤.
        –£—Å–∫–æ—Ä–µ–Ω–∏–µ –Ω–∞ 30-50% –∑–∞ —Å—á–µ—Ç –º–µ–Ω—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –∏–Ω–¥–µ–∫—Å–æ–≤ –∏ –±—ã—Å—Ç—Ä–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ.
        """
        try:
            # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã (—Ç–æ–ø-10 –ø–æ –æ–±—ä–µ–º—É —Ç–æ—Ä–≥–æ–≤)
            priority_symbols = [
                'BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'SOLUSDT', 'XRPUSDT',
                'ADAUSDT', 'DOGEUSDT', 'TRXUSDT', 'AVAXUSDT', 'LINKUSDT'
            ]
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º WHERE clause –¥–ª—è —á–∞—Å—Ç–∏—á–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
            symbols_condition = "', '".join(priority_symbols)
            where_clause = f"symbol IN ('{symbols_condition}')"
            
            # –ß–∞—Å—Ç–∏—á–Ω—ã–π –∏–Ω–¥–µ–∫—Å –¥–ª—è signals_log (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã)
            self.cursor.execute(f"""
                CREATE INDEX IF NOT EXISTS idx_signals_log_priority_symbols
                ON signals_log(symbol, entry_time, created_at)
                WHERE {where_clause}
            """)
            
            # –ß–∞—Å—Ç–∏—á–Ω—ã–π –∏–Ω–¥–µ–∫—Å –¥–ª—è trades (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã)
            self.cursor.execute(f"""
                CREATE INDEX IF NOT EXISTS idx_trades_priority_symbols
                ON trades(symbol, entry_time, exit_time)
                WHERE {where_clause}
            """)
            
            # –ß–∞—Å—Ç–∏—á–Ω—ã–π –∏–Ω–¥–µ–∫—Å –¥–ª—è active_signals (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∫—É—é –∫–æ–ª–æ–Ω–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å: ts –∏–ª–∏ created_at
            cur = self.conn.execute("PRAGMA table_info(active_signals)")
            cols = [row[1] for row in cur.fetchall()]
            active_signals_ts_col = "ts" if "ts" in cols else "created_at"
            
            self.cursor.execute(f"""
                CREATE INDEX IF NOT EXISTS idx_active_signals_priority_symbols
                ON active_signals(symbol, {active_signals_ts_col})
                WHERE {where_clause}
            """)
            
            # –ß–∞—Å—Ç–∏—á–Ω—ã–π –∏–Ω–¥–µ–∫—Å –¥–ª—è signals (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã)
            cur = self.conn.execute("PRAGMA table_info(signals)")
            cols = [row[1] for row in cur.fetchall()]
            signals_ts_col = "ts" if "ts" in cols else "created_at"
            
            self.cursor.execute(f"""
                CREATE INDEX IF NOT EXISTS idx_signals_priority_symbols
                ON signals(symbol, {signals_ts_col})
                WHERE {where_clause}
            """)
            
            self.conn.commit()
            logging.debug("‚úÖ [DB] –ß–∞—Å—Ç–∏—á–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ —Å–æ–∑–¥–∞–Ω—ã")
        except sqlite3.Error as e:
            logging.warning("‚ö†Ô∏è [DB] –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —á–∞—Å—Ç–∏—á–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤: %s", e)

    def update_priority_symbols(self, symbols: list):
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –∏ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–µ—Ç —á–∞—Å—Ç–∏—á–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã.
        
        Args:
            symbols: –°–ø–∏—Å–æ–∫ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
        """
        try:
            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —á–∞—Å—Ç–∏—á–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã
            indexes_to_drop = [
                'idx_signals_log_priority_symbols',
                'idx_trades_priority_symbols',
                'idx_active_signals_priority_symbols',
                'idx_signals_priority_symbols'
            ]
            
            for index_name in indexes_to_drop:
                try:
                    self.cursor.execute(f"DROP INDEX IF EXISTS {index_name}")
                except sqlite3.Error:
                    pass
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
            # (–º–æ–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ system_settings –¥–ª—è –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏)
            if symbols:
                symbols_str = ','.join(symbols)
                self.save_system_setting('priority_symbols', symbols_str)
            
            # –ü–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã —Å –Ω–æ–≤—ã–º —Å–ø–∏—Å–∫–æ–º
            self._create_partial_indexes()
            logging.info("‚úÖ [DB] –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –æ–±–Ω–æ–≤–ª–µ–Ω—ã: %s", symbols)
        except sqlite3.Error as e:
            logging.warning("‚ö†Ô∏è [DB] –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤: %s", e)

    def _profile_slow_query(self, query: str, params: tuple, duration: float):
        """
        –ü—Ä–æ—Ñ–∏–ª–∏—Ä—É–µ—Ç –º–µ–¥–ª–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∏ –ª–æ–≥–∏—Ä—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.
        
        Args:
            query: SQL –∑–∞–ø—Ä–æ—Å
            params: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
            duration: –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º –ø–ª–∞–Ω –∑–∞–ø—Ä–æ—Å–∞
            plan = None
            try:
                explain_query = f"EXPLAIN QUERY PLAN {query}"
                cursor = self.conn.cursor()
                if params:
                    cursor.execute(explain_query, params)
                else:
                    cursor.execute(explain_query)
                plan_rows = cursor.fetchall()
                plan = "\n".join([str(row) for row in plan_rows])
            except Exception:
                pass
            
            # –õ–æ–≥–∏—Ä—É–µ–º –º–µ–¥–ª–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å
            logging.warning(
                "‚ö†Ô∏è [DB] –ú–µ–¥–ª–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å (%.2f —Å–µ–∫):\n"
                "  Query: %s\n"
                "  Params: %s\n"
                "  Plan: %s",
                duration, query[:200], params, (plan[:200] if plan else 'N/A')
            )
            
        except Exception as e:
            logging.debug("‚ö†Ô∏è [DB] –û—à–∏–±–∫–∞ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞: %s", e)


class DatabaseSingleton(Database):
    """–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π singleton –¥–ª—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ __new__"""
    _instance = None

    def __new__(cls, *args, **kwargs):  # pylint: disable=unused-argument
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

def get_db():
    """–ü–æ–ª—É—á–∞–µ—Ç singleton —ç–∫–∑–µ–º–ø–ª—è—Ä –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    return DatabaseSingleton()
