"""
–ú–æ–¥—É–ª—å –¥–ª—è —Å–±–æ—Ä–∞ –∏ –∞–Ω–∞–ª–∏–∑–∞ –º–µ—Ç—Ä–∏–∫ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Ñ–∏–ª—å—Ç—Ä–æ–≤
"""

import time
import logging
from datetime import datetime, timedelta
from src.shared.utils.datetime_utils import get_utc_now
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
from collections import defaultdict, deque
import pandas as pd
import numpy as np
from enum import Enum

logger = logging.getLogger(__name__)


class FilterType(Enum):
    """–¢–∏–ø—ã —Ñ–∏–ª—å—Ç—Ä–æ–≤"""
    BB_FILTER = "bb_filter"
    EMA_FILTER = "ema_filter"
    RSI_FILTER = "rsi_filter"
    MACD_FILTER = "macd_filter"  # üÜï MACD —Ñ–∏–ª—å—Ç—Ä
    VOLUME_FILTER = "volume_filter"
    AI_FILTER = "ai_filter"
    NEWS_FILTER = "news_filter"
    BTC_TREND_FILTER = "btc_trend_filter"
    WHALE_FILTER = "whale_filter"
    # üÜï Institutional Indicators filters
    AMT_FILTER = "amt_filter"
    MARKET_PROFILE_FILTER = "market_profile_filter"
    INSTITUTIONAL_PATTERNS_FILTER = "institutional_patterns_filter"


@dataclass
class FilterMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Ñ–∏–ª—å—Ç—Ä–∞"""
    filter_type: FilterType
    total_signals: int = 0
    passed_signals: int = 0
    rejected_signals: int = 0
    processing_time: float = 0.0
    success_rate: float = 0.0
    rejection_rate: float = 0.0
    avg_processing_time: float = 0.0
    last_updated: datetime = field(default_factory=get_utc_now)
    
    def update_metrics(self, passed: bool, processing_time: float):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫"""
        self.total_signals += 1
        if passed:
            self.passed_signals += 1
        else:
            self.rejected_signals += 1
        
        self.processing_time += processing_time
        self.avg_processing_time = self.processing_time / self.total_signals
        self.success_rate = self.passed_signals / self.total_signals if self.total_signals > 0 else 0.0
        self.rejection_rate = self.rejected_signals / self.total_signals if self.total_signals > 0 else 0.0
        self.last_updated = get_utc_now()


@dataclass
class FilterPerformance:
    """–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ñ–∏–ª—å—Ç—Ä–∞"""
    filter_type: FilterType
    min_processing_time: float = float('inf')
    max_processing_time: float = 0.0
    avg_processing_time: float = 0.0
    processing_times: deque = field(default_factory=lambda: deque(maxlen=1000))
    
    def add_processing_time(self, processing_time: float):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        self.processing_times.append(processing_time)
        self.min_processing_time = min(self.min_processing_time, processing_time)
        self.max_processing_time = max(self.max_processing_time, processing_time)
        self.avg_processing_time = np.mean(list(self.processing_times))


class FilterMetricsCollector:
    """–°–±–æ—Ä—â–∏–∫ –º–µ—Ç—Ä–∏–∫ —Ñ–∏–ª—å—Ç—Ä–æ–≤"""
    
    def __init__(self):
        self.metrics: Dict[FilterType, FilterMetrics] = {}
        self.performance: Dict[FilterType, FilterPerformance] = {}
        self.rejection_reasons: Dict[FilterType, Dict[str, int]] = defaultdict(lambda: defaultdict(int))
        self.time_series: Dict[FilterType, List[Tuple[datetime, Dict[str, Any]]]] = defaultdict(list)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫ –¥–ª—è –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ —Ñ–∏–ª—å—Ç—Ä–æ–≤
        for filter_type in FilterType:
            self.metrics[filter_type] = FilterMetrics(filter_type=filter_type)
            self.performance[filter_type] = FilterPerformance(filter_type=filter_type)
    
    def record_filter_result(self, 
                           filter_type: FilterType, 
                           passed: bool, 
                           processing_time: float,
                           rejection_reason: Optional[str] = None):
        """–ó–∞–ø–∏—Å—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Ñ–∏–ª—å—Ç—Ä–∞"""
        try:
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
            self.metrics[filter_type].update_metrics(passed, processing_time)
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            self.performance[filter_type].add_processing_time(processing_time)
            
            # –ó–∞–ø–∏—Å—å –ø—Ä–∏—á–∏–Ω—ã –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è
            if not passed and rejection_reason:
                self.rejection_reasons[filter_type][rejection_reason] += 1
            
            # –ó–∞–ø–∏—Å—å –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞
            self.time_series[filter_type].append((
                get_utc_now(),
                {
                    'passed': passed,
                    'processing_time': processing_time,
                    'rejection_reason': rejection_reason
                }
            ))
            
            # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞
            if len(self.time_series[filter_type]) > 10000:
                self.time_series[filter_type] = self.time_series[filter_type][-5000:]
            
            logger.debug(f"–ú–µ—Ç—Ä–∏–∫–∏ —Ñ–∏–ª—å—Ç—Ä–∞ {filter_type.value} –æ–±–Ω–æ–≤–ª–µ–Ω—ã: "
                        f"passed={passed}, time={processing_time:.4f}s")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ –º–µ—Ç—Ä–∏–∫ —Ñ–∏–ª—å—Ç—Ä–∞ {filter_type.value}: {e}")
    
    def get_filter_metrics(self, filter_type: FilterType) -> FilterMetrics:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ —Ñ–∏–ª—å—Ç—Ä–∞"""
        return self.metrics.get(filter_type, FilterMetrics(filter_type=filter_type))
    
    def get_filter_performance(self, filter_type: FilterType) -> FilterPerformance:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ñ–∏–ª—å—Ç—Ä–∞"""
        return self.performance.get(filter_type, FilterPerformance(filter_type=filter_type))
    
    def get_rejection_reasons(self, filter_type: FilterType) -> Dict[str, int]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–∏—á–∏–Ω –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–∞"""
        return dict(self.rejection_reasons[filter_type])
    
    def get_top_rejection_reasons(self, filter_type: FilterType, limit: int = 5) -> List[Tuple[str, int]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ–ø –ø—Ä–∏—á–∏–Ω –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è"""
        reasons = self.get_rejection_reasons(filter_type)
        return sorted(reasons.items(), key=lambda x: x[1], reverse=True)[:limit]
    
    def get_time_series_data(self, 
                           filter_type: FilterType, 
                           start_time: Optional[datetime] = None,
                           end_time: Optional[datetime] = None) -> List[Tuple[datetime, Dict[str, Any]]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞"""
        data = self.time_series[filter_type]
        
        if start_time:
            data = [(dt, metrics) for dt, metrics in data if dt >= start_time]
        
        if end_time:
            data = [(dt, metrics) for dt, metrics in data if dt <= end_time]
        
        return data
    
    def get_aggregated_metrics(self, 
                             start_time: Optional[datetime] = None,
                             end_time: Optional[datetime] = None) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫"""
        try:
            total_signals = 0
            total_passed = 0
            total_rejected = 0
            total_processing_time = 0.0
            
            filter_breakdown = {}
            
            for filter_type in FilterType:
                metrics = self.get_filter_metrics(filter_type)
                
                # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏
                if start_time and metrics.last_updated < start_time:
                    continue
                if end_time and metrics.last_updated > end_time:
                    continue
                
                total_signals += metrics.total_signals
                total_passed += metrics.passed_signals
                total_rejected += metrics.rejected_signals
                total_processing_time += metrics.processing_time
                
                filter_breakdown[filter_type.value] = {
                    'total_signals': metrics.total_signals,
                    'passed_signals': metrics.passed_signals,
                    'rejected_signals': metrics.rejected_signals,
                    'success_rate': metrics.success_rate,
                    'rejection_rate': metrics.rejection_rate,
                    'avg_processing_time': metrics.avg_processing_time
                }
            
            overall_success_rate = total_passed / total_signals if total_signals > 0 else 0.0
            overall_rejection_rate = total_rejected / total_signals if total_signals > 0 else 0.0
            overall_avg_processing_time = total_processing_time / total_signals if total_signals > 0 else 0.0
            
            return {
                'total_signals': total_signals,
                'total_passed': total_passed,
                'total_rejected': total_rejected,
                'overall_success_rate': overall_success_rate,
                'overall_rejection_rate': overall_rejection_rate,
                'overall_avg_processing_time': overall_avg_processing_time,
                'filter_breakdown': filter_breakdown,
                'timestamp': get_utc_now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫: {e}")
            return {}
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–≤–æ–¥–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        try:
            performance_summary = {}
            
            for filter_type in FilterType:
                perf = self.get_filter_performance(filter_type)
                
                if perf.processing_times:
                    performance_summary[filter_type.value] = {
                        'min_processing_time': perf.min_processing_time,
                        'max_processing_time': perf.max_processing_time,
                        'avg_processing_time': perf.avg_processing_time,
                        'samples_count': len(perf.processing_times),
                        'std_processing_time': np.std(list(perf.processing_times)) if len(perf.processing_times) > 1 else 0.0
                    }
                else:
                    performance_summary[filter_type.value] = {
                        'min_processing_time': 0.0,
                        'max_processing_time': 0.0,
                        'avg_processing_time': 0.0,
                        'samples_count': 0,
                        'std_processing_time': 0.0
                    }
            
            return performance_summary
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–≤–æ–¥–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {e}")
            return {}
    
    def get_efficiency_report(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –æ–± —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"""
        try:
            report = {
                'timestamp': get_utc_now().isoformat(),
                'filters': {},
                'overall': {},
                'recommendations': []
            }
            
            # –ê–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞
            for filter_type in FilterType:
                metrics = self.get_filter_metrics(filter_type)
                performance = self.get_filter_performance(filter_type)
                rejection_reasons = self.get_top_rejection_reasons(filter_type, 3)
                
                report['filters'][filter_type.value] = {
                    'metrics': {
                        'total_signals': metrics.total_signals,
                        'passed_signals': metrics.passed_signals,
                        'rejected_signals': metrics.rejected_signals,
                        'success_rate': metrics.success_rate,
                        'rejection_rate': metrics.rejection_rate
                    },
                    'performance': {
                        'avg_processing_time': performance.avg_processing_time,
                        'min_processing_time': performance.min_processing_time,
                        'max_processing_time': performance.max_processing_time
                    },
                    'top_rejection_reasons': rejection_reasons
                }
            
            # –û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
            aggregated = self.get_aggregated_metrics()
            report['overall'] = aggregated
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            recommendations = self._generate_recommendations()
            report['recommendations'] = recommendations
            
            return report
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –æ—Ç—á–µ—Ç–∞ –æ–± —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏: {e}")
            return {'error': str(e)}
    
    def _generate_recommendations(self) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        recommendations = []
        
        try:
            # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            performance_summary = self.get_performance_summary()
            
            for filter_type, perf in performance_summary.items():
                if perf['samples_count'] > 0:
                    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                    if perf['avg_processing_time'] > 0.1:  # –ë–æ–ª–µ–µ 100–º—Å
                        recommendations.append(
                            f"–§–∏–ª—å—Ç—Ä {filter_type} —Ä–∞–±–æ—Ç–∞–µ—Ç –º–µ–¥–ª–µ–Ω–Ω–æ "
                            f"({perf['avg_processing_time']:.3f}s). "
                            "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è."
                        )
                    
                    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                    if perf['std_processing_time'] > perf['avg_processing_time'] * 0.5:
                        recommendations.append(
                            f"–§–∏–ª—å—Ç—Ä {filter_type} –∏–º–µ–µ—Ç –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å "
                            f"(std: {perf['std_processing_time']:.3f}s). "
                            "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∞–Ω–∞–ª–∏–∑ –∞–ª–≥–æ—Ä–∏—Ç–º–∞."
                        )
            
            # –ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
            aggregated = self.get_aggregated_metrics()
            
            if aggregated:
                # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏
                if aggregated['overall_success_rate'] < 0.1:  # –ú–µ–Ω–µ–µ 10%
                    recommendations.append(
                        "–û–±—â–∞—è —É—Å–ø–µ—à–Ω–æ—Å—Ç—å —Ñ–∏–ª—å—Ç—Ä–æ–≤ –æ—á–µ–Ω—å –Ω–∏–∑–∫–∞—è "
                        f"({aggregated['overall_success_rate']:.1%}). "
                        "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–µ—Ä–µ—Å–º–æ—Ç—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ñ–∏–ª—å—Ç—Ä–æ–≤."
                    )
                
                # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è–º
                if aggregated['overall_rejection_rate'] > 0.9:  # –ë–æ–ª–µ–µ 90%
                    recommendations.append(
                        "–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π "
                        f"({aggregated['overall_rejection_rate']:.1%}). "
                        "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ—Å–ª–∞–±–ª–µ–Ω–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏."
                    )
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}")
            recommendations.append(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {e}")
        
        return recommendations
    
    def export_metrics_to_csv(self, filepath: str):
        """–≠–∫—Å–ø–æ—Ä—Ç –º–µ—Ç—Ä–∏–∫ –≤ CSV"""
        try:
            data = []
            
            for filter_type in FilterType:
                metrics = self.get_filter_metrics(filter_type)
                performance = self.get_filter_performance(filter_type)
                
                data.append({
                    'filter_type': filter_type.value,
                    'total_signals': metrics.total_signals,
                    'passed_signals': metrics.passed_signals,
                    'rejected_signals': metrics.rejected_signals,
                    'success_rate': metrics.success_rate,
                    'rejection_rate': metrics.rejection_rate,
                    'avg_processing_time': metrics.avg_processing_time,
                    'min_processing_time': performance.min_processing_time,
                    'max_processing_time': performance.max_processing_time,
                    'last_updated': metrics.last_updated.isoformat()
                })
            
            df = pd.DataFrame(data)
            df.to_csv(filepath, index=False)
            
            logger.info(f"–ú–µ—Ç—Ä–∏–∫–∏ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ {filepath}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ –º–µ—Ç—Ä–∏–∫ –≤ CSV: {e}")
    
    def reset_metrics(self, filter_type: Optional[FilterType] = None):
        """–°–±—Ä–æ—Å –º–µ—Ç—Ä–∏–∫"""
        try:
            if filter_type:
                # –°–±—Ä–æ—Å –º–µ—Ç—Ä–∏–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞
                self.metrics[filter_type] = FilterMetrics(filter_type=filter_type)
                self.performance[filter_type] = FilterPerformance(filter_type=filter_type)
                self.rejection_reasons[filter_type] = defaultdict(int)
                self.time_series[filter_type] = []
            else:
                # –°–±—Ä–æ—Å –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫
                for ft in FilterType:
                    self.metrics[ft] = FilterMetrics(filter_type=ft)
                    self.performance[ft] = FilterPerformance(filter_type=ft)
                    self.rejection_reasons[ft] = defaultdict(int)
                    self.time_series[ft] = []
            
            logger.info(f"–ú–µ—Ç—Ä–∏–∫–∏ —Å–±—Ä–æ—à–µ–Ω—ã –¥–ª—è {filter_type.value if filter_type else '–≤—Å–µ—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤'}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±—Ä–æ—Å–µ –º–µ—Ç—Ä–∏–∫: {e}")


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–±–æ—Ä—â–∏–∫–∞ –º–µ—Ç—Ä–∏–∫
filter_metrics_collector = FilterMetricsCollector()


def record_filter_metrics(filter_type: FilterType, 
                         passed: bool, 
                         processing_time: float,
                         rejection_reason: Optional[str] = None):
    """–£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø–∏—Å–∏ –º–µ—Ç—Ä–∏–∫ —Ñ–∏–ª—å—Ç—Ä–∞"""
    filter_metrics_collector.record_filter_result(
        filter_type, passed, processing_time, rejection_reason
    )


def get_filter_metrics(filter_type: FilterType) -> FilterMetrics:
    """–£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ —Ñ–∏–ª—å—Ç—Ä–∞"""
    return filter_metrics_collector.get_filter_metrics(filter_type)


def get_efficiency_report() -> Dict[str, Any]:
    """–£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞ –æ–± —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"""
    return filter_metrics_collector.get_efficiency_report()
