"""
–£–ª—É—á—à–µ–Ω–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π –º–µ—Ç—Ä–∏–∫
"""

import logging
from typing import Dict, Any, Optional, Tuple, List
import pandas as pd
import numpy as np
from src.metrics.decorators import track_filter_metrics, metrics_context
from src.metrics.filter_metrics import FilterType

logger = logging.getLogger(__name__)

# –ò–º–ø–æ—Ä—Ç –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö RSI —É—Ä–æ–≤–Ω–µ–π
try:
    from src.filters.adaptive_rsi import get_adaptive_rsi_levels, should_use_adaptive_rsi
    ADAPTIVE_RSI_AVAILABLE = True
except ImportError:
    ADAPTIVE_RSI_AVAILABLE = False
    logger.warning("‚ö†Ô∏è –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ RSI —É—Ä–æ–≤–Ω–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")

# –ò–º–ø–æ—Ä—Ç –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–æ–≤
try:
    from src.utils.filter_logger import log_filter_check_async
    FILTER_LOGGER_AVAILABLE = True
except ImportError:
    FILTER_LOGGER_AVAILABLE = False
    logger.debug("–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ")


class EnhancedFilterBase:
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è —É–ª—É—á—à–µ–Ω–Ω—ã—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏"""

    def __init__(self, filter_type: FilterType):
        self.filter_type = filter_type
        self.logger = logging.getLogger(f"filter.{filter_type.value}")

    def apply_filter(self, data: Dict[str, Any], **kwargs) -> Tuple[bool, Optional[str]]:
        """
        –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —Å–±–æ—Ä–æ–º –º–µ—Ç—Ä–∏–∫

        Returns:
            Tuple[bool, Optional[str]]: (–ø—Ä–æ—à–µ–ª_—Ñ–∏–ª—å—Ç—Ä, –ø—Ä–∏—á–∏–Ω–∞_–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è)
        """
        with metrics_context(f"{self.filter_type.value}_filter", self.filter_type) as ctx:
            try:
                result, rejection_reason = self._filter_logic(data, **kwargs)
                ctx.set_result(result, rejection_reason)
                return result, rejection_reason

            except Exception as e:
                self.logger.error("–û—à–∏–±–∫–∞ –≤ —Ñ–∏–ª—å—Ç—Ä–µ %s: %s", self.filter_type.value, e)
                ctx.set_result(False, f"Exception: {str(e)}")
                return False, f"Exception: {str(e)}"

    def _filter_logic(self, data: Dict[str, Any], **kwargs) -> Tuple[bool, Optional[str]]:
        """–õ–æ–≥–∏–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞ - –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –≤ –Ω–∞—Å–ª–µ–¥–Ω–∏–∫–∞—Ö"""
        raise NotImplementedError("–ú–µ—Ç–æ–¥ _filter_logic –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω")


@track_filter_metrics(FilterType.BB_FILTER)
def enhanced_bb_filter(df, i: int, **kwargs) -> Tuple[bool, Optional[str]]:
    """
    –£–ª—É—á—à–µ–Ω–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä Bollinger Bands —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏

    Args:
        df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
        i: –ò–Ω–¥–µ–∫—Å —Ç–µ–∫—É—â–µ–π —Å–≤–µ—á–∏
        **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

    Returns:
        Tuple[bool, Optional[str]]: (–ø—Ä–æ—à–µ–ª_—Ñ–∏–ª—å—Ç—Ä, –ø—Ä–∏—á–∏–Ω–∞_–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è)
    """
    try:
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è –∏–Ω—Ç—Ä–∞–¥–µ–π)
        bb_window = kwargs.get('bb_window', 18)  # üÜï –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: –±—ã–ª–æ 20
        # bb_std –∏ bb_epsilon –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤ —Ä–∞—Å—á–µ—Ç–∞—Ö BB, –Ω–æ –Ω–µ –Ω–∞–ø—Ä—è–º—É—é –≤ —ç—Ç–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
        min_width = kwargs.get('bb_min_width', 0.015)  # üÜï –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: –±—ã–ª–æ 0.02
        position_long = kwargs.get('bb_position_long', 0.15)  # üÜï –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: –±—ã–ª–æ 0.2
        position_short = kwargs.get('bb_position_short', 0.85)  # üÜï –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: –±—ã–ª–æ 0.8
        squeeze_threshold = kwargs.get('bb_squeeze_threshold', 0.012)  # üÜï –ü–æ—Ä–æ–≥ —Å–∂–∞—Ç–∏—è

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if i < bb_window or i >= len(df):
            return False, f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è BB —Ñ–∏–ª—å—Ç—Ä–∞ (–Ω—É–∂–Ω–æ {bb_window})"

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–æ–ª–æ–Ω–æ–∫ BB
        required_columns = ['bb_upper', 'bb_lower', 'bb_mid']
        if not all(col in df.columns for col in required_columns):
            return False, "–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏ Bollinger Bands"

        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        current_close = df.iloc[i]['close']
        bb_upper = df.iloc[i]['bb_upper']
        bb_lower = df.iloc[i]['bb_lower']
        bb_mid = df.iloc[i]['bb_mid']

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN
        if pd.isna(current_close) or pd.isna(bb_upper) or pd.isna(bb_lower) or pd.isna(bb_mid):
            return False, "NaN –∑–Ω–∞—á–µ–Ω–∏—è –≤ BB –¥–∞–Ω–Ω—ã—Ö"

        # üÜï –ü—Ä–æ–≤–µ—Ä–∫–∞ —à–∏—Ä–∏–Ω—ã –ø–æ–ª–æ—Å (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è)
        bb_width = (bb_upper - bb_lower) / bb_mid if bb_mid > 0 else 0
        if bb_width < min_width:
            return False, f"–°–ª–∏—à–∫–æ–º —É–∑–∫–∏–µ –ø–æ–ª–æ—Å—ã: {bb_width:.3%}"

        # üÜï –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–∂–∞—Ç–∏–µ (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è)
        if bb_width < squeeze_threshold:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –ø–µ—Ä–µ–¥ —Å–∂–∞—Ç–∏–µ–º
            if i > 5:
                prev_widths = []
                for j in range(1, 6):
                    if i - j >= 0:
                        prev_upper = df.iloc[i-j]['bb_upper']
                        prev_lower = df.iloc[i-j]['bb_lower']
                        prev_mid = df.iloc[i-j]['bb_mid']
                        if prev_mid > 0:
                            prev_width = (prev_upper - prev_lower) / prev_mid
                            prev_widths.append(prev_width)

                # –ï—Å–ª–∏ –ø–æ–ª–æ—Å—ã —Ä–µ–∑–∫–æ —Å—É–∑–∏–ª–∏—Å—å - –≤–æ–∑–º–æ–∂–µ–Ω –ø—Ä–æ–±–æ–π
                if prev_widths and max(prev_widths) > bb_width * 1.5:
                    return False, "–†–µ–∑–∫–æ–µ —Å–∂–∞—Ç–∏–µ –ø–æ–ª–æ—Å - –≤–æ–∑–º–æ–∂–µ–Ω –ø—Ä–æ–±–æ–π"

        # üÜï –†–∞—Å—á–µ—Ç –ø–æ–∑–∏—Ü–∏–∏ —Ü–µ–Ω—ã (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞)
        bb_position = (current_close - bb_lower) / (bb_upper - bb_lower) if (bb_upper - bb_lower) > 0 else 0.5

        # üÜï –°—Ç—Ä–æ–≥–∏–µ —É—Å–ª–æ–≤–∏—è –¥–ª—è –ø–æ–∑–∏—Ü–∏–∏
        if bb_position < position_long:  # –í –Ω–∏–∂–Ω–∏—Ö 15%
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è –ª–æ–Ω–≥–æ–≤
            if i > 0:
                prev_upper = df.iloc[i-1]['bb_upper']
                prev_lower = df.iloc[i-1]['bb_lower']
                prev_close = df.iloc[i-1]['close']
                if (prev_upper - prev_lower) > 0:
                    prev_position = (prev_close - prev_lower) / (prev_upper - prev_lower)
                    if prev_position < position_long:
                        return False, "–¶–µ–Ω–∞ —Å–ª–∏—à–∫–æ–º –¥–æ–ª–≥–æ –≤ –Ω–∏–∂–Ω–µ–π –∑–æ–Ω–µ"
        elif bb_position > position_short:  # –í –≤–µ—Ä—Ö–Ω–∏—Ö 15%
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è —à–æ—Ä—Ç–æ–≤
            if i > 0:
                prev_upper = df.iloc[i-1]['bb_upper']
                prev_lower = df.iloc[i-1]['bb_lower']
                prev_close = df.iloc[i-1]['close']
                if (prev_upper - prev_lower) > 0:
                    prev_position = (prev_close - prev_lower) / (prev_upper - prev_lower)
                    if prev_position > position_short:
                        return False, "–¶–µ–Ω–∞ —Å–ª–∏—à–∫–æ–º –¥–æ–ª–≥–æ –≤ –≤–µ—Ä—Ö–Ω–µ–π –∑–æ–Ω–µ"
        else:
            return False, f"–¶–µ–Ω–∞ –≤ —Å—Ä–µ–¥–Ω–µ–π –∑–æ–Ω–µ BB: {bb_position:.2f}"

        # üÜï –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ª–æ–∂–Ω—ã–π –ø—Ä–æ–±–æ–π
        if i > 2:
            recent_positions = []
            for j in range(3):
                if i - j >= 0:
                    prev_upper = df.iloc[i-j]['bb_upper']
                    prev_lower = df.iloc[i-j]['bb_lower']
                    prev_close = df.iloc[i-j]['close']
                    if (prev_upper - prev_lower) > 0:
                        pos = (prev_close - prev_lower) / (prev_upper - prev_lower)
                        recent_positions.append(pos)

            # –ï—Å–ª–∏ —Ü–µ–Ω–∞ "–ø—Ä—ã–≥–∞–µ—Ç" —á–µ—Ä–µ–∑ –≥—Ä–∞–Ω–∏—Ü—ã - –≤–æ–∑–º–æ–∂–µ–Ω –ª–æ–∂–Ω—ã–π —Å–∏–≥–Ω–∞–ª
            if len(recent_positions) >= 2:
                position_changes = sum(1 for j in range(1, len(recent_positions)) if
                                     (recent_positions[j] < position_long and recent_positions[j-1] > position_short) or
                                     (recent_positions[j] > position_short and recent_positions[j-1] < position_long))

                if position_changes > 0:
                    return False, "–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Å–∫–∞—á–∫–∏ —á–µ—Ä–µ–∑ –ø–æ–ª–æ—Å—ã BB"

        return True, None

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –≤ BB —Ñ–∏–ª—å—Ç—Ä–µ: %s", e)
        return False, f"Exception: {str(e)}"


@track_filter_metrics(FilterType.EMA_FILTER)
def enhanced_ema_filter(df, i: int, **kwargs) -> Tuple[bool, Optional[str]]:
    """
    –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ô EMA —Ñ–∏–ª—å—Ç—Ä –¥–ª—è –∏–Ω—Ç—Ä–∞–¥–µ–π –∫—Ä–∏–ø—Ç–æ

    Args:
        df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
        i: –ò–Ω–¥–µ–∫—Å —Ç–µ–∫—É—â–µ–π —Å–≤–µ—á–∏
        **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

    Returns:
        Tuple[bool, Optional[str]]: (–ø—Ä–æ—à–µ–ª_—Ñ–∏–ª—å—Ç—Ä, –ø—Ä–∏—á–∏–Ω–∞_–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è)
    """
    try:
        # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        ema_fast = kwargs.get('ema_fast', 6)  # üÜï –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: –±—ã–ª–æ 7
        ema_medium = kwargs.get('ema_medium', 14)  # üÜï –ù–æ–≤–∞—è —Å—Ä–µ–¥–Ω—è—è EMA
        ema_slow = kwargs.get('ema_slow', 22)  # üÜï –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: –±—ã–ª–æ 25
        min_distance = kwargs.get('ema_min_distance', 0.008)  # üÜï –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: –±—ã–ª–æ 0.01
        trend_strength = kwargs.get('ema_trend_strength', 0.003)  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å–∏–ª–∞ —Ç—Ä–µ–Ω–¥–∞

        if i < ema_slow:
            return False, f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è EMA (–Ω—É–∂–Ω–æ {ema_slow})"

        # –ü–æ–ª—É—á–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è EMA (–¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏)
        ema_fast_col = f'ema{ema_fast}'
        ema_medium_col = f'ema{ema_medium}'
        ema_slow_col = f'ema{ema_slow}'

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–æ–ª–æ–Ω–æ–∫ EMA
        required_columns = [ema_fast_col, ema_medium_col, ema_slow_col]
        if not all(col in df.columns for col in required_columns):
            return False, f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏ EMA: {required_columns}"

        ema_fast_val = df.iloc[i][ema_fast_col]
        ema_medium_val = df.iloc[i][ema_medium_col]
        ema_slow_val = df.iloc[i][ema_slow_col]
        current_close = df.iloc[i]['close']

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN
        if pd.isna(current_close) or pd.isna(ema_fast_val) or pd.isna(ema_medium_val) or pd.isna(ema_slow_val):
            return False, "NaN –∑–Ω–∞—á–µ–Ω–∏—è –≤ EMA –¥–∞–Ω–Ω—ã—Ö"

        # üÜï –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –ü–†–û–í–ï–†–ö–ò:

        # 1. –ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç—Ä–µ–Ω–¥–∞
        fast_above_medium = ema_fast_val > ema_medium_val
        medium_above_slow = ema_medium_val > ema_slow_val

        # –í—Å–µ EMA –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤—ã—Å—Ç—Ä–æ–µ–Ω—ã –≤ —Ç—Ä–µ–Ω–¥
        if fast_above_medium != medium_above_slow:
            return False, "EMA –Ω–µ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω—ã - –Ω–µ—Ç —á–µ—Ç–∫–æ–≥–æ —Ç—Ä–µ–Ω–¥–∞"

        # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –º–µ–∂–¥—É EMA (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è)
        ema_distance = abs(ema_fast_val - ema_medium_val) / ema_medium_val if ema_medium_val > 0 else 0
        if ema_distance < min_distance:
            return False, f"EMA —Å–ª–∏—à–∫–æ–º –±–ª–∏–∑–∫–æ: {ema_distance:.3%}"

        # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏–ª—ã —Ç—Ä–µ–Ω–¥–∞
        trend_strength_actual = abs(ema_fast_val - ema_slow_val) / ema_slow_val if ema_slow_val > 0 else 0
        if trend_strength_actual < trend_strength:
            return False, f"–°–ª–∞–±—ã–π —Ç—Ä–µ–Ω–¥: {trend_strength_actual:.3%}"

        # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–æ–∂–µ–Ω–∏—è —Ü–µ–Ω—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ EMA
        if fast_above_medium:  # –í–æ—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥
            if current_close < ema_fast_val * 0.985:  # üÜï –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: –±—ã–ª–æ 0.98
                return False, "–¶–µ–Ω–∞ —Å–ª–∏—à–∫–æ–º –¥–∞–ª–µ–∫–æ –æ—Ç –±—ã—Å—Ç—Ä–æ–π EMA –≤ –≤–æ—Å—Ö–æ–¥—è—â–µ–º —Ç—Ä–µ–Ω–¥–µ"
        else:  # –ù–∏—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥
            if current_close > ema_fast_val * 1.015:  # üÜï –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: –±—ã–ª–æ 1.02
                return False, "–¶–µ–Ω–∞ —Å–ª–∏—à–∫–æ–º –¥–∞–ª–µ–∫–æ –æ—Ç –±—ã—Å—Ç—Ä–æ–π EMA –≤ –Ω–∏—Å—Ö–æ–¥—è—â–µ–º —Ç—Ä–µ–Ω–¥–µ"

        # 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–∞–∑–≤–æ—Ä–æ—Ç (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è)
        if i > 2:
            trend_direction_changes = 0
            for j in range(1, 3):
                if i - j >= 0:
                    prev_fast = df.iloc[i-j][ema_fast_col]
                    prev_medium = df.iloc[i-j][ema_medium_col]
                    if (prev_fast > prev_medium) != fast_above_medium:
                        trend_direction_changes += 1

            if trend_direction_changes >= 2:
                return False, "–ß–∞—Å—Ç—ã–µ —Å–º–µ–Ω—ã –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–∞"

        return True, None

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –≤ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–º EMA —Ñ–∏–ª—å—Ç—Ä–µ: %s", e)
        return False, f"Exception: {str(e)}"


@track_filter_metrics(FilterType.MACD_FILTER)
def enhanced_macd_filter(df, i: int, **kwargs) -> Tuple[bool, Optional[str]]:
    """
    –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ô MACD —Ñ–∏–ª—å—Ç—Ä –¥–ª—è –∏–Ω—Ç—Ä–∞–¥–µ–π –∫—Ä–∏–ø—Ç–æ

    Args:
        df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
        i: –ò–Ω–¥–µ–∫—Å —Ç–µ–∫—É—â–µ–π —Å–≤–µ—á–∏
        **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

    Returns:
        Tuple[bool, Optional[str]]: (–ø—Ä–æ—à–µ–ª_—Ñ–∏–ª—å—Ç—Ä, –ø—Ä–∏—á–∏–Ω–∞_–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è)
    """
    try:
        # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        # fast_period –∏ signal_period –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤ —Ä–∞—Å—á–µ—Ç–∞—Ö MACD, –Ω–æ –Ω–µ –Ω–∞–ø—Ä—è–º—É—é –≤ —ç—Ç–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
        slow_period = kwargs.get('macd_slow_period', 21)  # üÜï –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: –±—ã–ª–æ 26
        min_strength = kwargs.get('macd_min_strength', 0.003)  # üÜï –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: –±—ã–ª–æ 0.005
        histogram_min = kwargs.get('macd_histogram_min', 0.001)  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã
        trend_confirmation = kwargs.get('macd_trend_confirmation', 2)  # –¢—Ä–µ–±–æ–≤–∞—Ç—å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–∞

        if i < slow_period or i >= len(df):
            return False, f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è MACD (–Ω—É–∂–Ω–æ {slow_period})"

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–æ–ª–æ–Ω–æ–∫ MACD
        required_columns = ['macd', 'macd_signal', 'macd_hist']
        if not all(col in df.columns for col in required_columns):
            return False, "–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏ MACD"

        current_macd = df.iloc[i]['macd']
        current_signal = df.iloc[i]['macd_signal']
        current_hist = df.iloc[i]['macd_hist']

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN
        if pd.isna(current_macd) or pd.isna(current_signal) or pd.isna(current_hist):
            return False, "NaN –∑–Ω–∞—á–µ–Ω–∏—è –≤ MACD –¥–∞–Ω–Ω—ã—Ö"

        # üÜï –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –ü–†–û–í–ï–†–ö–ò:

        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π —Å–∏–ª—ã –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã
        if abs(current_hist) < histogram_min:
            return False, f"–°–ª–∞–±–∞—è –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ MACD: {current_hist:.4f}"

        # 2. –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–∞—Å—á–µ—Ç —Å–∏–ª—ã —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è
        macd_strength = abs(current_hist) / (abs(current_macd) + 1e-9)
        if macd_strength < min_strength:
            return False, f"–°–ª–∞–±–æ–µ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ MACD: {macd_strength:.4f}"

        # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ–º
        if i >= trend_confirmation:
            # –¢—Ä–µ–±—É–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è (2 —Å–≤–µ—á–∏)
            prev_macd = df.iloc[i-1]['macd']
            prev_signal = df.iloc[i-1]['macd_signal']

            if (current_macd > current_signal and prev_macd <= prev_signal) or \
               (current_macd < current_signal and prev_macd >= prev_signal):
                return False, "MACD —Ç–æ–ª—å–∫–æ —á—Ç–æ –ø–µ—Ä–µ—Å–µ–∫ —Å–∏–≥–Ω–∞–ª - –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ"

        # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏—é (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è)
        if i > 7:
            # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏—é
            lookback = 7
            recent_macd = df.iloc[i-lookback:i+1]['macd'].values
            recent_close = df.iloc[i-lookback:i+1]['close'].values

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏—é
            price_trend = recent_close[-1] > recent_close[0]  # True –µ—Å–ª–∏ —Ü–µ–Ω–∞ —Ä–∞—Å—Ç–µ—Ç
            macd_trend = recent_macd[-1] > recent_macd[0]  # True –µ—Å–ª–∏ MACD —Ä–∞—Å—Ç–µ—Ç

            if price_trend != macd_trend:
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏–ª—ã –¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏–∏
                price_change = abs(recent_close[-1] - recent_close[0]) / recent_close[0] if recent_close[0] > 0 else 0
                macd_change = abs(recent_macd[-1] - recent_macd[0])

                if price_change > 0.03 and macd_change > 0.001:  # –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –¥–≤–∏–∂–µ–Ω–∏—è
                    return False, "–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏—è MACD"

        return True, None

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –≤ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–º MACD —Ñ–∏–ª—å—Ç—Ä–µ: %s", e)
        return False, f"Exception: {str(e)}"


@track_filter_metrics(FilterType.RSI_FILTER)
def enhanced_rsi_filter(df, i: int, **kwargs) -> Tuple[bool, Optional[str]]:
    """
    –£–ª—É—á—à–µ–Ω–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä RSI —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏

    Args:
        df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
        i: –ò–Ω–¥–µ–∫—Å —Ç–µ–∫—É—â–µ–π —Å–≤–µ—á–∏
        **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

    Returns:
        Tuple[bool, Optional[str]]: (–ø—Ä–æ—à–µ–ª_—Ñ–∏–ª—å—Ç—Ä, –ø—Ä–∏—á–∏–Ω–∞_–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è)
    """
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if i < 14 or i >= len(df):
            return False, "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è RSI —Ñ–∏–ª—å—Ç—Ä–∞"

        # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–±–∞–∑–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è - –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è –∫—Ä–∏–ø—Ç–æ)
        base_rsi_period = kwargs.get('rsi_period', 14)
        base_rsi_oversold = kwargs.get('rsi_oversold', 28)  # üÜï –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: –±—ã–ª–æ 30
        base_rsi_overbought = kwargs.get('rsi_overbought', 72)  # üÜï –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: –±—ã–ª–æ 70

        # üÜï –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–µ —É—Ä–æ–≤–Ω–∏ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –∏ –≤–∫–ª—é—á–µ–Ω—ã
        use_adaptive = kwargs.get('use_adaptive_rsi', True) and ADAPTIVE_RSI_AVAILABLE
        symbol = kwargs.get('symbol', 'UNKNOWN')

        if use_adaptive and should_use_adaptive_rsi(symbol):
            try:
                adaptive_levels = get_adaptive_rsi_levels(
                    symbol, df, i,
                    base_overbought=base_rsi_overbought,
                    base_oversold=base_rsi_oversold,
                    base_period=base_rsi_period
                )
                rsi_oversold = adaptive_levels.get('oversold', base_rsi_oversold)
                rsi_overbought = adaptive_levels.get('overbought', base_rsi_overbought)
                volatility_pct = adaptive_levels.get('volatility', 0) * 100
                group = adaptive_levels.get('group', 'default')
                logger.debug("üìä [ADAPTIVE RSI] %s: –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å=%.2f%%, "
                           "–≥—Ä—É–ø–ø–∞=%s, —É—Ä–æ–≤–Ω–∏=%.0f/%.0f",
                           symbol, volatility_pct, group, rsi_oversold, rsi_overbought)
            except Exception as e:
                logger.debug("‚ö†Ô∏è [ADAPTIVE RSI] –û—à–∏–±–∫–∞ –¥–ª—è %s: %s, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–µ —É—Ä–æ–≤–Ω–∏", symbol, e)
                rsi_oversold = base_rsi_oversold
                rsi_overbought = base_rsi_overbought
        else:
            rsi_oversold = base_rsi_oversold
            rsi_overbought = base_rsi_overbought

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–æ–ª–æ–Ω–∫–∏ RSI
        if 'rsi' not in df.columns:
            return False, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–ª–æ–Ω–∫–∞ RSI"

        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è RSI
        current_rsi = df.iloc[i]['rsi']

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN
        if pd.isna(current_rsi):
            return False, "NaN –∑–Ω–∞—á–µ–Ω–∏–µ –≤ RSI"

        # –õ–æ–≥–∏–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        if current_rsi < rsi_oversold:
            return False, f"RSI –≤ –∑–æ–Ω–µ –ø–µ—Ä–µ–ø—Ä–æ–¥–∞–Ω–Ω–æ—Å—Ç–∏: {current_rsi:.2f}"

        if current_rsi > rsi_overbought:
            return False, f"RSI –≤ –∑–æ–Ω–µ –ø–µ—Ä–µ–∫—É–ø–ª–µ–Ω–Ω–æ—Å—Ç–∏: {current_rsi:.2f}"

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏—é
        divergence_lookback = kwargs.get('divergence_lookback', 8)  # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è –∫—Ä–∏–ø—Ç–æ (–±—ã–ª–æ 5)
        if i > divergence_lookback:
            # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏—é
            recent_rsi = df.iloc[i-divergence_lookback:i+1]['rsi'].values
            recent_close = df.iloc[i-divergence_lookback:i+1]['close'].values

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤–æ—Å—Ö–æ–¥—è—â—É—é –¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏—é
            if (recent_close[-1] < recent_close[0] and recent_rsi[-1] > recent_rsi[0]):
                return False, "–í–æ—Å—Ö–æ–¥—è—â–∞—è –¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏—è RSI"

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∏—Å—Ö–æ–¥—è—â—É—é –¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏—é
            if (recent_close[-1] > recent_close[0] and recent_rsi[-1] < recent_rsi[0]):
                return False, "–ù–∏—Å—Ö–æ–¥—è—â–∞—è –¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏—è RSI"

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å RSI
        volatility_threshold = kwargs.get('volatility_threshold', 8)  # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è –∫—Ä–∏–ø—Ç–æ (–±—ã–ª–æ 10)
        if i > 3:
            rsi_std = df.iloc[i-3:i+1]['rsi'].std()
            if rsi_std > volatility_threshold:  # –°–ª–∏—à–∫–æ–º –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã–π RSI
                return False, f"–°–ª–∏—à–∫–æ–º –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã–π RSI: std={rsi_std:.2f}"

        return True, None

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –≤ RSI —Ñ–∏–ª—å—Ç—Ä–µ: %s", e)
        return False, f"Exception: {str(e)}"


@track_filter_metrics(FilterType.VOLUME_FILTER)
def enhanced_volume_filter(df, i: int, **kwargs) -> Tuple[bool, Optional[str]]:
    """
    –£–ª—É—á—à–µ–Ω–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä –æ–±—ä–µ–º–∞ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏

    Args:
        df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
        i: –ò–Ω–¥–µ–∫—Å —Ç–µ–∫—É—â–µ–π —Å–≤–µ—á–∏
        **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

    Returns:
        Tuple[bool, Optional[str]]: (–ø—Ä–æ—à–µ–ª_—Ñ–∏–ª—å—Ç—Ä, –ø—Ä–∏—á–∏–Ω–∞_–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è)
    """
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if i < 20 or i >= len(df):
            return False, "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Volume —Ñ–∏–ª—å—Ç—Ä–∞"

        # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è –∫—Ä–∏–ø—Ç–æ)
        volume_ratio_threshold = kwargs.get('volume_ratio_threshold', 1.2)  # üÜï –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: –±—ã–ª–æ 1.5
        min_volume = kwargs.get('min_volume', 500)  # üÜï –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: –±—ã–ª–æ 1000
        max_ratio = kwargs.get('max_ratio', 8)  # üÜï –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: –±—ã–ª–æ 10
        spike_threshold = kwargs.get('spike_threshold', 5.0)  # üÜï –ü–æ—Ä–æ–≥ –≤—Å–ø–ª–µ—Å–∫–æ–≤
        min_volume_usd = kwargs.get('min_volume_usd', 10000)  # üÜï –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –æ–±—ä–µ–º –≤ USD

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–æ–ª–æ–Ω–æ–∫ –æ–±—ä–µ–º–∞
        if 'volume' not in df.columns:
            return False, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–ª–æ–Ω–∫–∞ volume"

        if 'volume_ratio' not in df.columns:
            return False, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–ª–æ–Ω–∫–∞ volume_ratio"

        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        current_volume = df.iloc[i]['volume']
        current_close = df.iloc[i]['close']
        volume_ratio = df.iloc[i]['volume_ratio']

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN
        if pd.isna(current_volume) or pd.isna(volume_ratio) or pd.isna(current_close):
            return False, "NaN –∑–Ω–∞—á–µ–Ω–∏—è –≤ Volume –¥–∞–Ω–Ω—ã—Ö"

        # üÜï –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –æ–±—ä–µ–º–∞ –≤ USD
        volume_usd = current_volume * current_close
        if volume_usd < min_volume_usd:
            return False, f"–°–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–∏–π –æ–±—ä–µ–º –≤ USD: {volume_usd:.0f}"

        # –õ–æ–≥–∏–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –æ–±—ä–µ–º–∞
        if current_volume < min_volume:
            return False, f"–°–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–∏–π –æ–±—ä–µ–º: {current_volume:.0f}"

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è –æ–±—ä–µ–º–∞
        if volume_ratio < volume_ratio_threshold:
            return False, f"–ù–∏–∑–∫–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –æ–±—ä–µ–º–∞: {volume_ratio:.2f}"

        # üÜï –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∞–Ω–æ–º–∞–ª—å–Ω—ã–µ –≤—Å–ø–ª–µ—Å–∫–∏ –æ–±—ä–µ–º–∞ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è)
        if volume_ratio > spike_threshold:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–∏—Ä–æ–¥—É –≤—Å–ø–ª–µ—Å–∫–∞
            if i > 0:
                price_change = abs(current_close - df.iloc[i-1]['close']) / df.iloc[i-1]['close']
                if price_change > 0.08:  # –î–≤–∏–∂–µ–Ω–∏–µ > 8%
                    return False, (
                        f"–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–π –≤—Å–ø–ª–µ—Å–∫ –æ–±—ä–µ–º–∞: ratio={volume_ratio:.2f}, "
                        f"price_change={price_change:.2%}"
                    )

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∞–Ω–æ–º–∞–ª—å–Ω–æ –≤—ã—Å–æ–∫–∏–π –æ–±—ä–µ–º (–æ–±–Ω–æ–≤–ª–µ–Ω–æ)
        if volume_ratio > max_ratio:  # üÜï –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: –±—ã–ª–æ 10
            return False, f"–ê–Ω–æ–º–∞–ª—å–Ω–æ –≤—ã—Å–æ–∫–∏–π –æ–±—ä–µ–º: {volume_ratio:.2f}"

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –æ–±—ä–µ–º–∞
        if i > 5:
            recent_volumes = df.iloc[i-5:i+1]['volume'].values
            volume_std = np.std(recent_volumes)
            volume_mean = np.mean(recent_volumes)

            if volume_std > volume_mean * 2:  # –°–ª–∏—à–∫–æ–º –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã–π –æ–±—ä–µ–º
                return False, f"–°–ª–∏—à–∫–æ–º –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã–π –æ–±—ä–µ–º: std={volume_std:.0f}"

        return True, None

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –≤ Volume —Ñ–∏–ª—å—Ç—Ä–µ: %s", e)
        return False, f"Exception: {str(e)}"


@track_filter_metrics(FilterType.AI_FILTER)
def enhanced_ai_filter(df, i: int, **kwargs) -> Tuple[bool, Optional[str]]:
    """
    –£–ª—É—á—à–µ–Ω–Ω—ã–π AI —Ñ–∏–ª—å—Ç—Ä —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏

    Args:
        df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
        i: –ò–Ω–¥–µ–∫—Å —Ç–µ–∫—É—â–µ–π —Å–≤–µ—á–∏
        **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

    Returns:
        Tuple[bool, Optional[str]]: (–ø—Ä–æ—à–µ–ª_—Ñ–∏–ª—å—Ç—Ä, –ø—Ä–∏—á–∏–Ω–∞_–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è)
    """
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if i < 50 or i >= len(df):
            return False, "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è AI —Ñ–∏–ª—å—Ç—Ä–∞"

        # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        ai_confidence_threshold = kwargs.get('ai_confidence_threshold', 0.7)
        # ai_pattern_min_count –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤, –Ω–æ –Ω–µ –Ω–∞–ø—Ä—è–º—É—é –≤ —ç—Ç–æ–π —Ñ—É–Ω–∫—Ü–∏–∏

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è AI –¥–∞–Ω–Ω—ã—Ö
        ai_columns = ['ai_confidence', 'ai_pattern_match', 'ai_sentiment']
        if not all(col in df.columns for col in ai_columns):
            return False, "–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç AI –∫–æ–ª–æ–Ω–∫–∏"

        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        ai_confidence = df.iloc[i]['ai_confidence']
        ai_pattern_match = df.iloc[i]['ai_pattern_match']
        ai_sentiment = df.iloc[i]['ai_sentiment']

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN
        if pd.isna(ai_confidence) or pd.isna(ai_pattern_match) or pd.isna(ai_sentiment):
            return False, "NaN –∑–Ω–∞—á–µ–Ω–∏—è –≤ AI –¥–∞–Ω–Ω—ã—Ö"

        # –õ–æ–≥–∏–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ AI
        if ai_confidence < ai_confidence_threshold:
            return False, f"–ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å AI: {ai_confidence:.2f}"

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω—É
        if ai_pattern_match < 0.5:
            return False, f"–°–ª–∞–±–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—É: {ai_pattern_match:.2f}"

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è
        if abs(ai_sentiment) < 0.3:  # –ù–µ–π—Ç—Ä–∞–ª—å–Ω–æ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ
            return False, f"–ù–µ–π—Ç—Ä–∞–ª—å–Ω–æ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {ai_sentiment:.2f}"

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–µ —Å –¥—Ä—É–≥–∏–º–∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏
        if i > 0:
            prev_confidence = df.iloc[i-1]['ai_confidence']
            if abs(ai_confidence - prev_confidence) > 0.5:  # –†–µ–∑–∫–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                return False, "–†–µ–∑–∫–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ AI"

        return True, None

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –≤ AI —Ñ–∏–ª—å—Ç—Ä–µ: %s", e)
        return False, f"Exception: {str(e)}"


class FilterPipeline:
    """–ü–∞–π–ø–ª–∞–π–Ω —Ñ–∏–ª—å—Ç—Ä–æ–≤ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏"""

    def __init__(self):
        self.filters = {
            FilterType.BB_FILTER: enhanced_bb_filter,
            FilterType.EMA_FILTER: enhanced_ema_filter,
            FilterType.RSI_FILTER: enhanced_rsi_filter,
            FilterType.VOLUME_FILTER: enhanced_volume_filter,
            FilterType.AI_FILTER: enhanced_ai_filter,
        }
        self.logger = logging.getLogger("filter_pipeline")

    def apply_filters(self, df, i: int, enabled_filters: Dict[FilterType, bool], **kwargs) -> Tuple[bool, List[str]]:
        """
        –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤

        Args:
            df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            i: –ò–Ω–¥–µ–∫—Å —Ç–µ–∫—É—â–µ–π —Å–≤–µ—á–∏
            enabled_filters: –°–ª–æ–≤–∞—Ä—å –≤–∫–ª—é—á–µ–Ω–Ω—ã—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤
            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

        Returns:
            Tuple[bool, List[str]]: (–ø—Ä–æ—à–µ–ª_–≤—Å–µ_—Ñ–∏–ª—å—Ç—Ä—ã, —Å–ø–∏—Å–æ–∫_–ø—Ä–∏—á–∏–Ω_–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è)
        """
        rejection_reasons = []

        for filter_type, is_enabled in enabled_filters.items():
            if not is_enabled:
                continue

            if filter_type not in self.filters:
                self.logger.warning("–§–∏–ª—å—Ç—Ä %s –Ω–µ –Ω–∞–π–¥–µ–Ω", filter_type.value)
                continue

            try:
                filter_func = self.filters[filter_type]
                passed, reason = filter_func(df, i, **kwargs)

                # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ñ–∏–ª—å—Ç—Ä–∞ –≤ –ë–î
                if FILTER_LOGGER_AVAILABLE:
                    try:
                        symbol = kwargs.get('symbol', 'UNKNOWN')
                        log_filter_check_async(
                            symbol=symbol,
                            filter_type=filter_type.value,
                            passed=passed,
                            reason=reason if not passed else None
                        )
                    except Exception as log_err:
                        self.logger.debug("–û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–∞ %s: %s", filter_type.value, log_err)

                if not passed:
                    rejection_reasons.append(f"{filter_type.value}: {reason}")
                    self.logger.debug("–°–∏–≥–Ω–∞–ª –æ—Ç–∫–ª–æ–Ω–µ–Ω —Ñ–∏–ª—å—Ç—Ä–æ–º %s: %s", filter_type.value, reason)
                else:
                    self.logger.debug("–°–∏–≥–Ω–∞–ª –ø—Ä–æ—à–µ–ª —Ñ–∏–ª—å—Ç—Ä %s", filter_type.value)

            except Exception as e:
                error_msg = f"–û—à–∏–±–∫–∞ –≤ —Ñ–∏–ª—å—Ç—Ä–µ {filter_type.value}: {e}"
                rejection_reasons.append(error_msg)
                self.logger.error(error_msg)

                # –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É —Ñ–∏–ª—å—Ç—Ä–∞
                if FILTER_LOGGER_AVAILABLE:
                    try:
                        symbol = kwargs.get('symbol', 'UNKNOWN')
                        log_filter_check_async(
                            symbol=symbol,
                            filter_type=filter_type.value,
                            passed=False,
                            reason=error_msg
                        )
                    except Exception:
                        pass

        # –°–∏–≥–Ω–∞–ª –ø—Ä–æ—Ö–æ–¥–∏—Ç, –µ—Å–ª–∏ –Ω–µ—Ç –ø—Ä–∏—á–∏–Ω –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è
        passed = len(rejection_reasons) == 0

        if passed:
            self.logger.info("–°–∏–≥–Ω–∞–ª –ø—Ä–æ—à–µ–ª –≤—Å–µ —Ñ–∏–ª—å—Ç—Ä—ã")
        else:
            reasons_str = ', '.join(rejection_reasons)
            self.logger.info("–°–∏–≥–Ω–∞–ª –æ—Ç–∫–ª–æ–Ω–µ–Ω: %s", reasons_str)

        return passed, rejection_reasons
