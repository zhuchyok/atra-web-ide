#!/usr/bin/env python3
"""
–ú–µ–Ω–µ–¥–∂–µ—Ä —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è AI-—Å–∏—Å—Ç–µ–º—ã —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
"""

import asyncio
import json
import logging
import os
import shutil
import time
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
from src.shared.utils.datetime_utils import get_utc_now

logger = logging.getLogger(__name__)


class AIStateManager:
    """
    –ú–µ–Ω–µ–¥–∂–µ—Ä —Å–æ—Å—Ç–æ—è–Ω–∏—è AI-—Å–∏—Å—Ç–µ–º—ã —Å —Ñ—É–Ω–∫—Ü–∏—è–º–∏:
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
    - –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π
    - –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ —Å–±–æ–µ–≤
    - –ú–∏–≥—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É –≤–µ—Ä—Å–∏—è–º–∏
    """
    
    def __init__(self, 
                 base_dir: str = "ai_learning_data",
                 backup_interval_hours: int = 6,
                 max_backups: int = 10):
        self.base_dir = base_dir
        self.backup_interval_hours = backup_interval_hours
        self.max_backups = max_backups
        
        # –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
        self.state_file = os.path.join(base_dir, "ai_regulator_state.json")
        self.pattern_file = os.path.join(base_dir, "pattern_effectiveness.json")
        self.backup_dir = os.path.join(base_dir, "backups")
        self.migration_log = os.path.join(base_dir, "migration_log.json")
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        self._ensure_directories()
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        self.auto_save_enabled = True
        self.last_backup_time = 0.0
        self.save_queue = asyncio.Queue()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏
        self._background_tasks: List[asyncio.Task] = []
        self._start_background_tasks_safe()
        
        logger.info("üíæ AI State Manager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        logger.info("  üìÅ –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: %s", self.base_dir)
        logger.info("  üîÑ –ò–Ω—Ç–µ—Ä–≤–∞–ª —Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–∏—è: %d —á–∞—Å–æ–≤", self.backup_interval_hours)
    
    def _ensure_directories(self):
        """–°–æ–∑–¥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        directories = [
            self.base_dir,
            self.backup_dir,
            os.path.join(self.base_dir, "symbol_params"),
            os.path.join(self.base_dir, "exports"),
            os.path.join(self.base_dir, "logs")
        ]
        
        for directory in directories:
            os.makedirs(directory, exist_ok=True)
    
    async def start_background_tasks(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Ñ–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏"""
        if self._background_tasks:
            return  # –£–∂–µ –∑–∞–ø—É—â–µ–Ω—ã
        
        # –ó–∞–¥–∞—á–∞ –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        save_task = asyncio.create_task(self._auto_save_worker())
        self._background_tasks.append(save_task)
        
        # –ó–∞–¥–∞—á–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π
        backup_task = asyncio.create_task(self._backup_worker())
        self._background_tasks.append(backup_task)
        
        # –ó–∞–¥–∞—á–∞ –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤
        cleanup_task = asyncio.create_task(self._cleanup_worker())
        self._background_tasks.append(cleanup_task)
        
        logger.info("üöÄ –ó–∞–ø—É—â–µ–Ω—ã —Ñ–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ State Manager")
    
    def _start_background_tasks_safe(self):
        """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –∑–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π event loop"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∑–∞–ø—É—â–µ–Ω–Ω—ã–π event loop
            loop = asyncio.get_running_loop()
            # –ï—Å–ª–∏ –µ—Å—Ç—å, —Å–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –≤ —Ç–µ–∫—É—â–µ–º loop
            if self.auto_save_enabled:
                save_task = asyncio.create_task(self._auto_save_worker())
                self._background_tasks.append(save_task)
            
            backup_task = asyncio.create_task(self._backup_worker())
            self._background_tasks.append(backup_task)
            
            cleanup_task = asyncio.create_task(self._cleanup_worker())
            self._background_tasks.append(cleanup_task)
            
            logger.info("üîÑ –§–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ –∑–∞–ø—É—â–µ–Ω—ã –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–º event loop")
            
        except RuntimeError:
            # –ù–µ—Ç –∑–∞–ø—É—â–µ–Ω–Ω–æ–≥–æ event loop, –∑–∞–ø—É—Å–∫–∞–µ–º –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
            import threading
            
            def run_background_tasks():
                try:
                    new_loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(new_loop)
                    
                    if self.auto_save_enabled:
                        save_task = new_loop.create_task(self._auto_save_worker())
                        self._background_tasks.append(save_task)
                    
                    backup_task = new_loop.create_task(self._backup_worker())
                    self._background_tasks.append(backup_task)
                    
                    cleanup_task = new_loop.create_task(self._cleanup_worker())
                    self._background_tasks.append(cleanup_task)
                    
                    logger.info("üîÑ –§–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ –∑–∞–ø—É—â–µ–Ω—ã –≤ –Ω–æ–≤–æ–º event loop")
                    new_loop.run_forever()
                    
                except Exception as e:
                    logger.error("‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á: %s", e)
            
            thread = threading.Thread(target=run_background_tasks, daemon=True)
            thread.start()
            logger.info("üîÑ –§–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ –∑–∞–ø—É—â–µ–Ω—ã –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ")
    
    async def stop_background_tasks(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ñ–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏"""
        for task in self._background_tasks:
            task.cancel()
        
        if self._background_tasks:
            await asyncio.gather(*self._background_tasks, return_exceptions=True)
        
        self._background_tasks.clear()
        logger.info("üõë –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã —Ñ–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ State Manager")
    
    async def _auto_save_worker(self):
        """–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è"""
        try:
            while True:
                # –ñ–¥–µ–º –∑–∞–¥–∞—á–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑ –æ—á–µ—Ä–µ–¥–∏
                save_data = await asyncio.wait_for(self.save_queue.get(), timeout=300)  # 5 –º–∏–Ω—É—Ç —Ç–∞–π–º–∞—É—Ç
                
                try:
                    await self._perform_save(save_data)
                    self.save_queue.task_done()
                except Exception as e:
                    logger.error("‚ùå –û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: %s", e)
        
        except asyncio.CancelledError:
            logger.debug("üõë Auto-save worker –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        except Exception as e:
            logger.error("‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ auto-save worker: %s", e)
    
    async def _backup_worker(self):
        """–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π"""
        try:
            while True:
                await asyncio.sleep(3600)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π —á–∞—Å
                
                current_time = time.time()
                time_since_backup = (current_time - self.last_backup_time) / 3600
                
                if time_since_backup >= self.backup_interval_hours:
                    await self.create_backup()
        
        except asyncio.CancelledError:
            logger.debug("üõë Backup worker –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        except Exception as e:
            logger.error("‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ backup worker: %s", e)
    
    async def _cleanup_worker(self):
        """–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        try:
            while True:
                await asyncio.sleep(24 * 3600)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑ –≤ –¥–µ–Ω—å
                await self.cleanup_old_files()
        
        except asyncio.CancelledError:
            logger.debug("üõë Cleanup worker –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        except Exception as e:
            logger.error("‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ cleanup worker: %s", e)
    
    async def save_state_async(self, 
                              regulator_state: Dict[str, Any],
                              pattern_data: Optional[Dict[str, Any]] = None,
                              priority: str = "normal"):
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        
        Args:
            regulator_state: –°–æ—Å—Ç–æ—è–Ω–∏–µ —Ä–µ–≥—É–ª—è—Ç–æ—Ä–∞
            pattern_data: –î–∞–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            priority: –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è ("high", "normal", "low")
        """
        save_data = {
            "regulator_state": regulator_state,
            "pattern_data": pattern_data,
            "priority": priority,
            "timestamp": time.time()
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ—á–µ—Ä–µ–¥—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        await self.save_queue.put(save_data)
        
        logger.debug("üíæ –î–æ–±–∞–≤–ª–µ–Ω–æ –≤ –æ—á–µ—Ä–µ–¥—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: %s)", priority)
    
    async def _perform_save(self, save_data: Dict[str, Any]):
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ"""
        try:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ä–µ–≥—É–ª—è—Ç–æ—Ä–∞
            if save_data["regulator_state"]:
                await self._save_json_file(self.state_file, save_data["regulator_state"])
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            if save_data["pattern_data"]:
                await self._save_json_file(self.pattern_file, save_data["pattern_data"])
            
            logger.debug("‚úÖ –°–æ—Å—Ç–æ—è–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ")
        
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è: %s", e)
            raise
    
    async def _save_json_file(self, file_path: str, data: Dict[str, Any]):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ JSON —Ñ–∞–π–ª–∞"""
        temp_file = file_path + ".tmp"
        
        try:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            with open(temp_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            
            # –ê—Ç–æ–º–∞—Ä–Ω–æ –ø–µ—Ä–µ–º–µ—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            shutil.move(temp_file, file_path)
        
        except Exception as e:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –ø—Ä–∏ –æ—à–∏–±–∫–µ
            if os.path.exists(temp_file):
                os.remove(temp_file)
            raise e
    
    async def load_state(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã"""
        state_data = {}
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ä–µ–≥—É–ª—è—Ç–æ—Ä–∞
            if os.path.exists(self.state_file):
                with open(self.state_file, 'r', encoding='utf-8') as f:
                    state_data["regulator"] = json.load(f)
                logger.debug("üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ä–µ–≥—É–ª—è—Ç–æ—Ä–∞")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            if os.path.exists(self.pattern_file):
                with open(self.pattern_file, 'r', encoding='utf-8') as f:
                    state_data["patterns"] = json.load(f)
                logger.debug("üìä –ó–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤")
            
            return state_data
        
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è: %s", e)
            
            # –ü—ã—Ç–∞–µ–º—Å—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏
            backup_state = await self.restore_from_backup()
            if backup_state:
                logger.info("‚úÖ –°–æ—Å—Ç–æ—è–Ω–∏–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏")
                return backup_state
            
            return {}
    
    async def create_backup(self) -> bool:
        """–°–æ–∑–¥–∞–µ—Ç —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è"""
        try:
            timestamp = get_utc_now().strftime("%Y%m%d_%H%M%S")
            backup_subdir = os.path.join(self.backup_dir, f"backup_{timestamp}")
            os.makedirs(backup_subdir, exist_ok=True)
            
            files_backed_up = 0
            
            # –ö–æ–ø–∏—Ä—É–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–π–ª—ã —Å–æ—Å—Ç–æ—è–Ω–∏—è
            for source_file in [self.state_file, self.pattern_file]:
                if os.path.exists(source_file):
                    filename = os.path.basename(source_file)
                    backup_file = os.path.join(backup_subdir, filename)
                    shutil.copy2(source_file, backup_file)
                    files_backed_up += 1
            
            # –ö–æ–ø–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∏–º–≤–æ–ª–æ–≤
            symbol_params_dir = os.path.join(self.base_dir, "symbol_params")
            if os.path.exists(symbol_params_dir):
                backup_symbol_dir = os.path.join(backup_subdir, "symbol_params")
                shutil.copytree(symbol_params_dir, backup_symbol_dir, dirs_exist_ok=True)
            
            # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏
            metadata = {
                "timestamp": time.time(),
                "datetime": timestamp,
                "files_count": files_backed_up,
                "backup_size_mb": self._get_directory_size(backup_subdir) / (1024 * 1024)
            }
            
            metadata_file = os.path.join(backup_subdir, "backup_metadata.json")
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2)
            
            self.last_backup_time = time.time()
            
            logger.info("üíæ –°–æ–∑–¥–∞–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: %s (—Ñ–∞–π–ª–æ–≤: %d)", timestamp, files_backed_up)
            
            # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏
            await self._cleanup_old_backups()
            
            return True
        
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏: %s", e)
            return False
    
    async def restore_from_backup(self, backup_name: Optional[str] = None) -> Optional[Dict[str, Any]]:
        """
        –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏
        
        Args:
            backup_name: –ò–º—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ –∏–ª–∏ None –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–µ–π
        """
        try:
            if backup_name:
                backup_path = os.path.join(self.backup_dir, backup_name)
            else:
                # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é
                backup_path = await self._find_latest_backup()
            
            if not backup_path or not os.path.exists(backup_path):
                logger.warning("‚ö†Ô∏è –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                return None
            
            restored_state = {}
            
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–∞–π–ª—ã —Å–æ—Å—Ç–æ—è–Ω–∏—è
            for filename in ["ai_regulator_state.json", "pattern_effectiveness.json"]:
                backup_file = os.path.join(backup_path, filename)
                if os.path.exists(backup_file):
                    with open(backup_file, 'r', encoding='utf-8') as f:
                        if filename == "ai_regulator_state.json":
                            restored_state["regulator"] = json.load(f)
                        else:
                            restored_state["patterns"] = json.load(f)
            
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∏–º–≤–æ–ª–æ–≤
            backup_symbol_dir = os.path.join(backup_path, "symbol_params")
            if os.path.exists(backup_symbol_dir):
                target_symbol_dir = os.path.join(self.base_dir, "symbol_params")
                if os.path.exists(target_symbol_dir):
                    shutil.rmtree(target_symbol_dir)
                shutil.copytree(backup_symbol_dir, target_symbol_dir)
            
            logger.info("‚úÖ –°–æ—Å—Ç–æ—è–Ω–∏–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏: %s", os.path.basename(backup_path))
            return restored_state
        
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏: %s", e)
            return None
    
    async def _find_latest_backup(self) -> Optional[str]:
        """–ù–∞—Ö–æ–¥–∏—Ç –ø–æ—Å–ª–µ–¥–Ω—é—é —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é"""
        try:
            if not os.path.exists(self.backup_dir):
                return None
            
            backup_dirs = []
            for item in os.listdir(self.backup_dir):
                backup_path = os.path.join(self.backup_dir, item)
                if os.path.isdir(backup_path) and item.startswith("backup_"):
                    metadata_file = os.path.join(backup_path, "backup_metadata.json")
                    if os.path.exists(metadata_file):
                        with open(metadata_file, 'r', encoding='utf-8') as f:
                            metadata = json.load(f)
                        backup_dirs.append((metadata["timestamp"], backup_path))
            
            if backup_dirs:
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–∑–¥–∞–Ω–∏—è –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π
                backup_dirs.sort(key=lambda x: x[0], reverse=True)
                return backup_dirs[0][1]
            
            return None
        
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π: %s", e)
            return None
    
    async def _cleanup_old_backups(self):
        """–û—á–∏—â–∞–µ—Ç —Å—Ç–∞—Ä—ã–µ —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏"""
        try:
            if not os.path.exists(self.backup_dir):
                return
            
            backup_dirs = []
            for item in os.listdir(self.backup_dir):
                backup_path = os.path.join(self.backup_dir, item)
                if os.path.isdir(backup_path) and item.startswith("backup_"):
                    metadata_file = os.path.join(backup_path, "backup_metadata.json")
                    if os.path.exists(metadata_file):
                        with open(metadata_file, 'r', encoding='utf-8') as f:
                            metadata = json.load(f)
                        backup_dirs.append((metadata["timestamp"], backup_path))
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –∏ —É–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ
            backup_dirs.sort(key=lambda x: x[0], reverse=True)
            
            if len(backup_dirs) > self.max_backups:
                for _, old_backup_path in backup_dirs[self.max_backups:]:
                    shutil.rmtree(old_backup_path)
                    logger.debug("üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ —Å—Ç–∞—Ä–∞—è —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: %s", os.path.basename(old_backup_path))
        
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π: %s", e)
    
    async def cleanup_old_files(self, max_age_days: int = 30):
        """–û—á–∏—â–∞–µ—Ç —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã –∏ –ª–æ–≥–∏"""
        try:
            cutoff_time = time.time() - (max_age_days * 24 * 3600)
            cleaned_files = 0
            
            # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –ª–æ–≥–∏
            logs_dir = os.path.join(self.base_dir, "logs")
            if os.path.exists(logs_dir):
                for filename in os.listdir(logs_dir):
                    file_path = os.path.join(logs_dir, filename)
                    if os.path.isfile(file_path):
                        file_mtime = os.path.getmtime(file_path)
                        if file_mtime < cutoff_time:
                            os.remove(file_path)
                            cleaned_files += 1
            
            # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ —ç–∫—Å–ø–æ—Ä—Ç—ã
            exports_dir = os.path.join(self.base_dir, "exports")
            if os.path.exists(exports_dir):
                for filename in os.listdir(exports_dir):
                    file_path = os.path.join(exports_dir, filename)
                    if os.path.isfile(file_path):
                        file_mtime = os.path.getmtime(file_path)
                        if file_mtime < cutoff_time:
                            os.remove(file_path)
                            cleaned_files += 1
            
            if cleaned_files > 0:
                logger.info("üßπ –û—á–∏—â–µ–Ω–æ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤: %d (—Å—Ç–∞—Ä—à–µ %d –¥–Ω–µ–π)", cleaned_files, max_age_days)
        
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤: %s", e)
    
    def _get_directory_size(self, directory: str) -> int:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –≤ –±–∞–π—Ç–∞—Ö"""
        total_size = 0
        try:
            for dirpath, dirnames, filenames in os.walk(directory):
                for filename in filenames:
                    file_path = os.path.join(dirpath, filename)
                    if os.path.exists(file_path):
                        total_size += os.path.getsize(file_path)
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ —Ä–∞–∑–º–µ—Ä–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: %s", e)
        
        return total_size
    
    async def export_data(self, export_format: str = "json") -> Optional[str]:
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ AI-—Å–∏—Å—Ç–µ–º—ã
        
        Args:
            export_format: –§–æ—Ä–º–∞—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞ ("json", "csv")
        
        Returns:
            –ü—É—Ç—å –∫ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        try:
            timestamp = get_utc_now().strftime("%Y%m%d_%H%M%S")
            export_filename = f"ai_data_export_{timestamp}.{export_format}"
            export_path = os.path.join(self.base_dir, "exports", export_filename)
            
            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
            export_data = await self.load_state()
            export_data["export_metadata"] = {
                "timestamp": time.time(),
                "datetime": timestamp,
                "format": export_format,
                "version": "1.0"
            }
            
            if export_format == "json":
                with open(export_path, 'w', encoding='utf-8') as f:
                    json.dump(export_data, f, indent=2, ensure_ascii=False)
            else:
                logger.warning("‚ö†Ô∏è –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞: %s", export_format)
                return None
            
            logger.info("üì§ –î–∞–Ω–Ω—ã–µ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã: %s", export_filename)
            return export_path
        
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –¥–∞–Ω–Ω—ã—Ö: %s", e)
            return None
    
    async def get_system_health(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ —Å–∏—Å—Ç–µ–º—ã"""
        try:
            health_info = {
                "timestamp": time.time(),
                "directories": {},
                "files": {},
                "backups": {},
                "disk_usage": {}
            }
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            directories = [self.base_dir, self.backup_dir]
            for directory in directories:
                health_info["directories"][directory] = {
                    "exists": os.path.exists(directory),
                    "writable": os.access(directory, os.W_OK) if os.path.exists(directory) else False,
                    "size_mb": self._get_directory_size(directory) / (1024 * 1024) if os.path.exists(directory) else 0
                }
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–π–ª—ã
            files = [self.state_file, self.pattern_file]
            for file_path in files:
                health_info["files"][os.path.basename(file_path)] = {
                    "exists": os.path.exists(file_path),
                    "size_kb": os.path.getsize(file_path) / 1024 if os.path.exists(file_path) else 0,
                    "last_modified": os.path.getmtime(file_path) if os.path.exists(file_path) else 0
                }
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏—è—Ö
            if os.path.exists(self.backup_dir):
                backup_count = len([d for d in os.listdir(self.backup_dir) 
                                  if os.path.isdir(os.path.join(self.backup_dir, d)) and d.startswith("backup_")])
                health_info["backups"] = {
                    "count": backup_count,
                    "last_backup_age_hours": (time.time() - self.last_backup_time) / 3600,
                    "total_size_mb": health_info["directories"][self.backup_dir]["size_mb"]
                }
            
            return health_info
        
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã: %s", e)
            return {"error": str(e)}


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è
state_manager: Optional[AIStateManager] = None


def get_state_manager() -> AIStateManager:
    """–ü–æ–ª—É—á–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è"""
    global state_manager
    
    if state_manager is None:
        state_manager = AIStateManager()
    
    return state_manager
