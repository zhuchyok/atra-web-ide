#!/usr/bin/env python3
"""
ü§ñ –ò–ò-–û–ü–¢–ò–ú–ò–ó–ê–¢–û–† TAKE PROFIT –£–†–û–í–ù–ï–ô
–ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è TP –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
"""

import json
import logging
import os
from datetime import datetime
from src.shared.utils.datetime_utils import get_utc_now
from typing import Dict, List, Tuple, Any

import numpy as np
import pandas as pd

logger = logging.getLogger(__name__)

class AITakeProfitOptimizer:
    """–ò–ò-—Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ Take Profit —É—Ä–æ–≤–Ω–µ–π"""

    def __init__(self, data_dir: str = "ai_tp_data"):
        self.data_dir = data_dir
        os.makedirs(data_dir, exist_ok=True)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ TP
        self.tp_effectiveness = self._load_tp_effectiveness()

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è ML –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        self.all_patterns = self._load_all_patterns()

        # –ö—ç—à –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ –∫ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        self.pattern_cache = {}
        self.cache_timestamp = None

        # –í–µ—Å–∞ –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤
        self.factor_weights = {
            'volatility': 0.3,      # –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
            'trend_strength': 0.25, # –°–∏–ª–∞ —Ç—Ä–µ–Ω–¥–∞
            'volume_profile': 0.2,  # –ü—Ä–æ—Ñ–∏–ª—å –æ–±—ä–µ–º–∞
            'support_resistance': 0.15, # –£—Ä–æ–≤–Ω–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏/—Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è
            'market_sentiment': 0.1,  # –†—ã–Ω–æ—á–Ω—ã–π —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç
            'pattern_similarity': 0.35  # –ü–æ—Ö–æ–∂–µ—Å—Ç—å –Ω–∞ —É—Å–ø–µ—à–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        }

        logger.info("ü§ñ –ò–ò-–æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä TP –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        if self.all_patterns:
            logger.info("üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ %d –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è ML –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏", len(self.all_patterns))

    def _load_tp_effectiveness(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫—É—é —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å TP –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–∏–º–≤–æ–ª–∞"""
        file_path = os.path.join(self.data_dir, "tp_effectiveness.json")

        if os.path.exists(file_path):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.error("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ TP: %s", e)

        return {}

    def _load_all_patterns(self) -> List[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è ML –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        try:
            # –ü—Ä–æ–±—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø—É—Ç–µ–π
            paths = [
                "ai_learning_data/trading_patterns.json",
                "../ai_learning_data/trading_patterns.json",
                "trading_patterns.json"
            ]

            for path in paths:
                if os.path.exists(path):
                    with open(path, 'r', encoding='utf-8') as f:
                        patterns = json.load(f)
                        logger.info("üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ %d –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏–∑ %s", len(patterns), path)
                        return patterns

            logger.warning("‚ö†Ô∏è –§–∞–π–ª trading_patterns.json –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
            return []

        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: %s", e)
            return []

    def _save_tp_effectiveness(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å TP"""
        file_path = os.path.join(self.data_dir, "tp_effectiveness.json")

        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(self.tp_effectiveness, f, indent=2, ensure_ascii=False)
            logger.debug("üíæ –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å TP —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ TP: %s", e)

    def calculate_volatility_factor(self, df: pd.DataFrame, current_index: int) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ñ–∞–∫—Ç–æ—Ä –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏"""
        try:
            if current_index < 20:
                return 1.0

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20 —Å–≤–µ—á–µ–π
            closes = df["close"].iloc[current_index - 20:current_index]
            volatility = closes.std() / closes.mean()

            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å (0.01-0.1 -> 0.5-2.0)
            volatility_factor = np.clip(0.5 + volatility * 15, 0.5, 2.0)

            logger.debug("üìä –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å: %.4f, —Ñ–∞–∫—Ç–æ—Ä: %.2f", volatility, volatility_factor)
            return volatility_factor

        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏: %s", e)
            return 1.0

    def calculate_trend_strength(self, df: pd.DataFrame, current_index: int) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å–∏–ª—É —Ç—Ä–µ–Ω–¥–∞"""
        try:
            if current_index < 50:
                return 1.0

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º EMA
            if 'ema_7' in df.columns and 'ema_25' in df.columns:
                ema_7 = df['ema_7'].iloc[current_index]
                ema_25 = df['ema_25'].iloc[current_index]
                current_price = df['close'].iloc[current_index]

                # –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É EMA –∏ —Ü–µ–Ω–æ–π
                ema_distance = abs(ema_7 - ema_25) / current_price
                price_ema_distance = abs(current_price - ema_7) / current_price

                # –°–∏–ª–∞ —Ç—Ä–µ–Ω–¥–∞ (—á–µ–º –±–æ–ª—å—à–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ, —Ç–µ–º —Å–∏–ª—å–Ω–µ–µ —Ç—Ä–µ–Ω–¥)
                trend_strength = np.clip(1 + ema_distance * 50 + price_ema_distance * 100, 0.5, 2.5)

                logger.debug("üìà –°–∏–ª–∞ —Ç—Ä–µ–Ω–¥–∞: %.2f", trend_strength)
                return trend_strength
            else:
                return 1.0

        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ —Å–∏–ª—ã —Ç—Ä–µ–Ω–¥–∞: %s", e)
            return 1.0

    def calculate_volume_profile(self, df: pd.DataFrame, current_index: int) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –ø—Ä–æ—Ñ–∏–ª—å –æ–±—ä–µ–º–∞"""
        try:
            if current_index < 20:
                return 1.0

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–±—ä–µ–º –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20 —Å–≤–µ—á–µ–π
            volumes = df["volume"].iloc[current_index - 20:current_index]
            current_volume = df["volume"].iloc[current_index]

            avg_volume = volumes.mean()
            volume_ratio = current_volume / avg_volume if avg_volume > 0 else 1.0

            # –í—ã—Å–æ–∫–∏–π –æ–±—ä–µ–º —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è TP
            volume_factor = np.clip(0.7 + volume_ratio * 0.6, 0.7, 1.8)

            logger.debug("üìä –û–±—ä–µ–º: %.2fx, —Ñ–∞–∫—Ç–æ—Ä: %.2f", volume_ratio, volume_factor)
            return volume_factor

        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –æ–±—ä–µ–º–∞: %s", e)
            return 1.0

    def calculate_support_resistance_factor(self, df: pd.DataFrame, current_index: int, side: str) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ñ–∞–∫—Ç–æ—Ä –ø–æ–¥–¥–µ—Ä–∂–∫–∏/—Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è"""
        try:
            if current_index < 50:
                return 1.0

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —É—Ä–æ–≤–Ω–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 50 —Å–≤–µ—á–µ–π
            highs = df["high"].iloc[current_index - 50:current_index]
            lows = df["low"].iloc[current_index - 50:current_index]
            current_price = df["close"].iloc[current_index]

            if side.lower() == "long":
                # –î–ª—è LONG: —Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏–µ (–º–∞–∫—Å–∏–º—É–º—ã)
                resistance_levels = highs.nlargest(5).values
                closest_resistance = min(resistance_levels, key=lambda x: abs(x - current_price))

                # –ï—Å–ª–∏ —Ü–µ–Ω–∞ –±–ª–∏–∑–∫–æ –∫ —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—é, —É–º–µ–Ω—å—à–∞–µ–º TP
                distance_to_resistance = (closest_resistance - current_price) / current_price
                resistance_factor = np.clip(0.8 + distance_to_resistance * 2, 0.8, 1.3)

            else:  # short
                # –î–ª—è SHORT: —Å–º–æ—Ç—Ä–∏–º –Ω–∞ –ø–æ–¥–¥–µ—Ä–∂–∫—É (–º–∏–Ω–∏–º—É–º—ã)
                support_levels = lows.nsmallest(5).values
                closest_support = min(support_levels, key=lambda x: abs(x - current_price))

                # –ï—Å–ª–∏ —Ü–µ–Ω–∞ –±–ª–∏–∑–∫–æ –∫ –ø–æ–¥–¥–µ—Ä–∂–∫–µ, —É–º–µ–Ω—å—à–∞–µ–º TP
                distance_to_support = (current_price - closest_support) / current_price
                support_factor = np.clip(0.8 + distance_to_support * 2, 0.8, 1.3)

                resistance_factor = support_factor

            logger.debug("üéØ –§–∞–∫—Ç–æ—Ä S/R: %.2f", resistance_factor)
            return resistance_factor

        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ S/R: %s", e)
            return 1.0

    def calculate_market_sentiment_factor(self, df: pd.DataFrame, current_index: int) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ñ–∞–∫—Ç–æ—Ä —Ä—ã–Ω–æ—á–Ω–æ–≥–æ —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç–∞"""
        try:
            sentiment_factors = []

            # RSI —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç
            if 'rsi' in df.columns:
                rsi = df['rsi'].iloc[current_index]
                if rsi > 70:  # –ü–µ—Ä–µ–∫—É–ø–ª–µ–Ω–Ω–æ—Å—Ç—å
                    sentiment_factors.append(0.8)
                elif rsi < 30:  # –ü–µ—Ä–µ–ø—Ä–æ–¥–∞–Ω–Ω–æ—Å—Ç—å
                    sentiment_factors.append(1.2)
                else:
                    sentiment_factors.append(1.0)

            # ADX —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç
            if 'adx' in df.columns:
                adx = df['adx'].iloc[current_index]
                if adx > 30:  # –°–∏–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–¥
                    sentiment_factors.append(1.2)
                elif adx < 20:  # –°–ª–∞–±—ã–π —Ç—Ä–µ–Ω–¥
                    sentiment_factors.append(0.9)
                else:
                    sentiment_factors.append(1.0)

            # Bollinger Bands —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç
            if 'bb_position' in df.columns:
                bb_pos = df['bb_position'].iloc[current_index]
                if bb_pos == 'near_upper':  # –ë–ª–∏–∑–∫–æ –∫ –≤–µ—Ä—Ö–Ω–µ–π –ø–æ–ª–æ—Å–µ
                    sentiment_factors.append(0.9)
                elif bb_pos == 'near_lower':  # –ë–ª–∏–∑–∫–æ –∫ –Ω–∏–∂–Ω–µ–π –ø–æ–ª–æ—Å–µ
                    sentiment_factors.append(1.1)
                else:
                    sentiment_factors.append(1.0)

            # –°—Ä–µ–¥–Ω–∏–π —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç
            if sentiment_factors:
                sentiment_factor = np.mean(sentiment_factors)
            else:
                sentiment_factor = 1.0

            logger.debug("üòä –°–µ–Ω—Ç–∏–º–µ–Ω—Ç: %.2f", sentiment_factor)
            return sentiment_factor

        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç–∞: %s", e)
            return 1.0

    def get_symbol_effectiveness(self, symbol: str, side: str) -> Dict[str, float]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫—É—é —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å TP –¥–ª—è —Å–∏–º–≤–æ–ª–∞"""
        key = f"{symbol}_{side}"

        if key in self.tp_effectiveness:
            return self.tp_effectiveness[key]

        # –î–µ—Ñ–æ–ª—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –Ω–æ–≤—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
        return {
            'tp1_success_rate': 0.6,
            'tp2_success_rate': 0.4,
            'avg_tp1_profit': 1.5,
            'avg_tp2_profit': 3.2,
            'optimal_tp1': 1.5,
            'optimal_tp2': 3.0
        }

    def update_symbol_effectiveness(self, symbol: str, side: str, tp1_hit: bool,
                                  tp2_hit: bool, profit_pct: float):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å TP –¥–ª—è —Å–∏–º–≤–æ–ª–∞"""
        key = f"{symbol}_{side}"

        if key not in self.tp_effectiveness:
            self.tp_effectiveness[key] = {
                'tp1_hits': 0,
                'tp1_misses': 0,
                'tp2_hits': 0,
                'tp2_misses': 0,
                'total_profits': [],
                'optimal_tp1': 1.5,
                'optimal_tp2': 3.0
            }

        data = self.tp_effectiveness[key]

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        if tp1_hit:
            data['tp1_hits'] += 1
        else:
            data['tp1_misses'] += 1

        if tp2_hit:
            data['tp2_hits'] += 1
        else:
            data['tp2_misses'] += 1

        data['total_profits'].append(profit_pct)

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø–æ—Å–ª–µ–¥–Ω–∏–º–∏ 100 —Å–¥–µ–ª–∫–∞–º–∏
        if len(data['total_profits']) > 100:
            data['total_profits'] = data['total_profits'][-100:]

        # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ TP
        self._recalculate_optimal_tp(data)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
        self._save_tp_effectiveness()

        logger.info("üìä –û–±–Ω–æ–≤–ª–µ–Ω–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å %s %s: TP1=%s, TP2=%s, –ø—Ä–∏–±—ã–ª—å=%.2f%%",
                    symbol, side, tp1_hit, tp2_hit, profit_pct)

    def _recalculate_optimal_tp(self, data: Dict[str, Any]):
        """–ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ TP –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        if len(data['total_profits']) < 5:
            return

        profits = np.array(data['total_profits'])

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–±—ã–ª–µ–π
        tp1_profits = profits[profits <= 2.5]  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º TP1 –≤ —Ä–∞–π–æ–Ω–µ 1.5-2.5%
        tp2_profits = profits[profits > 2.5]   # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º TP2 > 2.5%

        # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ TP –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ–¥–∏–∞–Ω—ã —É—Å–ø–µ—à–Ω—ã—Ö —Å–¥–µ–ª–æ–∫
        if len(tp1_profits) > 0:
            data['optimal_tp1'] = float(np.percentile(tp1_profits, 75))

        if len(tp2_profits) > 0:
            data['optimal_tp2'] = float(np.percentile(tp2_profits, 75))

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º success rate
        total_tp1 = data['tp1_hits'] + data['tp1_misses']
        total_tp2 = data['tp2_hits'] + data['tp2_misses']

        data['tp1_success_rate'] = data['tp1_hits'] / total_tp1 if total_tp1 > 0 else 0.6
        data['tp2_success_rate'] = data['tp2_hits'] / total_tp2 if total_tp2 > 0 else 0.4

    def find_similar_patterns(self, symbol: str, side: str, df: pd.DataFrame,
                              current_index: int, top_n: int = 1000) -> List[Dict[str, Any]]:
        """
        –ù–∞—Ö–æ–¥–∏—Ç –ø–æ—Ö–æ–∂–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤

        Args:
            symbol: –°–∏–º–≤–æ–ª
            side: LONG –∏–ª–∏ SHORT
            df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            current_index: –¢–µ–∫—É—â–∏–π –∏–Ω–¥–µ–∫—Å
            top_n: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª—É—á—à–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞

        Returns:
            –°–ø–∏—Å–æ–∫ –ø–æ—Ö–æ–∂–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Å –æ—Ü–µ–Ω–∫–æ–π —Å—Ö–æ–∂–µ—Å—Ç–∏
        """
        if not self.all_patterns:
            return []

        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—É—â–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
            current_indicators = self._extract_current_indicators(df, current_index)
            if not current_indicators:
                return []

            similar_patterns = []

            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ —Å–∏–º–≤–æ–ª—É –∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—é
            relevant_patterns = [
                p for p in self.all_patterns
                if p.get('symbol') == symbol and p.get('signal_type', '').upper() == side.upper()
            ]

            # –ï—Å–ª–∏ –Ω–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è —ç—Ç–æ–≥–æ —Å–∏–º–≤–æ–ª–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —ç—Ç–æ–≥–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
            if not relevant_patterns:
                relevant_patterns = [
                    p for p in self.all_patterns
                    if p.get('signal_type', '').upper() == side.upper()
                ]

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞
            for pattern in relevant_patterns:
                similarity_score = self._calculate_pattern_similarity(
                    current_indicators,
                    pattern.get('indicators', {})
                )

                if similarity_score > 0.3:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏
                    similar_patterns.append({
                        'pattern': pattern,
                        'similarity': similarity_score,
                        'profit_pct': pattern.get('profit_pct', 0),
                        'result': pattern.get('result', 'NEUTRAL')
                    })

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å—Ö–æ–∂–µ—Å—Ç–∏ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É
            similar_patterns.sort(key=lambda x: (x['similarity'], x['profit_pct']), reverse=True)

            return similar_patterns[:top_n]

        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: %s", e)
            return []

    def _extract_current_indicators(self, df: pd.DataFrame, current_index: int) -> Dict[str, float]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—É—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤"""
        try:
            if current_index >= len(df):
                return {}

            indicators = {}
            row = df.iloc[current_index]

            # –°–ø–∏—Å–æ–∫ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            indicator_keys = ['rsi', 'ema_7', 'ema_25', 'macd', 'bb_width', 'volume']

            for key in indicator_keys:
                if key in df.columns:
                    value = row[key]
                    if pd.notna(value) and np.isfinite(value):
                        indicators[key] = float(value)

            return indicators

        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤: %s", e)
            return {}

    def _calculate_pattern_similarity(self, indicators1: Dict[str, float],
                                     indicators2: Dict[str, float]) -> float:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç—å –º–µ–∂–¥—É –¥–≤—É–º—è –Ω–∞–±–æ—Ä–∞–º–∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤

        Returns:
            –û—Ü–µ–Ω–∫–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏ –æ—Ç 0 –¥–æ 1
        """
        if not indicators1 or not indicators2:
            return 0.0

        try:
            similarities = []
            weights = {'rsi': 0.3, 'ema_7': 0.2, 'ema_25': 0.2, 'macd': 0.15, 'bb_width': 0.1, 'volume': 0.05}

            for key, weight in weights.items():
                if key in indicators1 and key in indicators2:
                    val1 = indicators1[key]
                    val2 = indicators2[key]

                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –≤ –¥–∏–∞–ø–∞–∑–æ–Ω 0-1
                    if key == 'rsi':
                        val1_norm = val1 / 100.0
                        val2_norm = val2 / 100.0
                    elif key == 'volume':
                        # –î–ª—è –æ–±—ä–µ–º–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
                        val1_norm = min(val1 / 1000000.0, 1.0)
                        val2_norm = min(val2 / 1000000.0, 1.0)
                    else:
                        # –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–æ —Å—Ä–µ–¥–Ω–µ–º—É –∑–Ω–∞—á–µ–Ω–∏—é
                        val1_norm = min(abs(val1), 100.0) / 100.0
                        val2_norm = min(abs(val2), 100.0) / 100.0

                    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å (—á–µ–º –±–ª–∏–∂–µ –∑–Ω–∞—á–µ–Ω–∏—è, —Ç–µ–º –≤—ã—à–µ —Å—Ö–æ–∂–µ—Å—Ç—å)
                    similarity = 1.0 - abs(val1_norm - val2_norm)
                    similarities.append(similarity * weight)

            return sum(similarities) if similarities else 0.0

        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏: %s", e)
            return 0.0

    def calculate_optimal_tp_from_patterns(self, similar_patterns: List[Dict[str, Any]]) -> Tuple[float, float]:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ TP –Ω–∞ –æ—Å–Ω–æ–≤–µ —É—Å–ø–µ—à–Ω—ã—Ö –ø–æ—Ö–æ–∂–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤

        Args:
            similar_patterns: –°–ø–∏—Å–æ–∫ –ø–æ—Ö–æ–∂–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Å –æ—Ü–µ–Ω–∫–∞–º–∏ —Å—Ö–æ–∂–µ—Å—Ç–∏

        Returns:
            Tuple[optimal_tp1, optimal_tp2] –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
        """
        if not similar_patterns:
            return 2.0, 4.0  # –î–µ—Ñ–æ–ª—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è

        try:
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —É—Å–ø–µ—à–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            successful_patterns = [
                p for p in similar_patterns
                if p.get('result') == 'WIN' and p.get('profit_pct', 0) > 0
            ]

            if not successful_patterns:
                # –ï—Å–ª–∏ –Ω–µ—Ç —É—Å–ø–µ—à–Ω—ã—Ö, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ
                successful_patterns = similar_patterns

            # –ë–µ—Ä–µ–º —Ç–æ–ø-100 —Å–∞–º—ã—Ö –ø–æ—Ö–æ–∂–∏—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            top_patterns = successful_patterns[:100]

            # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ TP1 –∏ TP2
            tp1_profits = []
            tp2_profits = []

            for p in top_patterns:
                profit = p.get('profit_pct', 0)
                if 0 < profit <= 3.0:
                    tp1_profits.append(profit)
                elif profit > 3.0:
                    tp2_profits.append(profit)

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ TP –Ω–∞ –æ—Å–Ω–æ–≤–µ 75-–≥–æ –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—è
            if tp1_profits:
                optimal_tp1 = float(np.percentile(tp1_profits, 75))
            else:
                optimal_tp1 = 2.0

            if tp2_profits:
                optimal_tp2 = float(np.percentile(tp2_profits, 75))
            else:
                optimal_tp2 = 4.0

            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑—É–º–Ω—ã–º–∏ –ø—Ä–µ–¥–µ–ª–∞–º–∏
            optimal_tp1 = np.clip(optimal_tp1, 0.5, 5.0)
            optimal_tp2 = np.clip(optimal_tp2, 1.0, 8.0)

            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ TP2 > TP1
            if optimal_tp2 <= optimal_tp1:
                optimal_tp2 = optimal_tp1 * 1.5

            logger.debug("üéØ ML-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: TP1=%.2f%%, TP2=%.2f%% "
                        "(–Ω–∞ –æ—Å–Ω–æ–≤–µ %d –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: %d TP1, %d TP2)",
                        optimal_tp1, optimal_tp2, len(top_patterns),
                        len(tp1_profits), len(tp2_profits))

            return optimal_tp1, optimal_tp2

        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ TP –∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: %s", e)
            return 2.0, 4.0

    def calculate_ai_optimized_tp(self, symbol: str, side: str, df: pd.DataFrame,
                                current_index: int, base_tp1: float = 1.5,
                                base_tp2: float = 3.0) -> Tuple[float, float]:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –ò–ò-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ TP —É—Ä–æ–≤–Ω–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞

        Args:
            symbol: –¢–æ—Ä–≥–æ–≤—ã–π —Å–∏–º–≤–æ–ª
            side: LONG –∏–ª–∏ SHORT
            df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ —Å–≤–µ—á–µ–π
            current_index: –¢–µ–∫—É—â–∏–π –∏–Ω–¥–µ–∫—Å —Å–≤–µ—á–∏
            base_tp1: –ë–∞–∑–æ–≤—ã–π TP1 –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
            base_tp2: –ë–∞–∑–æ–≤—ã–π TP2 –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö

        Returns:
            Tuple[float, float]: –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ TP1 –∏ TP2 –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
        """
        try:
            logger.info("ü§ñ –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ò–ò-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ TP –¥–ª—è %s %s", symbol, side)

            # 1. –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫—É—é —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Å–∏–º–≤–æ–ª–∞
            effectiveness = self.get_symbol_effectiveness(symbol, side)

            # 2. –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤—Å–µ —Ñ–∞–∫—Ç–æ—Ä—ã
            volatility_factor = self.calculate_volatility_factor(df, current_index)
            trend_strength_factor = self.calculate_trend_strength(df, current_index)
            volume_factor = self.calculate_volume_profile(df, current_index)
            sr_factor = self.calculate_support_resistance_factor(df, current_index, side)
            sentiment_factor = self.calculate_market_sentiment_factor(df, current_index)

            # 3. –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–∞–∫—Ç–æ—Ä (–±–∞–∑–æ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã)
            base_combined_factor = (
                volatility_factor * self.factor_weights['volatility'] +
                trend_strength_factor * self.factor_weights['trend_strength'] +
                volume_factor * self.factor_weights['volume_profile'] +
                sr_factor * self.factor_weights['support_resistance'] +
                sentiment_factor * self.factor_weights['market_sentiment']
            )

            # 4. –£—á–∏—Ç—ã–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫—É—é —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
            historical_tp1 = effectiveness.get('optimal_tp1', base_tp1)
            historical_tp2 = effectiveness.get('optimal_tp2', base_tp2)

            # 5. üöÄ –ù–û–í–û–ï: ML-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Ö–æ–∂–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            pattern_tp1, pattern_tp2 = base_tp1, base_tp2
            pattern_confidence = 0.0

            if self.all_patterns:
                try:
                    # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
                    similar_patterns = self.find_similar_patterns(symbol, side, df, current_index, top_n=1000)

                    if similar_patterns:
                        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ TP –∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
                        pattern_tp1, pattern_tp2 = self.calculate_optimal_tp_from_patterns(similar_patterns)

                        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
                        top_10 = similar_patterns[:10]
                        successful_count = sum(1 for p in top_10 if p.get('result') == 'WIN')
                        avg_similarity = np.mean([p['similarity'] for p in top_10])
                        pattern_confidence = (successful_count / 10) * avg_similarity

                        logger.info("üß† ML-–∞–Ω–∞–ª–∏–∑: –Ω–∞–π–¥–µ–Ω–æ %d –ø–æ—Ö–æ–∂–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å=%.2f",
                                    len(similar_patterns), pattern_confidence)
                    else:
                        logger.debug("üìä ML-–∞–Ω–∞–ª–∏–∑: –ø–æ—Ö–æ–∂–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è")
                except Exception as e:
                    logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ ML-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: %s, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã", e)

            # 6. –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞—Å—á–µ—Ç —Å —É—á–µ—Ç–æ–º –≤—Å–µ—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤
            # –ï—Å–ª–∏ –µ—Å—Ç—å ML –¥–∞–Ω–Ω—ã–µ —Å –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö, –∏–Ω–∞—á–µ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥
            if pattern_confidence > 0.5:
                # –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ ML - –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
                ai_tp1 = pattern_tp1 * 0.6 + historical_tp1 * 0.3 + base_tp1 * base_combined_factor * 0.1
                ai_tp2 = pattern_tp2 * 0.6 + historical_tp2 * 0.3 + base_tp2 * base_combined_factor * 0.1
                logger.info("üß† –ò—Å–ø–æ–ª—å–∑—É–µ–º ML-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å=%.2f)", pattern_confidence)
            else:
                # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥
                ai_tp1 = historical_tp1 * 0.7 + base_tp1 * base_combined_factor * 0.3
                ai_tp2 = historical_tp2 * 0.7 + base_tp2 * base_combined_factor * 0.3
                if pattern_confidence > 0:
                    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à—É—é –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫—É –æ—Ç ML
                    ai_tp1 = ai_tp1 * 0.9 + pattern_tp1 * 0.1
                    ai_tp2 = ai_tp2 * 0.9 + pattern_tp2 * 0.1

            # 7. –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑—É–º–Ω—ã–º–∏ –ø—Ä–µ–¥–µ–ª–∞–º–∏
            ai_tp1 = np.clip(ai_tp1, 0.5, 5.0)
            ai_tp2 = np.clip(ai_tp2, 1.0, 8.0)

            # 8. –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ TP2 > TP1
            if ai_tp2 <= ai_tp1:
                ai_tp2 = ai_tp1 * 1.5

            logger.info("üéØ –ò–ò-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ TP –¥–ª—è %s: TP1=%.2f%%, TP2=%.2f%%",
                        symbol, ai_tp1, ai_tp2)
            logger.info("üìä –§–∞–∫—Ç–æ—Ä—ã: –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å=%.2f, —Ç—Ä–µ–Ω–¥=%.2f, –æ–±—ä–µ–º=%.2f, ML —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å=%.2f",
                        volatility_factor, trend_strength_factor, volume_factor, pattern_confidence)

            return ai_tp1, ai_tp2

        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –ò–ò-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö TP: %s", e)
            return base_tp1, base_tp2

    def get_ai_analysis_report(self, symbol: str, side: str, df: pd.DataFrame,
                             current_index: int) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏—è –ø–æ TP"""
        try:
            effectiveness = self.get_symbol_effectiveness(symbol, side)

            volatility_factor = self.calculate_volatility_factor(df, current_index)
            trend_strength_factor = self.calculate_trend_strength(df, current_index)
            volume_factor = self.calculate_volume_profile(df, current_index)
            sr_factor = self.calculate_support_resistance_factor(df, current_index, side)
            sentiment_factor = self.calculate_market_sentiment_factor(df, current_index)

            analysis = {
                'symbol': symbol,
                'side': side,
                'timestamp': get_utc_now().isoformat(),
                'historical_effectiveness': effectiveness,
                'current_factors': {
                    'volatility_factor': volatility_factor,
                    'trend_strength_factor': trend_strength_factor,
                    'volume_factor': volume_factor,
                    'support_resistance_factor': sr_factor,
                    'sentiment_factor': sentiment_factor
                },
                'recommendation': self._generate_tp_recommendation(
                    effectiveness, volatility_factor, trend_strength_factor, volume_factor
                )
            }

            return analysis

        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞: %s", e)
            return {}

    def _generate_tp_recommendation(self, effectiveness: Dict, volatility_factor: float,
                                  trend_strength_factor: float, volume_factor: float) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –ø–æ TP"""
        recommendations = []

        if effectiveness.get('tp1_success_rate', 0.6) > 0.7:
            recommendations.append("‚úÖ TP1 –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—ã—Å–æ–∫—É—é —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å")
        elif effectiveness.get('tp1_success_rate', 0.6) < 0.5:
            recommendations.append("‚ö†Ô∏è TP1 –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∏–∑–∫—É—é —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å")

        if volatility_factor > 1.5:
            recommendations.append("üìà –í—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å - —É–≤–µ–ª–∏—á–∏—Ç—å TP")
        elif volatility_factor < 0.8:
            recommendations.append("üìâ –ù–∏–∑–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å - —É–º–µ–Ω—å—à–∏—Ç—å TP")

        if trend_strength_factor > 1.5:
            recommendations.append("üöÄ –°–∏–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–¥ - —É–≤–µ–ª–∏—á–∏—Ç—å TP")

        if volume_factor > 1.3:
            recommendations.append("üìä –í—ã—Å–æ–∫–∏–π –æ–±—ä–µ–º - —Ö–æ—Ä–æ—à–∏–µ —à–∞–Ω—Å—ã –Ω–∞ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ TP")

        return "; ".join(recommendations) if recommendations else "üìä –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã TP"

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –ò–ò-–æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ TP
ai_tp_optimizer = AITakeProfitOptimizer()
