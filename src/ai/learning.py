#!/usr/bin/env python3
"""
ü§ñ –°–ò–°–¢–ï–ú–ê –û–ë–£–ß–ï–ù–ò–Ø –ò–ò –î–õ–Ø –¢–û–†–ì–û–í–û–ô –°–ò–°–¢–ï–ú–´
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–æ—Ä–≥–æ–≤–æ–π –ª–æ–≥–∏–∫–∏ –∏ –¥–∞–Ω–Ω—ã—Ö

–£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏:
- –õ–∏–º–∏—Ç 30K –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ (–æ–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è ML)
- –£–º–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤–∞–∂–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- –°–∏—Å—Ç–µ–º–∞ –≤–µ—Å–æ–≤ –¥–ª—è –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–∏
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –±–µ–∑ –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–∞
"""

# pylint: disable=too-many-lines

import asyncio
import json
import logging
import shutil
try:
    import numpy as np
except ImportError as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ numpy: {e}")
    np = None
from collections import Counter
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
import pickle
import os

try:
    from src.config.patterns import (
        get_learning_metrics_path,
        get_learning_model_path,
        get_patterns_file_path,
    )
except ImportError:
    # Fallback –µ—Å–ª–∏ patterns_config –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
    def get_learning_metrics_path():
        return "ai_learning_data/learning_metrics.json"
    def get_learning_model_path():
        return "ai_learning_data/learning_model.pkl"
    def get_patterns_file_path(env="main"):
        return "ai_learning_data/trading_patterns.json"

# –ò–º–ø–æ—Ä—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ò–ò
try:
    from ai.ai_config import get_pattern_config
except ImportError:
    try:
        from ai_config import get_pattern_config  # type: ignore
    except ImportError:
        get_pattern_config = None  # type: ignore

if callable(get_pattern_config):
    AI_CONFIG = get_pattern_config()
else:
    AI_CONFIG = {
        "max_patterns": 50000,
        "pattern_age_days": 60,
        "cleanup_frequency": 1000,
        "auto_cleanup_on_start": True,
    }

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class TradingPattern:
    """–ü–∞—Ç—Ç–µ—Ä–Ω —Ç–æ—Ä–≥–æ–≤–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
    symbol: str
    timestamp: datetime
    signal_type: str  # LONG/SHORT
    entry_price: float
    tp1: float
    tp2: float
    risk_pct: float
    leverage: float
    indicators: Dict[str, float]  # RSI, EMA, BB, etc.
    market_conditions: Dict[str, Any]  # BTC trend, volume, etc.
    result: Optional[str] = None  # WIN/LOSS/NEUTRAL
    profit_pct: Optional[float] = None

@dataclass
class LearningMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è –ò–ò"""
    total_patterns: int = 0
    successful_patterns: int = 0
    failed_patterns: int = 0
    accuracy: float = 0.0
    profit_factor: float = 0.0
    max_drawdown: float = 0.0
    sharpe_ratio: float = 0.0
    last_cleanup: Optional[str] = None

class AILearningSystem:
    """–°–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è –ò–ò –¥–ª—è —Ç–æ—Ä–≥–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã"""

    _instance = None
    _initialized = False

    def __new__(cls, data_dir: str = "ai_learning_data"):
        if cls._instance is None:
            cls._instance = super(AILearningSystem, cls).__new__(cls)
        return cls._instance

    def __init__(self, data_dir: str = "ai_learning_data"):
        # –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ–º –ø–æ–≤—Ç–æ—Ä–Ω—É—é –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é
        if AILearningSystem._initialized:
            return
        AILearningSystem._initialized = True
        self.data_dir = data_dir
        self.patterns_file = get_patterns_file_path("main")
        self.learning_model_file = get_learning_model_path()
        self.metrics_file = get_learning_metrics_path()

        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –¥–∞–Ω–Ω—ã—Ö
        os.makedirs(data_dir, exist_ok=True)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
        self.patterns = self.load_patterns()
        self.learning_model = self.load_learning_model()
        self.metrics = self.load_metrics()

        logger.info("ü§ñ –ò–ò —Å–∏—Å—Ç–µ–º–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞. –ü–∞—Ç—Ç–µ—Ä–Ω–æ–≤: %d", len(self.patterns))

        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ (–∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞)
        max_patterns = AI_CONFIG.get('max_patterns', 50000)
        auto_cleanup = AI_CONFIG.get('auto_cleanup_on_start', True)

        if auto_cleanup and len(self.patterns) > max_patterns:
            logger.info("üßπ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ %d –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤, –∑–∞–ø—É—Å–∫–∞–µ–º —É–º–Ω—É—é –∞–≤—Ç–æ–æ—á–∏—Å—Ç–∫—É...", len(self.patterns))
            self.auto_manage_patterns(max_patterns=max_patterns)

    def load_patterns(self) -> List[TradingPattern]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã"""
        if not os.path.exists(self.patterns_file):
            logger.warning("‚ö†Ô∏è –§–∞–π–ª –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: %s", self.patterns_file)
            return []

        try:
            logger.info("üì• –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ %s (UTF-8 JSON)", self.patterns_file)
            with open(self.patterns_file, 'r', encoding='utf-8') as file:
                data = json.load(file)
        except (IOError, OSError) as io_err:
            logger.error("‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: %s", io_err)
            return []
        except json.JSONDecodeError as json_err:
            logger.error("‚ùå JSONDecodeError –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: %s", json_err)
            backup_file = f"{self.patterns_file}.backup"
            logger.info("üíæ –°–æ–∑–¥–∞—ë–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é –±–∏—Ç–æ–≥–æ —Ñ–∞–π–ª–∞ ‚Üí %s", backup_file)
            try:
                shutil.copyfile(self.patterns_file, backup_file)
            except Exception as copy_err:  # pragma: no cover
                logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é: %s", copy_err)
            logger.info("‚ôªÔ∏è –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–∞–π–ª –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏ —Å–æ–∑–¥–∞—ë–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫")
            try:
                with open(self.patterns_file, 'w', encoding='utf-8') as file:
                    json.dump([], file, ensure_ascii=False, indent=2)
            except Exception as reset_err:
                logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: %s", reset_err)
            return []

        if not isinstance(data, list):
            logger.error("‚ùå –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: –æ–∂–∏–¥–∞–µ—Ç—Å—è —Å–ø–∏—Å–æ–∫, –ø–æ–ª—É—á–µ–Ω–æ %s", type(data))
            return []

        patterns: List[TradingPattern] = []
        skipped = 0

        for idx, item in enumerate(data):
            try:
                pattern = TradingPattern(
                    symbol=item['symbol'],
                    timestamp=datetime.fromisoformat(item['timestamp']),
                    signal_type=item['signal_type'],
                    entry_price=float(item['entry_price']),
                    tp1=float(item['tp1']),
                    tp2=float(item['tp2']),
                    risk_pct=float(item['risk_pct']),
                    leverage=float(item['leverage']),
                    indicators=item['indicators'],
                    market_conditions=item['market_conditions'],
                    result=item.get('result'),
                    profit_pct=item.get('profit_pct')
                )
            except (KeyError, TypeError, ValueError) as exc:
                skipped += 1
                if skipped <= 5:
                    logger.warning("‚ö†Ô∏è –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω –Ω–∞ –ø–æ–∑–∏—Ü–∏–∏ %d: %s", idx, exc)
                continue

            patterns.append(pattern)

        if skipped:
            logger.warning("‚ö†Ô∏è –ü—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø—Ä–æ–ø—É—â–µ–Ω–æ %d –∑–∞–ø–∏—Å–µ–π –∏–∑ %d", skipped, len(data))

        return patterns

    def save_patterns(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã"""
        try:
            data = []
            for pattern in self.patterns:
                # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ timestamp
                if pattern.timestamp is None:
                    logger.warning("‚ö†Ô∏è –ü–∞—Ç—Ç–µ—Ä–Ω %s –∏–º–µ–µ—Ç None timestamp, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º", pattern.symbol)
                    continue

                data.append({
                    'symbol': pattern.symbol,
                    'timestamp': pattern.timestamp.isoformat(),
                    'signal_type': pattern.signal_type,
                    'entry_price': pattern.entry_price,
                    'tp1': pattern.tp1,
                    'tp2': pattern.tp2,
                    'risk_pct': pattern.risk_pct,
                    'leverage': pattern.leverage,
                    'indicators': pattern.indicators,
                    'market_conditions': pattern.market_conditions,
                    'result': pattern.result,
                    'profit_pct': pattern.profit_pct
                })

            with open(self.patterns_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)

            logger.info("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ %d –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤", len(self.patterns))
        except (IOError, OSError, TypeError) as e:
            logger.error("–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: %s", e)

    def load_learning_model(self) -> Dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∏—è"""
        if os.path.exists(self.learning_model_file):
            try:
                with open(self.learning_model_file, 'rb') as f:
                    return pickle.load(f)
            except (IOError, OSError, pickle.UnpicklingError, EOFError) as e:
                logger.error("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: %s", e)
        return {
            'weights': {},
            'biases': {},
            'feature_importance': {},
            'last_updated': None
        }

    def save_learning_model(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∏—è"""
        try:
            with open(self.learning_model_file, 'wb') as f:
                pickle.dump(self.learning_model, f)
            logger.info("üíæ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
        except (IOError, OSError, pickle.PicklingError) as e:
            logger.error("–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: %s", e)

    def load_metrics(self) -> LearningMetrics:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è"""
        if os.path.exists(self.metrics_file):
            try:
                with open(self.metrics_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                return LearningMetrics(**data)
            except (IOError, OSError, json.JSONDecodeError, TypeError, KeyError) as e:
                logger.error("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–µ—Ç—Ä–∏–∫: %s", e)
        return LearningMetrics()

    def save_metrics(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏"""
        try:
            data = {
                'total_patterns': self.metrics.total_patterns,
                'successful_patterns': self.metrics.successful_patterns,
                'failed_patterns': self.metrics.failed_patterns,
                'accuracy': self.metrics.accuracy,
                'profit_factor': self.metrics.profit_factor,
                'max_drawdown': self.metrics.max_drawdown,
                'sharpe_ratio': self.metrics.sharpe_ratio
            }

            with open(self.metrics_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)

            logger.info("üíæ –ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")
        except (IOError, OSError, TypeError) as e:
            logger.error("–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫: %s", e)

    def _validate_symbol(self, symbol: str) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Å–∏–º–≤–æ–ª–∞ –ø–µ—Ä–µ–¥ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω–∞"""
        if not symbol or not isinstance(symbol, str):
            return False
        
        # –û—á–∏—Å—Ç–∫–∞
        clean_symbol = symbol.strip().upper()
        if not clean_symbol:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã (–±—É–∫–≤—ã, —Ü–∏—Ñ—Ä—ã, –¥–µ—Ñ–∏—Å, –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏–µ)
        import re
        if not re.match(r'^[A-Z0-9_-]+$', clean_symbol):
            return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–∞–∑—É–º–Ω—É—é –¥–ª–∏–Ω—É (2-20 —Å–∏–º–≤–æ–ª–æ–≤)
        if len(clean_symbol) < 2 or len(clean_symbol) > 20:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–∞—Ç—É/–≤—Ä–µ–º—è (–æ—à–∏–±–∫–∞ –≤ –¥–∞–Ω–Ω—ã—Ö)
        if re.match(r'^\d{4}-\d{2}-\d{2}', clean_symbol):
            return False
        
        return True

    def add_pattern(self, pattern: TradingPattern):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º"""
        # –í–∞–ª–∏–¥–∞—Ü–∏—è —Å–∏–º–≤–æ–ª–∞
        if not self._validate_symbol(pattern.symbol):
            logger.warning("‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω –ø–∞—Ç—Ç–µ—Ä–Ω —Å –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–º —Å–∏–º–≤–æ–ª–æ–º: '%s'", pattern.symbol)
            return
        
        self.patterns.append(pattern)
        self.metrics.total_patterns += 1

        if pattern.result == "WIN":
            self.metrics.successful_patterns += 1
        elif pattern.result == "LOSS":
            self.metrics.failed_patterns += 1

        # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
        self.update_metrics()

        logger.info("üìä –î–æ–±–∞–≤–ª–µ–Ω –ø–∞—Ç—Ç–µ—Ä–Ω: %s %s", pattern.symbol, pattern.signal_type)

        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏ (—á–∞—Å—Ç–æ—Ç–∞ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞)
        cleanup_freq = AI_CONFIG.get('cleanup_frequency', 1000)
        if len(self.patterns) % cleanup_freq == 0:
            self.auto_manage_patterns()

    def update_metrics(self):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è"""
        if self.metrics.total_patterns > 0:
            self.metrics.accuracy = self.metrics.successful_patterns / self.metrics.total_patterns

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º profit factor
            wins = [p.profit_pct for p in self.patterns if p.result == "WIN" and p.profit_pct]
            losses = [abs(p.profit_pct) for p in self.patterns if p.result == "LOSS" and p.profit_pct]

            if wins and losses:
                total_wins = sum(wins)
                total_losses = sum(losses)
                if total_losses > 0:
                    self.metrics.profit_factor = total_wins / total_losses

        logger.info("üìà –ú–µ—Ç—Ä–∏–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω—ã: –¢–æ—á–Ω–æ—Å—Ç—å %.2f%%", self.metrics.accuracy * 100)

    def auto_manage_patterns(self, max_patterns=None):
        """
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–ø—Ä–∞–≤–ª—è–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Å —É–º–Ω–æ–π –æ—á–∏—Å—Ç–∫–æ–π

        –°—Ç—Ä–∞—Ç–µ–≥–∏—è (–Ω–∞ –æ—Å–Ω–æ–≤–µ ML best practices):
        - –ú–∞–∫—Å–∏–º—É–º 30K –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ (–æ–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è ML –º–æ–¥–µ–ª–µ–π)
        - –í—Å–µ WIN/LOSS –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è (–≤–∞–∂–Ω—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è)
        - –°–≤–µ–∂–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã (<60 –¥–Ω–µ–π) –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã
        - –°—Ç–∞—Ä—ã–µ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ —É–¥–∞–ª—è—é—Ç—Å—è
        - –†–µ–¥–∫–∏–µ —Å–∏–º–≤–æ–ª—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è (–≤–∞–∂–Ω—ã –¥–ª—è –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏)
        """
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        if max_patterns is None:
            max_patterns = AI_CONFIG.get('max_patterns', 50000)

        if len(self.patterns) <= max_patterns:
            return  # –í—Å–µ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –Ω–æ—Ä–º—ã

        logger.info("üßπ –ù–∞—á–∏–Ω–∞–µ–º —É–º–Ω—É—é –æ—á–∏—Å—Ç–∫—É –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: %d ‚Üí –º–∞–∫—Å %d", len(self.patterns), max_patterns)

        pattern_age_days = AI_CONFIG.get('pattern_age_days', 60)
        cutoff_date = datetime.now(timezone.utc) - timedelta(days=pattern_age_days)

        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
        critical = []      # WIN/LOSS - –≤—Å–µ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
        important = []     # –°–≤–µ–∂–∏–µ (<60 –¥–Ω–µ–π)
        rare_symbols = []  # –†–µ–¥–∫–∏–µ —Å–∏–º–≤–æ–ª—ã (< 100 –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤)
        neutral_old = []   # –°—Ç–∞—Ä—ã–µ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ - –∫–∞–Ω–¥–∏–¥–∞—Ç—ã –Ω–∞ —É–¥–∞–ª–µ–Ω–∏–µ

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —á–∞—Å—Ç–æ—Ç—É —Å–∏–º–≤–æ–ª–æ–≤
        symbol_counts = Counter(p.symbol for p in self.patterns if hasattr(p, 'symbol') and self._validate_symbol(p.symbol))
        rare_threshold = AI_CONFIG.get('rare_symbol_threshold', 100)

        # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏ –∏ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏
        for p in self.patterns:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Å –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏
            if not self._validate_symbol(p.symbol):
                continue
            
            # –ö—Ä–∏—Ç–∏—á–Ω—ã–µ (WIN/LOSS) - –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            if hasattr(p, 'result') and p.result in ("WIN", "LOSS"):
                critical.append(p)
            # –°–≤–µ–∂–∏–µ - —Å–æ—Ö—Ä–∞–Ω—è–µ–º
            elif hasattr(p, 'timestamp') and p.timestamp:
                # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (—É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ TypeError)
                p_ts = p.timestamp
                if p_ts.tzinfo is None:
                    p_ts = p_ts.replace(tzinfo=timezone.utc)
                
                if p_ts > cutoff_date:
                    important.append(p)
            # –û—Å—Ç–∞–ª—å–Ω—ã–µ - –∫–∞–Ω–¥–∏–¥–∞—Ç—ã –Ω–∞ —É–¥–∞–ª–µ–Ω–∏–µ
            else:
                neutral_old.append(p)

        # üéØ –ë–ê–õ–ê–ù–°–ò–†–û–í–ö–ê WIN/LOSS
        wins = [p for p in critical if hasattr(p, 'result') and p.result == "WIN"]
        losses = [p for p in critical if hasattr(p, 'result') and p.result == "LOSS"]
        
        # –¶–µ–ª–µ–≤–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ: 65% WIN / 35% LOSS
        target_win_ratio = 0.65
        target_loss_ratio = 0.35
        
        # –ï—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ WIN, –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Ö –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
        if len(wins) > 0 and len(losses) > 0:
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ü–µ–ª–µ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ WIN –Ω–∞ –æ—Å–Ω–æ–≤–µ LOSS
            target_wins = int(len(losses) * (target_win_ratio / target_loss_ratio))
            
            if len(wins) > target_wins:
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º WIN –ø–æ –ø—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç–∏ –∏ —Å–≤–µ–∂–µ—Å—Ç–∏, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ª—É—á—à–∏–µ
                wins_sorted = sorted(
                    wins,
                    key=lambda x: (
                        -(hasattr(x, 'profit_pct') and x.profit_pct or 0),
                        -(x.timestamp.timestamp() if hasattr(x, 'timestamp') and x.timestamp else 0)
                    )
                )
                wins = wins_sorted[:target_wins]
                logger.info("   ‚öñÔ∏è –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞: –æ—Å—Ç–∞–≤–ª–µ–Ω–æ %d WIN –∏–∑ %d (—Ü–µ–ª—å: %d)", len(wins), len(wins_sorted), target_wins)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º LOSS –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏ (–±–æ–ª–µ–µ —Å–≤–µ–∂–∏–µ –∏ —Å –±–æ–ª—å—à–∏–º–∏ —É–±—ã—Ç–∫–∞–º–∏ - –≤–∞–∂–Ω–µ–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è)
        losses_sorted = sorted(
            losses,
            key=lambda x: (
                # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –±–æ–ª—å—à–∏–º —É–±—ã—Ç–∫–∞–º (–≤–∞–∂–Ω–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è)
                abs(hasattr(x, 'profit_pct') and x.profit_pct or 0),
                # –ó–∞—Ç–µ–º –ø–æ —Å–≤–µ–∂–µ—Å—Ç–∏ (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–º–∏)
                -(x.timestamp.timestamp() if hasattr(x, 'timestamp') and x.timestamp else 0)
            ),
            reverse=True
        )
        losses = losses_sorted
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏
        critical = wins + losses
        
        logger.info("   ‚öñÔ∏è –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ WIN/LOSS: WIN=%d (%.1f%%), LOSS=%d (%.1f%%)",
                   len(wins), len(wins) / len(critical) * 100 if critical else 0,
                   len(losses), len(losses) / len(critical) * 100 if critical else 0)

        # –ò–∑ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö –≤—ã–¥–µ–ª—è–µ–º —Ä–µ–¥–∫–∏–µ —Å–∏–º–≤–æ–ª—ã –¥–ª—è –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        # (–Ω–æ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –º–µ—Å—Ç–æ)
        # –£–õ–£–ß–®–ï–ù–ò–ï: –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ NEUTRAL –ø–∞—Ç—Ç–µ—Ä–Ω—ã (>60 –¥–Ω–µ–π) —Å—Ä–∞–∑—É
        neutral_old_filtered = []
        for p in neutral_old:
            if hasattr(p, 'timestamp') and p.timestamp and p.timestamp <= cutoff_date:
                # –°—Ç–∞—Ä—ã–π NEUTRAL - —É–¥–∞–ª—è–µ–º
                continue
            neutral_old_filtered.append(p)
        neutral_old = neutral_old_filtered
        
        if neutral_old:
            rare_symbols_from_neutral = []
            for p in neutral_old:
                if hasattr(p, 'symbol') and self._validate_symbol(p.symbol) and symbol_counts.get(p.symbol, 0) < rare_threshold:
                    rare_symbols_from_neutral.append(p)

            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–¥–∫–∏–µ —Å–∏–º–≤–æ–ª—ã —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –º–µ—Å—Ç–æ
            space_available = max_patterns - len(critical) - len(important)
            if space_available > 0:
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–¥–∫–∏–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–º–∏)
                rare_sorted = sorted(
                    rare_symbols_from_neutral,
                    key=lambda x: x.timestamp if hasattr(x, 'timestamp') and x.timestamp else datetime.min,
                    reverse=True
                )
                rare_symbols = rare_sorted[:min(len(rare_sorted), space_available)]

                # –£–±–∏—Ä–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–µ —Ä–µ–¥–∫–∏–µ –∏–∑ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö
                for rare_p in rare_symbols:
                    if rare_p in neutral_old:
                        neutral_old.remove(rare_p)

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–∫–æ–ª—å–∫–æ –º–æ–∂–µ–º –æ—Å—Ç–∞–≤–∏—Ç—å
        essential_count = len(critical) + len(important) + len(rare_symbols)

        # –£–õ–£–ß–®–ï–ù–ò–ï: –ï—Å–ª–∏ –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ, –æ—Ç—Å–µ–∏–≤–∞–µ–º –º–µ–Ω–µ–µ —É—Å–ø–µ—à–Ω—ã–µ
        if len(critical) > max_patterns * 0.8:  # –ï—Å–ª–∏ –∫—Ä–∏—Ç–∏–∫–∞ –±–æ–ª—å—à–µ 80% –ª–∏–º–∏—Ç–∞
            logger.warning("‚ö†Ô∏è –ö—Ä–∏—Ç–∏—á–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ: %d", len(critical))
            # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å–∞–º—ã–µ —É—Å–ø–µ—à–Ω—ã–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            space_for_critical = int(max_patterns * 0.7)  # 70% –º–µ—Å—Ç–∞ –¥–ª—è –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö
            critical = critical[:space_for_critical]
            logger.info("   ‚úÖ –û—Å—Ç–∞–≤–ª–µ–Ω–æ —Ç–æ–ø-%d —Å–∞–º—ã—Ö —É—Å–ø–µ—à–Ω—ã—Ö –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤", space_for_critical)

        if essential_count > max_patterns:
            # –î–∞–∂–µ –≤–∞–∂–Ω—ã—Ö —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ - –æ—Å—Ç–∞–≤–ª—è–µ–º —Å–∞–º—ã–µ —É—Å–ø–µ—à–Ω—ã–µ
            logger.warning("‚ö†Ô∏è –í–∞–∂–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –±–æ–ª—å—à–µ –ª–∏–º–∏—Ç–∞: %d > %d", essential_count, max_patterns)

            # –£–õ–£–ß–®–ï–ù–ò–ï: –°–æ—Ä—Ç–∏—Ä—É–µ–º –≤–∞–∂–Ω—ã–µ –ø–æ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏, –∑–∞—Ç–µ–º –ø–æ —Å–≤–µ–∂–µ—Å—Ç–∏
            important_sorted = sorted(
                important,
                key=lambda x: (
                    # –°–Ω–∞—á–∞–ª–∞ –ø–æ –ø—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
                    -(hasattr(x, 'profit_pct') and x.profit_pct or 0),
                    # –ó–∞—Ç–µ–º –ø–æ —Å–≤–µ–∂–µ—Å—Ç–∏ (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–º–∏)
                    -((x.timestamp.timestamp() if hasattr(x, 'timestamp') and x.timestamp else 0))
                )
            )

            space_for_important = max_patterns - len(critical) - len(rare_symbols)
            if space_for_important > 0:
                important = important_sorted[:space_for_important]
            else:
                important = []
            neutral_old = []
        else:
            # –ï—Å—Ç—å –º–µ—Å—Ç–æ –¥–ª—è –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö - –±–µ—Ä–µ–º —Å–∞–º—ã–µ —Å–≤–µ–∂–∏–µ
            space_for_neutral = max_patterns - essential_count
            if space_for_neutral > 0 and neutral_old:
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–º–∏)
                neutral_sorted = sorted(
                    neutral_old,
                    key=lambda x: x.timestamp if hasattr(x, 'timestamp') and x.timestamp else datetime.min,
                    reverse=True
                )
                neutral_old = neutral_sorted[:space_for_neutral]
            else:
                neutral_old = []

        # –°–æ–±–∏—Ä–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫
        original_count = len(self.patterns)
        self.patterns = critical + important + rare_symbols + neutral_old

        # –£–õ–£–ß–®–ï–ù–ù–ê–Ø —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—á–∏—Å—Ç–∫–∏
        final_count = len(self.patterns)

        # –°—á–∏—Ç–∞–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        win_count = sum(1 for p in critical if hasattr(p, 'result') and p.result == "WIN")
        loss_count = sum(1 for p in critical if hasattr(p, 'result') and p.result == "LOSS")

        # –°—Ä–µ–¥–Ω—è—è –ø—Ä–∏–±—ã–ª—å
        profits = [p.profit_pct for p in critical if hasattr(p, 'profit_pct') and p.profit_pct]
        avg_profit = sum(profits) / len(profits) if profits else 0.0

        logger.info("‚úÖ –£–ú–ù–ê–Ø –æ—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞:")
        logger.info("   üèÜ –ö—Ä–∏—Ç–∏—á–Ω—ã–µ (WIN/LOSS): %d (WIN: %d, LOSS: %d)", len(critical), win_count, loss_count)
        logger.info("   üí∞ –°—Ä–µ–¥–Ω—è—è –ø—Ä–∏–±—ã–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö: %.2f%%", avg_profit)
        logger.info("   üïê –°–≤–µ–∂–∏–µ (<60–¥): %d", len(important))
        logger.info("   üíé –†–µ–¥–∫–∏–µ —Å–∏–º–≤–æ–ª—ã: %d", len(rare_symbols))
        logger.info("   üìä –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ: %d", len(neutral_old))
        logger.info("   ‚úÖ –ò—Ç–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: %d –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ (–±—ã–ª–æ: %d)", final_count, original_count)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        self.save_patterns()

    def calculate_pattern_importance(self, pattern: TradingPattern) -> float:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (0.0 - 1.0)

        –ö—Ä–∏—Ç–µ—Ä–∏–∏ –≤–∞–∂–Ω–æ—Å—Ç–∏:
        - WIN/LOSS: –≤—ã—Å–æ–∫–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å (0.9-1.0)
        - –°–≤–µ–∂–µ—Å—Ç—å: –Ω–æ–≤—ã–µ –≤–∞–∂–Ω–µ–µ —Å—Ç–∞—Ä—ã—Ö
        - –†–µ–¥–∫–æ—Å—Ç—å —Å–∏–º–≤–æ–ª–∞: —Ä–µ–¥–∫–∏–µ –≤–∞–∂–Ω–µ–µ —á–∞—Å—Ç—ã—Ö
        - –ü—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç—å: –±–æ–ª—å—à–∏–µ –ø—Ä–∏–±—ã–ª–∏/—É–±—ã—Ç–∫–∏ –≤–∞–∂–Ω–µ–µ
        """
        importance = 0.0

        # –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–¥–µ–ª–∫–∏ (40% –≤–µ—Å–∞)
        if hasattr(pattern, 'result') and pattern.result:
            if pattern.result == "WIN":
                importance += 0.4
                # –ë–æ–Ω—É—Å –∑–∞ –≤—ã—Å–æ–∫—É—é –ø—Ä–∏–±—ã–ª—å
                if hasattr(pattern, 'profit_pct') and pattern.profit_pct and pattern.profit_pct > 5.0:
                    importance += 0.1
            elif pattern.result == "LOSS":
                importance += 0.4
                # –ë–æ–Ω—É—Å –∑–∞ –±–æ–ª—å—à–æ–π —É–±—ã—Ç–æ–∫ (—É—á–∏–º—Å—è –∏–∑–±–µ–≥–∞—Ç—å)
                if hasattr(pattern, 'profit_pct') and pattern.profit_pct and abs(pattern.profit_pct) > 3.0:
                    importance += 0.1

        # –°–≤–µ–∂–µ—Å—Ç—å (30% –≤–µ—Å–∞)
        if hasattr(pattern, 'timestamp') and pattern.timestamp:
            age_days = (datetime.now(timezone.utc) - pattern.timestamp.replace(tzinfo=timezone.utc) if pattern.timestamp.tzinfo is None else pattern.timestamp).days
            if age_days < 7:
                importance += 0.3
            elif age_days < 30:
                importance += 0.2
            elif age_days < 60:
                importance += 0.1

        # –†–µ–¥–∫–æ—Å—Ç—å —Å–∏–º–≤–æ–ª–∞ (20% –≤–µ—Å–∞)
        if hasattr(pattern, 'symbol') and pattern.symbol:
            symbol_counts = Counter(p.symbol for p in self.patterns if hasattr(p, 'symbol'))
            symbol_frequency = symbol_counts.get(pattern.symbol, 0)
            if symbol_frequency < 50:
                importance += 0.2
            elif symbol_frequency < 100:
                importance += 0.1

        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —É—Å–ª–æ–≤–∏—è (10% –≤–µ—Å–∞)
        if hasattr(pattern, 'market_conditions') and pattern.market_conditions:
            # –ü–∞—Ç—Ç–µ—Ä–Ω—ã —Å —Ä–µ–¥–∫–∏–º–∏ —Ä—ã–Ω–æ—á–Ω—ã–º–∏ —É—Å–ª–æ–≤–∏—è–º–∏ –±–æ–ª–µ–µ —Ü–µ–Ω–Ω—ã
            conditions = pattern.market_conditions
            if isinstance(conditions, dict) and conditions.get('volatility', 'normal') in ('high', 'low'):
                importance += 0.05
            if isinstance(conditions, dict) and conditions.get('trend_strength', 0) > 70:
                importance += 0.05

        return min(importance, 1.0)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 1.0

    def analyze_patterns(self) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏ –≤—ã—è–≤–ª—è–µ—Ç –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏"""
        if not self.patterns:
            return {"error": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"}

        analysis = {
            "total_patterns": len(self.patterns),
            "symbols": {},
            "signal_types": {"LONG": 0, "SHORT": 0},
            "success_rates": {},
            "best_indicators": {},
            "market_conditions": {}
        }

        # –ê–Ω–∞–ª–∏–∑ –ø–æ —Å–∏–º–≤–æ–ª–∞–º
        for pattern in self.patterns:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
            if not hasattr(pattern, 'symbol') or pattern.symbol is None:
                logger.warning("‚ö†Ô∏è –ü–∞—Ç—Ç–µ—Ä–Ω –±–µ–∑ —Å–∏–º–≤–æ–ª–∞ –ø—Ä–æ–ø—É—â–µ–Ω")
                continue

            symbol = pattern.symbol

            if symbol not in analysis["symbols"]:
                analysis["symbols"][symbol] = {"total": 0, "wins": 0, "losses": 0}

            analysis["symbols"][symbol]["total"] += 1

            # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            if hasattr(pattern, 'result') and pattern.result is not None:
                if pattern.result == "WIN":
                    analysis["symbols"][symbol]["wins"] += 1
                elif pattern.result == "LOSS":
                    analysis["symbols"][symbol]["losses"] += 1

            # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–∞ —Å–∏–≥–Ω–∞–ª–∞
            if hasattr(pattern, 'signal_type') and pattern.signal_type is not None:
                signal_type = pattern.signal_type
                if signal_type in analysis["signal_types"]:
                    analysis["signal_types"][signal_type] += 1
                else:
                    # –ï—Å–ª–∏ —Ç–∏–ø —Å–∏–≥–Ω–∞–ª–∞ –Ω–µ LONG/SHORT, –¥–æ–±–∞–≤–ª—è–µ–º –≤ –æ–±—â–∏–π —Å—á–µ—Ç—á–∏–∫
                    if "OTHER" not in analysis["signal_types"]:
                        analysis["signal_types"]["OTHER"] = 0
                    analysis["signal_types"]["OTHER"] += 1

        # –†–∞—Å—á–µ—Ç —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ –ø–æ —Å–∏–º–≤–æ–ª–∞–º
        for symbol, data in analysis["symbols"].items():
            if data["total"] > 0:
                success_rate = data["wins"] / data["total"]
                analysis["success_rates"][symbol] = success_rate

        logger.info("üîç –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: %d —Å–∏–º–≤–æ–ª–æ–≤", len(analysis['symbols']))
        return analysis

    def get_learning_recommendations(self) -> List[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—É—á–µ–Ω–∏—è"""
        recommendations = []

        if self.metrics.accuracy < 0.6:
            recommendations.append("‚ö†Ô∏è –ù–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å —Å–∏–≥–Ω–∞–ª–æ–≤. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–ª—É—á—à–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä—ã")

        if self.metrics.profit_factor < 1.2:
            recommendations.append("‚ö†Ô∏è –ù–∏–∑–∫–∏–π profit factor. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–µ—Ä–µ—Å–º–æ—Ç—Ä–µ—Ç—å —Ä–∏—Å–∫-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç")

        # –ê–Ω–∞–ª–∏–∑ –ª—É—á—à–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        analysis = self.analyze_patterns()
        if analysis.get("success_rates"):
            best_symbols = sorted(
                analysis["success_rates"].items(),
                key=lambda x: x[1],
                reverse=True
            )[:3]

            for symbol, rate in best_symbols:
                recommendations.append(f"‚úÖ {symbol}: —É—Å–ø–µ—à–Ω–æ—Å—Ç—å {rate:.1%}")

        return recommendations

    def validate_system_data(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã"""
        validation_results = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "checks": {},
            "errors": [],
            "warnings": [],
            "recommendations": []
        }

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–æ–≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        config_files = ["config.py", "user_data.json", "trading.db"]
        for file in config_files:
            if os.path.exists(file):
                validation_results["checks"][f"file_{file}"] = "‚úÖ –ù–∞–π–¥–µ–Ω"
            else:
                validation_results["errors"].append(f"‚ùå –§–∞–π–ª {file} –Ω–µ –Ω–∞–π–¥–µ–Ω")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ API –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π
        validation_results["checks"]["api_status"] = "üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ API..."

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        try:
            with open("user_data.json", 'r', encoding='utf-8') as f:
                user_data = json.load(f)

            for user_id, data in user_data.items():
                required_fields = ["deposit", "trade_mode", "filter_mode"]
                for field in required_fields:
                    if field not in data or data[field] is None:
                        validation_results["warnings"].append(
                            f"‚ö†Ô∏è –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id}: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç {field}"
                        )
        except (IOError, OSError, json.JSONDecodeError, KeyError) as e:
            validation_results["errors"].append(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è user_data.json: {e}")

        logger.info("üîç –í–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: %d –æ—à–∏–±–æ–∫", len(validation_results['errors']))
        return validation_results

    def auto_optimize_parameters(self) -> Dict[str, Any]:
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –í–°–ï –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∏—Å—Ç–µ–º—ã –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç–∏"""
        optimization_results = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "optimizations": {},
            "improvements": [],
            "parameter_changes": {}
        }

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å pandas/numpy
        if np is None:
            optimization_results["improvements"].append("‚ö†Ô∏è numpy –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
            return optimization_results

        # –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        if len(self.patterns) < 10:
            optimization_results["improvements"].append(
                "üìä –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏. –ù—É–∂–Ω–æ –±–æ–ª—å—à–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"
            )
            return optimization_results

        # –ê–Ω–∞–ª–∏–∑ –ª—É—á—à–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        analysis = self.analyze_patterns()

        # 1. –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –†–ò–°–ö–ê –ò –õ–ï–í–ï–†–ò–î–ñ–ê
        successful_patterns = [p for p in self.patterns if p.result == "WIN"]
        if successful_patterns:
            avg_successful_risk = np.mean([p.risk_pct for p in successful_patterns])
            avg_successful_leverage = np.mean([p.leverage for p in successful_patterns])

            optimization_results["parameter_changes"]["optimal_risk_pct"] = round(avg_successful_risk, 2)
            optimization_results["parameter_changes"]["optimal_leverage"] = round(avg_successful_leverage, 1)
            optimization_results["improvements"].append(
                f"üéØ –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∏—Å–∫: {avg_successful_risk:.2f}%, –ª–µ–≤–µ—Ä–∏–¥–∂: {avg_successful_leverage:.1f}x"
            )

        # 2. –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –¢–ï–ô–ö-–ü–†–û–§–ò–¢–û–í
        tp1_profits = [p.profit_pct for p in successful_patterns if p.tp1 and p.profit_pct <= 3.0]
        tp2_profits = [p.profit_pct for p in successful_patterns if p.tp2 and p.profit_pct > 3.0]

        if tp1_profits:
            optimal_tp1 = np.percentile(tp1_profits, 75)  # 75-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å
            optimization_results["parameter_changes"]["optimal_tp1"] = round(optimal_tp1, 2)

        if tp2_profits:
            optimal_tp2 = np.percentile(tp2_profits, 75)
            optimization_results["parameter_changes"]["optimal_tp2"] = round(optimal_tp2, 2)

        # 3. –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –§–ò–õ–¨–¢–†–û–í (RSI, EMA, Volume)
        rsi_analysis = self._analyze_indicator_performance("RSI")
        if rsi_analysis:
            optimization_results["parameter_changes"]["optimal_rsi_oversold"] = rsi_analysis.get(
                "best_oversold",
                30,
            )
            optimization_results["parameter_changes"]["optimal_rsi_overbought"] = rsi_analysis.get(
                "best_overbought",
                70,
            )

        ema_analysis = self._analyze_indicator_performance("EMA")
        if ema_analysis:
            optimization_results["parameter_changes"]["optimal_ema_fast"] = ema_analysis.get("best_fast", 21)
            optimization_results["parameter_changes"]["optimal_ema_slow"] = ema_analysis.get("best_slow", 50)

        # 4. –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –†–´–ù–û–ß–ù–´–• –£–°–õ–û–í–ò–ô
        market_conditions_analysis = self._analyze_market_conditions()
        if market_conditions_analysis:
            optimization_results["parameter_changes"]["optimal_btc_trend"] = (
                market_conditions_analysis.get("best_btc_trend", "BULLISH")
            )
            optimization_results["parameter_changes"]["optimal_volume_class"] = (
                market_conditions_analysis.get("best_volume", "HIGH")
            )

        # 5. –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –°–ò–ú–í–û–õ–û–í
        if analysis.get("success_rates"):
            best_symbols = [
                symbol for symbol, rate in analysis["success_rates"].items()
                if rate > 0.7
            ]
            if best_symbols:
                optimization_results["parameter_changes"]["preferred_symbols"] = best_symbols
                optimization_results["improvements"].append(
                    f"‚úÖ –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Ñ–æ–∫—É—Å –Ω–∞ —Å–∏–º–≤–æ–ª—ã: {', '.join(best_symbols)}"
                )

        # 6. –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –í–†–ï–ú–ï–ù–ò –¢–û–†–ì–û–í–õ–ò
        time_analysis = self._analyze_time_performance()
        if time_analysis:
            optimization_results["parameter_changes"]["optimal_trading_hours"] = (
                time_analysis.get("best_hours", [9, 15, 21])
            )
            optimization_results["improvements"].append(
                f"‚è∞ –õ—É—á—à–µ–µ –≤—Ä–µ–º—è —Ç–æ—Ä–≥–æ–≤–ª–∏: {time_analysis['best_hours']}"
            )

        # 7. –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø STOP-LOSS
        sl_analysis = self._analyze_stop_loss_performance()
        if sl_analysis:
            optimization_results["parameter_changes"]["optimal_stop_loss_pct"] = (
                round(sl_analysis.get("best_sl_pct", 2.0), 2)
            )

        logger.info(
            "üîß –ü–æ–ª–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: %d –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, %d —É–ª—É—á—à–µ–Ω–∏–π",
            len(optimization_results['parameter_changes']),
            len(optimization_results['improvements'])
        )
        return optimization_results

    def apply_optimized_parameters(self, optimization_results: Dict[str, Any]) -> bool:
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏–º–µ–Ω—è–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ —Å–∏—Å—Ç–µ–º—É"""
        try:
            if not optimization_results.get("parameter_changes"):
                logger.warning("‚ö†Ô∏è –ù–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è")
                return False

            applied_count = 0
            parameter_changes = optimization_results["parameter_changes"]

            # 1. –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–∏—Å–∫–∞ –∏ –ª–µ–≤–µ—Ä–∏–¥–∂–∞
            if "optimal_risk_pct" in parameter_changes:
                self._update_system_parameter("risk_pct", parameter_changes["optimal_risk_pct"])
                applied_count += 1
                logger.info("üéØ –ü—Ä–∏–º–µ–Ω–µ–Ω –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∏—Å–∫: %s%%", parameter_changes['optimal_risk_pct'])

            if "optimal_leverage" in parameter_changes:
                self._update_system_parameter("leverage", parameter_changes["optimal_leverage"])
                applied_count += 1
                logger.info("‚ö° –ü—Ä–∏–º–µ–Ω–µ–Ω –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ª–µ–≤–µ—Ä–∏–¥–∂: %sx", parameter_changes['optimal_leverage'])

            # 2. –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç—ã
            if "optimal_tp1" in parameter_changes:
                self._update_system_parameter("tp1", parameter_changes["optimal_tp1"])
                applied_count += 1
                logger.info("üéØ –ü—Ä–∏–º–µ–Ω–µ–Ω –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π TP1: %s%%", parameter_changes['optimal_tp1'])

            if "optimal_tp2" in parameter_changes:
                self._update_system_parameter("tp2", parameter_changes["optimal_tp2"])
                applied_count += 1
                logger.info("üéØ –ü—Ä–∏–º–µ–Ω–µ–Ω –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π TP2: %s%%", parameter_changes['optimal_tp2'])

            # 3. –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
            if "optimal_rsi_oversold" in parameter_changes:
                self._update_system_parameter("rsi_oversold", parameter_changes["optimal_rsi_oversold"])
                applied_count += 1
                logger.info("üìä –ü—Ä–∏–º–µ–Ω–µ–Ω –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π RSI oversold: %s", parameter_changes['optimal_rsi_oversold'])

            if "optimal_rsi_overbought" in parameter_changes:
                self._update_system_parameter("rsi_overbought", parameter_changes["optimal_rsi_overbought"])
                applied_count += 1
                logger.info("üìä –ü—Ä–∏–º–µ–Ω–µ–Ω –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π RSI overbought: %s", parameter_changes['optimal_rsi_overbought'])

            if "optimal_ema_fast" in parameter_changes:
                self._update_system_parameter("ema_fast", parameter_changes["optimal_ema_fast"])
                applied_count += 1
                logger.info("üìà –ü—Ä–∏–º–µ–Ω–µ–Ω –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π EMA fast: %s", parameter_changes['optimal_ema_fast'])

            if "optimal_ema_slow" in parameter_changes:
                self._update_system_parameter("ema_slow", parameter_changes["optimal_ema_slow"])
                applied_count += 1
                logger.info("üìà –ü—Ä–∏–º–µ–Ω–µ–Ω –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π EMA slow: %s", parameter_changes['optimal_ema_slow'])

            # 4. –ü—Ä–∏–º–µ–Ω—è–µ–º stop-loss
            if "optimal_stop_loss_pct" in parameter_changes:
                self._update_system_parameter("stop_loss_pct", parameter_changes["optimal_stop_loss_pct"])
                applied_count += 1
                logger.info("üõ°Ô∏è –ü—Ä–∏–º–µ–Ω–µ–Ω –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π Stop-Loss: %s%%", parameter_changes['optimal_stop_loss_pct'])

            # 5. –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
            if "preferred_symbols" in parameter_changes:
                self._update_system_parameter("preferred_symbols", parameter_changes["preferred_symbols"])
                applied_count += 1
                logger.info("üéØ –ü—Ä–∏–º–µ–Ω–µ–Ω—ã –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã: %s", parameter_changes['preferred_symbols'])

            # 6. –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è —Ç–æ—Ä–≥–æ–≤–ª–∏
            if "optimal_trading_hours" in parameter_changes:
                self._update_system_parameter("trading_hours", parameter_changes["optimal_trading_hours"])
                applied_count += 1
                logger.info("‚è∞ –ü—Ä–∏–º–µ–Ω–µ–Ω—ã –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ —á–∞—Å—ã —Ç–æ—Ä–≥–æ–≤–ª–∏: %s", parameter_changes['optimal_trading_hours'])

            logger.info("‚úÖ –£—Å–ø–µ—à–Ω–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–æ %d –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤", applied_count)
            return applied_count > 0

        except (KeyError, TypeError, ValueError) as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: %s", e)
            return False

    def _update_system_parameter(self, parameter_name: str, value: Any) -> bool:
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä –≤ —Å–∏—Å—Ç–µ–º–µ (–≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –∫–æ–Ω—Ñ–∏–≥–µ)"""
        try:
            # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –∫–æ–Ω—Ñ–∏–≥–æ–º
            # –ü–æ–∫–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏

            # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            optimized_params_file = os.path.join(self.data_dir, "optimized_parameters.json")

            # –ß–∏—Ç–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            if os.path.exists(optimized_params_file):
                with open(optimized_params_file, 'r', encoding='utf-8') as f:
                    params = json.load(f)
            else:
                params = {}

            # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä
            params[parameter_name] = value
            params["last_updated"] = datetime.now(timezone.utc).isoformat()

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞—Ç–Ω–æ
            with open(optimized_params_file, 'w', encoding='utf-8') as f:
                json.dump(params, f, ensure_ascii=False, indent=2)

            logger.debug("üìù –ü–∞—Ä–∞–º–µ—Ç—Ä %s –æ–±–Ω–æ–≤–ª–µ–Ω –≤ %s", parameter_name, optimized_params_file)
            return True

        except (IOError, OSError, json.JSONDecodeError, TypeError) as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ %s: %s", parameter_name, e)
            return False

    def _analyze_indicator_performance(self, indicator_name: str) -> Optional[Dict[str, Any]]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞"""
        try:
            if not self.patterns:
                return None

            successful_patterns = [p for p in self.patterns if p.result == "WIN"]
            if not successful_patterns:
                return None

            # –ê–Ω–∞–ª–∏–∑ RSI
            if indicator_name == "RSI":
                rsi_values = []
                for pattern in successful_patterns:
                    if "RSI" in pattern.indicators:
                        rsi_values.append(pattern.indicators["RSI"])

                if rsi_values:
                    avg_rsi = np.mean(rsi_values)
                    return {
                        "best_oversold": max(25, min(35, avg_rsi - 10)),
                        "best_overbought": min(75, max(65, avg_rsi + 10))
                    }

            # –ê–Ω–∞–ª–∏–∑ EMA
            elif indicator_name == "EMA":
                ema_fast_values = []
                ema_slow_values = []
                for pattern in successful_patterns:
                    if "EMA_Fast" in pattern.indicators:
                        ema_fast_values.append(pattern.indicators["EMA_Fast"])
                    if "EMA_Slow" in pattern.indicators:
                        ema_slow_values.append(pattern.indicators["EMA_Slow"])

                if ema_fast_values and ema_slow_values:
                    return {
                        "best_fast": max(10, min(30, int(np.mean(ema_fast_values)))),
                        "best_slow": max(40, min(60, int(np.mean(ema_slow_values))))
                    }

            return None

        except (KeyError, TypeError, ValueError, AttributeError) as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ %s: %s", indicator_name, e)
            return None

    def _analyze_market_conditions(self) -> Optional[Dict[str, Any]]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π"""
        try:
            if not self.patterns:
                return None

            successful_patterns = [p for p in self.patterns if p.result == "WIN"]
            if not successful_patterns:
                return None

            # –ê–Ω–∞–ª–∏–∑ BTC —Ç—Ä–µ–Ω–¥–∞
            btc_trends = {}
            volume_classes = {}

            for pattern in successful_patterns:
                if "BTC_Trend" in pattern.market_conditions:
                    trend = pattern.market_conditions["BTC_Trend"]
                    btc_trends[trend] = btc_trends.get(trend, 0) + 1

                if "Volume_Class" in pattern.market_conditions:
                    volume_class = pattern.market_conditions["Volume_Class"]
                    volume_classes[volume_class] = volume_classes.get(volume_class, 0) + 1

            result = {}
            if btc_trends:
                best_btc_trend = max(btc_trends, key=btc_trends.get)
                result["best_btc_trend"] = best_btc_trend

            if volume_classes:
                best_volume = max(volume_classes, key=volume_classes.get)
                result["best_volume"] = best_volume

            return result if result else None

        except (KeyError, TypeError, AttributeError) as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π: %s", e)
            return None

    def _analyze_time_performance(self) -> Optional[Dict[str, Any]]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ –≤—Ä–µ–º–µ–Ω–∏"""
        try:
            if not self.patterns:
                return None

            successful_patterns = [p for p in self.patterns if p.result == "WIN"]
            if not successful_patterns:
                return None

            # –ê–Ω–∞–ª–∏–∑ –ø–æ —á–∞—Å–∞–º
            hour_performance = {}
            for pattern in successful_patterns:
                hour = pattern.timestamp.hour
                hour_performance[hour] = hour_performance.get(hour, 0) + 1

            if hour_performance:
                # –ù–∞—Ö–æ–¥–∏–º 3 –ª—É—á—à–∏—Ö —á–∞—Å–∞
                best_hours = sorted(hour_performance, key=hour_performance.get, reverse=True)[:3]
                return {"best_hours": best_hours}

            return None

        except (AttributeError, TypeError) as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤—Ä–µ–º–µ–Ω–∏: %s", e)
            return None

    def _analyze_stop_loss_performance(self) -> Optional[Dict[str, Any]]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å stop-loss"""
        try:
            if not self.patterns:
                return None

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–µ—É–¥–∞—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ SL
            failed_patterns = [p for p in self.patterns if p.result == "LOSS"]
            if not failed_patterns:
                return None

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ä–µ–¥–Ω–∏–µ –ø–æ—Ç–µ—Ä–∏
            losses = [abs(p.profit_pct) for p in failed_patterns if p.profit_pct is not None]
            if losses:
                avg_loss = np.mean(losses)
                # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π SL –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –º–µ–Ω—å—à–µ —Å—Ä–µ–¥–Ω–µ–≥–æ —É–±—ã—Ç–∫–∞
                optimal_sl = max(1.0, min(3.0, avg_loss * 0.8))
                return {"best_sl_pct": optimal_sl}

            return None

        except (AttributeError, TypeError, ValueError) as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ stop-loss: %s", e)
            return None

    def generate_learning_report(self) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –æ–± –æ–±—É—á–µ–Ω–∏–∏"""
        report = f"""
ü§ñ –û–¢–ß–ï–¢ –û–ë –û–ë–£–ß–ï–ù–ò–ò –ò–ò –°–ò–°–¢–ï–ú–´
{'='*50}

üìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:
‚Ä¢ –í—Å–µ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {self.metrics.total_patterns}
‚Ä¢ –£—Å–ø–µ—à–Ω—ã—Ö: {self.metrics.successful_patterns}
‚Ä¢ –ù–µ—É–¥–∞—á–Ω—ã—Ö: {self.metrics.failed_patterns}
‚Ä¢ –¢–æ—á–Ω–æ—Å—Ç—å: {self.metrics.accuracy:.1%}
‚Ä¢ Profit Factor: {self.metrics.profit_factor:.2f}

üîç –ê–ù–ê–õ–ò–ó –ü–ê–¢–¢–ï–†–ù–û–í:
"""

        analysis = self.analyze_patterns()
        if analysis.get("success_rates"):
            report += "\nüìà –õ–£–ß–®–ò–ï –°–ò–ú–í–û–õ–´:\n"
            for symbol, rate in sorted(analysis["success_rates"].items(),
                                     key=lambda x: x[1], reverse=True)[:5]:
                report += f"‚Ä¢ {symbol}: {rate:.1%}\n"

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        recommendations = self.get_learning_recommendations()
        if recommendations:
            report += "\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:\n"
            for rec in recommendations:
                report += f"‚Ä¢ {rec}\n"

        return report

    async def continuous_learning(self):
        """–ù–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã"""
        logger.info("üîÑ –ó–∞–ø—É—Å–∫ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è...")

        while True:
            try:
                # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
                validation = self.validate_system_data()
                if validation["errors"]:
                    logger.warning("‚ö†Ô∏è –ù–∞–π–¥–µ–Ω—ã –æ—à–∏–±–∫–∏: %s", validation['errors'])

                # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
                optimization = self.auto_optimize_parameters()
                if optimization["improvements"]:
                    logger.info("üîß –£–ª—É—á—à–µ–Ω–∏—è: %s", optimization['improvements'])

                # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
                if optimization.get("parameter_changes"):
                    logger.info("ü§ñ –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã...")
                    applied = self.apply_optimized_parameters(optimization)
                    if applied:
                        logger.info("‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —É—Å–ø–µ—à–Ω–æ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã!")
                    else:
                        logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–º–µ–Ω–∏—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã")

                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
                self.save_patterns()
                self.save_learning_model()
                self.save_metrics()

                # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
                self.generate_learning_report()
                logger.info("üìä –û—Ç—á–µ—Ç –æ–± –æ–±—É—á–µ–Ω–∏–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω")

                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Ü–∏–∫–ª–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è
                await asyncio.sleep(3600)  # 1 —á–∞—Å

            except (IOError, OSError, KeyError, TypeError, ValueError) as e:
                logger.error("‚ùå –û—à–∏–±–∫–∞ –≤ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏: %s", e)
                await asyncio.sleep(300)  # 5 –º–∏–Ω—É—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–∏—Å—Ç–µ–º—ã –æ–±—É—á–µ–Ω–∏—è
ai_learning = AILearningSystem()

async def start_ai_learning():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Å–∏—Å—Ç–µ–º—É –æ–±—É—á–µ–Ω–∏—è –ò–ò"""
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã –æ–±—É—á–µ–Ω–∏—è –ò–ò...")
    await ai_learning.continuous_learning()

if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã
    print("ü§ñ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –æ–±—É—á–µ–Ω–∏—è –ò–ò...")

    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω
    test_pattern = TradingPattern(
        symbol="BTCUSDT",
        timestamp=datetime.now(timezone.utc),
        signal_type="LONG",
        entry_price=50000.0,
        tp1=51000.0,
        tp2=52000.0,
        risk_pct=2.0,
        leverage=1.0,
        indicators={"RSI": 45.0, "EMA7": 50000.0, "BB_upper": 51000.0},
        market_conditions={"BTC_trend": "BULLISH", "volume": "HIGH"},
        result="WIN",
        profit_pct=2.0
    )

    # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω
    ai_learning.add_pattern(test_pattern)

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
    test_report = ai_learning.generate_learning_report()
    print(test_report)
