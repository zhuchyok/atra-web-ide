# ‚úÖ GLM-4.7-Flash –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è

**–î–∞—Ç–∞:** 2026-01-27  
**–ú–æ–¥–µ–ª—å:** `glm-4.7-flash`  
**–°—Ç–∞—Ç—É—Å:** ‚úÖ **–ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–û**

---

## üöÄ –ú–æ–¥–µ–ª—å

**GLM-4.7-Flash** - –º–æ—â–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –∫–æ–¥–∏–Ω–≥–∞ –∏ reasoning:
- **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:** 30B-A3B Mixture of Experts (MoE), 29.9B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- **–†–∞–∑–º–µ—Ä:** ~19GB (Q4_K_M)
- **Context:** 198K tokens
- **SWE-bench:** 59.2 (–ª—É—á—à–µ —á–µ–º Qwen3-30B-A3B: 22.0 –∏ GPT-OSS-20B: 34.0)
- **œÑ¬≤-Bench:** 79.5
- **–ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π cloud code** - –æ—Ç–ª–∏—á–Ω–∞—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ –ø–ª–∞—Ç–Ω—ã–º —Å–µ—Ä–≤–∏—Å–∞–º

---

## ‚úÖ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è

### 1. `knowledge_os/app/local_router.py`

**OLLAMA_MODELS:**
- ‚úÖ `"coding": "glm-4.7-flash"` - —Ç–æ–ø –º–æ–¥–µ–ª—å –¥–ª—è –∫–æ–¥–∏–Ω–≥–∞
- ‚úÖ `"reasoning": "glm-4.7-flash"` - –º–æ—â–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è reasoning

**MODEL_MAP:**
- ‚úÖ `"coding": "glm-4.7-flash"` - –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è coding –∑–∞–¥–∞—á
- ‚úÖ `"reasoning": "glm-4.7-flash"` - –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è reasoning –∑–∞–¥–∞—á

### 2. `knowledge_os/app/extended_thinking.py`

**Fallback –º–æ–¥–µ–ª–∏:**
- ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ `glm-4.7-flash` –≤ –Ω–∞—á–∞–ª–æ –≤—Å–µ—Ö fallback —Å–ø–∏—Å–∫–æ–≤
- ‚úÖ –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö –∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –¥—Ä—É–≥–∏—Ö –º–æ–¥–µ–ª–µ–π

### 3. `backend/app/services/ollama.py`

**MODELS:**
- ‚úÖ `"coding": "glm-4.7-flash"` - –≤–º–µ—Å—Ç–æ qwen2.5-coder:32b
- ‚úÖ `"reasoning": "glm-4.7-flash"` - –≤–º–µ—Å—Ç–æ deepseek-r1-distill-llama:70b

**CLAUDE_CODE_MODELS:**
- ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ `glm-4.7-flash` –≤ –Ω–∞—á–∞–ª–æ —Å–ø–∏—Å–∫–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

---

## üìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä

–°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–µ—Ä–µ—Ç `glm-4.7-flash` –¥–ª—è:
- ‚úÖ **Coding –∑–∞–¥–∞—á–∏** - –ª—É—á—à–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ SWE-bench (59.2)
- ‚úÖ **Reasoning –∑–∞–¥–∞—á–∏** - –º–æ—â–Ω–∞—è 30B MoE –º–æ–¥–µ–ª—å —Å 198K context
- ‚úÖ **Fallback** - –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –¥—Ä—É–≥–∏—Ö –º–æ–¥–µ–ª–µ–π

### –†—É—á–Ω–æ–π –≤—ã–±–æ—Ä

```python
# –í –∫–æ–¥–µ –º–æ–∂–Ω–æ —è–≤–Ω–æ —É–∫–∞–∑–∞—Ç—å
model = "glm-4.7-flash"
```

---

## üéØ –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞

1. **–¢–æ–ø –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å** - SWE-bench: 59.2 (–ª—É—á—à–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤)
2. **–ë–æ–ª—å—à–æ–π context** - 198K tokens –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
3. **–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å** - 30B MoE –º–æ–¥–µ–ª—å, –Ω–æ —Ç–æ–ª—å–∫–æ ~19GB
4. **–ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π** - —Ä–∞–±–æ—Ç–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ —á–µ—Ä–µ–∑ Ollama
5. **Cloud code** - –æ—Ç–ª–∏—á–Ω–∞—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ –ø–ª–∞—Ç–Ω—ã–º —Å–µ—Ä–≤–∏—Å–∞–º

---

## üìù –ü—Ä–∏–º–µ—á–∞–Ω–∏—è

- –ú–æ–¥–µ–ª—å —Å–∫–∞—á–∏–≤–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ `ollama pull glm-4.7-flash` (~19GB)
- –¢—Ä–µ–±—É–µ—Ç—Å—è Ollama 0.14.3 –∏–ª–∏ –Ω–æ–≤–µ–µ
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è coding –∏ reasoning –∑–∞–¥–∞—á
- –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –≤ fallback —Å–ø–∏—Å–∫–∞—Ö

---

## ‚úÖ –°—Ç–∞—Ç—É—Å

**–í—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –æ–±–Ω–æ–≤–ª–µ–Ω—ã!** üéâ

–ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ —á–µ—Ä–µ–∑ `ollama pull`.
