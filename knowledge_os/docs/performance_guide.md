# Performance Guide

Подробное руководство по оптимизации производительности для:
- PostgreSQL
- Загрузки и обработки больших объёмов данных
- Rust
- Python и async‑кодa
- Бэктестинга и торговых стратегий
- Оптимизаций на уровне ОС и инфраструктуры

Высокоуровневые правила см. в `.cursor/rules/performance.mdc`.  
Этот файл — детальный справочник и чек‑лист.

---

## 1. PostgreSQL: базовые и критичные практики

### 1.1. Партиционирование по времени (обязательно)

1. Все таблицы с временными рядами должны быть **партиционированы по годам**:
   - `PARTITION BY RANGE (time)` или аналогичная схема.
   - Партиции создаются заранее (например, 2020–2026+).

2. Запросы должны быть написаны так, чтобы PostgreSQL мог применять **partition pruning**:
   - Проверять через `EXPLAIN ANALYZE`, что выбираются только нужные партиции.

---

### 1.2. Суррогатные ключи для временных меток

1. Для всех временных меток добавить поле:
   - `time_surrogate INTEGER = EXTRACT(EPOCH FROM time)::INTEGER`.

2. Использовать `time_surrogate`:
   - В фильтрах и индексах вместо `time`, когда это возможно.
   - Преимущества:
     - Ускорение на ~20–40%.
     - Экономия места на ~30–60%.

---

### 1.3. Индексы

1. **Покрывающие индексы (INCLUDE)**:
   - Создавать для часто запрашиваемых колонок.
   - Цель — **Index Only Scan** без обращения к основной таблице.

2. **BRIN‑индексы**:
   - Для больших, упорядоченных по времени таблиц (>100MB).
   - Эффективны для временных рядов, где данные добавляются в хронологическом порядке.

3. **Частичные индексы**:
   - Индексы только на приоритетные таймфреймы или подмножества данных.
   - Снижение размера индексов → быстрее обновления и запросы.

4. Регулярный аудит индексов:
   - Через `pg_stat_user_indexes`, `pg_stat_all_indexes`.
   - Удалять неиспользуемые индексы.

---

### 1.4. CHECK‑ограничения

- Использовать CHECK‑constraints на уровне БД для:
  - Валидности OHLC‑данных, объёмов, диапазонов цен.
- Любая ошибка валидации должна приводить к исключению:
  - Предотвращение попадания “грязных” данных в систему.

---

### 1.5. COPY и массовая загрузка

1. **COPY в бинарном формате**:
   - Использовать `COPY FROM STDIN BINARY` для массовой загрузки.
   - В 10–100x быстрее, чем множественные INSERT.
   - На 20–30% быстрее текстового COPY.

2. Рекомендуемый паттерн:
   - Загрузка во временную/UNLOGGED таблицу.
   - Валидация/преобразование.
   - Перенос данных в основную таблицу (INSERT SELECT / ATTACH PARTITION).

---

### 1.6. UNLOGGED таблицы

- Для временной массовой загрузки:
  - Использовать **UNLOGGED** таблицы.
  - Ускорение на 20–30% за счёт отсутствия записи в WAL.
- После загрузки:
  - Переносить данные в основную логируемую таблицу.

---

### 1.7. Prepared Statements

- Для повторяющихся запросов:
  - Использовать подготовленные выражения (prepared statements).
  - Ускорение ~10–20% за счёт отсутствия повторного парсинга/планирования.

---

### 1.8. Настройка PostgreSQL

Рекомендуемые параметры (ориентировочно, далее тюнинг по профилю нагрузки):

- `shared_buffers ≈ 25–30% RAM`
- `work_mem` увеличен для аналитических запросов (например, до 512MB, но учитывать количество параллельных запросов)
- `maintenance_work_mem ≈ 2GB` (для VACUUM/CREATE INDEX)
- `effective_cache_size ≈ 75% RAM`
- `max_parallel_workers_per_gather` ≥ 4
- `enable_partitionwise_aggregate = on`
- `enable_partitionwise_join = on`
- `jit = on` для сложных запросов

---

### 1.9. fillfactor

- Для всех таблиц и индексов:
  - `fillfactor = 90`.
- Цель:
  - Уменьшить фрагментацию.
  - Поддерживать HOT‑updates.

---

### 1.10. Параллельные запросы

- Включить и использовать параллельные запросы для больших таблиц:
  - Контроль через `max_parallel_workers_per_gather` и связанные параметры.
- Проверять использование параллельных планов через `EXPLAIN ANALYZE`.

---

## 2. Дополнительные оптимизации PostgreSQL

### 2.1. Cжатие и архивирование старых данных

- Старые партиции:
  - Сжимать.
  - Переносить в отдельное хранилище/таблицы, если нужны только агрегаты.

---

### 2.2. Материализованные представления

- Для тяжёлых аналитических запросов:
  - Использовать MATERIALIZED VIEW.
  - Обновление по расписанию (off‑peak).

---

### 2.3. Анализ медленных запросов

- Все запросы > 1 секунды:
  - Анализировать через `EXPLAIN ANALYZE`.
  - Логировать через `pg_stat_statements`.

---

### 2.4. Мониторинг индексов и статистики

- Регулярный анализ:
  - `pg_stat_user_indexes`, `pg_stat_all_tables`.
- Настройка:
  - `default_statistics_target` и/или per‑column statistics target.

---

### 2.5. JIT‑компиляция

- Включать JIT:
  - Для сложных запросов с высокой стоимостью (cost > 100000).
- Настраивать глобально или per‑query при необходимости.

---

### 2.6. TimescaleDB (опционально)

- Для time‑series и агрегаций:
  - Рассмотреть TimescaleDB (hypertables, continuous aggregates).
- Только если профит оправдывает усложнение инфраструктуры.

---

## 3. Продвинутые оптимизации Rust

### 3.1. Профилирование и флаги компиляции

- Использовать:
  - Release сборки (`opt-level = 3`).
  - `codegen-units = 1` для максимальной оптимизации.
  - Link Time Optimization (LTO) — даёт +5–15% производительности.
- Profile‑guided optimization (PGO):
  - Сбор профильных данных.
  - Пересборка с PGO даёт +10–30%.

---

### 3.2. Память и кеш

- Оптимизация:
  - Выравнивание структур.
  - Минимизация аллокаций.
  - Работа с данными по cache‑friendly паттернам (последовательный доступ).

---

### 3.3. SIMD

- Для больших массивов и векторных операций:
  - Использовать SIMD‑инструкции (через crates или std::simd).
  - Потенциальное ускорение — до порядков (в зависимости от задачи).

---

### 3.4. Zero‑copy и сериализация

- Zero‑copy serialization/deserialization там, где это возможно:
  - Особенно при работе с PostgreSQL COPY и большими массивами.

---

### 3.5. Аллокаторы

- Сравнить:
  - Стандартный аллокатор vs `jemalloc` (или другой).
  - Возможное ускорение 5–15% в некоторых профилях нагрузки.

---

### 3.6. Feature flags

- Использовать feature flags:
  - Для отключения ненужного функционала.
  - Снижения размера бинарника и поверхности кода.

---

## 4. Продвинутые оптимизации Python и async

### 4.1. asyncio и event loop

- Использовать **uvloop** для asyncio:
  - Ускорение event‑loop на 2–4x относительно стандартного.

---

### 4.2. Batching и gather

- Для I/O‑операций:
  - Использовать `asyncio.gather` для batch‑операций.
  - Не вызывать внешние ресурсы по одному элементу, а пакетами.

---

### 4.3. Размер batch‑ов

- Типичный диапазон:
  - 100–1000 элементов в батче (подбирать экспериментально под задачу).
- Баланс:
  - Слишком маленький — много оверхеда.
  - Слишком большой — всплески памяти и latency.

---

### 4.4. Async‑генераторы

- Для больших потоков данных:
  - Использовать async‑генераторы для **memory‑efficient streaming**.
  - Избегать загрузки всего набора данных в память.

---

## 5. Продвинутые практики PostgreSQL (детали)

### 5.1. Query plan cache / prepared statement reuse

- Активно переиспользовать подготовленные запросы:
  - Уменьшение парсинга/планирования.
  - Стабильность планов.

---

### 5.2. Параллельные index scan

- Для больших таблиц:
  - Параллельные сканы индексов дают ускорение 2–4x.
  - Настройка через параметры параллелизма.

---

### 5.3. Соединение и pooling

- Использовать connection pooling (PgBouncer и т.п.).
- Настроить:
  - TCP keepalives.
  - Ограничения на количество одновременных соединений.

---

### 5.4. Streaming результатов

- Для больших выборок:
  - Использовать курсоры и streaming результата.
  - Избегать вытаскивания всего результата сразу.

---

### 5.5. AQO и статистика

- Adaptive Query Optimization (если используется):
  - Может дать +10–70% для сложных запросов.
- Настройка:
  - `constraint_exclusion`, `statistics_target` и пр.

---

### 5.6. TOAST и сжатие

- Контроль:
  - Использование TOAST‑механизмов.
  - Возможность настройки/оптимизации сжатия для большого текста/JSON.

---

## 6. Оптимизация загрузки данных

### 6.1. Индексы при массовой загрузке

- На время очень больших загрузок:
  - Отключать/удалять индексы, затем пересоздавать.
  - Ускорение 50–90%.

---

### 6.2. Транзакции

- Управление транзакциями:
  - Группировать операции.
  - Не делать одну огромную транзакцию на миллионы строк, а разбивать.

---

### 6.3. Chunking

- Для очень больших датасетов:
  - Делить на чанки (например, по 10 000 записей или по дням/месяцам).
  - Баланс между скоростью и использованием памяти.

---

### 6.4. WAL‑настройки для загрузки

- Для bulk‑операций:
  - Тюнинг параметров WAL, checkpoint’ов.
  - Возможное ускорение 20–30%.

---

## 7. Оптимизации на уровне ОС и инфраструктуры

### 7.1. Дисковая подсистема

- SSD / NVMe.
- RAID 10 для комбинации скорости и надёжности.
- Разделение:
  - data / WAL / индексы — по разным дискам (при необходимости).

---

### 7.2. CPU и планировщик

- Отключение агрессивных режимов энергосбережения на прод‑серверах.
- Возможное использование `taskset` для пиннинга процессов к ядрам.

---

## 8. Дополнительные техники

### 8.1. Временные таблицы

- Для сложных цепочек запросов:
  - Временные таблицы могут дать ускорение 20–40%.

---

### 8.2. Архивация старых данных

- Архивирование и удаление неактуальных данных:
  - Снижение размеров таблиц на 30–80%.
  - Ускорение запросов по “живому” набору.

---

### 8.3. Кеширование на уровне приложения

- Использование кэша (например, Redis):
  - Снижение нагрузки на БД на 50–90% для часто запрашиваемых данных.

---

### 8.4. Мониторинг bloat

- Регулярно:
  - Проверять bloat таблиц и индексов.
  - Планировать VACUUM/REINDEX.

---

### 8.5. PgBouncer и application_name

- PgBouncer:
  - Для connection pooling.
- `application_name`:
  - Для трассировки запросов по сервисам/ролям.

---

## 9. Процесс оптимизации и критерии успеха

### 9.1. Процесс

1. **Измерение**  
   - Всегда измерять производительность до оптимизаций.

2. **Профилирование**  
   - Использовать специализированные инструменты:
     - Rust: `perf`, `flamegraph`, `cargo bench`.
     - Python: `cProfile`, `py-spy`, `memory_profiler`.
     - PostgreSQL: `EXPLAIN ANALYZE`, `pg_stat_statements`, `pg_stat_user_indexes`.

3. **Итеративность**  
   - Вносить изменения по одному.
   - После каждого изменения — повторное измерение.

4. **Документирование**  
   - Фиксировать:
     - Какие оптимизации применены.
     - Какой был эффект (до/после).

---

### 9.2. Целевые критерии (для ориентиров)

**Производительность:**

- Загрузка 4 лет данных (1 тикер, 15m) — **< 3 секунд**.
- Бэктест на 4 года данных (15m) — **< 20 секунд**.
- Загрузка всех тикеров (64 инструмента, 15m) — **< 3 минут**.

**Надёжность:**

- 0 ошибок валидации данных.
- 100% покрытие retry для временных ошибок.
- 0 потерь данных при загрузке (после валидации).

---