"""
Knowledge Applicator ‚Äî –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∏–∑—É—á–µ–Ω–Ω—ã—Ö –∑–Ω–∞–Ω–∏–π –∫ –∫–æ—Ä–ø–æ—Ä–∞—Ü–∏–∏ (Singularity 10.0)

–ü—Ä–∏–º–µ–Ω—è–µ—Ç:
1. Lessons learned ‚Üí guidance (.cursorrules –∏–ª–∏ –ø—Ä–∞–≤–∏–ª–∞)
2. –†–µ—Ç—Ä–æ—Å–ø–µ–∫—Ç–∏–≤—ã ‚Üí knowledge_nodes (–∏–∑ interaction_logs —Å feedback)
3. –ù–æ–≤—ã–µ –∑–Ω–∞–Ω–∏—è ‚Üí —ç–≤–æ–ª—é—Ü–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤ (—Ç–æ–ø-–∏–Ω—Å–∞–π—Ç—ã –∏–∑ knowledge_nodes)
4. Lessons/–∏–Ω—Å–∞–π—Ç—ã —Å –∫–æ–¥-—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å—é ‚Üí –∑–∞–¥–∞—á–∏ ¬´–í–Ω–µ–¥—Ä–∏—Ç—å –≤ –∫–æ–¥¬ª (ExpeL-style: insight ‚Üí actionable task)

–ú–∏—Ä–æ–≤—ã–µ –ø—Ä–∞–∫—Ç–∏–∫–∏:
- ExpeL (AAAI 2024): Experience ‚Üí Knowledge Extraction ‚Üí Task Inference; —É –Ω–∞—Å: lessons ‚Üí code_improvement tasks ‚Üí worker.
- BCG 10/20/70: 10% –æ–±—É—á–µ–Ω–∏–µ, 20% –æ–±–º–µ–Ω, 70% –ø—Ä–∞–∫—Ç–∏–∫–∞ ‚Äî –∑–Ω–∞–Ω–∏—è –≤ .cursorrules + –∑–∞–¥–∞—á–∏ –Ω–∞ –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ –≤ –∫–æ–¥.
- Closed-loop: —Ä–µ—Ç—Ä–æ—Å–ø–µ–∫—Ç–∏–≤—ã –≤ –ë–î, —É—Ä–æ–∫–∏ –≤ –ø—Ä–∞–≤–∏–ª–∞, –∫–æ–¥-–∏–Ω—Å–∞–π—Ç—ã –≤ –∑–∞–¥–∞—á–∏ –¥–ª—è –≤–æ—Ä–∫–µ—Ä–∞/–∞–≥–µ–Ω—Ç–∞.
"""

from __future__ import annotations

import asyncio
import hashlib
import json
import logging
import os
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any

logger = logging.getLogger(__name__)

try:
    import asyncpg
    ASYNCPG_AVAILABLE = True
except ImportError:
    asyncpg = None
    ASYNCPG_AVAILABLE = False


DB_URL = os.getenv("DATABASE_URL", "postgresql://admin:secret@localhost:5432/knowledge_os")
_PROJECT_ROOT = Path(__file__).resolve().parents[2]
_CURSORRULES_PATHS = [
    _PROJECT_ROOT / ".cursorrules",
    _PROJECT_ROOT.parent / ".cursorrules",
]


async def _apply_lessons_to_guidance(conn: asyncpg.Connection) -> bool:
    """
    Lessons learned –∏–∑ adaptive_learning_logs ‚Üí –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ guidance (.cursorrules).
    –¢–æ–ø-5 –ø–æ impact_score –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –≤ –±–ª–æ–∫ "Lessons Learned".
    """
    try:
        rows = await conn.fetch("""
            SELECT learned_insight, impact_score, learning_type
            FROM adaptive_learning_logs
            WHERE impact_score > 0.5
            ORDER BY impact_score DESC
            LIMIT 5
        """)
        if not rows:
            logger.debug("No high-impact lessons to apply")
            return False

        insights = [r["learned_insight"] for r in rows]
        block = "\n## Lessons Learned (auto-applied)\n\n" + "\n".join(f"- {i}" for i in insights)

        for path in _CURSORRULES_PATHS:
            if path.exists():
                content = path.read_text(encoding="utf-8", errors="replace")
                marker = "## Lessons Learned (auto-applied)"
                if marker in content:
                    start = content.find(marker)
                    end = content.find("\n## ", start + 5)
                    end = end if end > 0 else len(content)
                    new_content = content[:start] + block.rstrip() + "\n" + (content[end:] if end < len(content) else "")
                else:
                    new_content = content.rstrip() + "\n\n" + block + "\n"
                path.write_text(new_content, encoding="utf-8")
                logger.info("Updated guidance at %s with %d lessons", path, len(insights))
                return True
        return False
    except Exception as e:
        logger.warning("apply_lessons_to_guidance: %s", e)
        return False


async def _apply_retrospectives_to_knowledge(conn: asyncpg.Connection) -> bool:
    """
    –†–µ—Ç—Ä–æ—Å–ø–µ–∫—Ç–∏–≤—ã –∏–∑ interaction_logs (feedback_text –ø—Ä–∏ feedback_score) ‚Üí knowledge_nodes.
    –ü–æ–ª—É—á–∞–µ–º domain_id –¥–ª—è "Feedback" –∏–ª–∏ —Å–æ–∑–¥–∞—ë–º, –≤—Å—Ç–∞–≤–ª—è–µ–º –∏–Ω—Å–∞–π—Ç—ã.
    """
    try:
        rows = await conn.fetch("""
            SELECT il.feedback_text, il.feedback_score, il.user_query, il.assistant_response
            FROM interaction_logs il
            WHERE il.feedback_text IS NOT NULL
              AND LENGTH(TRIM(il.feedback_text)) > 10
              AND il.created_at > NOW() - INTERVAL '7 days'
            ORDER BY il.created_at DESC
            LIMIT 10
        """)
        if not rows:
            return False

        domain_id = await conn.fetchval(
            "SELECT id FROM domains WHERE name ILIKE $1", "Feedback"
        )
        if not domain_id:
            await conn.execute(
                "INSERT INTO domains (name, description) VALUES ($1, $2) ON CONFLICT (name) DO NOTHING",
                "Feedback",
                "Lessons from user feedback",
            )
            domain_id = await conn.fetchval(
                "SELECT id FROM domains WHERE name ILIKE $1", "Feedback"
            )

        inserted = 0
        get_embedding_fn = None
        try:
            from semantic_cache import get_embedding as _ge
            get_embedding_fn = _ge
        except Exception:
            try:
                from app.semantic_cache import get_embedding as _ge
                get_embedding_fn = _ge
            except Exception:
                pass
        for r in rows:
            content = f"Feedback (score={r['feedback_score']}): {r['feedback_text']}"
            content_trim = content[:5000]
            metadata = json.dumps({"source": "interaction_logs", "feedback_score": r["feedback_score"]})
            embedding = None
            if get_embedding_fn:
                try:
                    embedding = await get_embedding_fn(content_trim[:8000])
                except Exception:
                    pass
            if embedding is not None:
                await conn.execute("""
                    INSERT INTO knowledge_nodes (domain_id, content, metadata, confidence_score, source_ref, embedding)
                    VALUES ($1, $2, $3::jsonb, 0.7, 'retrospective', $4::vector)
                """, domain_id, content_trim, metadata, str(embedding))
            else:
                await conn.execute("""
                    INSERT INTO knowledge_nodes (domain_id, content, metadata, confidence_score, source_ref)
                    VALUES ($1, $2, $3::jsonb, 0.7, 'retrospective')
                """, domain_id, content_trim, metadata)
            inserted += 1

        if inserted > 0:
            logger.info("Inserted %d retrospectives into knowledge_nodes", inserted)
            return True
        return False
    except Exception as e:
        logger.warning("apply_retrospectives_to_knowledge: %s", e)
        return False


async def _evolve_prompts_from_insights(conn: asyncpg.Connection) -> bool:
    """
    –¢–æ–ø-–∏–Ω—Å–∞–π—Ç—ã –∏–∑ knowledge_nodes ‚Üí –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —ç–≤–æ–ª—é—Ü–∏–∏ –ø—Ä–æ–º–ø—Ç–æ–≤.
    –°–æ–∑–¥–∞—ë—Ç –∑–∞–¥–∞—á–∏ (tasks) –¥–ª—è Prompt Engineer –∏–ª–∏ –ø–∏—à–µ—Ç –≤ staging.
    –†–µ–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–æ–≤ ‚Äî —á–µ—Ä–µ–∑ enhanced_expert_evolver –∏–ª–∏ human review.
    """
    try:
        rows = await conn.fetch("""
            SELECT k.content, k.confidence_score, d.name as domain_name
            FROM knowledge_nodes k
            LEFT JOIN domains d ON k.domain_id = d.id
            WHERE k.is_verified = true
               OR k.confidence_score > 0.8
            ORDER BY k.confidence_score DESC, k.created_at DESC
            LIMIT 5
        """)
        if not rows:
            return False

        # –°–æ–∑–¥–∞—ë–º –∑–∞–¥–∞—á—É –¥–ª—è Prompt Engineer –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–æ–ø-–∏–Ω—Å–∞–π—Ç–æ–≤
        insight_summary = "\n".join(f"- [{r['domain_name']}] {r['content'][:200]}..." for r in rows)
        title = "Prompt evolution from top insights"
        description = f"Apply these verified insights to expert prompts:\n\n{insight_summary[:2000]}"

        metadata = json.dumps({
            "source": "knowledge_applicator",
            "insights_count": len(rows),
            "assignee_hint": "Prompt Engineer",
        })
        await conn.execute("""
            INSERT INTO tasks (title, description, status, priority, metadata)
            VALUES ($1, $2, 'pending', 'medium', $3::jsonb)
        """, title, description, metadata)

        logger.info("Created prompt evolution task with %d insights", len(rows))
        return True
    except Exception as e:
        logger.warning("evolve_prompts_from_insights: %s", e)
        return False


# –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è ¬´–∫–æ–¥-—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö¬ª —É—Ä–æ–∫–æ–≤ (ExpeL: –∏–∑–≤–ª–µ–∫–∞–µ–º—ã–µ –∏–Ω—Å–∞–π—Ç—ã ‚Üí actionable code tasks)
_CODE_RELEVANT_KEYWORDS = (
    "–∫–æ–¥", "code", "—Ç–µ—Å—Ç", "test", "api", "–≤–∞–ª–∏–¥–∞—Ü", "validation", "–æ—à–∏–±–∫", "error",
    "—Ñ–∞–π–ª", "file", "–º–æ–¥—É–ª—å", "module", "—Ñ—É–Ω–∫—Ü–∏", "function", "–∫–ª–∞—Å—Å", "class",
    "–±–∞–∑–∞", "database", "–∑–∞–ø—Ä–æ—Å", "query", "–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç", "security", "–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç",
    "async", "—Ç–∞–π–º–∞—É—Ç", "timeout", "retry", "–ø–æ–≤—Ç–æ—Ä", "–ª–æ–≥–∏—Ä–æ–≤–∞–Ω", "log",
)


def _is_code_relevant(text: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞, –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –ª–∏ —É—Ä–æ–∫/–∏–Ω—Å–∞–π—Ç –∫ –∫–æ–¥—É –∏–ª–∏ –ø—Ä–∞–∫—Ç–∏–∫–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏."""
    if not text or len(text) < 15:
        return False
    lower = text.lower()
    return any(kw in lower for kw in _CODE_RELEVANT_KEYWORDS)


async def _create_code_improvement_tasks(conn: asyncpg.Connection) -> bool:
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á ¬´–í–Ω–µ–¥—Ä–∏—Ç—å –≤ –∫–æ–¥¬ª –∏–∑ —É—Ä–æ–∫–æ–≤ –∏ –≤–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–Ω—Å–∞–π—Ç–æ–≤ (ExpeL-style closed loop).
    –í—ã—Å–æ–∫–æ-–∏–º–ø–∞–∫—Ç–Ω—ã–µ lessons –∏ –∫–æ–¥-—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ knowledge_nodes ‚Üí tasks —Å assignee_hint Backend/QA/DevOps.
    """
    try:
        created = 0
        # 1) Lessons –∏–∑ adaptive_learning_logs (–∫–æ–¥-—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ, –≤—ã—Å–æ–∫–∏–π impact)
        rows = await conn.fetch("""
            SELECT learned_insight, impact_score, learning_type
            FROM adaptive_learning_logs
            WHERE impact_score > 0.5
            ORDER BY impact_score DESC
            LIMIT 10
        """)
        for r in rows:
            insight = (r["learned_insight"] or "").strip()
            if not _is_code_relevant(insight):
                continue
            # –ù–µ —Å–æ–∑–¥–∞—ë–º –¥—É–±–ª–∏–∫–∞—Ç –ø–æ —Ç–æ–º—É –∂–µ —É—Ä–æ–∫—É
            exists = await conn.fetchval("""
                SELECT 1 FROM tasks
                WHERE metadata->>'source' = 'knowledge_applicator_code_improvement'
                  AND description LIKE $1
                  AND status NOT IN ('completed', 'cancelled')
                  AND created_at > NOW() - INTERVAL '14 days'
                LIMIT 1
            """, insight[:80] + "%")
            if exists:
                continue
            domain_id = await conn.fetchval(
                "SELECT id FROM domains WHERE name IN ('Engineering', 'Backend', 'QA', 'DevOps') LIMIT 1"
            )
            if not domain_id:
                domain_id = await conn.fetchval("SELECT id FROM domains LIMIT 1")
            victoria_id = await conn.fetchval("SELECT id FROM experts WHERE name = '–í–∏–∫—Ç–æ—Ä–∏—è' LIMIT 1")
            meta = json.dumps({
                "source": "knowledge_applicator_code_improvement",
                "assignee_hint": "Backend Developer",
                "lesson_impact": r["impact_score"],
                "learning_type": r.get("learning_type"),
            })
            await conn.execute("""
                INSERT INTO tasks (title, description, status, priority, domain_id, creator_expert_id, metadata)
                VALUES ($1, $2, 'pending', 'medium', $3, $4, $5::jsonb)
            """, "üîß –í–Ω–µ–¥—Ä–∏—Ç—å –≤ –∫–æ–¥: —É—Ä–æ–∫ –∏–∑ –æ–±—É—á–µ–Ω–∏—è", insight[:3000], domain_id, victoria_id, meta)
            created += 1
            if created >= 3:
                break

        # 2) –í–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–Ω—Å–∞–π—Ç—ã –∏–∑ knowledge_nodes (–∫–æ–¥-—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ)
        if created < 3:
            kn_rows = await conn.fetch("""
                SELECT k.id, k.content, k.confidence_score, d.name as domain_name
                FROM knowledge_nodes k
                LEFT JOIN domains d ON k.domain_id = d.id
                WHERE (k.is_verified = true OR k.confidence_score > 0.85)
                  AND k.created_at > NOW() - INTERVAL '30 days'
                ORDER BY k.confidence_score DESC, k.created_at DESC
                LIMIT 15
            """)
            for r in kn_rows:
                content = (r["content"] or "").strip()
                if not _is_code_relevant(content) or len(content) < 20:
                    continue
                exists = await conn.fetchval("""
                    SELECT 1 FROM tasks
                    WHERE metadata->>'source' = 'knowledge_applicator_code_improvement'
                      AND description LIKE $1
                      AND status NOT IN ('completed', 'cancelled')
                      AND created_at > NOW() - INTERVAL '7 days'
                    LIMIT 1
                """, content[:100] + "%")
                if exists:
                    continue
                domain_id = await conn.fetchval(
                    "SELECT id FROM domains WHERE name = $1", r["domain_name"] or "Engineering"
                )
                if not domain_id:
                    domain_id = await conn.fetchval("SELECT id FROM domains LIMIT 1")
                victoria_id = await conn.fetchval("SELECT id FROM experts WHERE name = '–í–∏–∫—Ç–æ—Ä–∏—è' LIMIT 1")
                meta = json.dumps({
                    "source": "knowledge_applicator_code_improvement",
                    "assignee_hint": "Backend Developer",
                    "knowledge_node_id": r["id"],
                })
                await conn.execute("""
                    INSERT INTO tasks (title, description, status, priority, domain_id, creator_expert_id, metadata)
                    VALUES ($1, $2, 'pending', 'medium', $3, $4, $5::jsonb)
                """, "üîß –í–Ω–µ–¥—Ä–∏—Ç—å –≤ –∫–æ–¥: –∏–Ω—Å–∞–π—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π", content[:3000], domain_id, victoria_id, meta)
                created += 1
                if created >= 5:
                    break

        if created > 0:
            logger.info("Created %d code improvement task(s) from lessons/insights", created)
            return True
        return False
    except Exception as e:
        logger.warning("create_code_improvement_tasks: %s", e)
        return False


async def _apply_all_knowledge_async() -> Dict[str, bool]:
    if not ASYNCPG_AVAILABLE:
        logger.warning("asyncpg not available, skipping knowledge application")
        return {"guidance_updated": False, "knowledge_base_updated": False, "prompts_evolved": False, "code_tasks_created": False}

    conn = await asyncpg.connect(DB_URL)
    try:
        guidance_updated = await _apply_lessons_to_guidance(conn)
        knowledge_base_updated = await _apply_retrospectives_to_knowledge(conn)
        prompts_evolved = await _evolve_prompts_from_insights(conn)
        code_tasks_created = await _create_code_improvement_tasks(conn)
        return {
            "guidance_updated": guidance_updated,
            "knowledge_base_updated": knowledge_base_updated,
            "prompts_evolved": prompts_evolved,
            "code_tasks_created": code_tasks_created,
        }
    finally:
        await conn.close()


def apply_all_knowledge() -> Dict[str, bool]:
    """
    –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—ë—Ä—Ç–∫–∞ –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –≤—Å–µ—Ö –∑–Ω–∞–Ω–∏–π.
    –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –∏–∑ scripts/apply_knowledge.py.
    """
    try:
        return asyncio.run(_apply_all_knowledge_async())
    except Exception as e:
        logger.error("apply_all_knowledge failed: %s", e, exc_info=True)
        return {"guidance_updated": False, "knowledge_base_updated": False, "prompts_evolved": False, "code_tasks_created": False}


async def apply_all_knowledge_async() -> Dict[str, bool]:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è –≤—ã–∑–æ–≤–∞ –∏–∑ Nightly Learner.
    """
    try:
        return await _apply_all_knowledge_async()
    except Exception as e:
        logger.error("apply_all_knowledge_async failed: %s", e, exc_info=True)
        return {"guidance_updated": False, "knowledge_base_updated": False, "prompts_evolved": False, "code_tasks_created": False}
