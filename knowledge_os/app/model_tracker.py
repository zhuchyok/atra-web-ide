"""
Model Tracker - ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð¾Ñ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ð½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð² Ð±Ð°Ð·Ñƒ Ð·Ð½Ð°Ð½Ð¸Ð¹
ÐŸÐµÑ€Ð¸Ð¾Ð´Ð¸Ñ‡ÐµÑÐºÐ¸ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸, Ð¾Ñ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°ÐµÑ‚ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ Ð¸ Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÐµÑ‚ Ð±Ð°Ð·Ñƒ Ð·Ð½Ð°Ð½Ð¸Ð¹
"""

import asyncio
import os
import json
import httpx
import asyncpg
from datetime import datetime, timezone
from typing import List, Dict, Optional, Set
import logging
try:
    from .model_notifier import ModelNotifier
except ImportError:
    try:
        from model_notifier import ModelNotifier
    except ImportError:
        # Ð•ÑÐ»Ð¸ ModelNotifier Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½, ÑÐ¾Ð·Ð´Ð°ÐµÐ¼ Ð·Ð°Ð³Ð»ÑƒÑˆÐºÑƒ
        class ModelNotifier:
            def __init__(self, *args, **kwargs):
                pass
            async def notify_new_model(self, *args, **kwargs):
                pass

logger = logging.getLogger(__name__)

DB_URL = os.getenv('DATABASE_URL', 'postgresql://admin:secret@localhost:5432/knowledge_os')
OLLAMA_URL = os.getenv('OLLAMA_BASE_URL', 'http://localhost:11434')
CHECK_INTERVAL = int(os.getenv('MODEL_TRACKER_INTERVAL', '3600'))  # 1 Ñ‡Ð°Ñ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ

class ModelTracker:
    """ÐžÑ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°ÐµÑ‚ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð² Ð±Ð°Ð·Ñƒ Ð·Ð½Ð°Ð½Ð¸Ð¹"""
    
    def __init__(self, db_url: str = DB_URL, ollama_url: str = OLLAMA_URL):
        self.db_url = db_url
        self.ollama_url = ollama_url
        self.last_known_models: Set[str] = set()
        self._running = False
        self.notifier = ModelNotifier(db_url)
    
    async def get_available_models(self) -> List[Dict]:
        """ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑÐ¿Ð¸ÑÐ¾Ðº Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ñ‡ÐµÑ€ÐµÐ· API"""
        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(f"{self.ollama_url}/api/tags")
                if response.status_code == 200:
                    data = response.json()
                    return data.get('models', [])
        except Exception as e:
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹: {e}")
        return []
    
    async def get_model_details(self, model_name: str) -> Optional[Dict]:
        """ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½ÑƒÑŽ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ð¼Ð¾Ð´ÐµÐ»Ð¸"""
        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                # ÐŸÑ€Ð¾Ð±ÑƒÐµÐ¼ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ñ‡ÐµÑ€ÐµÐ· API
                response = await client.get(f"{self.ollama_url}/api/tags")
                if response.status_code == 200:
                    data = response.json()
                    for model in data.get('models', []):
                        if model.get('name') == model_name:
                            return model
        except Exception as e:
            logger.warning(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð´ÐµÑ‚Ð°Ð»ÐµÐ¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸ {model_name}: {e}")
        return None
    
    async def save_model_to_knowledge_base(self, model: Dict, conn: asyncpg.Connection):
        """Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð² Ð±Ð°Ð·Ñƒ Ð·Ð½Ð°Ð½Ð¸Ð¹"""
        model_name = model.get('name', 'unknown')
        size = model.get('size', 0)
        details = model.get('details', {})
        
        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸ÑŽ Ð¼Ð¾Ð´ÐµÐ»Ð¸
        category = self._determine_model_category(model_name, details)
        
        # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚ Ð´Ð»Ñ Ð±Ð°Ð·Ñ‹ Ð·Ð½Ð°Ð½Ð¸Ð¹
        content = f"""ðŸ¤– ÐœÐ¾Ð´ÐµÐ»ÑŒ: {model_name}

ðŸ“Š Ð¥Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸ÐºÐ¸:
- Ð Ð°Ð·Ð¼ÐµÑ€: {self._format_size(size)}
- ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹: {details.get('parameter_size', 'Ð½ÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð¾')}
- Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚: {details.get('format', 'Ð½ÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð¾')}
- ÐšÐ²Ð°Ð½Ñ‚Ð¾Ð²Ð°Ð½Ð¸Ðµ: {details.get('quantization_level', 'Ð½ÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð¾')}
- Ð¡ÐµÐ¼ÐµÐ¹ÑÑ‚Ð²Ð¾: {', '.join(details.get('families', []))}

ðŸŽ¯ ÐÐ°Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ: {category}

ðŸ“… ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾: {datetime.now(timezone.utc).isoformat()}
"""
        
        # ÐœÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ
        metadata = {
            "type": "model",
            "model_name": model_name,
            "size_bytes": size,
            "size_formatted": self._format_size(size),
            "parameter_size": details.get('parameter_size'),
            "format": details.get('format'),
            "quantization_level": details.get('quantization_level'),
            "families": details.get('families', []),
            "category": category,
            "modified_at": model.get('modified_at'),
            "digest": model.get('digest'),
            "last_tracked": datetime.now(timezone.utc).isoformat()
        }
        
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¸Ð»Ð¸ ÑÐ¾Ð·Ð´Ð°ÐµÐ¼ Ð´Ð¾Ð¼ÐµÐ½ "AI Models"
        domain_id = await conn.fetchval("SELECT id FROM domains WHERE name = $1", "AI Models")
        if not domain_id:
            domain_id = await conn.fetchval("INSERT INTO domains (name) VALUES ($1) RETURNING id", "AI Models")
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚ Ð»Ð¸ ÑƒÐ¶Ðµ Ð·Ð°Ð¿Ð¸ÑÑŒ Ð¾Ð± ÑÑ‚Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸
        existing = await conn.fetchrow("""
            SELECT id, metadata FROM knowledge_nodes 
            WHERE domain_id = $1 
            AND content LIKE $2
            ORDER BY created_at DESC
            LIMIT 1
        """, domain_id, f"%ÐœÐ¾Ð´ÐµÐ»ÑŒ: {model_name}%")
        
        if existing:
            # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰ÑƒÑŽ Ð·Ð°Ð¿Ð¸ÑÑŒ
            existing_metadata = existing['metadata'] or {}
            # ÐŸÐ°Ñ€ÑÐ¸Ð¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ð¹ metadata ÐµÑÐ»Ð¸ ÑÑ‚Ð¾ ÑÑ‚Ñ€Ð¾ÐºÐ°
            if isinstance(existing_metadata, str):
                try:
                    existing_metadata = json.loads(existing_metadata)
                except (json.JSONDecodeError, TypeError):
                    existing_metadata = {}
            elif not isinstance(existing_metadata, dict):
                existing_metadata = {}
            
            # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ metadata
            existing_metadata.update(metadata)
            
            await conn.execute("""
                UPDATE knowledge_nodes 
                SET content = $1, 
                    metadata = $2,
                    confidence_score = 1.0,
                    is_verified = TRUE,
                    updated_at = NOW()
                WHERE id = $3
            """, content, json.dumps(existing_metadata), existing['id'])
            
            logger.info(f"âœ… ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð° Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ Ð¼Ð¾Ð´ÐµÐ»Ð¸: {model_name}")
        else:
            # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð½Ð¾Ð²ÑƒÑŽ Ð·Ð°Ð¿Ð¸ÑÑŒ
            await conn.execute("""
                INSERT INTO knowledge_nodes (domain_id, content, metadata, confidence_score, is_verified)
                VALUES ($1, $2, $3, $4, $5)
            """, domain_id, content, json.dumps(metadata), 1.0, True)
            
            logger.info(f"âœ¨ Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð° Ð½Ð¾Ð²Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð² Ð±Ð°Ð·Ñƒ Ð·Ð½Ð°Ð½Ð¸Ð¹: {model_name}")
    
    def _determine_model_category(self, model_name: str, details: Dict) -> str:
        """ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚ÑŒ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸ÑŽ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¸Ð¼ÐµÐ½Ð¸ Ð¸ Ð´ÐµÑ‚Ð°Ð»ÐµÐ¹"""
        name_lower = model_name.lower()
        
        if 'coder' in name_lower or 'code' in name_lower:
            return "Coding - Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° ÐºÐ¾Ð´Ð°"
        elif 'r1' in name_lower or 'reasoning' in name_lower or 'distill' in name_lower:
            return "Reasoning - Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ñ Ð¸ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ"
        elif 'vision' in name_lower or 'dream' in name_lower:
            return "Vision - Ñ€Ð°Ð±Ð¾Ñ‚Ð° Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸ÑÐ¼Ð¸"
        elif 'embed' in name_lower:
            return "Embeddings - Ð²ÐµÐºÑ‚Ð¾Ñ€Ð½Ñ‹Ðµ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ñ"
        elif 'tiny' in name_lower or 'mini' in name_lower:
            return "Fast - Ð±Ñ‹ÑÑ‚Ñ€Ñ‹Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹"
        elif '70b' in name_lower or '104b' in name_lower or 'large' in name_lower:
            return "Complex - ÑÐ»Ð¾Ð¶Ð½Ñ‹Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸, Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ðµ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾"
        elif 'phi' in name_lower or 'qwen' in name_lower:
            return "General - Ð¾Ð±Ñ‰Ð¸Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸"
        else:
            return "General - Ð¾Ð±Ñ‰Ð¸Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸"
    
    def _format_size(self, size_bytes: int) -> str:
        """Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð² Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼Ñ‹Ð¹ Ð²Ð¸Ð´"""
        if size_bytes < 1024:
            return f"{size_bytes} B"
        elif size_bytes < 1024 * 1024:
            return f"{size_bytes / 1024:.1f} KB"
        elif size_bytes < 1024 * 1024 * 1024:
            return f"{size_bytes / (1024 * 1024):.1f} MB"
        else:
            return f"{size_bytes / (1024 * 1024 * 1024):.2f} GB"
    
    async def track_models(self):
        """ÐžÑ‚ÑÐ»ÐµÐ´Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð² Ð±Ð°Ð·Ñƒ Ð·Ð½Ð°Ð½Ð¸Ð¹"""
        try:
            models = await self.get_available_models()
            if not models:
                logger.warning("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹")
                return
            
            current_models = {model.get('name') for model in models if model.get('name')}
            new_models = current_models - self.last_known_models
            removed_models = self.last_known_models - current_models
            
            if new_models:
                logger.info(f"ðŸ†• ÐžÐ±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ñ‹ Ð½Ð¾Ð²Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸: {', '.join(new_models)}")
            
            if removed_models:
                logger.info(f"âš ï¸ ÐœÐ¾Ð´ÐµÐ»Ð¸ ÑƒÐ´Ð°Ð»ÐµÐ½Ñ‹: {', '.join(removed_models)}")
            
            # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð²ÑÐµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð² Ð±Ð°Ð·Ñƒ Ð·Ð½Ð°Ð½Ð¸Ð¹
            conn = await asyncpg.connect(self.db_url)
            try:
                for model in models:
                    await self.save_model_to_knowledge_base(model, conn)
                
                # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ ÑÐ²Ð¾Ð´ÐºÑƒ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ð¹
                if new_models or removed_models:
                    await self._save_changes_summary(conn, new_models, removed_models, current_models)
                
                # Ð£Ð²ÐµÐ´Ð¾Ð¼Ð»ÑÐµÐ¼ Ð¾ Ð½Ð¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÑÑ…
                if new_models:
                    model_details_dict = {m.get('name'): m for m in models if m.get('name') in new_models}
                    await self.notifier.notify_about_new_models(list(new_models), model_details_dict)
                
            finally:
                await conn.close()
            
            self.last_known_models = current_models
            logger.info(f"âœ… ÐžÑ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ð½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾. Ð’ÑÐµÐ³Ð¾ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹: {len(current_models)}")
            
        except Exception as e:
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ñ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ð½Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹: {e}", exc_info=True)
    
    async def _save_changes_summary(self, conn: asyncpg.Connection, new_models: Set[str], 
                                   removed_models: Set[str], current_models: Set[str]):
        """Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ ÑÐ²Ð¾Ð´ÐºÑƒ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ð¹ Ð² Ð±Ð°Ð·Ñƒ Ð·Ð½Ð°Ð½Ð¸Ð¹"""
        summary_content = f"""ðŸ“Š Ð¡Ð²Ð¾Ð´ÐºÐ° Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ð¹ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹

ðŸ†• ÐÐ¾Ð²Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ ({len(new_models)}):
{chr(10).join(f'- {m}' for m in new_models) if new_models else '- ÐÐµÑ‚ Ð½Ð¾Ð²Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹'}

âš ï¸ Ð£Ð´Ð°Ð»ÐµÐ½Ð½Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ ({len(removed_models)}):
{chr(10).join(f'- {m}' for m in removed_models) if removed_models else '- ÐÐµÑ‚ ÑƒÐ´Ð°Ð»ÐµÐ½Ð½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹'}

ðŸ“¦ Ð’ÑÐµÐ³Ð¾ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹: {len(current_models)}

ðŸ“… ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾: {datetime.now(timezone.utc).isoformat()}
"""
        
        metadata = {
            "type": "model_changes_summary",
            "new_models": list(new_models),
            "removed_models": list(removed_models),
            "total_models": len(current_models),
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        
        domain_id = await conn.fetchval("SELECT id FROM domains WHERE name = $1", "AI Models")
        if not domain_id:
            domain_id = await conn.fetchval("INSERT INTO domains (name) VALUES ($1) RETURNING id", "AI Models")
        
        await conn.execute("""
            INSERT INTO knowledge_nodes (domain_id, content, metadata, confidence_score, is_verified)
            VALUES ($1, $2, $3, $4, $5)
        """, domain_id, summary_content, json.dumps(metadata), 1.0, True)
    
    async def run_continuous(self):
        """Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒ Ð½ÐµÐ¿Ñ€ÐµÑ€Ñ‹Ð²Ð½Ð¾Ðµ Ð¾Ñ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ð½Ð¸Ðµ"""
        self._running = True
        logger.info(f"ðŸš€ Ð—Ð°Ð¿ÑƒÑ‰ÐµÐ½Ð¾ Ð¾Ñ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ð½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ (Ð¸Ð½Ñ‚ÐµÑ€Ð²Ð°Ð»: {CHECK_INTERVAL} ÑÐµÐº)")
        
        # ÐŸÐµÑ€Ð²Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÑ€Ð°Ð·Ñƒ
        await self.track_models()
        
        while self._running:
            await asyncio.sleep(CHECK_INTERVAL)
            if self._running:
                await self.track_models()
    
    def stop(self):
        """ÐžÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ Ð¾Ñ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ð½Ð¸Ðµ"""
        self._running = False
        logger.info("â¹ï¸ ÐžÑ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ð½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾")


async def main():
    """Ð“Ð»Ð°Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð·Ð°Ð¿ÑƒÑÐºÐ° Ð¾Ñ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ð½Ð¸Ñ"""
    tracker = ModelTracker()
    try:
        await tracker.run_continuous()
    except KeyboardInterrupt:
        tracker.stop()
        logger.info("ÐžÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¼")


if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    asyncio.run(main())
