"""
–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π —Ä–æ—É—Ç–µ—Ä –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–∏—Ä–æ–≤—ã—Ö –ø—Ä–∞–∫—Ç–∏–∫:
- Task Complexity Estimation (–æ—Ü–µ–Ω–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∑–∞–¥–∞—á–∏)
- Query-Model Interaction Modeling (–≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –∑–∞–ø—Ä–æ—Å-–º–æ–¥–µ–ª—å)
- Multi-Metric Optimization (–±–∞–ª–∞–Ω—Å –∫–∞—á–µ—Å—Ç–≤–∞, —Å–∫–æ—Ä–æ—Å—Ç–∏, —Å—Ç–æ–∏–º–æ—Å—Ç–∏)
- Performance-Cost Trade-off (–±–∞–ª–∞–Ω—Å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ —Å—Ç–æ–∏–º–æ—Å—Ç–∏)
"""
import logging
import asyncio
try:
    import asyncpg
    ASYNCPG_AVAILABLE = True
except ImportError:
    asyncpg = None
    ASYNCPG_AVAILABLE = False
from typing import Dict, Optional, List, Tuple
from datetime import datetime
from dataclasses import dataclass

logger = logging.getLogger(__name__)

@dataclass
class ModelCapability:
    """–°–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–∞–¥–∞—á"""
    model_name: str
    task_types: List[str]  # –¢–∏–ø—ã –∑–∞–¥–∞—á, —Å –∫–æ—Ç–æ—Ä—ã–º–∏ –º–æ–¥–µ–ª—å —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è
    avg_quality: float  # –°—Ä–µ–¥–Ω–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤ (0-1)
    avg_latency_ms: float  # –°—Ä–µ–¥–Ω—è—è –∑–∞–¥–µ—Ä–∂–∫–∞ –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
    success_rate: float  # –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—à–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ (0-1)
    cost_per_token: float  # –°—Ç–æ–∏–º–æ—Å—Ç—å –∑–∞ —Ç–æ–∫–µ–Ω (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è)
    max_context: int  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
    reasoning_capability: float  # –°–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∫ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—é (0-1)
    coding_capability: float  # –°–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é (0-1)
    speed_capability: float  # –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏ (0-1, –≤—ã—à–µ = –±—ã—Å—Ç—Ä–µ–µ)

@dataclass
class TaskComplexity:
    """–û—Ü–µ–Ω–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∑–∞–¥–∞—á–∏"""
    complexity_score: float  # 0-1, –≥–¥–µ 1 = –æ—á–µ–Ω—å —Å–ª–æ–∂–Ω–∞—è
    requires_reasoning: bool
    requires_coding: bool
    requires_creativity: bool
    estimated_tokens: int
    task_type: str  # coding, reasoning, fast, general, etc.


class TaskCategory:
    """–ö–∞—Ç–µ–≥–æ—Ä–∏—è –∑–∞–¥–∞—á–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å .value (extended_thinking, fallback)."""
    def __init__(self, value: str):
        self.value = value


class IntelligentModelRouter:
    """
    –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π —Ä–æ—É—Ç–µ—Ä –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–∏—Ä–æ–≤—ã—Ö –ø—Ä–∞–∫—Ç–∏–∫:
    1. Task Complexity Estimation
    2. Query-Model Interaction Modeling
    3. Multi-Metric Optimization
    """
    
    def __init__(self, db_url: str):
        self.db_url = db_url
        self._pool = None
        self._model_capabilities_cache = {}
        self._cache_ttl = 300  # 5 –º–∏–Ω—É—Ç
        
        # –ë–∞–∑–æ–≤—ã–µ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π (–æ–±–Ω–æ–≤–ª—è—é—Ç—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)
        self._base_capabilities = {
            'phi3.5:3.8b': ModelCapability(
                model_name='phi3.5:3.8b',
                task_types=['fast', 'general', 'simple_query'],
                avg_quality=0.7,
                avg_latency_ms=500,
                success_rate=0.85,
                cost_per_token=0.1,
                max_context=128000,
                reasoning_capability=0.6,
                coding_capability=0.65,
                speed_capability=0.9
            ),
            'glm-4.7-flash:q8_0': ModelCapability(  # Ollama –º–æ–¥–µ–ª—å (Mac Studio)
                model_name='glm-4.7-flash:q8_0',
                task_types=['coding', 'reasoning', 'general'],
                avg_quality=0.85,
                avg_latency_ms=1200,
                success_rate=0.92,
                cost_per_token=0.3,
                max_context=198000,
                reasoning_capability=0.85,
                coding_capability=0.9,
                speed_capability=0.7
            ),
            'qwen2.5-coder:32b': ModelCapability(
                model_name='qwen2.5-coder:32b',
                task_types=['coding', 'complex_coding'],
                avg_quality=0.9,
                avg_latency_ms=2000,
                success_rate=0.95,
                cost_per_token=0.5,
                max_context=128000,
                reasoning_capability=0.75,
                coding_capability=0.95,
                speed_capability=0.5
            ),
            'deepseek-r1-distill-llama:70b': ModelCapability(
                model_name='deepseek-r1-distill-llama:70b',
                task_types=['reasoning', 'complex_reasoning', 'planning'],
                avg_quality=0.95,
                avg_latency_ms=3000,
                success_rate=0.98,
                cost_per_token=0.8,
                max_context=128000,
                reasoning_capability=0.98,
                coding_capability=0.8,
                speed_capability=0.3
            )
        }
    
    async def get_pool(self):
        if not ASYNCPG_AVAILABLE or asyncpg is None:
            return None
        if self._pool is None:
            self._pool = await asyncpg.create_pool(
                self.db_url,
                min_size=1,
                max_size=3,
                max_inactive_connection_lifetime=300
            )
        return self._pool
    
    def estimate_task_complexity(self, prompt: str, category: str = None) -> TaskComplexity:
        """
        –û—Ü–µ–Ω–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∑–∞–¥–∞—á–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–∏—Ä–æ–≤—ã—Ö –ø—Ä–∞–∫—Ç–∏–∫
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–º–ø—Ç–∞ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        """
        prompt_lower = prompt.lower()
        prompt_length = len(prompt)
        
        # –ü—Ä–∏–∑–Ω–∞–∫–∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        reasoning_indicators = ['–ø–æ–¥—É–º–∞–π', '–ª–æ–≥–∏–∫–∞', '—Ä–∞—Å—Å—É–∂–¥', '–∞–Ω–∞–ª–∏–∑', '—Å—Ç—Ä–∞—Ç–µ–≥–∏—è', '–ø–ª–∞–Ω–∏—Ä', '–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞']
        coding_indicators = ['–∫–æ–¥', '–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä—É–π', '—Ñ—É–Ω–∫—Ü–∏—è', '–∫–ª–∞—Å—Å', '–∞–ª–≥–æ—Ä–∏—Ç–º', '—Ä–µ–∞–ª–∏–∑—É–π', '–Ω–∞–ø–∏—à–∏ –∫–æ–¥']
        creativity_indicators = ['—Å–æ–∑–¥–∞–π', '–ø—Ä–∏–¥—É–º–∞–π', '–¥–∏–∑–∞–π–Ω', '–∫—Ä–µ–∞—Ç–∏–≤', '–∏–Ω–Ω–æ–≤–∞—Ü']
        
        requires_reasoning = any(ind in prompt_lower for ind in reasoning_indicators)
        requires_coding = any(ind in prompt_lower for ind in coding_indicators)
        requires_creativity = any(ind in prompt_lower for ind in creativity_indicators)
        
        # –û—Ü–µ–Ω–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ (0-1)
        complexity_score = 0.0
        
        # –ë–∞–∑–æ–≤–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å –ø–æ –¥–ª–∏–Ω–µ
        if prompt_length < 100:
            complexity_score += 0.1
        elif prompt_length < 500:
            complexity_score += 0.3
        elif prompt_length < 1000:
            complexity_score += 0.5
        else:
            complexity_score += 0.7
        
        # Reasoning –¥–æ–±–∞–≤–ª—è–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        if requires_reasoning:
            complexity_score += 0.3
        if requires_coding:
            complexity_score += 0.2
        if requires_creativity:
            complexity_score += 0.2
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏—è –≤–ª–∏—è–µ—Ç –Ω–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç—å
        if category == 'reasoning':
            complexity_score = max(complexity_score, 0.7)
        elif category == 'coding':
            complexity_score = max(complexity_score, 0.6)
        elif category == 'fast':
            complexity_score = min(complexity_score, 0.4)
        
        complexity_score = min(complexity_score, 1.0)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∑–∞–¥–∞—á–∏
        if requires_coding:
            task_type = 'coding'
        elif requires_reasoning:
            task_type = 'reasoning'
        elif category == 'fast' or prompt_length < 300:
            task_type = 'fast'
        else:
            task_type = 'general'
        
        return TaskComplexity(
            complexity_score=complexity_score,
            requires_reasoning=requires_reasoning,
            requires_coding=requires_coding,
            requires_creativity=requires_creativity,
            estimated_tokens=prompt_length // 4,  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤
            task_type=task_type
        )
    
    async def get_model_capabilities(self, model_name: str) -> Optional[ModelCapability]:
        """–ü–æ–ª—É—á–∏—Ç—å –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        if model_name in self._model_capabilities_cache:
            cached = self._model_capabilities_cache[model_name]
            if (datetime.now() - cached['timestamp']).seconds < self._cache_ttl:
                return cached['capability']
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–∑ –ë–î (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ asyncpg –¥–æ—Å—Ç—É–ø–µ–Ω)
        try:
            pool = await self.get_pool()
            if pool is None:
                raise RuntimeError("asyncpg not available")
            async with pool.acquire() as conn:
                stats = await conn.fetchrow("""
                    SELECT 
                        model_name,
                        AVG(quality_score) as avg_quality,
                        AVG(latency_ms) as avg_latency,
                        COUNT(*) FILTER (WHERE success = true)::float / COUNT(*) as success_rate,
                        COUNT(*) as total_attempts
                    FROM model_performance_log
                    WHERE model_name = $1
                    AND created_at > NOW() - INTERVAL '7 days'
                    GROUP BY model_name
                """, model_name)
                
                if stats and stats['total_attempts'] > 10:
                    # –û–±–Ω–æ–≤–ª—è–µ–º –±–∞–∑–æ–≤—ã–µ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
                    base = self._base_capabilities.get(model_name)
                    if base:
                        updated = ModelCapability(
                            model_name=model_name,
                            task_types=base.task_types,
                            avg_quality=float(stats['avg_quality'] or base.avg_quality),
                            avg_latency_ms=float(stats['avg_latency'] or base.avg_latency_ms),
                            success_rate=float(stats['success_rate'] or base.success_rate),
                            cost_per_token=base.cost_per_token,
                            max_context=base.max_context,
                            reasoning_capability=base.reasoning_capability,
                            coding_capability=base.coding_capability,
                            speed_capability=base.speed_capability
                        )
                        # –ö—ç—à–∏—Ä—É–µ–º
                        self._model_capabilities_cache[model_name] = {
                            'capability': updated,
                            'timestamp': datetime.now()
                        }
                        return updated
        except Exception as e:
            logger.debug(f"Error getting model capabilities: {e}")
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—ã–µ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏
        return self._base_capabilities.get(model_name)
    
    def calculate_model_task_fit(
        self,
        model_cap: ModelCapability,
        task_complexity: TaskComplexity
    ) -> float:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –º–æ–¥–µ–ª–∏ –∑–∞–¥–∞—á–µ (Query-Model Interaction)
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç score 0-1, –≥–¥–µ 1 = –∏–¥–µ–∞–ª—å–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
        """
        fit_score = 0.0
        
        # 1. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç–∏–ø—É –∑–∞–¥–∞—á–∏ (0-0.4)
        if task_complexity.task_type in model_cap.task_types:
            fit_score += 0.4
        elif task_complexity.task_type == 'coding' and model_cap.coding_capability > 0.7:
            fit_score += 0.3
        elif task_complexity.task_type == 'reasoning' and model_cap.reasoning_capability > 0.7:
            fit_score += 0.3
        
        # 2. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∑–∞–¥–∞—á–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—è–º –º–æ–¥–µ–ª–∏ (0-0.3)
        if task_complexity.complexity_score <= 0.4:
            # –ü—Ä–æ—Å—Ç–∞—è –∑–∞–¥–∞—á–∞ - –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º –±—ã—Å—Ç—Ä—ã–µ –º–æ–¥–µ–ª–∏
            fit_score += model_cap.speed_capability * 0.3
        elif task_complexity.complexity_score <= 0.7:
            # –°—Ä–µ–¥–Ω—è—è –∑–∞–¥–∞—á–∞ - –±–∞–ª–∞–Ω—Å –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Å–∫–æ—Ä–æ—Å—Ç–∏
            quality_speed_balance = (model_cap.avg_quality * 0.6 + model_cap.speed_capability * 0.4)
            fit_score += quality_speed_balance * 0.3
        else:
            # –°–ª–æ–∂–Ω–∞—è –∑–∞–¥–∞—á–∞ - –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
            if task_complexity.requires_reasoning:
                fit_score += model_cap.reasoning_capability * 0.3
            elif task_complexity.requires_coding:
                fit_score += model_cap.coding_capability * 0.3
            else:
                fit_score += model_cap.avg_quality * 0.3
        
        # 3. –£—Å–ø–µ—à–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ (0-0.2)
        fit_score += model_cap.success_rate * 0.2
        
        # 4. –ö–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤ (0-0.1)
        fit_score += model_cap.avg_quality * 0.1
        
        return min(fit_score, 1.0)
    
    def calculate_cost_efficiency_score(
        self,
        model_cap: ModelCapability,
        task_complexity: TaskComplexity
    ) -> float:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç cost-efficiency score (–±–∞–ª–∞–Ω—Å –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Å—Ç–æ–∏–º–æ—Å—Ç–∏)
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è cost-aware routing
        """
        # –ö–∞—á–µ—Å—Ç–≤–æ –Ω–∞ –µ–¥–∏–Ω–∏—Ü—É —Å—Ç–æ–∏–º–æ—Å—Ç–∏
        quality_per_cost = model_cap.avg_quality / max(model_cap.cost_per_token, 0.01)
        
        # –£—á–∏—Ç—ã–≤–∞–µ–º —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–¥–∞—á–∏
        if task_complexity.complexity_score > 0.7:
            # –î–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á –∫–∞—á–µ—Å—Ç–≤–æ –≤–∞–∂–Ω–µ–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏
            return model_cap.avg_quality * 0.7 + quality_per_cost * 0.3
        else:
            # –î–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–¥–∞—á —Å—Ç–æ–∏–º–æ—Å—Ç—å –≤–∞–∂–Ω–µ–µ
            return quality_per_cost * 0.7 + model_cap.avg_quality * 0.3
    
    def classify_task(self, prompt: str, category: str = None) -> TaskCategory:
        """
        –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∑–∞–¥–∞—á—É –ø–æ —Ç–∏–ø—É (–¥–ª—è fallback –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è).
        Returns TaskCategory —Å .value (coding, reasoning, fast, general).
        """
        task_complexity = self.estimate_task_complexity(prompt, category)
        return TaskCategory(task_complexity.task_type)

    def get_fallback_models(
        self,
        model_name: str,
        task_category,
        max_fallbacks: int = 5
    ) -> List[str]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ fallback-–º–æ–¥–µ–ª–µ–π –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –æ—Å–Ω–æ–≤–Ω–æ–π.
        task_category ‚Äî TaskCategory –∏–ª–∏ –æ–±—ä–µ–∫—Ç —Å .value.
        """
        cat_value = getattr(task_category, 'value', str(task_category)) if task_category else 'general'
        all_models = list(self._base_capabilities.keys())
        fallbacks = [m for m in all_models if m != model_name]
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –º–æ–¥–µ–ª–∏ —Ç–æ–≥–æ –∂–µ —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏ (–ø–æ task_types)
        def score(m: str) -> float:
            cap = self._base_capabilities.get(m)
            if not cap:
                return 0.0
            if cat_value in cap.task_types:
                return 1.0
            if 'general' in cap.task_types:
                return 0.5
            return 0.3
        fallbacks.sort(key=score, reverse=True)
        return fallbacks[:max_fallbacks]

    async def select_optimal_model(
        self,
        prompt: str,
        category: str = None,
        available_models: List[str] = None,
        optimize_for: str = 'quality',  # 'quality', 'speed', 'cost', 'balanced'
        prioritize_quality: bool = False,
        prioritize_speed: bool = False,
        **kwargs
    ) -> Tuple[Optional[str], TaskCategory, float]:
        """
        –í—ã–±—Ä–∞—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–∏—Ä–æ–≤—ã—Ö –ø—Ä–∞–∫—Ç–∏–∫.
        
        Args:
            prompt: –ü—Ä–æ–º–ø—Ç –∑–∞–¥–∞—á–∏
            category: –ö–∞—Ç–µ–≥–æ—Ä–∏—è –∑–∞–¥–∞—á–∏
            available_models: –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
            optimize_for: –ß—Ç–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å ('quality', 'speed', 'cost', 'balanced')
            prioritize_quality: –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∫–∞—á–µ—Å—Ç–≤–∞ (–º–∞–ø–ø–∏—Ç—Å—è –≤ optimize_for='quality')
            prioritize_speed: –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç —Å–∫–æ—Ä–æ—Å—Ç–∏ (–º–∞–ø–ø–∏—Ç—Å—è –≤ optimize_for='speed')
        
        Returns:
            Tuple[model_name, TaskCategory, confidence_score]
        """
        if prioritize_speed:
            optimize_for = 'speed'
        elif prioritize_quality:
            optimize_for = 'quality'
        if available_models is None:
            available_models = list(self._base_capabilities.keys())
        
        # 1. –û—Ü–µ–Ω–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∑–∞–¥–∞—á–∏
        task_complexity = self.estimate_task_complexity(prompt, category)
        task_category = TaskCategory(task_complexity.task_type)
        
        logger.info(f"üìä [ROUTER] –°–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–¥–∞—á–∏: {task_complexity.complexity_score:.2f}, —Ç–∏–ø: {task_complexity.task_type}")
        
        # 2. –ü–æ–ª—É—á–∞–µ–º —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π
        model_scores = {}
        for model_name in available_models:
            model_cap = await self.get_model_capabilities(model_name)
            if not model_cap:
                continue
            
            # 3. Query-Model Interaction: —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –º–æ–¥–µ–ª–∏ –∑–∞–¥–∞—á–µ
            fit_score = self.calculate_model_task_fit(model_cap, task_complexity)
            
            # 4. Multi-Metric Optimization
            if optimize_for == 'quality':
                # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞
                final_score = fit_score * 0.6 + model_cap.avg_quality * 0.4
            elif optimize_for == 'speed':
                # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏
                speed_score = 1.0 - (model_cap.avg_latency_ms / 5000.0)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–æ 0-1
                final_score = fit_score * 0.4 + speed_score * 0.6
            elif optimize_for == 'cost':
                # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å—Ç–æ–∏–º–æ—Å—Ç–∏
                cost_efficiency = self.calculate_cost_efficiency_score(model_cap, task_complexity)
                final_score = fit_score * 0.4 + cost_efficiency * 0.6
            else:  # balanced
                # –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
                speed_score = 1.0 - (model_cap.avg_latency_ms / 5000.0)
                cost_efficiency = self.calculate_cost_efficiency_score(model_cap, task_complexity)
                final_score = (
                    fit_score * 0.4 +
                    model_cap.avg_quality * 0.3 +
                    speed_score * 0.15 +
                    cost_efficiency * 0.15
                )
            
            model_scores[model_name] = {
                'score': final_score,
                'fit_score': fit_score,
                'capability': model_cap
            }
        
        if not model_scores:
            return None, 0.0
        
        # 5. –í—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å —Å –ª—É—á—à–∏–º score
        best_model = max(model_scores.items(), key=lambda x: x[1]['score'])
        model_name, scores = best_model
        
        logger.info(
            f"üéØ [ROUTER] –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å: {model_name} "
            f"(score: {scores['score']:.3f}, fit: {scores['fit_score']:.3f}, "
            f"quality: {scores['capability'].avg_quality:.2f})"
        )
        
        return model_name, task_category, scores['score']
    
    async def get_alternative_models(
        self,
        prompt: str,
        category: str = None,
        top_n: int = 3
    ) -> List[Tuple[str, float]]:
        """–ü–æ–ª—É—á–∏—Ç—å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏ (–¥–ª—è fallback –∏–ª–∏ ensemble)"""
        task_complexity = self.estimate_task_complexity(prompt, category)
        available_models = list(self._base_capabilities.keys())
        
        model_scores = []
        for model_name in available_models:
            model_cap = await self.get_model_capabilities(model_name)
            if not model_cap:
                continue
            
            fit_score = self.calculate_model_task_fit(model_cap, task_complexity)
            model_scores.append((model_name, fit_score))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ score –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º top_n
        model_scores.sort(key=lambda x: x[1], reverse=True)
        return model_scores[:top_n]

# Singleton
_router_instance = None

def get_intelligent_router(db_url: str = None) -> IntelligentModelRouter:
    global _router_instance
    if _router_instance is None:
        import os
        db_url = db_url or os.getenv('DATABASE_URL', 'postgresql://admin:secret@localhost:5432/knowledge_os')
        _router_instance = IntelligentModelRouter(db_url)
    return _router_instance
