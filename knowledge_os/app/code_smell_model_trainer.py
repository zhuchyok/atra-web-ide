"""
Code Smell Model Trainer: –û–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –±–∞–≥–æ–≤ –≤ –∫–æ–¥–µ

–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:
- –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑ code_smell_training_data
- Feature engineering (code complexity, history, patterns)
- –û–±—É—á–µ–Ω–∏–µ LightGBM/XGBoost –º–æ–¥–µ–ª–∏
- –í–∞–ª–∏–¥–∞—Ü–∏—è: precision > 70%, recall > 60%
"""

import asyncio
import os
import json
import logging
import pickle
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import numpy as np

# Import database connection from evaluator
from evaluator import get_pool

# Try to import ML libraries
try:
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import precision_score, recall_score, classification_report
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    LIGHTGBM_AVAILABLE = False

try:
    from sklearn.ensemble import RandomForestClassifier
    RANDOM_FOREST_AVAILABLE = True
except ImportError:
    RANDOM_FOREST_AVAILABLE = False

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

DB_URL = os.getenv('DATABASE_URL', 'postgresql://admin:secret@localhost:5432/knowledge_os')

# –ü–æ—Ä–æ–≥–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
MIN_PRECISION = 0.70  # 70%
MIN_RECALL = 0.60  # 60%

# –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
MODEL_PATH = os.path.join(os.path.dirname(__file__), '..', 'models', 'code_smell_model.pkl')
os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)


class CodeSmellModelTrainer:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ML –º–æ–¥–µ–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –±–∞–≥–æ–≤"""
    
    def __init__(self, db_url: str = DB_URL, model_type: str = "lightgbm"):
        self.db_url = db_url
        self.model_type = model_type
        self.model = None
        self.feature_names = [
            'cyclomatic_complexity',
            'function_count',
            'class_count',
            'avg_function_length',
            'has_null_pointer_pattern',
            'has_race_condition_pattern',
            'has_memory_leak_pattern',
            'has_type_error_pattern',
            'has_logic_error_pattern',
            'magic_numbers_count',
            'file_size',
            'recent_changes'
        ]
    
    async def load_training_data(self, days: int = 90) -> Tuple[List[Dict], List[bool]]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏–∑ –ë–î.
        
        Args:
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –∏—Å—Ç–æ—Ä–∏–∏
        
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (features_list, labels)
        """
        pool = await get_pool()
        async with pool.acquire() as conn:
            rows = await conn.fetch("""
                SELECT 
                    code_features,
                    actual_bug,
                    bug_type
                FROM code_smell_training_data
                WHERE created_at > NOW() - INTERVAL '1 day' * $1
                ORDER BY created_at DESC
            """, days)
            
            features_list = []
            labels = []
            
            for row in rows:
                features = row['code_features'] or {}
                actual_bug = row['actual_bug'] or False
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º features
                feature_dict = {
                    'cyclomatic_complexity': float(features.get('cyclomatic_complexity', 0.0)),
                    'function_count': float(features.get('function_count', 0.0)),
                    'class_count': float(features.get('class_count', 0.0)),
                    'avg_function_length': float(features.get('avg_function_length', 0.0)),
                    'has_null_pointer_pattern': 1.0 if 'null_pointer' in str(features.get('anti_patterns', [])).lower() else 0.0,
                    'has_race_condition_pattern': 1.0 if 'race_condition' in str(features.get('anti_patterns', [])).lower() else 0.0,
                    'has_memory_leak_pattern': 1.0 if 'memory_leak' in str(features.get('anti_patterns', [])).lower() else 0.0,
                    'has_type_error_pattern': 1.0 if 'type_error' in str(features.get('anti_patterns', [])).lower() else 0.0,
                    'has_logic_error_pattern': 1.0 if 'logic_error' in str(features.get('anti_patterns', [])).lower() else 0.0,
                    'magic_numbers_count': float(features.get('magic_numbers_count', 0.0)),
                    'file_size': float(features.get('file_size', 0.0)),
                    'recent_changes': float(features.get('recent_changes', 0.0))
                }
                
                features_list.append(feature_dict)
                labels.append(bool(actual_bug))
            
            logger.info(f"üìä Loaded {len(features_list)} training samples ({sum(labels)} bugs, {len(labels) - sum(labels)} non-bugs)")
            return features_list, labels
    
    def _prepare_features(self, features_list: List[Dict]) -> np.ndarray:
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç features –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏.
        
        Args:
            features_list: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å features
        
        Returns:
            NumPy array —Å features
        """
        feature_matrix = []
        
        for features in features_list:
            feature_vector = [
                features.get(name, 0.0) for name in self.feature_names
            ]
            feature_matrix.append(feature_vector)
        
        return np.array(feature_matrix)
    
    async def train_model(self, days: int = 90) -> bool:
        """
        –û–±—É—á–∞–µ—Ç ML –º–æ–¥–µ–ª—å –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –∏—Å—Ç–æ—Ä–∏–∏
        
        Returns:
            True –µ—Å–ª–∏ –æ–±—É—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∏ –º–µ—Ç—Ä–∏–∫–∏ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç—ã
        """
        if not SKLEARN_AVAILABLE:
            logger.error("‚ùå scikit-learn –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –æ–±—É—á–µ–Ω–∏–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ")
            return False
        
        logger.info(f"üöÄ [CODE SMELL TRAINER] –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ (–¥–∞–Ω–Ω—ã–µ –∑–∞ {days} –¥–Ω–µ–π)...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        features_list, labels = await self.load_training_data(days=days)
        
        if not features_list or not labels:
            logger.warning("‚ö†Ô∏è [CODE SMELL TRAINER] –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return False
        
        if len(features_list) < 50:
            logger.warning(f"‚ö†Ô∏è [CODE SMELL TRAINER] –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {len(features_list)} (–º–∏–Ω–∏–º—É–º 50)")
            return False
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º features
        X = self._prepare_features(features_list)
        y = np.array(labels, dtype=int)
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/test
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y if len(set(y)) > 1 else None
        )
        
        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        if self.model_type == "lightgbm" and LIGHTGBM_AVAILABLE:
            # LightGBM
            train_data = lgb.Dataset(X_train, label=y_train, feature_name=self.feature_names)
            val_data = lgb.Dataset(X_test, label=y_test, reference=train_data, feature_name=self.feature_names)
            
            params = {
                'objective': 'binary',
                'metric': 'binary_logloss',
                'boosting_type': 'gbdt',
                'num_leaves': 31,
                'learning_rate': 0.05,
                'feature_fraction': 0.9,
                'bagging_fraction': 0.8,
                'bagging_freq': 5,
                'verbose': -1
            }
            
            self.model = lgb.train(
                params,
                train_data,
                valid_sets=[val_data],
                num_boost_round=100,
                callbacks=[lgb.early_stopping(stopping_rounds=10), lgb.log_evaluation(period=0)]
            )
        elif RANDOM_FOREST_AVAILABLE:
            # Random Forest (fallback)
            self.model = RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                random_state=42,
                n_jobs=-1
            )
            self.model.fit(X_train, y_train)
        else:
            logger.error("‚ùå [CODE SMELL TRAINER] –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö ML –±–∏–±–ª–∏–æ—Ç–µ–∫")
            return False
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
        y_pred = self.model.predict(X_test)
        y_pred_proba = None
        
        if hasattr(self.model, 'predict_proba'):
            y_pred_proba = self.model.predict_proba(X_test)[:, 1]
        elif hasattr(self.model, 'predict'):
            y_pred_proba = self.model.predict(X_test, raw_score=False) if LIGHTGBM_AVAILABLE else y_pred
        
        precision = precision_score(y_test, y_pred, zero_division=0)
        recall = recall_score(y_test, y_pred, zero_division=0)
        
        logger.info(f"üìä [CODE SMELL TRAINER] Precision: {precision:.2%}, Recall: {recall:.2%}")
        logger.info(f"üìä [CODE SMELL TRAINER] Classification report:\n{classification_report(y_test, y_pred)}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–æ—Å—Ç–∏–≥–Ω—É—Ç—ã –ª–∏ —Ü–µ–ª–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        if precision >= MIN_PRECISION and recall >= MIN_RECALL:
            logger.info(f"‚úÖ [CODE SMELL TRAINER] –ú–µ—Ç—Ä–∏–∫–∏ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç—ã! Precision: {precision:.2%} >= {MIN_PRECISION:.2%}, Recall: {recall:.2%} >= {MIN_RECALL:.2%}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
            try:
                with open(MODEL_PATH, 'wb') as f:
                    pickle.dump({
                        'model': self.model,
                        'feature_names': self.feature_names,
                        'model_type': self.model_type,
                        'precision': precision,
                        'recall': recall,
                        'trained_at': datetime.now().isoformat()
                    }, f)
                logger.info(f"‚úÖ [CODE SMELL TRAINER] –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {MODEL_PATH}")
                return True
            except Exception as e:
                logger.error(f"‚ùå [CODE SMELL TRAINER] –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
                return False
        else:
            logger.warning(f"‚ö†Ô∏è [CODE SMELL TRAINER] –ú–µ—Ç—Ä–∏–∫–∏ –Ω–µ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç—ã. Precision: {precision:.2%} < {MIN_PRECISION:.2%} –∏–ª–∏ Recall: {recall:.2%} < {MIN_RECALL:.2%}")
            return False
    
    def load_model(self) -> bool:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∏–∑ —Ñ–∞–π–ª–∞.
        
        Returns:
            True –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ
        """
        try:
            if not os.path.exists(MODEL_PATH):
                logger.warning(f"‚ö†Ô∏è [CODE SMELL TRAINER] –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {MODEL_PATH}")
                return False
            
            with open(MODEL_PATH, 'rb') as f:
                model_data = pickle.load(f)
                self.model = model_data['model']
                self.feature_names = model_data.get('feature_names', self.feature_names)
                self.model_type = model_data.get('model_type', self.model_type)
            
            logger.info(f"‚úÖ [CODE SMELL TRAINER] –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {MODEL_PATH}")
            return True
        except Exception as e:
            logger.error(f"‚ùå [CODE SMELL TRAINER] –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            return False
    
    def predict(self, features: Dict) -> Tuple[float, bool]:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –±–∞–≥–∞ –¥–ª—è –∑–∞–¥–∞–Ω–Ω—ã—Ö features.
        
        Args:
            features: –°–ª–æ–≤–∞—Ä—å —Å features –∫–æ–¥–∞
        
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (probability, is_bug) - –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –±–∞–≥–∞ –∏ –±–∏–Ω–∞—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        """
        if not self.model:
            logger.warning("‚ö†Ô∏è [CODE SMELL TRAINER] –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return 0.0, False
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º features
        feature_vector = np.array([[
            features.get(name, 0.0) for name in self.feature_names
        ]])
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º
        if hasattr(self.model, 'predict_proba'):
            proba = self.model.predict_proba(feature_vector)[0, 1]
        elif hasattr(self.model, 'predict'):
            if LIGHTGBM_AVAILABLE and isinstance(self.model, lgb.Booster):
                proba = self.model.predict(feature_vector)[0]
            else:
                proba = float(self.model.predict(feature_vector)[0])
        else:
            proba = 0.0
        
        is_bug = proba >= 0.5  # –ü–æ—Ä–æ–≥ –¥–ª—è –±–∏–Ω–∞—Ä–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        
        return float(proba), bool(is_bug)


async def train_code_smell_model(days: int = 90) -> bool:
    """–û–±–µ—Ä—Ç–∫–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏"""
    trainer = CodeSmellModelTrainer()
    return await trainer.train_model(days=days)


if __name__ == "__main__":
    asyncio.run(train_code_smell_model())

