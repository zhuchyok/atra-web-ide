"""
–í–µ—Ä–æ–Ω–∏–∫–∞: –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Å –≤–µ–±-–ø–æ–∏—Å–∫–æ–º
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –≤–µ–±-–ø–æ–∏—Å–∫–æ–º –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤
Singularity 5.0: Web-Enabled Local Intelligence
"""

import asyncio
import logging
import os
from typing import Optional, List, Dict, Any
import httpx

# DuckDuckGo search with fallback
try:
    from duckduckgo_search import DDGS
    DDGS_AVAILABLE = True
except ImportError:
    DDGS = None
    DDGS_AVAILABLE = False

logger = logging.getLogger(__name__)

# Config: –≤ Docker –∏—Å–ø–æ–ª—å–∑—É–µ–º host.docker.internal
_is_docker = os.path.exists('/.dockerenv') or os.getenv('DOCKER_CONTAINER', 'false').lower() == 'true'
if _is_docker:
    _default_ollama = os.getenv('OLLAMA_API_URL') or os.getenv('OLLAMA_BASE_URL') or 'http://host.docker.internal:11434'
    _default_mlx = os.getenv('MLX_API_URL') or 'http://host.docker.internal:11435'
else:
    _default_ollama = os.getenv('MAC_LLM_URL') or os.getenv('OLLAMA_API_URL') or 'http://localhost:11434'
    _default_mlx = os.getenv('MLX_API_URL') or 'http://localhost:11435'

MAC_LLM_URL = os.getenv('MAC_LLM_URL') or _default_ollama
SERVER_LLM_URL = os.getenv('SERVER_LLM_URL') or os.getenv('OLLAMA_API_URL') or _default_ollama

class VeronicaWebResearcher:
    """
    –í–µ—Ä–æ–Ω–∏–∫–∞: –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –≤–µ–±-–ø–æ–∏—Å–∫–∞.
    –†–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ —Ç–æ–∫–µ–Ω–æ–≤, –∏—Å–ø–æ–ª—å–∑—É—è –ª–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –Ω–∞ Mac Studio.
    """
    
    def __init__(self):
        ollama_url = MAC_LLM_URL or SERVER_LLM_URL or _default_ollama
        mlx_url = os.getenv('MLX_API_URL') or _default_mlx
        self.nodes = [
            {"name": "Mac Studio (Ollama)", "url": ollama_url, "priority": 1},
            {"name": "Mac Studio (MLX)", "url": mlx_url, "priority": 2}
        ]
    
    async def web_search(self, query: str, max_results: int = 5) -> List[Dict[str, Any]]:
        """
        –í–µ–±-–ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ DuckDuckGo (–±–µ–∑ —Ç–æ–∫–µ–Ω–æ–≤).
        """
        if not DDGS_AVAILABLE:
            logger.warning("‚ö†Ô∏è [WEB SEARCH] duckduckgo_search –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install duckduckgo-search")
            return []
        
        try:
            logger.info(f"üîç [WEB SEARCH] –í–µ—Ä–æ–Ω–∏–∫–∞ –∏—â–µ—Ç: {query}")
            with DDGS() as ddgs:
                results = list(ddgs.text(query, max_results=max_results))
            
            formatted_results = []
            for res in results:
                formatted_results.append({
                    "title": res.get('title', ''),
                    "url": res.get('href', ''),
                    "snippet": res.get('body', ''),
                    "source": "duckduckgo"
                })
            
            logger.info(f"‚úÖ [WEB SEARCH] –ù–∞–π–¥–µ–Ω–æ {len(formatted_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            return formatted_results
        except Exception as e:
            logger.error(f"‚ùå [WEB SEARCH] –û—à–∏–±–∫–∞: {e}")
            return []
    
    async def process_with_local_model(
        self, 
        prompt: str, 
        web_results: Optional[List[Dict]] = None,
        category: str = "research"
    ) -> str:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª—å—é (–±–µ–∑ —Ç–æ–∫–µ–Ω–æ–≤).
        –ú–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–µ–±-–ø–æ–∏—Å–∫–∞.
        """
        # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–π —É–∑–µ–ª
        healthy_node = await self._get_healthy_node()
        if not healthy_node:
            return "‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç —Å –≤–µ–±-—Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        full_prompt = prompt
        if web_results:
            full_prompt += "\n\nüìö –†–ï–ó–£–õ–¨–¢–ê–¢–´ –í–ï–ë-–ü–û–ò–°–ö–ê:\n"
            for i, result in enumerate(web_results[:3], 1):
                full_prompt += f"\n{i}. {result['title']}\n"
                full_prompt += f"   URL: {result['url']}\n"
                full_prompt += f"   {result['snippet'][:200]}...\n"
            full_prompt += "\n–ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –æ—Ç–≤–µ—Ç–∞.\n"
        
        # –í—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (MLX –º–æ–¥–µ–ª–∏ Mac Studio)
        model_map = {
            "research": "deepseek-r1-distill-llama:70b",  # MLX –º–æ–¥–µ–ª—å (Mac Studio)
            "coding": "qwen2.5-coder:32b",  # MLX –º–æ–¥–µ–ª—å (Mac Studio)
            "fast": "phi3.5:3.8b",  # Ollama –º–æ–¥–µ–ª—å
            "default": "qwen2.5-coder:32b"  # MLX –º–æ–¥–µ–ª—å (Mac Studio)
        }
        model = model_map.get(category, model_map["default"])
        
        try:
            logger.info(f"ü§ñ [VERONICA] –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ {healthy_node['name']} (–º–æ–¥–µ–ª—å: {model})")
            
            async with httpx.AsyncClient(timeout=120.0) as client:
                response = await client.post(
                    f"{healthy_node['url']}/api/generate",
                    json={
                        "model": model,
                        "prompt": full_prompt,
                        "stream": False
                    }
                )
                
                if response.status_code == 200:
                    result = response.json()
                    answer = result.get('response', '')
                    logger.info(f"‚úÖ [VERONICA] –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω ({len(answer)} —Å–∏–º–≤–æ–ª–æ–≤)")
                    return answer
                else:
                    logger.error(f"‚ùå [VERONICA] –û—à–∏–±–∫–∞: {response.status_code}")
                    return f"‚ùå –û—à–∏–±–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏: {response.status_code}"
        except Exception as e:
            logger.error(f"‚ùå [VERONICA] –û—à–∏–±–∫–∞: {e}")
            return f"‚ùå –û—à–∏–±–∫–∞: {e}"
    
    async def _get_healthy_node(self) -> Optional[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∑–¥–æ—Ä–æ–≤–æ–≥–æ —É–∑–ª–∞"""
        async with httpx.AsyncClient(timeout=5.0) as client:
            for node in self.nodes:
                try:
                    response = await client.get(f"{node['url']}/api/tags", timeout=2.0)
                    if response.status_code == 200:
                        return node
                except:
                    continue
        return None
    
    async def research_and_analyze(
        self, 
        query: str, 
        category: str = "research",
        use_web: bool = True
    ) -> Dict[str, Any]:
        """
        –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª: –≤–µ–±-–ø–æ–∏—Å–∫ + –∞–Ω–∞–ª–∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª—å—é (–±–µ–∑ —Ç–æ–∫–µ–Ω–æ–≤).
        """
        logger.info(f"üî¨ [VERONICA RESEARCH] –ó–∞–ø—Ä–æ—Å: {query}")
        
        # –®–∞–≥ 1: –í–µ–±-–ø–æ–∏—Å–∫ (–µ—Å–ª–∏ –Ω—É–∂–µ–Ω)
        web_results = []
        if use_web:
            web_results = await self.web_search(query, max_results=5)
        
        # –®–∞–≥ 2: –ê–Ω–∞–ª–∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª—å—é
        analysis_prompt = f"""
        –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—Ä–æ—Å –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç–≤–µ—Ç.
        –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–µ–±-–ø–æ–∏—Å–∫–∞, –∏—Å–ø–æ–ª—å–∑—É–π –∏—Ö –¥–ª—è –æ–±–æ–≥–∞—â–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞.
        
        –ó–ê–ü–†–û–°: {query}
        """
        
        answer = await self.process_with_local_model(
            analysis_prompt,
            web_results=web_results if web_results else None,
            category=category
        )
        
        return {
            "query": query,
            "web_results": web_results,
            "analysis": answer,
            "tokens_used": 0,  # –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å = 0 —Ç–æ–∫–µ–Ω–æ–≤
            "source": "veronica_local"
        }

async def test_veronica_web_research():
    """–¢–µ—Å—Ç –í–µ—Ä–æ–Ω–∏–∫–∏ —Å –≤–µ–±-–ø–æ–∏—Å–∫–æ–º"""
    print("üß™ –¢–µ—Å—Ç: –í–µ—Ä–æ–Ω–∏–∫–∞ —Å –≤–µ–±-–ø–æ–∏—Å–∫–æ–º\n")
    
    veronica = VeronicaWebResearcher()
    
    # –¢–µ—Å—Ç 1: –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å –±–µ–∑ –≤–µ–±-–ø–æ–∏—Å–∫–∞
    print("üì§ –¢–µ—Å—Ç 1: –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å (–±–µ–∑ –≤–µ–±-–ø–æ–∏—Å–∫–∞)")
    result1 = await veronica.process_with_local_model(
        "–û–±—ä—è—Å–Ω–∏, —á—Ç–æ —Ç–∞–∫–æ–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–∞—è —Ç–æ—Ä–≥–æ–≤–ª—è",
        category="research"
    )
    print(f"‚úÖ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω ({len(result1)} —Å–∏–º–≤–æ–ª–æ–≤)")
    print(f"   –ü–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤: {result1[:200]}...\n")
    
    # –¢–µ—Å—Ç 2: –ó–∞–ø—Ä–æ—Å —Å –≤–µ–±-–ø–æ–∏—Å–∫–æ–º
    print("üì§ –¢–µ—Å—Ç 2: –ó–∞–ø—Ä–æ—Å —Å –≤–µ–±-–ø–æ–∏—Å–∫–æ–º")
    result2 = await veronica.research_and_analyze(
        "–Ω–æ–≤—ã–µ —Ç—Ä–µ–Ω–¥—ã –≤ –∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–æ–π —Ç–æ—Ä–≥–æ–≤–ª–µ 2025",
        category="research",
        use_web=True
    )
    print(f"‚úÖ –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
    print(f"   –í–µ–±-—Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(result2['web_results'])}")
    print(f"   –ê–Ω–∞–ª–∏–∑: {len(result2['analysis'])} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"   –¢–æ–∫–µ–Ω–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {result2['tokens_used']} (0 = –±–µ—Å–ø–ª–∞—Ç–Ω–æ!)")
    
    return True

if __name__ == "__main__":
    asyncio.run(test_veronica_web_research())

