"""
ML Router Trainer
–û–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–æ—É—Ç–∏–Ω–≥–∞
Singularity 8.0: Intelligent Improvements
"""

import asyncio
import logging
import asyncpg
import os
import json
import pickle
from typing import Optional, List, Dict, Any, Tuple
from datetime import datetime, timedelta
import numpy as np

logger = logging.getLogger(__name__)

DB_URL = os.getenv('DATABASE_URL', 'postgresql://admin:secret@localhost:5432/knowledge_os')

try:
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import accuracy_score, classification_report
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    logger.warning("‚ö†Ô∏è scikit-learn –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, ML –æ–±—É—á–µ–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ")

class MLRouterTrainer:
    """
    –û–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–æ—É—Ç–∏–Ω–≥–∞.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç RandomForest –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–æ—É—Ç–∞.
    """
    
    def __init__(self, db_url: str = DB_URL):
        """
        Args:
            db_url: URL –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        """
        self.db_url = db_url
        self.model = None
        self.model_path = os.path.join(os.path.dirname(__file__), 'ml_router_model.pkl')
    
    async def load_training_data(self, days: int = 30, min_samples: int = 100) -> Tuple[List[Dict], List[str]]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏–∑ –ë–î.
        
        Args:
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            min_samples: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤
        
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (features, labels)
        """
        if not SKLEARN_AVAILABLE:
            logger.error("‚ùå scikit-learn –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –æ–±—É—á–µ–Ω–∏–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ")
            return [], []
        
        try:
            conn = await asyncpg.connect(self.db_url)
            try:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π
                rows = await conn.fetch("""
                    SELECT 
                        task_type,
                        prompt_length,
                        category,
                        selected_route,
                        performance_score,
                        tokens_saved,
                        latency_ms,
                        quality_score,
                        success,
                        features,
                        actual_route_used,
                        user_satisfaction
                    FROM ml_routing_training_data
                    WHERE created_at > NOW() - INTERVAL '1 day' * $1
                    AND success = TRUE
                    AND performance_score IS NOT NULL
                    ORDER BY created_at DESC
                    LIMIT 10000
                """, days)
                
                if len(rows) < min_samples:
                    logger.warning(f"‚ö†Ô∏è [ML TRAINER] –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {len(rows)} < {min_samples}")
                    return [], []
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º features –∏ labels
                features_list = []
                labels = []
                
                for row in rows:
                    # Features
                    feature_dict = {
                        'prompt_length': row['prompt_length'],
                        'task_type_coding': 1 if row['task_type'] == 'coding' else 0,
                        'task_type_general': 1 if row['task_type'] == 'general' else 0,
                        'task_type_research': 1 if row['task_type'] == 'research' else 0,
                        'category_coding': 1 if row['category'] == 'coding' else 0,
                        'category_general': 1 if row['category'] == 'general' else 0,
                        'performance_score': row['performance_score'] or 0.5,
                        'tokens_saved': row['tokens_saved'] or 0,
                        'latency_ms': row['latency_ms'] or 0,
                        'quality_score': row['quality_score'] or 0.5,
                        'user_satisfaction': row['user_satisfaction'] or 0.5,
                    }
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º features –∏–∑ JSONB
                    if row['features']:
                        feature_dict.update(row['features'])
                    
                    # –í—Ä–µ–º—è –¥–Ω—è (hour of day)
                    hour = datetime.now().hour
                    feature_dict['hour_of_day'] = hour
                    feature_dict['is_weekend'] = 1 if datetime.now().weekday() >= 5 else 0
                    
                    features_list.append(feature_dict)
                    
                    # Label: –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–æ—É—Ç (actual_route_used –∏–ª–∏ selected_route)
                    optimal_route = row['actual_route_used'] or row['selected_route']
                    labels.append(optimal_route)
                
                logger.info(f"‚úÖ [ML TRAINER] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(features_list)} –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
                return features_list, labels
            finally:
                await conn.close()
        except Exception as e:
            logger.error(f"‚ùå [ML TRAINER] –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return [], []
    
    def _prepare_features(self, features_list: List[Dict]) -> np.ndarray:
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç features –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        if not features_list:
            return np.array([])
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–ª—é—á–∏
        all_keys = set()
        for feat in features_list:
            all_keys.update(feat.keys())
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∫–ª—é—á–∏ –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
        sorted_keys = sorted(all_keys)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ numpy array
        feature_matrix = []
        for feat in features_list:
            row = [feat.get(key, 0) for key in sorted_keys]
            feature_matrix.append(row)
        
        return np.array(feature_matrix)
    
    async def train_model(self, days: int = 30) -> bool:
        """
        –û–±—É—á–∞–µ—Ç ML –º–æ–¥–µ–ª—å –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –∏—Å—Ç–æ—Ä–∏–∏
        
        Returns:
            True –µ—Å–ª–∏ –æ–±—É—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ
        """
        if not SKLEARN_AVAILABLE:
            logger.error("‚ùå scikit-learn –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –æ–±—É—á–µ–Ω–∏–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ")
            return False
        
        logger.info(f"üöÄ [ML TRAINER] –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ (–¥–∞–Ω–Ω—ã–µ –∑–∞ {days} –¥–Ω–µ–π)...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        features_list, labels = await self.load_training_data(days=days)
        
        if not features_list or not labels:
            logger.warning("‚ö†Ô∏è [ML TRAINER] –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return False
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º features
        X = self._prepare_features(features_list)
        y = np.array(labels)
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/test
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        self.model = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            random_state=42,
            n_jobs=-1
        )
        
        self.model.fit(X_train, y_train)
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
        y_pred = self.model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        logger.info(f"‚úÖ [ML TRAINER] –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞, accuracy: {accuracy:.2%}")
        logger.info(f"üìä [ML TRAINER] Classification report:\n{classification_report(y_test, y_pred)}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
        try:
            with open(self.model_path, 'wb') as f:
                pickle.dump(self.model, f)
            logger.info(f"üíæ [ML TRAINER] –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {self.model_path}")
        except Exception as e:
            logger.error(f"‚ùå [ML TRAINER] –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
            return False
        
        return accuracy > 0.7  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å 70%
    
    def load_model(self) -> bool:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∏–∑ —Ñ–∞–π–ª–∞.
        
        Returns:
            True –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ
        """
        if not SKLEARN_AVAILABLE:
            return False
        
        try:
            if os.path.exists(self.model_path):
                with open(self.model_path, 'rb') as f:
                    self.model = pickle.load(f)
                logger.info(f"‚úÖ [ML TRAINER] –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {self.model_path}")
                return True
            else:
                logger.warning(f"‚ö†Ô∏è [ML TRAINER] –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {self.model_path}")
                return False
        except Exception as e:
            logger.error(f"‚ùå [ML TRAINER] –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            return False
    
    def predict_optimal_route(
        self,
        task_type: str,
        prompt_length: int,
        category: Optional[str] = None,
        features: Optional[Dict[str, Any]] = None
    ) -> Optional[str]:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–æ—É—Ç –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞.
        
        Args:
            task_type: –¢–∏–ø –∑–∞–¥–∞—á–∏
            prompt_length: –î–ª–∏–Ω–∞ –ø—Ä–æ–º–ø—Ç–∞
            category: –ö–∞—Ç–µ–≥–æ—Ä–∏—è
            features: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ features
        
        Returns:
            –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π —Ä–æ—É—Ç –∏–ª–∏ None
        """
        if not self.model:
            if not self.load_model():
                return None
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º features
        feature_dict = {
            'prompt_length': prompt_length,
            'task_type_coding': 1 if task_type == 'coding' else 0,
            'task_type_general': 1 if task_type == 'general' else 0,
            'task_type_research': 1 if task_type == 'research' else 0,
            'category_coding': 1 if category == 'coding' else 0,
            'category_general': 1 if category == 'general' else 0,
            'performance_score': 0.5,  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
            'tokens_saved': 0,
            'latency_ms': 0,
            'quality_score': 0.5,
            'user_satisfaction': 0.5,
            'hour_of_day': datetime.now().hour,
            'is_weekend': 1 if datetime.now().weekday() >= 5 else 0,
        }
        
        if features:
            feature_dict.update(features)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ numpy array (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ –∂–µ –∫–ª—é—á–∏, —á—Ç–æ –∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏)
        # –î–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ –∂–µ –∫–ª—é—á–∏, —á—Ç–æ –∏ –≤ –æ–±—É—á–µ–Ω–∏–∏
        X = self._prepare_features([feature_dict])
        
        if X.size == 0:
            return None
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º
        try:
            prediction = self.model.predict(X)[0]
            return prediction
        except Exception as e:
            logger.error(f"‚ùå [ML TRAINER] –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            return None

# Singleton instance
_trainer_instance: Optional[MLRouterTrainer] = None

def get_ml_router_trainer(db_url: str = DB_URL) -> MLRouterTrainer:
    """–ü–æ–ª—É—á–∏—Ç—å singleton —ç–∫–∑–µ–º–ø–ª—è—Ä —Ç—Ä–µ–Ω–µ—Ä–∞"""
    global _trainer_instance
    if _trainer_instance is None:
        _trainer_instance = MLRouterTrainer(db_url=db_url)
    return _trainer_instance
