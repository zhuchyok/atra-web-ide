
import asyncio
import os
import json
import subprocess
import sys
import logging
from datetime import datetime

logger = logging.getLogger(__name__)

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# --- EMERGENCY REPAIR BLOCK ---
try:
    import asyncpg
except ImportError:
    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'asyncpg'])
    import asyncpg
# ------------------------------

# –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ —Ñ–æ—Ä–º–∞—Ç, —á—Ç–æ –∏ –¥—Ä—É–≥–∏–µ –º–æ–¥—É–ª–∏
DB_URL = os.getenv('DATABASE_URL', 'postgresql://admin:secret@localhost:5432/knowledge_os')

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –ø—É–ª —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π (singleton)
_pool = None

async def get_pool():
    global _pool
    if _pool is None:
        _pool = await asyncpg.create_pool(
            DB_URL, 
            min_size=1, 
            max_size=5,  # –£–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–≥—Ä—É–∑–∫–∏ –ë–î
            max_inactive_connection_lifetime=300,  # –ó–∞–∫—Ä—ã–≤–∞–µ–º –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã–µ —á–µ—Ä–µ–∑ 5 –º–∏–Ω—É—Ç
            command_timeout=60
        )
    return _pool

try:
    from ai_core import run_smart_agent_async
except ImportError:
    # –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ —Å –ø–æ–ª–Ω—ã–º –ø—É—Ç–µ–º
    import importlib.util
    ai_core_path = os.path.join(os.path.dirname(__file__), 'ai_core.py')
    spec = importlib.util.spec_from_file_location("ai_core", ai_core_path)
    ai_core = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(ai_core)
    run_smart_agent_async = ai_core.run_smart_agent_async

async def run_cursor_agent_smart(prompt: str, expert_name: str):
    """Smart replacement for the old cursor-agent call."""
    return await run_smart_agent_async(prompt, expert_name=expert_name, category="autonomous_worker")

async def process_task(pool, task):
    task_id = task['id']
    expert_name = task['assignee']
    task_title = task['title']
    preferred_source = task.get('preferred_source')  # MLX –∏–ª–∏ Ollama
    print(f'[{datetime.now()}] Expert {expert_name} processing: {task_title} [Source: {preferred_source or "auto"}]')
    
    # Heartbeat –º–µ—Ö–∞–Ω–∏–∑–º - –æ–±–Ω–æ–≤–ª—è–µ–º updated_at –∫–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥, —á—Ç–æ–±—ã –∑–∞–¥–∞—á–∞ –Ω–µ —Å—á–∏—Ç–∞–ª–∞—Å—å –∑–∞—Å—Ç—Ä—è–≤—à–µ–π
    heartbeat_task = None
    heartbeat_stopped = False
    
    async def update_heartbeat():
        """Heartbeat —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –ø–∞–¥–µ–Ω–∏–π - –æ–±–Ω–æ–≤–ª—è–µ—Ç updated_at –∫–∞–∂–¥—ã–µ 15 —Å–µ–∫—É–Ω–¥"""
        nonlocal heartbeat_stopped
        while not heartbeat_stopped:
            try:
                async with pool.acquire() as conn:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∑–∞–¥–∞—á–∞ –≤—Å–µ –µ—â–µ –≤ in_progress (–Ω–µ –±—ã–ª–∞ —Å–±—Ä–æ—à–µ–Ω–∞ –º–æ–Ω–∏—Ç–æ—Ä–æ–º)
                    status = await conn.fetchval("SELECT status FROM tasks WHERE id = $1", task_id)
                    if status != 'in_progress':
                        heartbeat_stopped = True
                        break
                    # –û–±–Ω–æ–≤–ª—è–µ–º updated_at - —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –∑–∞—Å—Ç—Ä–µ–≤–∞–Ω–∏—è
                    await conn.execute("UPDATE tasks SET updated_at = NOW() WHERE id = $1 AND status = 'in_progress'", task_id)
                await asyncio.sleep(15)  # Heartbeat –∫–∞–∂–¥—ã–µ 15 —Å–µ–∫—É–Ω–¥ (–±—ã—Å—Ç—Ä–µ–µ –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏)
            except asyncio.CancelledError:
                heartbeat_stopped = True
                break
            except Exception as e:
                logger.debug(f"Heartbeat error for task {task_id}: {e}")
                # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É –¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ heartbeat
                try:
                    await asyncio.sleep(15)
                except asyncio.CancelledError:
                    heartbeat_stopped = True
                    break
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é –¥–ª—è –∞—Ç–æ–º–∞—Ä–Ω–æ—Å—Ç–∏
    async with pool.acquire() as conn:
        async with conn.transaction():
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π, —á—Ç–æ –∑–∞–¥–∞—á–∞ –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –¥—Ä—É–≥–∏–º worker'–æ–º
            result = await conn.execute("""
                UPDATE tasks 
                SET status = 'in_progress', updated_at = NOW() 
                WHERE id = $1 
                AND (status = 'pending' OR (status = 'in_progress' AND updated_at < NOW() - INTERVAL '1 hour'))
            """, task_id)
    
            # –ï—Å–ª–∏ –∑–∞–¥–∞—á–∞ —É–∂–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è (–Ω–µ –æ–±–Ω–æ–≤–∏–ª–∞—Å—å), –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            if result == "UPDATE 0":
                print(f'[{datetime.now()}] Task {task_id} already being processed or recently updated, skipping...')
                return
            
            expert_config = await conn.fetchrow("SELECT id, system_prompt, role, department FROM experts WHERE name = $1", expert_name)
            if not expert_config:
                await conn.execute("UPDATE tasks SET status = 'failed', result = 'Expert not found', updated_at = NOW() WHERE id = $1", task_id)
                return

            # üåü –ú–ò–†–û–í–´–ï –ü–†–ê–ö–¢–ò–ö–ò: –û–±–æ–≥–∞—â–∞–µ–º –∑–∞–¥–∞—á—É –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º —Ñ–∞–π–ª–æ–≤
            task_description = task['description']
            task_metadata = task.get('metadata', {})
            if isinstance(task_metadata, str):
                try:
                    task_metadata = json.loads(task_metadata)
                except:
                    task_metadata = {}
            
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —á–∏—Ç–∞–µ–º —Ñ–∞–π–ª—ã –∏–∑ metadata
            try:
                from file_context_enricher import get_file_enricher
                enricher = get_file_enricher()
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º file_path –∏–∑ metadata
                file_path = task_metadata.get('file_path') or task_metadata.get('file')
                keywords = task_metadata.get('keywords', [])
                
                if file_path:
                    # –û–±–æ–≥–∞—â–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏ –∫–æ–¥–æ–º —Ñ–∞–π–ª–∞
                    task_description = enricher.enrich_task_with_file_context(
                        task_description,
                        file_path=file_path,
                        metadata=task_metadata,
                        keywords=keywords
                    )
                    logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} –æ–±–æ–≥–∞—â–µ–Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º —Ñ–∞–π–ª–∞: {file_path}")
                elif task_metadata.get('file_paths'):
                    # –ù–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤
                    file_paths = task_metadata.get('file_paths', [])
                    task_description = enricher.enrich_task_with_multiple_files(
                        task_description,
                        file_paths=file_paths,
                        metadata=task_metadata
                    )
                    logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} –æ–±–æ–≥–∞—â–µ–Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º {len(file_paths)} —Ñ–∞–π–ª–æ–≤")
            except ImportError:
                logger.debug("file_context_enricher –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ")
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º: {e}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ")

            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç —Å –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–º –æ–ø–∏—Å–∞–Ω–∏–µ–º
            # üåü –ú–ò–†–û–í–´–ï –ü–†–ê–ö–¢–ò–ö–ò: –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –æ —Ä–∞–±–æ—Ç–µ —Å –∫–æ–¥–æ–º
            file_access_instructions = ""
            if task_metadata.get('file_path') or task_metadata.get('file_paths'):
                file_access_instructions = """
üìÅ –†–ê–ë–û–¢–ê –° –ö–û–î–û–ú (–ú–ò–†–û–í–´–ï –ü–†–ê–ö–¢–ò–ö–ò):
1. –í –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –≤—ã—à–µ –µ—Å—Ç—å –†–ï–ê–õ–¨–ù–´–ô –ö–û–î —Ñ–∞–π–ª–∞(–æ–≤) - –∏—Å–ø–æ–ª—å–∑—É–π –ï–ì–û –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
2. –ù–ï –ø—Ä–∏–¥—É–º—ã–≤–∞–π —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –∫–æ–¥–µ
3. –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –ø—Ä–æ—á–∏—Ç–∞—Ç—å –¥—Ä—É–≥–∏–µ —Ñ–∞–π–ª—ã, –∏—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç read_file (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω —á–µ—Ä–µ–∑ –∞–≥–µ–Ω—Ç–∞)
4. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –¢–û–õ–¨–ö–û —Ç–æ, —á—Ç–æ —Ä–µ–∞–ª—å–Ω–æ –µ—Å—Ç—å –≤ –∫–æ–¥–µ
5. –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Ç–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ —Ä–µ–∞–ª—å–Ω–æ –µ—Å—Ç—å –≤ –∫–æ–¥–µ
"""
            
            # üåü –°–ü–ï–¶–ò–ê–õ–¨–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê: –ó–∞–¥–∞—á–∏ —Ä–∞–∑–≤–µ–¥–∫–∏ (–¥–æ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–º–ø—Ç–∞)
            if task_metadata.get('source') in ('scout_orchestrator', 'dashboard_scout', 'enhanced_scout_orchestrator'):
                try:
                    sys.path.insert(0, os.path.dirname(__file__))
                    from scout_task_processor import process_scout_task
                    logger.info(f"üïµÔ∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á–∏ —Ä–∞–∑–≤–µ–¥–∫–∏: {task['title']}")
                    scout_result = await process_scout_task(task_metadata, task_description)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    async with pool.acquire() as conn:
                        async with conn.transaction():
                            await conn.execute(
                                "UPDATE tasks SET status = 'completed', result = $2, updated_at = NOW() WHERE id = $1",
                                task_id, scout_result
                            )
                    logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ —Ä–∞–∑–≤–µ–¥–∫–∏ {task_id} –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {scout_result[:100]}...")
                    return  # –í—ã—Ö–æ–¥–∏–º, –Ω–µ –≤—ã–∑—ã–≤–∞—è LLM
                except ImportError as e:
                    logger.warning(f"scout_task_processor –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ({e}), –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–µ—Ä–µ–∑ LLM")
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–¥–∞—á–∏ —Ä–∞–∑–≤–µ–¥–∫–∏: {e}, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–µ—Ä–µ–∑ LLM")
                    import traceback
                    traceback.print_exc()

            # üåü –°–ü–ï–¶–ò–ê–õ–¨–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê: –°–∏–º—É–ª—è—Ü–∏—è –±–∏–∑–Ω–µ—Å-–∏–¥–µ–∏ (–¥–∞—à–±–æ—Ä–¥)
            if task_metadata.get('source') == 'dashboard_simulator':
                sim_id = task_metadata.get('simulation_id')
                if sim_id is not None:
                    try:
                        from simulator import run_simulation as run_sim
                        logger.info(f"üöÄ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∏–º—É–ª—è—Ü–∏–∏ –±–∏–∑–Ω–µ—Å-–∏–¥–µ–∏ #{sim_id}: {task['title']}")
                        await run_sim(int(sim_id))
                        async with pool.acquire() as conn:
                            result_text = await conn.fetchval("SELECT result FROM simulations WHERE id = $1", int(sim_id))
                            if result_text:
                                await conn.execute(
                                    "UPDATE tasks SET status = 'completed', result = $2, updated_at = NOW() WHERE id = $1",
                                    task_id, result_text
                                )
                                logger.info(f"‚úÖ –°–∏–º—É–ª—è—Ü–∏—è #{sim_id} –∑–∞–≤–µ—Ä—à–µ–Ω–∞, –∑–∞–¥–∞—á–∞ {task_id} –æ—Ç–º–µ—á–µ–Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω–æ–π.")
                            else:
                                await conn.execute(
                                    "UPDATE tasks SET status = 'failed', result = '–°–∏–º—É–ª—è—Ü–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∞, –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ –∑–∞–ø–∏—Å–∞–Ω', updated_at = NOW() WHERE id = $1",
                                    task_id
                                )
                        return
                    except ImportError as e:
                        logger.warning(f"simulator –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ({e}), –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–µ—Ä–µ–∑ LLM")
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ —Å–∏–º—É–ª—è—Ü–∏–∏ #{sim_id}: {e}", exc_info=True)
                        async with pool.acquire() as conn:
                            await conn.execute(
                                "UPDATE tasks SET status = 'failed', result = $2, updated_at = NOW() WHERE id = $1",
                                task_id, f"–û—à–∏–±–∫–∞ —Å–∏–º—É–ª—è—Ü–∏–∏: {str(e)}"
                            )
                        return
            
            prompt = f"""{expert_config['system_prompt']}

Role: {expert_config['role']}
Dept: {expert_config['department']}

TASK: {task['title']}

DESC: {task_description}
{file_access_instructions}

üí° –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: 
- –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –≤—ã—à–µ –µ—Å—Ç—å –∫–æ–¥ —Ñ–∞–π–ª–∞, –∏—Å–ø–æ–ª—å–∑—É–π –ï–ì–û –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
- –ù–ï –ø—Ä–∏–¥—É–º—ã–≤–∞–π —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –∫–æ–¥–µ!
- –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –ø—Ä–æ—á–∏—Ç–∞—Ç—å –¥—Ä—É–≥–∏–µ —Ñ–∞–π–ª—ã, –∏—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç read_file (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
"""
    
    # –ö–†–ò–¢–ò–ß–ù–û: –ó–∞–ø—É—Å–∫–∞–µ–º heartbeat –°–†–ê–ó–£ –ø–æ—Å–ª–µ –ø–µ—Ä–µ–≤–æ–¥–∞ –≤ in_progress, –î–û –≤—ã–∑–æ–≤–∞ run_cursor_agent_smart
    # –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ updated_at –±—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª—è—Ç—å—Å—è –¥–∞–∂–µ –µ—Å–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–∏—Å–Ω–µ—Ç
    heartbeat_task = asyncio.create_task(update_heartbeat())
    
    # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞, —á—Ç–æ–±—ã –ø–µ—Ä–≤—ã–π heartbeat —É—Å–ø–µ–ª –≤—ã–ø–æ–ª–Ω–∏—Ç—å—Å—è
    await asyncio.sleep(0.1)
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–ª—è router (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω)
    router_instance = None
    if preferred_source:
        try:
            from local_router import LocalAIRouter
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä router'–∞ —Å –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–º –∏—Å—Ç–æ—á–Ω–∏–∫–æ–º
            router_instance = LocalAIRouter()
            router_instance._preferred_source = preferred_source
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –≥–ª–æ–±–∞–ª—å–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ ai_core
            import ai_core
            if hasattr(ai_core, '_current_router'):
                ai_core._current_router = router_instance
        except Exception as e:
            logger.debug(f"Could not set preferred source: {e}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º task_id –≤ router –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
    if router_instance:
        router_instance._current_task_id = task_id
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≤–Ω–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ (–º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–ª–≥–æ–π)
    try:
        try:
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–∞–π–º–∞—É—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–¥–∞—á–∏ (5 –º–∏–Ω—É—Ç –º–∞–∫—Å–∏–º—É–º)
            report = await asyncio.wait_for(
                run_cursor_agent_smart(prompt, expert_name),
                timeout=300.0  # 5 –º–∏–Ω—É—Ç —Ç–∞–π–º–∞—É—Ç
            )
        except asyncio.TimeoutError:
            print(f'[{datetime.now()}] ‚è±Ô∏è Task {task_id} timed out after 5 minutes')
            report = None
        except Exception as e:
            print(f'[{datetime.now()}] Error calling agent for task {task_id}: {e}')
            import traceback
            traceback.print_exc()
            report = None

        # –ü–æ–ª—É—á–∞–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∏–∑ router'–∞
        used_model = None
        if router_instance and hasattr(router_instance, '_used_model'):
            used_model = router_instance._used_model
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ metadata –∑–∞–¥–∞—á–∏
            async with pool.acquire() as conn:
                await conn.execute("""
                    UPDATE tasks 
                    SET metadata = metadata || jsonb_build_object('used_model', $2)
                    WHERE id = $1
                """, task_id, used_model)
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã –æ—Ç–≤–µ—Ç–æ–≤
        if report is None:
            report = None
        elif isinstance(report, tuple):
            # –ï—Å–ª–∏ –∫–æ—Ä—Ç–µ–∂ - –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç (–æ—Ç–≤–µ—Ç)
            report = report[0] if report[0] else (report[1] if len(report) > 1 else None)
        elif isinstance(report, dict):
            report = report.get('response', report.get('text', str(report)))
        elif not isinstance(report, str):
            report = str(report)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        print(f'[{datetime.now()}] Agent response for task {task_id} (length: {len(report) if report else 0}): {report[:100] if report else "None"}...')

        # –ë–æ–ª–µ–µ –º—è–≥–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - –ø—Ä–∏–Ω–∏–º–∞–µ–º –ª—é–±–æ–π –æ—Ç–≤–µ—Ç –¥–ª–∏–Ω–Ω–µ–µ 5 —Å–∏–º–≤–æ–ª–æ–≤
        if report and isinstance(report, str) and len(report.strip()) > 5:
            # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
            try:
                from model_performance_tracker import get_performance_tracker
                tracker = get_performance_tracker()
                
                # –í—ã—á–∏—Å–ª—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–∞
                quality_score = tracker.calculate_quality_score(report)
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å (–∏–∑ metadata –∑–∞–¥–∞—á–∏ –∏–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
                used_model = 'phi3.5:3.8b'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
                try:
                    async with pool.acquire() as conn:
                        metadata = await conn.fetchval("SELECT metadata FROM tasks WHERE id = $1", task_id)
                        if metadata and metadata.get('used_model'):
                            used_model = metadata['used_model']
                except:
                    pass
                
                # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –ø–æ–ø—ã—Ç–∫—É
                await tracker.record_attempt(
                    task_id=task_id,
                    model=used_model,
                    category='autonomous_worker',
                    success=True,
                    response_length=len(report),
                    latency_ms=0,  # TODO: –¥–æ–±–∞–≤–∏—Ç—å –∏–∑–º–µ—Ä–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏
                    quality_score=quality_score
                )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è –Ω–∞ –±–æ–ª–µ–µ –º–æ—â–Ω—É—é –º–æ–¥–µ–ª—å
                should_upgrade, next_model = await tracker.should_upgrade_model(
                    task_id=task_id,
                    current_model=used_model,
                    category='autonomous_worker',
                    response=report
                )
                
                if should_upgrade and next_model:
                    logger.info(f"üîÑ [MODEL UPGRADE] –ó–∞–¥–∞—á–∞ {task_id} —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª–µ–µ –º–æ—â–Ω—É—é –º–æ–¥–µ–ª—å: {next_model}")
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∞–ø–≥—Ä–µ–π–¥–∞
                    async with pool.acquire() as conn:
                        await conn.execute("""
                            UPDATE tasks 
                            SET metadata = metadata || jsonb_build_object('model_upgrade_needed', true, 'recommended_model', $2)
                            WHERE id = $1
                        """, task_id, next_model)
            except Exception as e:
                logger.debug(f"Model performance tracking failed: {e}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ—Ç–≤–µ—Ç –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å–æ–æ–±—â–µ–Ω–∏–µ–º –æ–± –æ—à–∏–±–∫–µ
            error_indicators = ['‚ö†Ô∏è', '‚ùå', '‚åõ', 'Error', 'failed', '–Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω', '–Ω–µ –º–æ–≥—É', '–í—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã', '–û—à–∏–±–∫–∞ —Å–≤—è–∑–∏']
            is_error = any(indicator in report for indicator in error_indicators)
            
            if is_error:
                # –ï—Å–ª–∏ –∞–≥–µ–Ω—Ç –≤–µ—Ä–Ω—É–ª –æ—à–∏–±–∫—É, –ù–ï –ø–æ–º–µ—á–∞–µ–º –∑–∞–¥–∞—á—É –∫–∞–∫ completed
                # –í–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ pending –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏
                print(f'[{datetime.now()}] ‚ö†Ô∏è Agent returned error for task {task_id}, NOT completing task. Will retry later.')
                print(f'[{datetime.now()}] Error response: {report[:200]}...')
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ –ø–æ–ø—ã—Ç–æ–∫ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ pending
                attempt_count = 0
                try:
                    async with pool.acquire() as conn:
                        metadata = await conn.fetchval("SELECT metadata FROM tasks WHERE id = $1", task_id)
                        if metadata and metadata.get('attempt_count'):
                            attempt_count = int(metadata.get('attempt_count', 0))
                except (asyncpg.PostgresError, ValueError, TypeError) as e:
                    logger.debug(f"Error reading attempt_count for task {task_id}: {e}, using default 0")
                    attempt_count = 0
                
                attempt_count += 1
                
                # –ü–æ—Å–ª–µ 5 –ø–æ–ø—ã—Ç–æ–∫ –ø–æ–º–µ—á–∞–µ–º –∫–∞–∫ failed, –∞ –Ω–µ completed
                if attempt_count >= 5:
                    print(f'[{datetime.now()}] ‚ö†Ô∏è Task {task_id} failed after {attempt_count} attempts, marking as FAILED')
                    async with pool.acquire() as conn:
                        await conn.execute("""
                            UPDATE tasks 
                            SET status = 'failed', 
                                result = $2, 
                                updated_at = NOW(),
                                metadata = metadata || jsonb_build_object('auto_failed', true, 'attempt_count', $3, 'failure_reason', 'AI agent unavailable after multiple attempts')
                            WHERE id = $1
                        """, task_id, f"–ó–∞–¥–∞—á–∞ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞: AI –∞–≥–µ–Ω—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ—Å–ª–µ {attempt_count} –ø–æ–ø—ã—Ç–æ–∫.\n\n–û—à–∏–±–∫–∞: {report[:500]}", attempt_count)
                    print(f'[{datetime.now()}] ‚úÖ Task {task_id} marked as FAILED after {attempt_count} attempts.')
                else:
                    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –Ω–µ—É–¥–∞—á–Ω—É—é –ø–æ–ø—ã—Ç–∫—É
                    try:
                        from model_performance_tracker import get_performance_tracker
                        tracker = get_performance_tracker()
                        used_model = 'phi3.5:3.8b'
                        try:
                            async with pool.acquire() as conn:
                                metadata = await conn.fetchval("SELECT metadata FROM tasks WHERE id = $1", task_id)
                                if metadata and metadata.get('used_model'):
                                    used_model = metadata['used_model']
                        except:
                            pass
                        
                        await tracker.record_attempt(
                            task_id=task_id,
                            model=used_model,
                            category='autonomous_worker',
                            success=False,
                            response_length=len(report) if report else 0,
                            quality_score=0.0
                        )
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è –Ω–∞ –±–æ–ª–µ–µ –º–æ—â–Ω—É—é –º–æ–¥–µ–ª—å
                        should_upgrade, next_model = await tracker.should_upgrade_model(
                            task_id=task_id,
                            current_model=used_model,
                            category='autonomous_worker',
                            response=report
                        )
                        
                        if should_upgrade and next_model:
                            logger.info(f"üîÑ [AUTO UPGRADE] –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ {next_model} –¥–ª—è –∑–∞–¥–∞—á–∏ {task_id}")
                            # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–¥–∞—á—É —Å —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é
                            async with pool.acquire() as conn:
                                await conn.execute("""
                                    UPDATE tasks 
                                    SET status = 'pending', 
                                        updated_at = NOW(), 
                                        metadata = metadata || jsonb_build_object(
                                            'last_attempt_failed', true, 
                                            'attempt_count', $2, 
                                            'last_error', $3,
                                            'model_upgrade_needed', true,
                                            'recommended_model', $4
                                        )
                                    WHERE id = $1
                                """, task_id, attempt_count, report[:500], next_model)
                            print(f'[{datetime.now()}] üîÑ Task {task_id} upgraded to model {next_model} for retry')
                            return
                    except Exception as e:
                        logger.debug(f"Model upgrade check failed: {e}")
                    
                    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ pending –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏
                    async with pool.acquire() as conn:
                        await conn.execute("""
                            UPDATE tasks 
                            SET status = 'pending', 
                                updated_at = NOW(), 
                                metadata = metadata || jsonb_build_object('last_attempt_failed', true, 'attempt_count', $2, 'last_error', $3)
                            WHERE id = $1
                        """, task_id, attempt_count, report[:500])
                    print(f'[{datetime.now()}] ‚ö†Ô∏è Task {task_id} reverted to PENDING (attempt {attempt_count}/5). Will retry later.')
                return  # –ù–ï –ø–æ–º–µ—á–∞–µ–º –∫–∞–∫ completed!
            
            # –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø–µ—Ä–µ–¥ –æ—Ç–º–µ—Ç–∫–æ–π completed (–∞–Ω–∞–ª–æ–≥ manager_review –≤ —Ü–µ–ø–æ—á–∫–µ –ë–î)
            try:
                try:
                    from task_result_validator import validate_task_result
                except ImportError:
                    from app.task_result_validator import validate_task_result
                req_text = (task.get('title') or '') + ' ' + (task_description or '')
                is_valid, score = validate_task_result(req_text, report or '')
                if not is_valid or score < 0.5:
                    logger.warning(f"‚ö†Ô∏è [SMART WORKER] –ó–∞–¥–∞—á–∞ {task_id} –Ω–µ –ø—Ä–æ—à–ª–∞ –ø—Ä–æ–≤–µ—Ä–∫—É (score={score:.2f}), –æ—Å—Ç–∞–≤–ª—è—é –≤ pending –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏")
                    async with pool.acquire() as conn:
                        await conn.execute("""
                            UPDATE tasks SET status = 'pending', updated_at = NOW(),
                            metadata = COALESCE(metadata, '{}'::jsonb) || jsonb_build_object('validation_failed', true, 'validation_score', $2)
                            WHERE id = $1
                        """, task_id, score)
                    return
            except ImportError:
                pass
            except Exception as e:
                logger.debug(f"Validation skip for task {task_id}: {e}")
    
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ù–ï –æ—à–∏–±–∫–∞)
            async with pool.acquire() as conn:
                async with conn.transaction():
                    await conn.execute("UPDATE tasks SET status = 'completed', result = $2, updated_at = NOW() WHERE id = $1", task_id, report)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ knowledge_nodes (–±–µ–∑ domain_id –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –æ—à–∏–±–æ–∫)
                    try:
                        await conn.execute("""
                            INSERT INTO knowledge_nodes (content, metadata, confidence_score, source_ref)
                            VALUES ($1, $2, 0.85, $3)
                        """, f"üìä REPORT BY {expert_name}: {task_title}\n\n{report}", json.dumps({
                            'task_id': str(task_id), 
                            'expert': expert_name, 
                            'fallback_used': is_error,
                            'department': expert_config['department']
                        }), 'autonomous_worker')
                        print(f'[{datetime.now()}] ‚úÖ Knowledge saved for task {task_id}')
                    except Exception as e:
                        print(f'[{datetime.now()}] ‚ö†Ô∏è Error saving to knowledge_nodes: {e}')
                        import traceback
                    traceback.print_exc()
        print(f'[{datetime.now()}] ‚úÖ Task {task_id} COMPLETED.')
    except Exception as e:
        print(f'[{datetime.now()}] ‚ùå Error processing task {task_id}: {e}')
        import traceback
        traceback.print_exc()
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–¥–∞—á—É –≤ pending –ø—Ä–∏ –æ—à–∏–±–∫–µ
        async with pool.acquire() as conn:
            await conn.execute("""
                UPDATE tasks 
                SET status = 'pending', 
                    updated_at = NOW(),
                    metadata = COALESCE(metadata, '{}'::jsonb) || jsonb_build_object('processing_error', $2)
                WHERE id = $1
            """, task_id, str(e)[:500])
    finally:
        # –û—á–∏—â–∞–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫
        if router_instance and hasattr(router_instance, '_preferred_source'):
            router_instance._preferred_source = None
        
        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º heartbeat –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ
        heartbeat_stopped = True
        if heartbeat_task and not heartbeat_task.done():
            heartbeat_task.cancel()
            try:
                await asyncio.wait_for(heartbeat_task, timeout=1.0)
            except (asyncio.CancelledError, asyncio.TimeoutError):
                pass
    
    if not (report and isinstance(report, str) and len(report.strip()) > 5):
        # –ï—Å–ª–∏ –∞–≥–µ–Ω—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç, —Å–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –∏ –∑–∞–≤–µ—Ä—à–∞–µ–º –∑–∞–¥–∞—á—É
        attempt_count = 0
        try:
            async with pool.acquire() as conn:
                metadata = await conn.fetchval("SELECT metadata FROM tasks WHERE id = $1", task_id)
                if metadata and metadata.get('attempt_count'):
                    attempt_count = int(metadata.get('attempt_count', 0))
        except:
            pass
        
        attempt_count += 1
        
        # –ü–æ—Å–ª–µ 3 –ø–æ–ø—ã—Ç–æ–∫ –∑–∞–≤–µ—Ä—à–∞–µ–º –∑–∞–¥–∞—á—É —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º –æ—Ç–≤–µ—Ç–æ–º
        if attempt_count >= 3:
            print(f'[{datetime.now()}] ‚ö†Ô∏è Task {task_id} failed after {attempt_count} attempts, completing with minimal response')
            minimal_response = f"""–ó–∞–¥–∞—á–∞: {task_title}

–°—Ç–∞—Ç—É—Å: –ó–∞–≤–µ—Ä—à–µ–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ—Å–ª–µ {attempt_count} –Ω–µ—É–¥–∞—á–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ AI –∞–≥–µ–Ω—Ç–æ–º.

–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: AI –∞–≥–µ–Ω—Ç –±—ã–ª –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ó–∞–¥–∞—á–∞ –ø–æ–º–µ—á–µ–Ω–∞ –∫–∞–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω–∞—è –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –æ—á–µ—Ä–µ–¥–∏."""
            # –ü—Ä–æ—Å—Ç–∞–≤–ª—è–µ–º –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è, —á—Ç–æ–±—ã –≤ –¥–∞—à–±–æ—Ä–¥–µ –Ω–µ –±—ã–ª–æ ¬´–ù–µ –Ω–∞–∑–Ω–∞—á–µ–Ω¬ª
            assignee_id = task.get('assignee_expert_id')
            async with pool.acquire() as conn:
                if assignee_id:
                    await conn.execute("""
                        UPDATE tasks 
                        SET status = 'completed', result = $2, updated_at = NOW(),
                            assignee_expert_id = $4,
                            metadata = COALESCE(metadata, '{}'::jsonb) || jsonb_build_object('auto_completed', true, 'attempt_count', $3)
                        WHERE id = $1
                    """, task_id, minimal_response, attempt_count, assignee_id)
                else:
                    await conn.execute("""
                        UPDATE tasks 
                        SET status = 'completed', result = $2, updated_at = NOW(),
                            assignee_expert_id = (SELECT id FROM experts WHERE name = '–í–∏–∫—Ç–æ—Ä–∏—è' LIMIT 1),
                            metadata = COALESCE(metadata, '{}'::jsonb) || jsonb_build_object('auto_completed', true, 'attempt_count', $3)
                        WHERE id = $1
                    """, task_id, minimal_response, attempt_count)
            print(f'[{datetime.now()}] ‚úÖ Task {task_id} AUTO-COMPLETED after {attempt_count} attempts (assignee set).')
        else:
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ –ø–æ–ø—ã—Ç–æ–∫ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ pending
            async with pool.acquire() as conn:
                await conn.execute("""
                    UPDATE tasks 
                    SET status = 'pending', 
                        updated_at = NOW(), 
                        metadata = metadata || jsonb_build_object('last_attempt_failed', true, 'attempt_count', $2)
                    WHERE id = $1
                """, task_id, attempt_count)
            print(f'[{datetime.now()}] ‚ö†Ô∏è Task {task_id} FAILED (attempt {attempt_count}/3). Reverted to pending.')
    
    # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º heartbeat –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ
    heartbeat_stopped = True
    if heartbeat_task and not heartbeat_task.done():
        heartbeat_task.cancel()
        try:
            await asyncio.wait_for(heartbeat_task, timeout=1.0)
        except (asyncio.CancelledError, asyncio.TimeoutError):
            pass

async def main():
    print(f'[{datetime.now()}] üöÄ AUTONOMOUS SMART WORKER v4.0 (PARALLEL) starting...')
    pool = await get_pool()
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    MAX_CONCURRENT_TASKS = int(os.getenv('SMART_WORKER_MAX_CONCURRENT', '10'))
    BATCH_SIZE = int(os.getenv('SMART_WORKER_BATCH_SIZE', '50'))
    
    print(f'[{datetime.now()}] ‚ö° Parallel processing: {MAX_CONCURRENT_TASKS} concurrent tasks, batch size: {BATCH_SIZE}')
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∏—Å—Ç–µ–º—É —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è –∫–æ—Ä–ø–æ—Ä–∞—Ü–∏–∏ (Singularity 10.0)
    try:
        from corporation_self_learning import get_corporation_learner
        learner = get_corporation_learner()
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤ —Ñ–æ–Ω–µ
        asyncio.create_task(learner.start_continuous_learning(interval_hours=6))
        print(f'[{datetime.now()}] üß† [SINGULARITY 10.0] –°–∏—Å—Ç–µ–º–∞ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è –∑–∞–ø—É—â–µ–Ω–∞')
    except Exception as e:
        logger.debug(f"Could not start corporation learning: {e}")
    
    while True:
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º LEFT JOIN —á—Ç–æ–±—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∑–∞–¥–∞—á–∏ –¥–∞–∂–µ –µ—Å–ª–∏ —ç–∫—Å–ø–µ—Ä—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω
            # –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä—É–µ–º –∑–∞–¥–∞—á–∏ —Å –≤—ã—Å–æ–∫–æ–π bug_probability (Code-Smell Predictor, Singularity 9.0)
            async with pool.acquire() as conn:
                tasks = await conn.fetch("""
                    SELECT t.id, t.title, t.description, 
                           COALESCE(e.name, '–í–∏–∫—Ç–æ—Ä–∏—è') as assignee,
                           COALESCE(e.id, (SELECT id FROM experts WHERE name = '–í–∏–∫—Ç–æ—Ä–∏—è' LIMIT 1)) as assignee_expert_id,
                           COALESCE((t.metadata->>'bug_probability')::float, 0.0) as bug_probability
                    FROM tasks t 
                    LEFT JOIN experts e ON t.assignee_expert_id = e.id 
                    WHERE t.status = 'pending' 
                    ORDER BY 
                        COALESCE((t.metadata->>'bug_probability')::float, 0.0) DESC,  -- –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –∑–∞–¥–∞—á–∏ —Å –≤—ã—Å–æ–∫–æ–π bug_probability
                        t.created_at ASC 
                    LIMIT $1
                """, BATCH_SIZE)
            
            if tasks:
                print(f'[{datetime.now()}] Found {len(tasks)} pending tasks. Processing in parallel (max {MAX_CONCURRENT_TASKS} concurrent)...')
                
                # –ò–ù–¢–ï–õ–õ–ï–ö–¢–£–ê–õ–¨–ù–û–ï –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–∏—Ä–æ–≤—ã—Ö –ø—Ä–∞–∫—Ç–∏–∫
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º Task Complexity Estimation –∏ Query-Model Interaction
                mlx_tasks = []
                ollama_tasks = []
                
                try:
                    from intelligent_model_router import get_intelligent_router
                    intelligent_router = get_intelligent_router()
                    
                    for task in tasks:
                        # –û—Ü–µ–Ω–∏–≤–∞–µ–º —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–¥–∞—á–∏
                        prompt = f"{task.get('title', '')} {task.get('description', '')}"
                        task_complexity = intelligent_router.estimate_task_complexity(prompt, category=None)
                        
                        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∏ —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏
                        # MLX –ª—É—á—à–µ –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö reasoning –∏ coding –∑–∞–¥–∞—á
                        # Ollama –ª—É—á—à–µ –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö –∏ –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–¥–∞—á
                        if (task_complexity.complexity_score > 0.6 and 
                            (task_complexity.requires_reasoning or task_complexity.requires_coding)):
                            # –°–ª–æ–∂–Ω—ã–µ reasoning/coding ‚Üí MLX (–º–æ—â–Ω—ã–µ –º–æ–¥–µ–ª–∏)
                            task['preferred_source'] = 'mlx'
                            mlx_tasks.append(task)
                        elif task_complexity.complexity_score < 0.4 or task_complexity.task_type == 'fast':
                            # –ü—Ä–æ—Å—Ç—ã–µ/–±—ã—Å—Ç—Ä—ã–µ ‚Üí Ollama
                            task['preferred_source'] = 'ollama'
                            ollama_tasks.append(task)
                        else:
                            # –°—Ä–µ–¥–Ω–∏–µ –∑–∞–¥–∞—á–∏ - —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
                            if len(mlx_tasks) <= len(ollama_tasks):
                                task['preferred_source'] = 'mlx'
                                mlx_tasks.append(task)
                            else:
                                task['preferred_source'] = 'ollama'
                                ollama_tasks.append(task)
                except Exception as e:
                    logger.debug(f"Intelligent routing failed: {e}, using simple distribution")
                    # Fallback –Ω–∞ –ø—Ä–æ—Å—Ç–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
                    for task in tasks:
                        bug_prob = task.get('bug_probability', 0.0)
                        if bug_prob > 0.5:
                            task['preferred_source'] = 'mlx'
                            mlx_tasks.append(task)
                        else:
                            task['preferred_source'] = 'ollama'
                            ollama_tasks.append(task)
                
                print(f'[{datetime.now()}] üìä –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: MLX={len(mlx_tasks)}, Ollama={len(ollama_tasks)}')
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —á–µ—Ä–µ–∑ –û–ë–ê –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
                all_tasks_to_process = []
                
                # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
                for task in mlx_tasks:
                    all_tasks_to_process.append(task)
                
                for task in ollama_tasks:
                    all_tasks_to_process.append(task)
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –±–∞—Ç—á–∞–º–∏
                for i in range(0, len(all_tasks_to_process), MAX_CONCURRENT_TASKS):
                    batch = all_tasks_to_process[i:i + MAX_CONCURRENT_TASKS]
                    print(f'[{datetime.now()}] Processing batch {i//MAX_CONCURRENT_TASKS + 1}: {len(batch)} tasks (MLX –∏ Ollama –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)')
                    
                    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ - –∑–∞–¥–∞—á–∏ –±—É–¥—É—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è —á–µ—Ä–µ–∑ –æ–±–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
                    await asyncio.gather(*[
                        process_task(pool, task) 
                        for task in batch
                    ], return_exceptions=True)
                    
                    # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏
                    if i + MAX_CONCURRENT_TASKS < len(all_tasks_to_process):
                        await asyncio.sleep(1)
                
                print(f'[{datetime.now()}] ‚úÖ Batch completed: {len(tasks)} tasks processed')
            else:
                print(f'[{datetime.now()}] No pending tasks found. Waiting...')
            
            await asyncio.sleep(5)  # –£–º–µ–Ω—å—à–∏–ª–∏ –∑–∞–¥–µ—Ä–∂–∫—É, —Ç–∞–∫ –∫–∞–∫ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±—ã—Å—Ç—Ä–µ–µ
        except Exception as e:
            print(f'[{datetime.now()}] Main loop error: {e}')
            import traceback
            traceback.print_exc()
            await asyncio.sleep(30)

if __name__ == '__main__':
    asyncio.run(main())

