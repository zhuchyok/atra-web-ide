"""
Tacit Knowledge Miner: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–µ—è–≤–Ω—ã—Ö —Å—Ç–∏–ª–µ–≤—ã—Ö –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:
- –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏–∑ interaction_logs –∏ knowledge_nodes
- –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç–∏–ª–µ–≤—ã—Ö –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π (naming conventions, error handling, testing style)
- –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–∏–ª–µ–≤–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞ –≤ —Å—Ç–∏–ª–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
"""

import asyncio
import os
import json
import logging
import re
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
import numpy as np

# Import database connection from evaluator
from evaluator import get_pool

# Import embedding function from semantic_cache
try:
    from semantic_cache import get_embedding
except ImportError:
    get_embedding = None

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

DB_URL = os.getenv('DATABASE_URL', 'postgresql://admin:secret@localhost:5432/knowledge_os')

# –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–æ—Ñ–∏–ª—è
MIN_INTERACTIONS_FOR_PROFILE = 10

# –ü–æ—Ä–æ–≥ similarity –¥–ª—è —Å—Ç–∏–ª–µ–≤–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
STYLE_SIMILARITY_THRESHOLD = 0.85


@dataclass
class StyleProfile:
    """–°—Ç–∏–ª–µ–≤–æ–π –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    user_identifier: str
    style_vector: List[float]  # Embedding –≤–µ–∫—Ç–æ—Ä —Å—Ç–∏–ª—è
    preferences: Dict[str, any]  # {naming_convention, error_handling, testing_style, ...}
    similarity_score: float  # Cosine similarity —Å —ç—Ç–∞–ª–æ–Ω–Ω—ã–º —Å—Ç–∏–ª–µ–º
    created_at: datetime
    updated_at: datetime


class TacitKnowledgeMiner:
    """–ö–ª–∞—Å—Å –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –Ω–µ—è–≤–Ω—ã—Ö —Å—Ç–∏–ª–µ–≤—ã—Ö –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π"""
    
    def __init__(self, db_url: str = DB_URL):
        self.db_url = db_url
    
    async def extract_style_patterns(self, user_identifier: str) -> Optional[Dict[str, any]]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç–∏–ª–µ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        
        Args:
            user_identifier: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–∏–∑ metadata->>'user_identifier')
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è–º–∏ —Å—Ç–∏–ª—è –∏–ª–∏ None, –µ—Å–ª–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö
        """
        pool = await get_pool()
        async with pool.acquire() as conn:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –∫–æ–¥–æ–º
            interactions = await conn.fetch("""
                SELECT 
                    il.user_query,
                    il.assistant_response,
                    il.metadata,
                    il.created_at
                FROM interaction_logs il
                WHERE il.metadata->>'user_identifier' = $1
                  AND (il.user_query ILIKE '%def %' 
                       OR il.user_query ILIKE '%class %'
                       OR il.assistant_response ILIKE '%def %'
                       OR il.assistant_response ILIKE '%class %')
                ORDER BY il.created_at DESC
                LIMIT 100
            """, user_identifier)
            
            if len(interactions) < MIN_INTERACTIONS_FOR_PROFILE:
                logger.debug(f"Insufficient interactions for user {user_identifier}: {len(interactions)}")
                return None
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            code_samples = []
            for interaction in interactions:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–¥ –∏–∑ –æ—Ç–≤–µ—Ç–∞
                code = self._extract_code(interaction['assistant_response'])
                if code:
                    code_samples.append(code)
            
            if not code_samples:
                return None
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç–∏–ª–µ–≤—ã–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è
            preferences = {
                'naming_convention': self._detect_naming_convention(code_samples),
                'error_handling': self._detect_error_handling_style(code_samples),
                'testing_style': self._detect_testing_style(code_samples),
                'documentation_style': self._detect_documentation_style(code_samples),
                'code_structure': self._detect_code_structure(code_samples),
                'variable_naming': self._detect_variable_naming(code_samples),
                'function_style': self._detect_function_style(code_samples)
            }
            
            # –°–æ–∑–¥–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–∏–ª—è –¥–ª—è embedding
            style_text = self._create_style_text(preferences)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º embedding –≤–µ–∫—Ç–æ—Ä–∞ —Å—Ç–∏–ª—è
            style_vector = None
            if get_embedding:
                try:
                    style_vector = await get_embedding(style_text)
                except Exception as e:
                    logger.error(f"Error generating embedding: {e}")
            
            if not style_vector:
                # Fallback: —Å–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–π –≤–µ–∫—Ç–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π
                style_vector = self._create_fallback_vector(preferences)
            
            return {
                'preferences': preferences,
                'style_vector': style_vector,
                'style_text': style_text,
                'code_samples_count': len(code_samples)
            }
    
    def _extract_code(self, text: str) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–¥ –∏–∑ —Ç–µ–∫—Å—Ç–∞ (Python –±–ª–æ–∫–∏ –≤ markdown)"""
        # –ò—â–µ–º –±–ª–æ–∫–∏ –∫–æ–¥–∞ –≤ markdown
        code_pattern = r'```(?:python)?\n(.*?)```'
        matches = re.findall(code_pattern, text, re.DOTALL)
        if matches:
            return '\n'.join(matches)
        
        # –ï—Å–ª–∏ –Ω–µ—Ç markdown, –∏—â–µ–º –±–ª–æ–∫–∏ —Å def/class
        lines = text.split('\n')
        code_lines = []
        in_code = False
        for line in lines:
            if line.strip().startswith(('def ', 'class ', 'import ', 'from ')):
                in_code = True
            if in_code:
                code_lines.append(line)
            if in_code and line.strip() == '':
                break
        
        return '\n'.join(code_lines) if code_lines else None
    
    def _detect_naming_convention(self, code_samples: List[str]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–Ω–≤–µ–Ω—Ü–∏—é –∏–º–µ–Ω–æ–≤–∞–Ω–∏—è (snake_case, camelCase, etc.)"""
        snake_case_count = 0
        camel_case_count = 0
        
        for code in code_samples:
            # –ò—â–µ–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–π –∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
            functions = re.findall(r'def\s+([a-zA-Z_][a-zA-Z0-9_]*)', code)
            variables = re.findall(r'([a-zA-Z_][a-zA-Z0-9_]*)\s*=', code)
            
            for name in functions + variables:
                if '_' in name:
                    snake_case_count += 1
                elif name[0].islower() and any(c.isupper() for c in name[1:]):
                    camel_case_count += 1
        
        if snake_case_count > camel_case_count * 2:
            return 'snake_case'
        elif camel_case_count > snake_case_count * 2:
            return 'camelCase'
        else:
            return 'snake_case'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    def _detect_error_handling_style(self, code_samples: List[str]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç–∏–ª—å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫"""
        try_except_count = 0
        if_checks_count = 0
        no_handling_count = 0
        
        for code in code_samples:
            if 'try:' in code or 'except' in code:
                try_except_count += 1
            elif 'if' in code and ('error' in code.lower() or 'none' in code.lower()):
                if_checks_count += 1
            else:
                no_handling_count += 1
        
        total = len(code_samples)
        if try_except_count / total > 0.3:
            return 'defensive_with_exceptions'
        elif if_checks_count / total > 0.3:
            return 'defensive_with_checks'
        else:
            return 'minimal'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    def _detect_testing_style(self, code_samples: List[str]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç–∏–ª—å —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        test_patterns = {
            'pytest': r'(pytest|@pytest)',
            'unittest': r'(unittest|TestCase)',
            'assert': r'assert\s+'
        }
        
        test_counts = {key: 0 for key in test_patterns}
        for code in code_samples:
            for test_type, pattern in test_patterns.items():
                if re.search(pattern, code, re.IGNORECASE):
                    test_counts[test_type] += 1
        
        if test_counts['pytest'] > 0:
            return 'tdd_with_pytest'
        elif test_counts['unittest'] > 0:
            return 'tdd_with_unittest'
        elif test_counts['assert'] > 0:
            return 'basic_asserts'
        else:
            return 'minimal'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    def _detect_documentation_style(self, code_samples: List[str]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç–∏–ª—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏"""
        docstring_count = 0
        comment_count = 0
        
        for code in code_samples:
            if '"""' in code or "'''" in code:
                docstring_count += 1
            if '#' in code:
                comment_count += 1
        
        total = len(code_samples)
        if docstring_count / total > 0.3:
            return 'detailed_docstrings'
        elif comment_count / total > 0.3:
            return 'inline_comments'
        else:
            return 'minimal'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    def _detect_code_structure(self, code_samples: List[str]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–æ–¥–∞"""
        class_count = 0
        function_count = 0
        
        for code in code_samples:
            class_count += len(re.findall(r'class\s+', code))
            function_count += len(re.findall(r'def\s+', code))
        
        total_functions = function_count
        total_classes = class_count
        
        if total_classes > 0 and total_classes / (total_functions + total_classes) > 0.3:
            return 'oop_oriented'
        else:
            return 'functional'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    def _detect_variable_naming(self, code_samples: List[str]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç–∏–ª—å –∏–º–µ–Ω–æ–≤–∞–Ω–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö"""
        descriptive_count = 0
        short_count = 0
        
        for code in code_samples:
            variables = re.findall(r'([a-zA-Z_][a-zA-Z0-9_]*)\s*=', code)
            for var in variables:
                if len(var) > 10:
                    descriptive_count += 1
                elif len(var) <= 3:
                    short_count += 1
        
        if descriptive_count > short_count * 2:
            return 'descriptive_names'
        elif short_count > descriptive_count * 2:
            return 'short_names'
        else:
            return 'balanced'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    def _detect_function_style(self, code_samples: List[str]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç–∏–ª—å —Ñ—É–Ω–∫—Ü–∏–π"""
        async_count = 0
        generator_count = 0
        simple_count = 0
        
        for code in code_samples:
            functions = re.findall(r'(?:async\s+)?def\s+([a-zA-Z_][a-zA-Z0-9_]*)', code)
            for func_def in re.findall(r'def\s+[^:]+:', code):
                if 'async' in func_def:
                    async_count += 1
                elif 'yield' in code:
                    generator_count += 1
                else:
                    simple_count += 1
        
        total = async_count + generator_count + simple_count
        if total == 0:
            return 'simple'
        
        if async_count / total > 0.3:
            return 'async_heavy'
        elif generator_count / total > 0.3:
            return 'generator_heavy'
        else:
            return 'simple'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    def _create_style_text(self, preferences: Dict[str, any]) -> str:
        """–°–æ–∑–¥–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–∏–ª—è –¥–ª—è embedding"""
        style_parts = []
        for key, value in preferences.items():
            style_parts.append(f"{key}: {value}")
        return "; ".join(style_parts)
    
    def _create_fallback_vector(self, preferences: Dict[str, any]) -> List[float]:
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ—Å—Ç–æ–π –≤–µ–∫—Ç–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π (fallback)"""
        # –†–∞–∑–º–µ—Ä 768 = nomic-embed-text; knowledge_nodes.embedding vector(768)
        vector = [0.0] * 768
        style_text = self._create_style_text(preferences)
        
        for i, char in enumerate(style_text):
            idx = (i * ord(char)) % 768
            vector[idx] += ord(char) / 1000.0
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ–∫—Ç–æ—Ä
        norm = np.linalg.norm(vector)
        if norm > 0:
            vector = [v / norm for v in vector]
        
        return vector
    
    def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É –≤–µ–∫—Ç–æ—Ä–∞–º–∏"""
        try:
            v1 = np.array(vec1)
            v2 = np.array(vec2)
            
            dot_product = np.dot(v1, v2)
            norm1 = np.linalg.norm(v1)
            norm2 = np.linalg.norm(v2)
            
            if norm1 == 0 or norm2 == 0:
                return 0.0
            
            return float(dot_product / (norm1 * norm2))
        except Exception as e:
            logger.error(f"Error calculating cosine similarity: {e}")
            return 0.0
    
    async def get_style_profile(self, user_identifier: str) -> Optional[StyleProfile]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∏–ª–µ–≤–æ–π –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –ë–î"""
        pool = await get_pool()
        async with pool.acquire() as conn:
            row = await conn.fetchrow("""
                SELECT 
                    id,
                    user_identifier,
                    style_vector,
                    preferences,
                    similarity_score,
                    created_at,
                    updated_at
                FROM user_style_profiles
                WHERE user_identifier = $1
                ORDER BY updated_at DESC
                LIMIT 1
            """, user_identifier)
            
            if not row:
                return None
            
            return StyleProfile(
                user_identifier=row['user_identifier'],
                style_vector=row['style_vector'] or [],
                preferences=row['preferences'] or {},
                similarity_score=float(row['similarity_score'] or 0.0),
                created_at=row['created_at'],
                updated_at=row['updated_at']
            )
    
    async def save_style_profile(self, user_identifier: str, style_data: Dict[str, any]) -> Optional[str]:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç–∏–ª–µ–≤–æ–π –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –ë–î"""
        pool = await get_pool()
        async with pool.acquire() as conn:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –ø—Ä–æ—Ñ–∏–ª—å
            existing = await conn.fetchrow("""
                SELECT id FROM user_style_profiles WHERE user_identifier = $1
            """, user_identifier)
            
            if existing:
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –ø—Ä–æ—Ñ–∏–ª—å
                await conn.execute("""
                    UPDATE user_style_profiles
                    SET style_vector = $1,
                        preferences = $2,
                        updated_at = NOW()
                    WHERE user_identifier = $3
                """, style_data['style_vector'], json.dumps(style_data['preferences']), user_identifier)
                profile_id = str(existing['id'])
            else:
                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –ø—Ä–æ—Ñ–∏–ª—å
                profile_id = await conn.fetchval("""
                    INSERT INTO user_style_profiles 
                    (user_identifier, style_vector, preferences, similarity_score)
                    VALUES ($1, $2, $3, $4)
                    RETURNING id
                """, 
                user_identifier,
                style_data['style_vector'],
                json.dumps(style_data['preferences']),
                0.0  # similarity_score –±—É–¥–µ—Ç –≤—ã—á–∏—Å–ª–µ–Ω –ø–æ–∑–∂–µ
                )
                profile_id = str(profile_id) if profile_id else None
            
            logger.info(f"‚úÖ Saved style profile for user {user_identifier}: {profile_id}")
            return profile_id
    
    async def calculate_style_similarity(self, generated_code: str, user_identifier: str) -> float:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç similarity –º–µ–∂–¥—É —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∫–æ–¥–æ–º –∏ —Å—Ç–∏–ª–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        
        Args:
            generated_code: –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–¥
            user_identifier: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        
        Returns:
            Cosine similarity (0.0-1.0)
        """
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        profile = await self.get_style_profile(user_identifier)
        if not profile or not profile.style_vector:
            return 0.0
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç–∏–ª—å –∏–∑ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–¥–∞
        generated_style = self._extract_code(generated_code)
        if not generated_style:
            return 0.0
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç–∏–ª—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–¥–∞
        code_samples = [generated_style]
        preferences = {
            'naming_convention': self._detect_naming_convention(code_samples),
            'error_handling': self._detect_error_handling_style(code_samples),
            'testing_style': self._detect_testing_style(code_samples),
            'documentation_style': self._detect_documentation_style(code_samples),
            'code_structure': self._detect_code_structure(code_samples),
            'variable_naming': self._detect_variable_naming(code_samples),
            'function_style': self._detect_function_style(code_samples)
        }
        
        # –°–æ–∑–¥–∞–µ–º embedding –≤–µ–∫—Ç–æ—Ä–∞ –¥–ª—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å—Ç–∏–ª—è
        style_text = self._create_style_text(preferences)
        generated_vector = None
        
        if get_embedding:
            try:
                generated_vector = await get_embedding(style_text)
            except Exception as e:
                logger.error(f"Error generating embedding for similarity: {e}")
        
        if not generated_vector:
            generated_vector = self._create_fallback_vector(preferences)
        
        # –í—ã—á–∏—Å–ª—è–µ–º cosine similarity
        similarity = self._cosine_similarity(profile.style_vector, generated_vector)
        
        return similarity


async def update_style_profiles():
    """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∏–ª–µ–≤—ã–µ –ø—Ä–æ—Ñ–∏–ª–∏ –¥–ª—è –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
    logger.info("üé® Starting style profile update...")
    pool = await get_pool()
    
    async with pool.acquire() as conn:
        # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        users = await conn.fetch("""
            SELECT DISTINCT metadata->>'user_identifier' as user_id
            FROM interaction_logs
            WHERE metadata->>'user_identifier' IS NOT NULL
            LIMIT 50
        """)
        
        miner = TacitKnowledgeMiner()
        updated_count = 0
        
        for user_row in users:
            user_id = user_row['user_id']
            if not user_id:
                continue
            
            try:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç–∏–ª–µ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
                style_data = await miner.extract_style_patterns(user_id)
                if style_data:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ—Ñ–∏–ª—å
                    await miner.save_style_profile(user_id, style_data)
                    updated_count += 1
                    logger.info(f"‚úÖ Updated style profile for user {user_id}")
            except Exception as e:
                logger.error(f"‚ùå Error updating style profile for user {user_id}: {e}")
        
        logger.info(f"‚úÖ Updated {updated_count} style profiles")


if __name__ == "__main__":
    asyncio.run(update_style_profiles())

