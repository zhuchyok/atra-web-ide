import logging
import json
import re
from typing import List, Dict, Any, Optional
from dataclasses import dataclass

logger = logging.getLogger(__name__)

@dataclass
class Entity:
    name: str
    type: str
    confidence: float
    metadata: Dict[str, Any]

class EntityExtractor:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—É—â–Ω–æ—Å—Ç–∏ –∏ —Å–≤—è–∑–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è GraphRAG.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥: —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è + LLM (—á–µ—Ä–µ–∑ ai_core).
    """
    def __init__(self):
        # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–π —ç–∫—Å—Ç—Ä–∞–∫—Ü–∏–∏
        self.patterns = {
            "expert": r"@(\w+)",
            "file": r"`([\w\./-]+\.\w+)`",
            "tech": r"(Docker|PostgreSQL|Redis|FastAPI|Svelte|Python|MLX|Ollama|DeepSeek)",
            "concept": r"üíé\s*([–ê-–ØA-Z\s]+)"
        }

    async def extract_entities(self, content: str) -> List[Entity]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ —ç–∫—Å—Ç—Ä–∞–∫—Ü–∏–∏ —Å—É—â–Ω–æ—Å—Ç–µ–π."""
        entities = []
        
        # 1. –ë—ã—Å—Ç—Ä–∞—è —ç–∫—Å—Ç—Ä–∞–∫—Ü–∏—è –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º
        for e_type, pattern in self.patterns.items():
            matches = re.finditer(pattern, content)
            for match in matches:
                entities.append(Entity(
                    name=match.group(1),
                    type=e_type,
                    confidence=0.8,
                    metadata={"source": "regex"}
                ))

        # 2. –ì–ª—É–±–æ–∫–∞—è —ç–∫—Å—Ç—Ä–∞–∫—Ü–∏—è —á–µ—Ä–µ–∑ LLM (–µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –¥–ª–∏–Ω–Ω—ã–π –∏ –≤–∞–∂–Ω—ã–π)
        if len(content) > 200:
            try:
                from app.ai_core import run_smart_agent_async
                prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ–∫—Å—Ç –∏ –∏–∑–≤–ª–µ–∫–∏ –∫–ª—é—á–µ–≤—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏ (—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, –ª—é–¥–∏, –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏, —Ñ–∞–π–ª—ã).
–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤: [{{"name": "...", "type": "...", "confidence": 0.9}}]
–¢–ï–ö–°–¢:
{content[:1000]}"""
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–µ–≥–∫—É—é –º–æ–¥–µ–ª—å –¥–ª—è —ç–∫—Å—Ç—Ä–∞–∫—Ü–∏–∏
                response = await run_smart_agent_async(prompt, expert_name="–í–∏–∫—Ç–æ—Ä–∏—è", category="fast")
                
                # –ü–∞—Ä—Å–∏–Ω–≥ JSON
                json_match = re.search(r'\[.*\]', response, re.DOTALL)
                if json_match:
                    llm_entities = json.loads(json_match.group(0))
                    for le in llm_entities:
                        entities.append(Entity(
                            name=le['name'],
                            type=le['type'],
                            confidence=le.get('confidence', 0.7),
                            metadata={"source": "llm"}
                        ))
            except Exception as e:
                logger.debug(f"LLM Entity Extraction failed: {e}")

        # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ –∏–º–µ–Ω–∏
        unique_entities = {e.name.lower(): e for e in entities}.values()
        return list(unique_entities)

_extractor = None
def get_entity_extractor():
    global _extractor
    if _extractor is None:
        _extractor = EntityExtractor()
    return _extractor
