"""
–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ MLX API Server –∏ Ollama.
–ü—Ä–∏ –∑–∞–ø—É—Å–∫–µ —á–∞—Ç–∞ –∏ –ø–æ –∑–∞–ø—Ä–æ—Å—É ‚Äî –∞–∫—Ç—É–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π (–º–æ–≥—É—Ç –º–µ–Ω—è—Ç—å—Å—è).
–ö—ç—à —Å TTL, —á—Ç–æ–±—ã –Ω–µ –¥–µ—Ä–≥–∞—Ç—å /api/tags –Ω–∞ –∫–∞–∂–¥—ã–π –∑–∞–ø—Ä–æ—Å.

–í–ê–ñ–ù–û: –ú–æ–¥–µ–ª–∏ Ollama –∏ MLX —Ö—Ä–∞–Ω—è—Ç—Å—è –†–ê–ó–î–ï–õ–¨–ù–û, –Ω–µ —Å–º–µ—à–∏–≤–∞—é—Ç—Å—è!
- Ollama: –ª–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –ø–æ—Ä—Ç—É 11434
- MLX: Apple Silicon –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –ø–æ—Ä—Ç—É 11435
"""

import asyncio
import logging
import os
import time
from typing import Any, Dict, List, Optional, Tuple
from dataclasses import dataclass

logger = logging.getLogger(__name__)

# –ö—ç—à: {"mlx": [...], "ollama": [...], "scanned_at": float, "metrics": {"ollama": {...}, "mlx": {...}}}
_scan_cache: Optional[Dict] = None
_SCAN_TTL_SEC = 120  # 2 –º–∏–Ω—É—Ç—ã
# –í–∫–ª—é—á–∏—Ç—å probe –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –ø—Ä–∏ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏ (–∑–∞–º–µ—Ä load/unload/deploy/processing —Å –∑–∞–ø–∞—Å–æ–º)
_PROBE_NEW_MODELS = os.getenv("MODEL_PROBE_ON_SCAN", "true").lower() in ("true", "1", "yes")

# ==============================================================================
# –ü–†–ò–û–†–ò–¢–ï–¢–´ –ú–û–î–ï–õ–ï–ô (–æ—Ç —Å–∞–º–æ–π –º–æ—â–Ω–æ–π –∫ –º–µ–Ω–µ–µ –º–æ—â–Ω–æ–π)
# –í–ê–ñ–ù–û: –°–ø–∏—Å–∫–∏ –¥–ª—è Ollama –∏ MLX –†–ê–ó–ù–´–ï, –Ω–µ –ø—É—Ç–∞—Ç—å!
# ==============================================================================

# –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª—è OLLAMA (–ø–æ—Ä—Ç 11434) - –ø–æ –º–æ—â–Ω–æ—Å—Ç–∏
OLLAMA_BEST_FIRST: List[str] = [
    "deepseek-r1:32b",          # 32B Reasoning (Board/VIP)
    "qwen2.5-coder:32b",        # 32B Main Engineer
    "qwq:32b",                  # 32B Logic
    "deepseek-r1:14b",          # 14B Fast Reasoning
    "glm-4.7-flash:q8_0",       # 31B Fast Reasoning
    "qwen3-coder:30b",          # 30B Previous Gen
    "llava:7b",                 # Vision 7B
    "moondream:latest",         # Vision small
    "tinyllama:1.1b-chat",      # Tiny fallback
]

# –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª—è MLX (–ø–æ—Ä—Ç 11435)
MLX_BEST_FIRST: List[str] = [
    "qwen2.5:3b",                    # 3B light
    "phi3:mini-4k",                  # Mini
    "tinyllama:1.1b-chat",           # Tiny fallback
]

# –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –º–æ–¥–µ–ª–µ–π Ollama –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–ø–µ—Ä–≤—ã–π –¥–æ—Å—Ç—É–ø–Ω—ã–π –∏–∑ —Å–ø–∏—Å–∫–∞ –±—É–¥–µ—Ç –≤—ã–±—Ä–∞–Ω)
OLLAMA_PRIORITY_BY_CATEGORY: Dict[str, List[str]] = {
    "fast": ["deepseek-r1:14b", "qwen2.5-coder:32b", "tinyllama:1.1b-chat"],
    "default": ["qwen2.5-coder:32b", "deepseek-r1:32b", "qwq:32b"],
    "general": ["qwen2.5-coder:32b", "glm-4.7-flash:q8_0", "deepseek-r1:14b"],
    "coding": ["qwen2.5-coder:32b", "qwq:32b", "qwen3-coder:30b"],
    "reasoning": ["deepseek-r1:32b", "qwq:32b", "glm-4.7-flash:q8_0"],
    "complex": ["deepseek-r1:32b", "qwen2.5-coder:32b", "qwq:32b"],
    "vision": ["moondream:latest", "llava:7b"],
    "vip": ["deepseek-r1:32b", "qwen2.5-coder:32b"],
}

# –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –º–æ–¥–µ–ª–µ–π MLX ‚Äî —Ç–æ–ª—å–∫–æ –ª—ë–≥–∫–∏–µ (32b —É–±—Ä–∞–Ω: ~35 –ì–ë –ø—Ä–æ—Ü–µ—Å—Å, Metal/–ø–∞–º—è—Ç—å)
MLX_PRIORITY_BY_CATEGORY: Dict[str, List[str]] = {
    "fast": ["phi3.5:3.8b", "qwen2.5:3b", "tinyllama:1.1b-chat"],
    "default": ["phi3.5:3.8b", "qwen2.5:3b", "tinyllama:1.1b-chat"],
    "general": ["phi3.5:3.8b", "qwen2.5:3b", "tinyllama:1.1b-chat"],
    "coding": ["phi3.5:3.8b", "qwen2.5:3b", "tinyllama:1.1b-chat"],
    "reasoning": ["phi3.5:3.8b", "qwen2.5:3b", "tinyllama:1.1b-chat"],
    "complex": ["phi3.5:3.8b", "qwen2.5:3b", "tinyllama:1.1b-chat"],
}


@dataclass
class ModelSelection:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–µ–π - Ollama –∏ MLX —Ä–∞–∑–¥–µ–ª—å–Ω–æ"""
    ollama_best: Optional[str] = None
    ollama_models: List[str] = None
    mlx_best: Optional[str] = None
    mlx_models: List[str] = None
    ollama_sizes: Dict[str, int] = None  # –í –±–∞–π—Ç–∞—Ö
    
    def __post_init__(self):
        if self.ollama_models is None:
            self.ollama_models = []
        if self.mlx_models is None:
            self.mlx_models = []
        if self.ollama_sizes is None:
            self.ollama_sizes = {}


def _mlx_scan_timeout() -> float:
    """–¢–∞–π–º–∞—É—Ç —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è MLX (—Å–µ–∫). –ò–∑ Docker –¥–æ host.docker.internal:11435 —á–∞—Å—Ç–æ –¥–æ–ª—å—à–µ ‚Äî –∑–∞–¥–∞—Ç—å MLX_SCAN_TIMEOUT=12."""
    return float(os.getenv("MLX_SCAN_TIMEOUT", "5"))


def _ollama_scan_timeout() -> float:
    """–¢–∞–π–º–∞—É—Ç —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è Ollama (—Å–µ–∫). –ò–∑ Docker –¥–æ host.docker.internal:11434 —á–∞—Å—Ç–æ –¥–æ–ª—å—à–µ ‚Äî –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 15 –≤ Docker."""
    default = 15.0 if (os.path.exists("/.dockerenv") or os.getenv("DOCKER_CONTAINER", "").lower() == "true") else 5.0
    return float(os.getenv("OLLAMA_SCAN_TIMEOUT", str(int(default))))


async def _fetch_mlx_models(mlx_url: str, timeout: Optional[float] = None) -> List[str]:
    """–°–∫–∞–Ω–∏—Ä—É–µ—Ç MLX API Server (/api/tags –∏–ª–∏ /), –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∏–º—ë–Ω –º–æ–¥–µ–ª–µ–π/–∫–∞—Ç–µ–≥–æ—Ä–∏–π. –ü—Ä–∏ –ø—É—Å—Ç–æ–º/–æ—Ç–∫–ª—é—á—ë–Ω–Ω–æ–º URL –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç [] –±–µ–∑ –∑–∞–ø—Ä–æ—Å–∞."""
    if not mlx_url or (mlx_url.strip().lower() in ("", "none", "disabled", "off")):
        return []
    if timeout is None:
        timeout = _mlx_scan_timeout()
    try:
        import httpx
        async with httpx.AsyncClient(timeout=timeout) as client:
            # MLX API Server: /api/tags –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç {"models": [{"name": "fast", ...}, ...]}
            r = await client.get(f"{mlx_url}/api/tags")
            if r.status_code != 200:
                try:
                    r2 = await client.get(f"{mlx_url}/")
                    if r2.status_code == 200:
                        data = r2.json()
                        return list(data.get("available_models", []))
                except Exception:
                    pass
                return []
            data = r.json()
            models = data.get("models", [])
            return [m.get("name", "") for m in models if m.get("name")]
    except Exception as e:
        logger.debug("MLX scan: %s", e)
        return []


async def _fetch_ollama_models_with_details(ollama_url: str, timeout: Optional[float] = None) -> Tuple[List[str], Dict[str, int]]:
    """–°–∫–∞–Ω–∏—Ä—É–µ—Ç Ollama /api/tags, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∏–º—ë–Ω –º–æ–¥–µ–ª–µ–π –∏ –∏—Ö —Ä–∞–∑–º–µ—Ä—ã –≤ –±–∞–π—Ç–∞—Ö."""
    if timeout is None:
        timeout = _ollama_scan_timeout()
    try:
        import httpx
        async with httpx.AsyncClient(timeout=timeout) as client:
            r = await client.get(f"{ollama_url}/api/tags")
            if r.status_code != 200:
                return [], {}
            data = r.json()
            models_data = data.get("models", [])
            names = [m.get("name", "") for m in models_data if m.get("name")]
            sizes = {m.get("name"): m.get("size", 0) for m in models_data if m.get("name")}
            return names, sizes
    except Exception as e:
        logger.debug("Ollama scan: %s", e)
        return [], {}


async def _check_model_health(model_name: str, ollama_url: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–¥–æ—Ä–æ–≤—å–µ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ /api/show (Singularity 10.0)."""
    if not model_name or "embedding" in model_name: return True
    try:
        import httpx
        async with httpx.AsyncClient(timeout=5.0) as client:
            r = await client.post(f"{ollama_url}/api/show", json={"name": model_name})
            return r.status_code == 200
    except Exception:
        return False

async def get_available_models(
    mlx_url: str,
    ollama_url: str,
    ttl_sec: int = _SCAN_TTL_SEC,
    force_refresh: bool = False,
) -> Tuple[List[str], List[str]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (mlx_models, ollama_models) ‚Äî —Å–ø–∏—Å–∫–∏ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏–º—ë–Ω –º–æ–¥–µ–ª–µ–π.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫—ç—à —Å TTL; –ø—Ä–∏ force_refresh –∏–ª–∏ –∏—Å—Ç–µ—á–µ–Ω–∏–∏ TTL —Å–∫–∞–Ω–∏—Ä—É–µ—Ç –∑–∞–Ω–æ–≤–æ.
    –ü—Ä–∏ –≤–∫–ª—é—á—ë–Ω–Ω–æ–º MODEL_PROBE_ON_SCAN –¥–ª—è –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è probe (load/unload/deploy/processing —Å –∑–∞–ø–∞—Å–æ–º).
    """
    global _scan_cache
    now = time.time()
    if not force_refresh and _scan_cache is not None and (now - _scan_cache.get("scanned_at", 0)) < ttl_sec:
        return (_scan_cache.get("mlx") or [], _scan_cache.get("ollama") or [])

    # –°–∫–∞–Ω–∏—Ä—É–µ–º MLX –∏ Ollama (—Ç–µ–ø–µ—Ä—å —Å —Ä–∞–∑–º–µ—Ä–∞–º–∏)
    mlx_task = asyncio.create_task(_fetch_mlx_models(mlx_url))
    ollama_task = asyncio.create_task(_fetch_ollama_models_with_details(ollama_url))
    
    mlx_list = await mlx_task
    ollama_list, ollama_sizes = await ollama_task

    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ä–∞–±–æ—á–∏–µ –º–æ–¥–µ–ª–∏ (Singularity 10.0: Anti-Corruption)
    working_ollama = []
    working_sizes = {}
    for m in ollama_list:
        if await _check_model_health(m, ollama_url):
            working_ollama.append(m)
            working_sizes[m] = ollama_sizes.get(m, 0)
        else:
            logger.error(f"üö® [CORRUPTION] –ú–æ–¥–µ–ª—å {m} –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∞ –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –ò—Å–∫–ª—é—á–∞–µ–º –∏–∑ —Ä–æ—É—Ç–∏–Ω–≥–∞.")
    
    ollama_list = working_ollama

    _scan_cache = {
        "mlx": mlx_list,
        "ollama": ollama_list,
        "ollama_sizes": working_sizes,
        "scanned_at": now,
        "mlx_url": mlx_url,
        "ollama_url": ollama_url,
    }

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ (Singularity 10.0: Anti-Corruption)
    async def check_model_integrity(model_name: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∞ –ª–∏ –º–æ–¥–µ–ª—å (Ollama Tensor Check)."""
        try:
            import httpx
            async with httpx.AsyncClient(timeout=10.0) as client:
                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
                r = await client.post(f"{ollama_url}/api/show", json={"name": model_name})
                if r.status_code != 200:
                    return False
                # –ï—Å–ª–∏ Ollama –º–æ–∂–µ—Ç –ø–æ–∫–∞–∑–∞—Ç—å –¥–µ—Ç–∞–ª–∏, –º–æ–¥–µ–ª—å —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –∂–∏–≤–∞
                return True
        except Exception:
            return False

    # Probe –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ —Ñ–æ–Ω–µ
    if _PROBE_NEW_MODELS and ollama_list:
        try:
            from app.model_performance_probe import probe_new_models_if_needed
            asyncio.create_task(
                probe_new_models_if_needed(
                    ollama_models=ollama_list,
                    mlx_models=mlx_list or [],
                    ollama_url=ollama_url,
                    mlx_url=mlx_url or "",
                )
            )
        except Exception as e:
            logger.debug("Probe new models (background): %s", e)

    # –ü–æ–¥–≥—Ä—É–∑–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ –ë–î –≤ –∫—ç—à (–¥–ª—è get_model_metrics)
    try:
        from app.model_performance_probe import get_metrics_for_models
        ollama_metrics = await get_metrics_for_models(ollama_list, "ollama")
        mlx_metrics = await get_metrics_for_models(mlx_list or [], "mlx")
        _scan_cache["metrics"] = {"ollama": ollama_metrics, "mlx": mlx_metrics}
    except Exception as e:
        logger.debug("Load model metrics: %s", e)
        _scan_cache["metrics"] = {"ollama": {}, "mlx": {}}

    logger.info("–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π: MLX=%s, Ollama=%s", len(mlx_list), len(ollama_list))
    if mlx_list:
        logger.debug("MLX –º–æ–¥–µ–ª–∏: %s", mlx_list[:10])
    if ollama_list:
        logger.debug("Ollama –º–æ–¥–µ–ª–∏: %s", ollama_list[:10])
    return (mlx_list, ollama_list)


# ==============================================================================
# –§–£–ù–ö–¶–ò–ò –í–´–ë–û–†–ê –ú–û–î–ï–õ–ï–ô (Ollama –∏ MLX –†–ê–ó–î–ï–õ–¨–ù–û!)
# ==============================================================================

def pick_best_ollama(ollama_models: List[str]) -> Optional[str]:
    """
    –í—ã–±–∏—Ä–∞–µ—Ç —Å–∞–º—É—é –º–æ—â–Ω—É—é –º–æ–¥–µ–ª—å –∏–∑ –¢–û–õ–¨–ö–û Ollama —Å–ø–∏—Å–∫–∞.
    –ù–µ —Å–º–µ—à–∏–≤–∞–µ—Ç —Å MLX - —ç—Ç–æ –≤–∞–∂–Ω–æ –¥–ª—è executor/planner –∫–æ—Ç–æ—Ä—ã–µ —Ö–æ–¥—è—Ç –≤ Ollama API.
    """
    if not ollama_models:
        return None
    lower_to_exact = {m.strip().lower(): m.strip() for m in ollama_models if m}
    for name in OLLAMA_BEST_FIRST:
        key = name.strip().lower()
        if key in lower_to_exact:
            return lower_to_exact[key]
    return ollama_models[0].strip() if ollama_models else None


def pick_best_mlx(mlx_models: List[str]) -> Optional[str]:
    """
    –í—ã–±–∏—Ä–∞–µ—Ç —Å–∞–º—É—é –º–æ—â–Ω—É—é –º–æ–¥–µ–ª—å –∏–∑ –¢–û–õ–¨–ö–û MLX —Å–ø–∏—Å–∫–∞.
    –ù–µ —Å–º–µ—à–∏–≤–∞–µ—Ç —Å Ollama - MLX –º–æ–¥–µ–ª–∏ –∑–∞–ø—É—Å–∫–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ MLX API Server.
    """
    if not mlx_models:
        return None
    lower_to_exact = {m.strip().lower(): m.strip() for m in mlx_models if m}
    for name in MLX_BEST_FIRST:
        key = name.strip().lower()
        if key in lower_to_exact:
            return lower_to_exact[key]
    return mlx_models[0].strip() if mlx_models else None


def pick_ollama_for_category(category: str, ollama_models: List[str]) -> Optional[str]:
    """
    –í—ã–±–∏—Ä–∞–µ—Ç –º–æ–¥–µ–ª—å Ollama –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∑–∞–¥–∞—á–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–≤—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –∏–∑ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ –¥–ª—è —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏.
    """
    if not ollama_models:
        return None
    priorities = OLLAMA_PRIORITY_BY_CATEGORY.get(category, OLLAMA_PRIORITY_BY_CATEGORY["default"])
    lower_to_exact = {m.strip().lower(): m.strip() for m in ollama_models if m}
    for name in priorities:
        key = name.strip().lower()
        if key in lower_to_exact:
            return lower_to_exact[key]
    return ollama_models[0].strip() if ollama_models else None


def pick_mlx_for_category(category: str, mlx_models: List[str]) -> Optional[str]:
    """
    –í—ã–±–∏—Ä–∞–µ—Ç –º–æ–¥–µ–ª—å MLX –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∑–∞–¥–∞—á–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–≤—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –∏–∑ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ –¥–ª—è —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏.
    """
    if not mlx_models:
        return None
    priorities = MLX_PRIORITY_BY_CATEGORY.get(category, MLX_PRIORITY_BY_CATEGORY.get("default", []))
    lower_to_exact = {m.strip().lower(): m.strip() for m in mlx_models if m}
    for name in priorities:
        key = name.strip().lower()
        if key in lower_to_exact:
            return lower_to_exact[key]
    return mlx_models[0].strip() if mlx_models else None


def _default_ollama_url() -> str:
    import os
    if os.getenv("OLLAMA_API_URL"):
        return os.getenv("OLLAMA_API_URL", "").rstrip("/")
    if os.getenv("OLLAMA_BASE_URL"):
        return os.getenv("OLLAMA_BASE_URL", "").rstrip("/")
    is_docker = os.path.exists("/.dockerenv") or os.getenv("DOCKER_CONTAINER", "").lower() in ("true", "1")
    return "http://host.docker.internal:11434" if is_docker else "http://localhost:11434"


def _default_mlx_url() -> str:
    import os
    raw = os.getenv("MLX_API_URL", "").strip()
    if raw.lower() in ("none", "disabled", "off", "false"):
        return ""
    if raw:
        return raw.rstrip("/")
    is_docker = os.path.exists("/.dockerenv") or os.getenv("DOCKER_CONTAINER", "").lower() in ("true", "1")
    return "http://host.docker.internal:11435" if is_docker else "http://localhost:11435"


async def scan_and_select_models(
    mlx_url: Optional[str] = None,
    ollama_url: Optional[str] = None,
    force_refresh: bool = False,
) -> ModelSelection:
    """
    –°–∫–∞–Ω–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª–∏ –∏ –≤—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à–∏–µ –∏–∑ –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –†–ê–ó–î–ï–õ–¨–ù–û.
    
    Returns:
        ModelSelection —Å —Ä–∞–∑–¥–µ–ª—å–Ω—ã–º–∏ —Å–ø–∏—Å–∫–∞–º–∏ –∏ –ª—É—á—à–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏ –¥–ª—è Ollama –∏ MLX
    """
    mlx_url = mlx_url or _default_mlx_url()
    ollama_url = ollama_url or _default_ollama_url()
    mlx_models, ollama_models = await get_available_models(mlx_url, ollama_url, force_refresh=force_refresh)
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ä–∞–±–æ—á–∏–µ –º–æ–¥–µ–ª–∏ (Singularity 10.0: Anti-Corruption)
    working_ollama = []
    for m in ollama_models:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –∏–ª–∏ –æ–±–µ—Ä—Ç–∫—É, —Ç–∞–∫ –∫–∞–∫ scan_and_select_models –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è
        # –ù–æ _check_model_health —É–∂–µ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è, —Ç–∞–∫ —á—Ç–æ –ø—Ä–æ—Å—Ç–æ await
        try:
            # –ù–µ–±–æ–ª—å—à–æ–π —Ö–∞–∫: –µ—Å–ª–∏ –º—ã –≤–Ω—É—Ç—Ä–∏ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏, –º–æ–∂–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å await
            import httpx
            async def check_inner(name):
                if not name or "embedding" in name: return True
                try:
                    async with httpx.AsyncClient(timeout=5.0) as client:
                        r = await client.post(f"{ollama_url}/api/show", json={"name": name})
                        return r.status_code == 200
                except Exception: return False
            
            # –î–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–æ–ø-5 –º–æ–¥–µ–ª–µ–π
            is_ok = True
            if m in OLLAMA_BEST_FIRST[:5]:
                is_ok = await check_inner(m)
            
            if is_ok:
                working_ollama.append(m)
            else:
                logger.error(f"üö® [CORRUPTION] –ú–æ–¥–µ–ª—å {m} –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∞. –ò—Å–∫–ª—é—á–∞–µ–º.")
        except Exception:
            working_ollama.append(m)
    
    ollama_models = working_ollama

    result = ModelSelection(
        ollama_models=ollama_models,
        ollama_best=pick_best_ollama(ollama_models),
        mlx_models=mlx_models,
        mlx_best=pick_best_mlx(mlx_models),
        ollama_sizes=_scan_cache.get("ollama_sizes", {})
    )
    
    logger.info("=" * 60)
    logger.info("üìä –°–ö–ê–ù–ò–†–û–í–ê–ù–ò–ï –ú–û–î–ï–õ–ï–ô (Ollama –∏ MLX –†–ê–ó–î–ï–õ–¨–ù–û)")
    logger.info("=" * 60)
    logger.info("üîµ OLLAMA (–ø–æ—Ä—Ç 11434):")
    logger.info("   –ù–∞–π–¥–µ–Ω–æ: %d –º–æ–¥–µ–ª–µ–π", len(ollama_models))
    logger.info("   –ú–æ–¥–µ–ª–∏: %s", ollama_models[:10] if ollama_models else [])
    logger.info("   ‚úÖ –õ—É—á—à–∞—è: %s", result.ollama_best or "(–Ω–µ—Ç)")
    logger.info("-" * 60)
    logger.info("üü¢ MLX (–ø–æ—Ä—Ç 11435):")
    logger.info("   –ù–∞–π–¥–µ–Ω–æ: %d –º–æ–¥–µ–ª–µ–π", len(mlx_models))
    logger.info("   –ú–æ–¥–µ–ª–∏: %s", mlx_models[:10] if mlx_models else [])
    logger.info("   ‚úÖ –õ—É—á—à–∞—è: %s", result.mlx_best or "(–Ω–µ—Ç)")
    logger.info("=" * 60)
    
    return result


# –û–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å–æ —Å—Ç–∞—Ä—ã–º API
def pick_best_available_victoria(
    ollama_models: List[str],
    mlx_models: Optional[List[str]] = None,
) -> Optional[str]:
    """
    DEPRECATED: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ pick_best_ollama() –∏–ª–∏ pick_best_mlx() –æ—Ç–¥–µ–ª—å–Ω–æ.
    
    –û—Å—Ç–∞–≤–ª–µ–Ω–æ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏.
    –¢–µ–ø–µ—Ä—å –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –¢–û–õ–¨–ö–û –∏–∑ Ollama (executor/planner —Ö–æ–¥—è—Ç –≤ Ollama API).
    """
    logger.warning("‚ö†Ô∏è pick_best_available_victoria() deprecated - –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ pick_best_ollama()")
    return pick_best_ollama(ollama_models)


def pick_ollama_model_for_category(category: str, ollama_models: List[str]) -> Optional[str]:
    """DEPRECATED: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ pick_ollama_for_category()"""
    return pick_ollama_for_category(category, ollama_models)


def invalidate_cache() -> None:
    """–°–±—Ä–æ—Å–∏—Ç—å –∫—ç—à (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–∏ —Å–º–µ–Ω–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è)."""
    global _scan_cache
    _scan_cache = None


def get_model_metrics(
    model_name: str,
    source: str,
) -> Optional[Dict[str, Any]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏ (–≤—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏, –≤—ã–≥—Ä—É–∑–∫–∏, —Ä–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏—è, –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å –∑–∞–ø–∞—Å–æ–º)
    –∏–∑ –∫—ç—à–∞ —Å–∫–∞–Ω–µ—Ä–∞. –ö—ç—à –∑–∞–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø—Ä–∏ get_available_models() –∏–∑ –ë–î model_performance_metrics.
    
    Args:
        model_name: –ò–º—è –º–æ–¥–µ–ª–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä phi3.5:3.8b)
        source: 'ollama' | 'mlx'
    
    Returns:
        Dict —Å –∫–ª—é—á–∞–º–∏: load_time_sec, unload_time_sec, deploy_time_sec, processing_sec_per_1k_tokens,
        load_time_sec_with_margin, unload_time_sec_with_margin, deploy_time_sec_with_margin,
        processing_sec_per_1k_with_margin, margin_factor (—Å–≤–æ–π —É –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏), last_probed_at; –∏–ª–∏ None –µ—Å–ª–∏ –º–µ—Ç—Ä–∏–∫ –Ω–µ—Ç.
    """
    if _scan_cache is None:
        return None
    metrics = (_scan_cache.get("metrics") or {}).get(source) or {}
    m = metrics.get(model_name)
    if m is None:
        return None
    # ModelMetrics dataclass -> dict –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ (—É –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ —Å–≤–æ–∏ –∑–Ω–∞—á–µ–Ω–∏—è)
    return {
        "load_time_sec": m.load_time_sec,
        "unload_time_sec": m.unload_time_sec,
        "deploy_time_sec": m.deploy_time_sec,
        "processing_sec_per_1k_tokens": m.processing_sec_per_1k_tokens,
        "load_time_sec_with_margin": m.load_time_sec_with_margin,
        "unload_time_sec_with_margin": m.unload_time_sec_with_margin,
        "deploy_time_sec_with_margin": m.deploy_time_sec_with_margin,
        "processing_sec_per_1k_with_margin": m.processing_sec_per_1k_with_margin,
        "margin_factor": m.margin_factor,
        "last_probed_at": m.last_probed_at,
    }


async def get_available_models_with_metrics(
    mlx_url: str,
    ollama_url: str,
    ttl_sec: int = _SCAN_TTL_SEC,
    force_refresh: bool = False,
) -> Tuple[List[str], List[str], Dict[str, Dict[str, Dict[str, Any]]]]:
    """
    –¢–æ –∂–µ —á—Ç–æ get_available_models(), –ø–ª—é—Å —Ç—Ä–µ—Ç–∏–π —ç–ª–µ–º–µ–Ω—Ç ‚Äî –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –º–æ–¥–µ–ª—è–º:
    {"ollama": {model_name: {...}}, "mlx": {model_name: {...}}}.
    –ö–∞–∂–¥–∞—è –∑–∞–ø–∏—Å—å —Å–æ–¥–µ—Ä–∂–∏—Ç load_time_sec, unload_time_sec, deploy_time_sec, processing_sec_per_1k_tokens
    –∏ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Å –∑–∞–ø–∞—Å–æ–º (_with_margin).
    """
    mlx_list, ollama_list = await get_available_models(mlx_url, ollama_url, ttl_sec=ttl_sec, force_refresh=force_refresh)
    metrics = (_scan_cache or {}).get("metrics") or {"ollama": {}, "mlx": {}}
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º ModelMetrics –≤ dict
    out_metrics: Dict[str, Dict[str, Dict[str, Any]]] = {"ollama": {}, "mlx": {}}
    for src in ("ollama", "mlx"):
        for name, m in (metrics.get(src) or {}).items():
            out_metrics[src][name] = {
                "load_time_sec": m.load_time_sec,
                "unload_time_sec": m.unload_time_sec,
                "deploy_time_sec": m.deploy_time_sec,
                "processing_sec_per_1k_tokens": m.processing_sec_per_1k_tokens,
                "load_time_sec_with_margin": m.load_time_sec_with_margin,
                "unload_time_sec_with_margin": m.unload_time_sec_with_margin,
                "deploy_time_sec_with_margin": m.deploy_time_sec_with_margin,
                "processing_sec_per_1k_with_margin": m.processing_sec_per_1k_with_margin,
                "margin_factor": m.margin_factor,
                "last_probed_at": m.last_probed_at,
            }
    return (mlx_list, ollama_list, out_metrics)
