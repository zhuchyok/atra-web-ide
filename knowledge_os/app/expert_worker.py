import asyncio
import json
import logging
import os
import signal
import asyncpg
from datetime import datetime, timezone

# –°–∏–Ω–≥—É–ª—è—Ä–Ω–æ—Å—Ç—å 10.0: –ò–º–ø–æ—Ä—Ç—ã —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä–∞–∑–Ω—ã—Ö –ø—É—Ç–µ–π (Docker/Local)
try:
    from redis_manager import redis_manager
    from ai_core import run_smart_agent_async
    from services.knowledge_service import knowledge_service
except ImportError:
    try:
        from app.redis_manager import redis_manager
        from app.ai_core import run_smart_agent_async
        from app.services.knowledge_service import knowledge_service
    except ImportError:
        # Fallback –¥–ª—è —Ç–µ—Å—Ç–æ–≤ –∏–ª–∏ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –æ–∫—Ä—É–∂–µ–Ω–∏–π
        import sys
        sys.path.append(os.path.dirname(os.path.abspath(__file__)))
        from redis_manager import redis_manager
        from ai_core import run_smart_agent_async
        from services.knowledge_service import knowledge_service

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger("ExpertWorker")

DB_URL = os.getenv("DATABASE_URL")
STREAM_NAME = "expert_tasks"
GROUP_NAME = "expert_workers"
CONSUMER_NAME = f"worker_{os.uname()[1]}"

async def process_task(task_data: dict):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–¥–∞—á—É –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç."""
    task_id = task_data["task_id"]
    expert_name = task_data["expert_name"]
    description = task_data["description"]
    
    logger.info(f"üõ†Ô∏è [WORKER] –ù–∞—á–∞–ª–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ {task_id} –¥–ª—è {expert_name}")
    
    try:
        # 1. –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –≤ –ë–î –∏ Redis
        # –°–∏–Ω–≥—É–ª—è—Ä–Ω–æ—Å—Ç—å 10.0: –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ task_id –≤–∞–ª–∏–¥–Ω—ã–º UUID –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º –∫ –ë–î
        is_valid_uuid = False
        try:
            import uuid
            uuid.UUID(str(task_id))
            is_valid_uuid = True
        except ValueError:
            logger.warning(f"‚ö†Ô∏è Task ID {task_id} is not a valid UUID, skipping DB update")

        conn = await asyncpg.connect(DB_URL)
        try:
            if is_valid_uuid:
                await conn.execute("UPDATE tasks SET status = 'in_progress', updated_at = NOW() WHERE id = $1", task_id)
            
            await redis_manager.update_task_status(task_id, "in_progress", metadata={"expert": expert_name})
            
            # 2. –í—ã–ø–æ–ª–Ω—è–µ–º —á–µ—Ä–µ–∑ AI Core –∏–ª–∏ ReAct Agent (Singularity 14.0)
            if task_data.get("metadata", {}).get("complex") or expert_name == "–í–∏–∫—Ç–æ—Ä–∏—è":
                logger.info(f"üß† [WORKER] –ò—Å–ø–æ–ª—å–∑—É–µ–º ReAct Agent –¥–ª—è —Å–ª–æ–∂–Ω–æ–π –∑–∞–¥–∞—á–∏ {task_id}")
                try:
                    from react_agent import ReActAgent
                    agent = ReActAgent(agent_name=expert_name)
                    # –°–∏–Ω–≥—É–ª—è—Ä–Ω–æ—Å—Ç—å 10.0: –ü–µ—Ä–µ–¥–∞–µ–º —Ü–µ–ª—å –≤ –º–µ—Ç–æ–¥ run()
                    report = await agent.run(goal=description)
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (Singularity 14.0: Anti-Loop)
                    if isinstance(report, dict):
                        report_text = report.get("response") or report.get("result") or ""
                        # –ï—Å–ª–∏ –∞–≥–µ–Ω—Ç –≤–µ—Ä–Ω—É–ª finish –±–µ–∑ —Ç–µ–∫—Å—Ç–∞, –Ω–æ –∑–∞–¥–∞—á–∞ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ (–Ω–µ—Ç —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ –ª–æ–≥–∞—Ö —à–∞–≥–æ–≤)
                        if not report_text.strip() and report.get("status") == "finish":
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª–∏ –ª–∏ —É—Å–ø–µ—à–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –≤ —à–∞–≥–∞—Ö
                            has_actions = any(s.get("action") and s.get("action") != "finish" for s in report.get("steps", []))
                            if not has_actions:
                                raise Exception("–ê–≥–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–∏–ª –∑–∞–¥–∞—á—É –±–µ–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–µ–π—Å—Ç–≤–∏–π –∏ –±–µ–∑ –æ—Ç—á–µ—Ç–∞. –í–µ—Ä–æ—è—Ç–Ω–æ–µ –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏–µ.")
                    else:
                        report_text = str(report)
                except Exception as e:
                    logger.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ ReAct Agent, fallback –Ω–∞ AI Core: {e}")
                    report = await run_smart_agent_async(
                        description, 
                        expert_name=expert_name, 
                        category=task_data.get("category", "general")
                    )
                    report_text = str(report.get("result") if isinstance(report, dict) else report)
            else:
                report = await run_smart_agent_async(
                    description, 
                    expert_name=expert_name, 
                    category=task_data.get("category", "general")
                )
                report_text = str(report.get("result") if isinstance(report, dict) else report)
            
            # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            # –°–∏–Ω–≥—É–ª—è—Ä–Ω–æ—Å—Ç—å 10.0: –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º, —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç ‚Äî —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞ –¥–ª—è PostgreSQL
            if isinstance(report_text, dict):
                report_text = json.dumps(report_text, ensure_ascii=False, indent=2)
            else:
                report_text = str(report_text)

            if is_valid_uuid:
                await conn.execute("""
                    UPDATE tasks SET status = 'completed', result = $2, completed_at = NOW()
                    WHERE id = $1
                """, task_id, report_text)
            
            await redis_manager.update_task_status(task_id, "completed", result=report_text)
            
            # –°–∏–Ω–≥—É–ª—è—Ä–Ω–æ—Å—Ç—å 10.0: –°–Ω–∏–º–∞–µ–º –±–ª–æ–∫–∏—Ä–æ–≤–∫—É –∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
            await redis_manager.release_task_lock(task_id)
            
            # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Å–∞–π—Ç –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
            await knowledge_service.save_insight(
                report_text, 
                expert_name, 
                metadata={"task_id": task_id, "source": "worker_service"}
            )
            
            logger.info(f"‚úÖ [WORKER] –ó–∞–¥–∞—á–∞ {task_id} —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
            
        finally:
            await conn.close()
            
    except Exception as e:
        logger.error(f"‚ùå [WORKER] –û—à–∏–±–∫–∞ –∑–∞–¥–∞—á–∏ {task_id}: {e}", exc_info=True)
        error_msg = str(e)
        await redis_manager.update_task_status(task_id, "failed", result=error_msg)
        
        # –°–∏–Ω–≥—É–ª—è—Ä–Ω–æ—Å—Ç—å 10.0: –°–æ—Ö—Ä–∞–Ω—è–µ–º last_error –≤ PostgreSQL –¥–ª—è —Å–∏—Å—Ç–µ–º—ã —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è
        try:
            if is_valid_uuid:
                conn = await asyncpg.connect(DB_URL)
                try:
                    await conn.execute("""
                        UPDATE tasks 
                        SET status = 'failed', 
                            result = $2,
                            metadata = COALESCE(metadata, '{}'::jsonb) || jsonb_build_object('last_error', $3::text)
                        WHERE id = $1
                    """, task_id, error_msg, error_msg[:200])
                finally:
                    await conn.close()
        except Exception as db_err:
            logger.error(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—à–∏–±–∫—É –≤ –ë–î: {db_err}")

        # –°–∏–Ω–≥—É–ª—è—Ä–Ω–æ—Å—Ç—å 10.0: –°–Ω–∏–º–∞–µ–º –±–ª–æ–∫–∏—Ä–æ–≤–∫—É –ø—Ä–∏ –æ—à–∏–±–∫–µ, —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å
        await redis_manager.release_task_lock(task_id)

async def worker_loop():
    """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –≤–æ—Ä–∫–µ—Ä–∞: —Å–ª—É—à–∞–µ—Ç Redis Stream."""
    client = await redis_manager.get_client()
    
    # –°–æ–∑–¥–∞–µ–º –≥—Ä—É–ø–ø—É –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª–µ–π, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    try:
        await client.xgroup_create(f"stream:{STREAM_NAME}", GROUP_NAME, mkstream=True)
    except Exception:
        pass # –ì—Ä—É–ø–ø–∞ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç

    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∏—Å—Ç–µ–º—É —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è –∫–æ—Ä–ø–æ—Ä–∞—Ü–∏–∏ (Singularity 14.0)
    try:
        from corporation_self_learning import get_corporation_learner
        learner = get_corporation_learner()
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤ —Ñ–æ–Ω–µ (–∏–Ω—Ç–µ—Ä–≤–∞–ª 6 —á–∞—Å–æ–≤)
        asyncio.create_task(learner.start_continuous_learning(interval_hours=6))
        logger.info("üß† [SINGULARITY 10.0] Collective Learning system started")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è [SINGULARITY 10.0] Could not start collective learning: {e}")

    logger.info(f"üöÄ [WORKER] –í–æ—Ä–∫–µ—Ä –∑–∞–ø—É—â–µ–Ω. –°–ª—É—à–∞—é –ø–æ—Ç–æ–∫ {STREAM_NAME}...")

    while True:
        try:
            # –°–∏–Ω–≥—É–ª—è—Ä–Ω–æ—Å—Ç—å 10.0: –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≤–∏—Å—à–∏–µ –∑–∞–¥–∞—á–∏ –¥—Ä—É–≥–∏—Ö –≤–æ—Ä–∫–µ—Ä–æ–≤ (Autoclaim)
            # –ï—Å–ª–∏ –∑–∞–¥–∞—á–∞ –≤–∏—Å–∏—Ç –±–æ–ª–µ–µ 5 –º–∏–Ω—É—Ç (300000 –º—Å), –ø–µ—Ä–µ—Ö–≤–∞—Ç—ã–≤–∞–µ–º –µ—ë
            stale_messages = await redis_manager.autoclaim_tasks(STREAM_NAME, GROUP_NAME, CONSUMER_NAME, min_idle_time_ms=300000)
            
            # –ß–∏—Ç–∞–µ–º –Ω–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            messages = await client.xreadgroup(
                GROUP_NAME, CONSUMER_NAME, {f"stream:{STREAM_NAME}": ">"}, count=1, block=5000
            )
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∑–∞–≤–∏—Å—à–∏–µ –∏ –Ω–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            all_messages = []
            if stale_messages:
                all_messages.append((f"stream:{STREAM_NAME}", stale_messages))
            if messages:
                all_messages.extend(messages)

            if not all_messages:
                continue

            for stream, msgs in all_messages:
                for msg_id, data in msgs:
                    try:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ (Dead Letter Queue logic)
                        # –ï—Å–ª–∏ –∑–∞–¥–∞—á–∞ –ø—Ä–æ–≤–∞–ª–∏–ª–∞—Å—å –±–æ–ª–µ–µ 3 —Ä–∞–∑, –ø–æ–º–µ—á–∞–µ–º –∫–∞–∫ failed
                        info = await client.xpending_range(f"stream:{STREAM_NAME}", GROUP_NAME, msg_id, msg_id, 1)
                        if info and info[0]['times_delivered'] > 3:
                            logger.error(f"üíÄ [DLQ] –ó–∞–¥–∞—á–∞ {msg_id} –ø—Ä–µ–≤—ã—Å–∏–ª–∞ –ª–∏–º–∏—Ç –ø–æ–ø—ã—Ç–æ–∫ (3). –£–¥–∞–ª—è–µ–º –∏–∑ –æ—á–µ—Ä–µ–¥–∏.")
                            await client.xack(f"stream:{STREAM_NAME}", GROUP_NAME, msg_id)
                            continue

                        # –°–∏–Ω–≥—É–ª—è—Ä–Ω–æ—Å—Ç—å 10.0: –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –∫–∞–∫ JSON-—Å—Ç—Ä–æ–∫–∏, —Ç–∞–∫ –∏ –ø—Ä—è–º–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è
                        raw_payload = data.get(b"payload") or data.get("payload")
                        if isinstance(raw_payload, (str, bytes)):
                            payload = json.loads(raw_payload)
                        else:
                            # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ —É–∂–µ –≤ –≤–∏–¥–µ —Å–ª–æ–≤–∞—Ä—è (–ø—Ä–∏—à–ª–∏ –Ω–µ –∫–∞–∫ JSON —Å—Ç—Ä–æ–∫–∞)
                            payload = {k.decode() if isinstance(k, bytes) else k: 
                                      v.decode() if isinstance(v, bytes) else v 
                                      for k, v in data.items()}
                        
                        await process_task(payload)
                        # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
                        await client.xack(f"stream:{STREAM_NAME}", GROUP_NAME, msg_id)
                    except Exception as e:
                        logger.error(f"‚ùå [WORKER] –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è {msg_id}: {e}")
                    
        except Exception as e:
            logger.error(f"‚ö†Ô∏è [WORKER] –û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ: {e}")
            await asyncio.sleep(5)

if __name__ == "__main__":
    try:
        asyncio.run(worker_loop())
    except KeyboardInterrupt:
        logger.info("üõë [WORKER] –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ —Å–∏–≥–Ω–∞–ª—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
