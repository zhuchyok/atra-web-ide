"""
[KNOWLEDGE OS] Knowledge Graph Engine.
Managing knowledge graph and links between nodes.
Part of the ATRA Singularity framework.
"""

import asyncio
import getpass
import json
import logging
import os
from dataclasses import dataclass
from enum import Enum
from typing import Any, Dict, List, Optional

# Third-party imports with fallback
try:
    import asyncpg
    ASYNCPG_AVAILABLE = True
except ImportError:
    asyncpg = None
    ASYNCPG_AVAILABLE = False

logger = logging.getLogger(__name__)

USER_NAME = getpass.getuser()
# Priority: 1. env var, 2. local user (Mac), 3. fallback to admin (Server)
if USER_NAME == 'zhuchyok':
    DEFAULT_DB_URL = f'postgresql://{USER_NAME}@localhost:5432/knowledge_os'
else:
    DEFAULT_DB_URL = 'postgresql://admin:secret@localhost:5432/knowledge_os'

DB_URL = os.getenv('DATABASE_URL', DEFAULT_DB_URL)


class LinkType(Enum):
    """–¢–∏–ø—ã —Å–≤—è–∑–µ–π –º–µ–∂–¥—É —É–∑–ª–∞–º–∏ –∑–Ω–∞–Ω–∏–π"""
    DEPENDS_ON = "depends_on"  # –ó–∞–≤–∏—Å–∏—Ç –æ—Ç
    CONTRADICTS = "contradicts"  # –ü—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—Ç
    ENHANCES = "enhances"  # –£–ª—É—á—à–∞–µ—Ç/—Ä–∞—Å—à–∏—Ä—è–µ—Ç
    RELATED_TO = "related_to"  # –°–≤—è–∑–∞–Ω–æ —Å
    SUPERSEDES = "supersedes"  # –ó–∞–º–µ–Ω—è–µ—Ç
    PART_OF = "part_of"  # –Ø–≤–ª—è–µ—Ç—Å—è —á–∞—Å—Ç—å—é


@dataclass
class KnowledgeLink:
    """–°–≤—è–∑—å –º–µ–∂–¥—É —É–∑–ª–∞–º–∏ –∑–Ω–∞–Ω–∏–π"""
    source_id: str
    target_id: str
    link_type: LinkType
    strength: float = 1.0
    metadata: Dict[str, Any] = None

    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}


class KnowledgeGraph:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≥—Ä–∞—Ñ–æ–º –∑–Ω–∞–Ω–∏–π"""

    def __init__(self, db_url: str = DB_URL):
        self.db_url = db_url

    async def create_link(
        self,
        source_id: str,
        target_id: str,
        link_type: LinkType,
        strength: float = 1.0,
        metadata: Optional[Dict] = None
    ) -> Optional[str]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–≤—è–∑–∏ –º–µ–∂–¥—É —É–∑–ª–∞–º–∏ –∑–Ω–∞–Ω–∏–π"""
        if source_id == target_id:
            logger.error("Cannot create link: source and target are the same")
            return None

        if not ASYNCPG_AVAILABLE:
            logger.error("‚ùå asyncpg is not installed. Operation aborted.")
            return None

        try:
            conn = await asyncpg.connect(self.db_url)
            try:
                link_id = await conn.fetchval("""
                    INSERT INTO knowledge_links
                    (source_node_id, target_node_id, link_type, strength, metadata)
                    VALUES ($1, $2, $3, $4, $5)
                    ON CONFLICT (source_node_id, target_node_id, link_type)
                    DO UPDATE SET
                        strength = EXCLUDED.strength,
                        metadata = EXCLUDED.metadata,
                        updated_at = CURRENT_TIMESTAMP
                    RETURNING id
                """, source_id, target_id, link_type.value, strength, json.dumps(metadata or {}))

                logger.info("‚úÖ Created link: %s --[%s]--> %s",
                            source_id, link_type.value, target_id)
                return str(link_id)
            finally:
                await conn.close()
        except Exception as exc:  # pylint: disable=broad-exception-caught
            logger.error("Error creating link: %s", exc)
            return None

    async def get_links(
        self,
        node_id: str,
        link_type: Optional[LinkType] = None,
        direction: str = "both"  # "outgoing", "incoming", "both"
    ) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Å–≤—è–∑–µ–π —É–∑–ª–∞"""
        if not ASYNCPG_AVAILABLE:
            return []

        try:
            conn = await asyncpg.connect(self.db_url)
            try:
                if direction == "outgoing":
                    query = """
                        SELECT * FROM knowledge_graph_view
                        WHERE source_node_id = $1
                    """
                    params = [node_id]
                elif direction == "incoming":
                    query = """
                        SELECT * FROM knowledge_graph_view
                        WHERE target_node_id = $1
                    """
                    params = [node_id]
                else:  # both
                    query = """
                        SELECT * FROM knowledge_graph_view
                        WHERE source_node_id = $1 OR target_node_id = $1
                    """
                    params = [node_id]

                if link_type:
                    query += " AND link_type = $2"
                    params.append(link_type.value)

                rows = await conn.fetch(query, *params)
                return [dict(row) for row in rows]
            finally:
                await conn.close()
        except Exception as exc:  # pylint: disable=broad-exception-caught
            logger.error("Error getting links: %s", exc)
            return []

    async def get_related_nodes(
        self,
        node_id: str,
        link_types: Optional[List[LinkType]] = None,
        max_depth: int = 2,
        min_strength: float = 0.5
    ) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —É–∑–ª–æ–≤ (—Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ)"""
        if not ASYNCPG_AVAILABLE:
            return []

        try:
            conn = await asyncpg.connect(self.db_url)
            try:
                if link_types:
                    link_types_str = [lt.value for lt in link_types]
                else:
                    link_types_str = [
                        LinkType.DEPENDS_ON.value,
                        LinkType.ENHANCES.value,
                        LinkType.RELATED_TO.value
                    ]

                rows = await conn.fetch(
                    "SELECT * FROM get_related_nodes($1, $2, $3, $4)",
                    node_id,
                    link_types_str,
                    max_depth,
                    min_strength
                )
                return [dict(row) for row in rows]
            finally:
                await conn.close()
        except Exception as exc:  # pylint: disable=broad-exception-caught
            logger.error("Error getting related nodes: %s", exc)
            return []

    async def delete_link(
        self,
        source_id: str,
        target_id: str,
        link_type: LinkType
    ) -> bool:
        """–£–¥–∞–ª–µ–Ω–∏–µ —Å–≤—è–∑–∏"""
        if not ASYNCPG_AVAILABLE:
            return False

        try:
            conn = await asyncpg.connect(self.db_url)
            try:
                result = await conn.execute("""
                    DELETE FROM knowledge_links
                    WHERE source_node_id = $1
                      AND target_node_id = $2
                      AND link_type = $3
                """, source_id, target_id, link_type.value)

                return result == "DELETE 1"
            finally:
                await conn.close()
        except Exception as exc:  # pylint: disable=broad-exception-caught
            logger.error("Error deleting link: %s", exc)
            return False

    async def get_graph_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≥—Ä–∞—Ñ–∞"""
        if not ASYNCPG_AVAILABLE:
            return {}

        try:
            conn = await asyncpg.connect(self.db_url)
            try:
                # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤—è–∑–µ–π
                total_links = await conn.fetchval("SELECT count(*) FROM knowledge_links")

                # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤—è–∑–µ–π –ø–æ —Ç–∏–ø–∞–º
                links_by_type = await conn.fetch("""
                    SELECT link_type, count(*) as count
                    FROM knowledge_links
                    GROUP BY link_type
                    ORDER BY count DESC
                """)

                # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–∑–ª–æ–≤ —Å–æ —Å–≤—è–∑—è–º–∏
                nodes_with_links = await conn.fetchval("""
                    SELECT count(DISTINCT source_node_id) + count(DISTINCT target_node_id)
                    FROM knowledge_links
                """)

                # –°—Ä–µ–¥–Ω—è—è —Å–∏–ª–∞ —Å–≤—è–∑–µ–π
                avg_strength = await conn.fetchval("""
                    SELECT AVG(strength) FROM knowledge_links
                """) or 0.0

                return {
                    "total_links": total_links,
                    "links_by_type": {row["link_type"]: row["count"] for row in links_by_type},
                    "nodes_with_links": nodes_with_links,
                    "avg_strength": float(avg_strength)
                }
            finally:
                await conn.close()
        except Exception as exc:  # pylint: disable=broad-exception-caught
            logger.error("Error getting graph stats: %s", exc)
            return {}

    async def auto_detect_links(
        self,
        node_id: str,
        similarity_threshold: float = 0.8
    ) -> List[str]:
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Å–≤—è–∑–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞"""
        if not ASYNCPG_AVAILABLE:
            return []

        try:
            conn = await asyncpg.connect(self.db_url)
            try:
                # –ü–æ–ª—É—á–∞–µ–º embedding —Ç–µ–∫—É—â–µ–≥–æ —É–∑–ª–∞
                node = await conn.fetchrow("""
                    SELECT id, content, embedding, domain_id
                    FROM knowledge_nodes
                    WHERE id = $1
                """, node_id)

                if not node or not node["embedding"]:
                    return []

                # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ —É–∑–ª—ã
                similar_nodes = await conn.fetch("""
                    SELECT
                        id,
                        content,
                        domain_id,
                        1 - (embedding <=> $1::vector) as similarity
                    FROM knowledge_nodes
                    WHERE id != $2
                      AND embedding IS NOT NULL
                      AND (1 - (embedding <=> $1::vector)) >= $3
                    ORDER BY similarity DESC
                    LIMIT 10
                """, node["embedding"], node_id, similarity_threshold)

                created_links = []
                for similar in similar_nodes:
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Å–≤—è–∑–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ö–æ–¥—Å—Ç–≤–∞ –∏ –¥–æ–º–µ–Ω–∞
                    if similar["domain_id"] == node["domain_id"]:
                        link_type = LinkType.RELATED_TO
                    else:
                        link_type = LinkType.ENHANCES

                    strength = float(similar["similarity"])

                    link_id = await self.create_link(
                        node_id,
                        str(similar["id"]),
                        link_type,
                        strength
                    )

                    if link_id:
                        created_links.append(link_id)

                logger.info("‚úÖ Auto-detected %d links for node %s",
                            len(created_links), node_id)
                return created_links
            finally:
                await conn.close()
        except Exception as exc:  # pylint: disable=broad-exception-caught
            logger.error("Error auto-detecting links: %s", exc)
            return []


async def run_auto_link_detection():
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Å–≤—è–∑–µ–π –¥–ª—è –≤—Å–µ—Ö —É–∑–ª–æ–≤ –±–µ–∑ —Å–≤—è–∑–µ–π"""
    if not ASYNCPG_AVAILABLE:
        logger.error("‚ùå asyncpg is not installed. Detection aborted.")
        return

    logger.info("üîó Starting auto-link detection...")

    graph = KnowledgeGraph()
    conn = await asyncpg.connect(DB_URL)

    try:
        # –ü–æ–ª—É—á–∞–µ–º —É–∑–ª—ã –±–µ–∑ —Å–≤—è–∑–µ–π
        nodes_without_links = await conn.fetch("""
            SELECT k.id
            FROM knowledge_nodes k
            LEFT JOIN knowledge_links kl ON k.id = kl.source_node_id OR k.id = kl.target_node_id
            WHERE kl.id IS NULL
            LIMIT 20
        """)

        logger.info("Found %d nodes without links", len(nodes_without_links))

        for node in nodes_without_links:
            await graph.auto_detect_links(str(node["id"]))
            await asyncio.sleep(0.5)  # Rate limiting

        logger.info("‚úÖ Auto-link detection completed")
    except Exception as exc:  # pylint: disable=broad-exception-caught
        logger.error("Auto-link detection error: %s", exc)
    finally:
        await conn.close()


if __name__ == "__main__":
    asyncio.run(run_auto_link_detection())
