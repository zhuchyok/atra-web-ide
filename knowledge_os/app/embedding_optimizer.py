"""
Embedding Optimizer
–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
Singularity 8.0: Performance Optimization
"""

import asyncio
import logging
import hashlib
import asyncpg
import os
from typing import Optional, List, Dict, Any
from datetime import datetime, timezone

logger = logging.getLogger(__name__)

DB_URL = os.getenv('DATABASE_URL', 'postgresql://admin:secret@localhost:5432/knowledge_os')

# Rust-—É—Å–∫–æ—Ä–µ–Ω–∏–µ: –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è + —Ö—ç—à –¥–ª—è –∫–ª—é—á–µ–π –∫—ç—à–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
try:
    from cache_normalizer import (
        normalize_and_hash as _rust_normalize_and_hash,
        normalize_text as _rust_normalize_text,
        normalize_and_hash_batch as _rust_normalize_and_hash_batch,
    )
    _USE_RUST_NORMALIZER = True
except ImportError:
    _USE_RUST_NORMALIZER = False
    _rust_normalize_and_hash = None
    _rust_normalize_text = None
    _rust_normalize_and_hash_batch = None

class EmbeddingOptimizer:
    """
    –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —á–µ—Ä–µ–∑ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ batch-–æ–±—Ä–∞–±–æ—Ç–∫—É.
    –£—Å–∫–æ—Ä—è–µ—Ç –ø–æ–∏—Å–∫ –≤ –∫—ç—à–µ –Ω–∞ 50-70%.
    """
    
    def __init__(self, db_url: str = DB_URL):
        """
        Args:
            db_url: URL –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        """
        self.db_url = db_url
        self._memory_cache: Dict[str, List[float]] = {}  # In-memory –∫—ç—à
        self._cache_size = 1000  # –ú–∞–∫—Å–∏–º—É–º —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –≤ –ø–∞–º—è—Ç–∏
        self._batch_queue: List[Dict[str, Any]] = []  # –û—á–µ—Ä–µ–¥—å –¥–ª—è batch-–æ–±—Ä–∞–±–æ—Ç–∫–∏
        self._batch_size = 10  # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
        self._batch_timeout = 0.5  # –¢–∞–π–º–∞—É—Ç –±–∞—Ç—á–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
    
    def _normalize_text(self, text: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è (—É–±–∏—Ä–∞–µ—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã, –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É)"""
        if _USE_RUST_NORMALIZER and _rust_normalize_text:
            return _rust_normalize_text(text)
        return ' '.join(text.lower().split())
    
    def _get_text_hash(self, text: str) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ö—ç—à –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ (Rust –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏, –∏–Ω–∞—á–µ Python)"""
        if _USE_RUST_NORMALIZER:
            return _rust_normalize_and_hash(text)
        normalized = self._normalize_text(text)
        return hashlib.md5(normalized.encode()).hexdigest()

    def _get_text_hashes_batch(self, texts: List[str]) -> List[str]:
        """–ë–∞—Ç—á —Ö—ç—à–µ–π: –æ–¥–∏–Ω –≤—ã–∑–æ–≤ Rust –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏, –∏–Ω–∞—á–µ N –≤—ã–∑–æ–≤–æ–≤ Python (–º–µ–Ω—å—à–µ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ Python‚ÜîRust)."""
        if _USE_RUST_NORMALIZER and _rust_normalize_and_hash_batch is not None:
            return _rust_normalize_and_hash_batch(texts)
        return [self._get_text_hash(t) for t in texts]

    async def _get_cached_embedding_by_hash(self, text_hash: str) -> Optional[List[float]]:
        """–ü–æ–ª—É—á–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –∏–∑ –∫—ç—à–∞ –ø–æ —É–∂–µ –≤—ã—á–∏—Å–ª–µ–Ω–Ω–æ–º—É —Ö—ç—à—É (–ø–∞–º—è—Ç—å -> –ë–î)."""
        if text_hash in self._memory_cache:
            return self._memory_cache[text_hash]
        try:
            conn = await asyncpg.connect(self.db_url)
            try:
                table_exists = await conn.fetchval("""
                    SELECT EXISTS (
                        SELECT 1 FROM information_schema.tables 
                        WHERE table_name = 'embedding_cache'
                    )
                """)
                if not table_exists:
                    return None
                row = await conn.fetchrow(
                    "SELECT embedding FROM embedding_cache WHERE text_hash = $1", text_hash
                )
                if row:
                    embedding = row["embedding"]
                    if len(self._memory_cache) >= self._cache_size:
                        oldest_key = next(iter(self._memory_cache))
                        del self._memory_cache[oldest_key]
                    self._memory_cache[text_hash] = embedding
                    return embedding
            finally:
                await conn.close()
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è [EMBEDDING CACHE] DB lookup failed: {e}")
        return None

    async def get_cached_embedding(self, text: str) -> Optional[List[float]]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –∏–∑ –∫—ç—à–∞ (–ø–∞–º—è—Ç—å -> –ë–î).

        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞

        Returns:
            –≠–º–±–µ–¥–¥–∏–Ω–≥ –∏–ª–∏ None
        """
        text_hash = self._get_text_hash(text)
        cached = await self._get_cached_embedding_by_hash(text_hash)
        if cached:
            logger.debug(f"‚úÖ [EMBEDDING CACHE] Hit for: {text[:50]}...")
        return cached
    
    async def save_embedding(self, text: str, embedding: List[float]):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –≤ –∫—ç—à (–ø–∞–º—è—Ç—å –∏ –ë–î).
        
        Args:
            text: –¢–µ–∫—Å—Ç
            embedding: –≠–º–±–µ–¥–¥–∏–Ω–≥
        """
        text_hash = self._get_text_hash(text)
        normalized_text = self._normalize_text(text)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ memory cache
        if len(self._memory_cache) >= self._cache_size:
            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ (FIFO)
            oldest_key = next(iter(self._memory_cache))
            del self._memory_cache[oldest_key]
        self._memory_cache[text_hash] = embedding
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î (–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ, –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º)
        asyncio.create_task(self._save_embedding_to_db(text_hash, normalized_text, embedding))
    
    async def _save_embedding_to_db(self, text_hash: str, normalized_text: str, embedding: List[float]):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –≤ –ë–î"""
        try:
            conn = await asyncpg.connect(self.db_url)
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç–∞–±–ª–∏—Ü—ã
                table_exists = await conn.fetchval("""
                    SELECT EXISTS (
                        SELECT 1 FROM information_schema.tables 
                        WHERE table_name = 'embedding_cache'
                    )
                """)
                
                if not table_exists:
                    logger.debug("‚ö†Ô∏è [EMBEDDING CACHE] –¢–∞–±–ª–∏—Ü–∞ embedding_cache –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                    return
                
                await conn.execute("""
                    INSERT INTO embedding_cache (text_hash, normalized_text, embedding, created_at)
                    VALUES ($1, $2, $3::vector, NOW())
                    ON CONFLICT (text_hash) DO UPDATE 
                    SET embedding = EXCLUDED.embedding,
                        created_at = NOW()
                """, text_hash, normalized_text, str(embedding))
            finally:
                await conn.close()
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è [EMBEDDING CACHE] Failed to save to DB: {e}")
    
    async def get_embeddings_batch(self, texts: List[str], get_embedding_func) -> List[Optional[List[float]]]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –±–∞—Ç—á–∞ —Ç–µ–∫—Å—Ç–æ–≤.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫—ç—à –¥–ª—è —É–∂–µ –≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.
        
        Args:
            texts: –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤
            get_embedding_func: –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
        
        Returns:
            –°–ø–∏—Å–æ–∫ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        """
        results = []
        texts_to_compute = []
        indices_to_compute = []
        # –û–¥–∏–Ω –≤—ã–∑–æ–≤ –±–∞—Ç—á–∞ –¥–ª—è –≤—Å–µ—Ö —Ö—ç—à–µ–π (Rust –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ ‚Äî –º–µ–Ω—å—à–µ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ Python‚ÜîRust)
        hashes = self._get_text_hashes_batch(texts)
        for i, (text, text_hash) in enumerate(zip(texts, hashes)):
            cached = await self._get_cached_embedding_by_hash(text_hash)
            if cached:
                results.append((i, cached))
            else:
                texts_to_compute.append(text)
                indices_to_compute.append(i)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –∫—ç—à–µ
        if texts_to_compute:
            logger.debug(f"üì¶ [EMBEDDING BATCH] Computing {len(texts_to_compute)} embeddings...")
            # –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
            embeddings = await asyncio.gather(*[
                get_embedding_func(text) for text in texts_to_compute
            ], return_exceptions=True)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à –∏ –¥–æ–±–∞–≤–ª—è–µ–º –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            for idx, text, embedding in zip(indices_to_compute, texts_to_compute, embeddings):
                if isinstance(embedding, Exception):
                    logger.error(f"‚ùå [EMBEDDING BATCH] Failed for text {idx}: {embedding}")
                    results.append((idx, None))
                elif embedding:
                    await self.save_embedding(text, embedding)
                    results.append((idx, embedding))
                else:
                    results.append((idx, None))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∏–Ω–¥–µ–∫—Å–∞–º
        results.sort(key=lambda x: x[0])
        return [emb for _, emb in results]

# Singleton instance
_optimizer_instance: Optional[EmbeddingOptimizer] = None

def get_embedding_optimizer(db_url: str = DB_URL) -> EmbeddingOptimizer:
    """–ü–æ–ª—É—á–∏—Ç—å singleton —ç–∫–∑–µ–º–ø–ª—è—Ä –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞"""
    global _optimizer_instance
    if _optimizer_instance is None:
        _optimizer_instance = EmbeddingOptimizer(db_url=db_url)
    return _optimizer_instance

