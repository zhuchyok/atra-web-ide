"""
Streaming Orchestrator - event-driven –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è Knowledge OS.

–ü–æ–ª–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π orchestrator –Ω–∞ –±–∞–∑–µ Redis Streams:
- –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏–π —á–µ—Ä–µ–∑ EventProducer
- –†–µ–∞–∫—Ü–∏—è –Ω–∞ —Å–æ–±—ã—Ç–∏—è —á–µ—Ä–µ–∑ EventConsumer
- –¢–∏–ø–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è
- –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
"""

import asyncio
import os
import sys
import json
import logging
import subprocess
from datetime import datetime
from typing import Optional, List, Dict, Any

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ src
sys.path.insert(0, '/root/knowledge_os/src')

import asyncpg

from infrastructure.streaming import (
    EventProducer,
    EventConsumer,
    StreamManager,
    EventType,
    KnowledgeEvent,
    TaskEvent,
    InsightEvent,
)
from infrastructure.streaming.consumer import ConsumerConfig

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(name)s | %(message)s'
)
logger = logging.getLogger("streaming_orchestrator")

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
DB_URL = os.getenv('DATABASE_URL', 'postgresql://admin:secret@localhost:5432/knowledge_os')
REDIS_URL = os.getenv('REDIS_URL', 'redis://localhost:6379')

# Resource lock (–ø—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ Redis)
_lock_key = "orchestrator:lock"

# Connection pool
_pool: Optional[asyncpg.Pool] = None


async def get_pool() -> asyncpg.Pool:
    """–ü–æ–ª—É—á–∞–µ—Ç –∏–ª–∏ —Å–æ–∑–¥–∞—ë—Ç connection pool."""
    global _pool
    if _pool is None:
        _pool = await asyncpg.create_pool(
            DB_URL,
            min_size=1,
            max_size=5,  # –£–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–≥—Ä—É–∑–∫–∏ –ë–î
            max_inactive_connection_lifetime=300,
            command_timeout=60
        )
    return _pool


def run_cursor_agent(prompt: str, timeout: int = 300) -> Optional[str]:
    """–í—ã–∑—ã–≤–∞–µ—Ç cursor-agent –¥–ª—è AI –æ–ø–µ—Ä–∞—Ü–∏–π."""
    try:
        env = os.environ.copy()
        result = subprocess.run(
            ['/root/.local/bin/cursor-agent', '--print', prompt],
            capture_output=True,
            text=True,
            check=True,
            timeout=timeout,
            env=env
        )
        return result.stdout.strip()
    except Exception as e:
        logger.error(f"Cursor agent error: {e}")
        return None


class StreamingOrchestrator:
    """
    Event-driven –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä Knowledge OS.
    
    –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç:
    - –ö—Ä–æ—Å—Å-–¥–æ–º–µ–Ω–Ω–æ–µ —Å–≤—è–∑—ã–≤–∞–Ω–∏–µ –∑–Ω–∞–Ω–∏–π
    - –ê–≤—Ç–æ–Ω–æ–º–Ω—ã–π —Ä–µ–∫—Ä—É—Ç–∏–Ω–≥ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
    - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ "–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–º–∏ –ø—É—Å—Ç—ã–Ω—è–º–∏"
    - –ì–µ–Ω–µ—Ä–∞—Ü–∏—é —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –≥–∏–ø–æ—Ç–µ–∑
    """
    
    def __init__(self):
        self.producer: Optional[EventProducer] = None
        self.stream_manager: Optional[StreamManager] = None
        
        # Consumer –¥–ª—è —Ä–µ–∞–∫—Ü–∏–∏ –Ω–∞ —Å–æ–±—ã—Ç–∏—è
        self.insight_consumer = EventConsumer(
            redis_url=REDIS_URL,
            config=ConsumerConfig(
                stream_name="insight_stream",
                group_name="orchestrator",
                consumer_name="orchestrator-insight-processor",
                batch_size=5,
                block_ms=2000,
            )
        )
        
        self._register_handlers()
    
    def _register_handlers(self):
        """–†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ—Ç –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–æ–±—ã—Ç–∏–π."""
        
        @self.insight_consumer.on_event(EventType.INSIGHT_HYPOTHESIS)
        async def handle_hypothesis(event: InsightEvent, raw_data: Dict) -> bool:
            """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–æ–≤—ã–µ –≥–∏–ø–æ—Ç–µ–∑—ã - –º–æ–∂–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å –∑–∞–¥–∞—á–∏ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏."""
            logger.info(f"üî¨ New hypothesis to validate: {event.hypothesis[:100]}...")
            
            # –°–æ–∑–¥–∞—ë–º –∑–∞–¥–∞—á—É –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏—é –≥–∏–ø–æ—Ç–µ–∑—ã
            pool = await get_pool()
            
            # –ù–∞—Ö–æ–¥–∏–º —ç–∫—Å–ø–µ—Ä—Ç–∞ –ø–æ –¥–æ–º–µ–Ω—É
            expert = await pool.fetchrow("""
                SELECT e.id, e.name FROM experts e
                JOIN domains d ON e.domain_id = d.id
                WHERE d.name = $1
                ORDER BY RANDOM() LIMIT 1
            """, event.source_domain)
            
            if expert:
                victoria_id = await pool.fetchval(
                    "SELECT id FROM experts WHERE name = '–í–∏–∫—Ç–æ—Ä–∏—è'"
                )
                
                task_id = await pool.fetchval("""
                    INSERT INTO tasks (title, description, status, assignee_expert_id, creator_expert_id, metadata)
                    VALUES ($1, $2, 'pending', $3, $4, $5)
                    RETURNING id
                """,
                    f"üî¨ –í–∞–ª–∏–¥–∞—Ü–∏—è –≥–∏–ø–æ—Ç–µ–∑—ã: {event.source_domain} ‚Üî {event.target_domain}",
                    f"–ü—Ä–æ–≤–µ—Ä—å –≥–∏–ø–æ—Ç–µ–∑—É: {event.hypothesis}\n\n–û—Ü–µ–Ω–∏ –µ—ë –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏.",
                    expert['id'],
                    victoria_id,
                    json.dumps({"source": "hypothesis_validation", "insight_id": event.insight_id})
                )
                
                # –ü—É–±–ª–∏–∫—É–µ–º —Å–æ–±—ã—Ç–∏–µ —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–¥–∞—á–∏
                if self.producer and task_id:
                    await self.producer.publish_task_created(
                        task_id=str(task_id),
                        title=f"–í–∞–ª–∏–¥–∞—Ü–∏—è –≥–∏–ø–æ—Ç–µ–∑—ã: {event.source_domain} ‚Üî {event.target_domain}",
                        description=f"–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≥–∏–ø–æ—Ç–µ–∑—É: {event.hypothesis[:200]}",
                        assignee_expert_id=str(expert['id']),
                        assignee_name=expert['name'],
                        priority="high"
                    )
                    logger.info(f"üìã Created validation task {task_id} for {expert['name']}")
            
            return True
    
    async def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä."""
        self.stream_manager = StreamManager(REDIS_URL)
        await self.stream_manager.initialize()
        
        self.producer = EventProducer(REDIS_URL)
        await self.producer.connect()
        
        logger.info("‚úÖ StreamingOrchestrator initialized")
    
    async def run_orchestration_cycle(self):
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –æ–¥–∏–Ω —Ü–∏–∫–ª –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏–∏."""
        logger.info(f"[{datetime.now()}] üöÄ STREAMING ORCHESTRATOR v4.0 starting cycle...")
        
        pool = await get_pool()
        
        # === –§–ê–ó–ê 1: –°–ë–û–† –ù–û–í–´–• –ó–ù–ê–ù–ò–ô ===
        new_knowledge = await pool.fetch("""
            SELECT k.id, k.content, d.name as domain, k.metadata, k.domain_id
            FROM knowledge_nodes k
            JOIN domains d ON k.domain_id = d.id
            WHERE k.created_at > NOW() - INTERVAL '6 hours'
            AND (k.metadata->>'orchestrated' IS NULL OR k.metadata->>'orchestrated' = 'false')
            LIMIT 50
        """)
        
        logger.info(f"üìö Found {len(new_knowledge)} new knowledge nodes to process")
        
        # === –§–ê–ó–ê 2: –ö–†–û–°–°-–î–û–ú–ï–ù–ù–û–ï –°–í–Ø–ó–´–í–ê–ù–ò–ï ===
        for node in new_knowledge:
            await self._process_knowledge_node(pool, node)
        
        # === –§–ê–ó–ê 3: –î–í–ò–ì–ê–¢–ï–õ–¨ –õ–Æ–ë–û–ü–´–¢–°–¢–í–ê ===
        await self._run_curiosity_engine(pool)
        
        # === –§–ê–ó–ê 4: HEALTH CHECK ===
        if self.stream_manager:
            health = await self.stream_manager.health_check()
            logger.info(f"üìä Streams health: {health['status']}")
        
        logger.info(f"[{datetime.now()}] ‚úÖ Orchestration cycle completed")
    
    async def _process_knowledge_node(self, pool: asyncpg.Pool, node: Dict[str, Any]):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —É–∑–µ–ª –∑–Ω–∞–Ω–∏–π - —Å–æ–∑–¥–∞—ë—Ç –∫—Ä–æ—Å—Å-–¥–æ–º–µ–Ω–Ω—ã–µ —Å–≤—è–∑–∏."""
        logger.info(f"üß© Processing: {node['content'][:50]}...")
        
        # –ù–∞—Ö–æ–¥–∏–º —Å–ª—É—á–∞–π–Ω—ã–π —É–∑–µ–ª –∏–∑ –¥—Ä—É–≥–æ–≥–æ –¥–æ–º–µ–Ω–∞
        random_node = await pool.fetchrow("""
            SELECT k.id, k.content, d.name as domain
            FROM knowledge_nodes k
            JOIN domains d ON k.domain_id = d.id
            WHERE k.domain_id != $1
            ORDER BY RANDOM() LIMIT 1
        """, node['domain_id'])
        
        if not random_node:
            return
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫—Ä–æ—Å—Å-–¥–æ–º–µ–Ω–Ω—É—é –≥–∏–ø–æ—Ç–µ–∑—É
        link_prompt = f"""
        –í—ã - –í–∏–∫—Ç–æ—Ä–∏—è (Team Lead). –ù–∞–π–¥–∏—Ç–µ –Ω–µ–æ—á–µ–≤–∏–¥–Ω—É—é —Å–≤—è–∑—å –º–µ–∂–¥—É –¥–≤—É–º—è —Ñ–∞–∫—Ç–∞–º–∏ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –æ—Ç–¥–µ–ª–æ–≤:
        
        –§–ê–ö–¢ –ê ({node['domain']}): {node['content']}
        –§–ê–ö–¢ –ë ({random_node['domain']}): {random_node['content']}
        
        –ó–ê–î–ê–ß–ê: –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ –æ–¥–Ω—É –∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω—É—é –≥–∏–ø–æ—Ç–µ–∑—É (Synthetic Hypothesis) –Ω–∞ —Å—Ç—ã–∫–µ —ç—Ç–∏—Ö –∑–Ω–∞–Ω–∏–π.
        –í–µ—Ä–Ω–∏—Ç–µ –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç –≥–∏–ø–æ—Ç–µ–∑—ã (1-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è).
        """
        
        hypothesis = run_cursor_agent(link_prompt)
        
        if hypothesis:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
            knowledge_id = await pool.fetchval("""
                INSERT INTO knowledge_nodes (domain_id, content, confidence_score, metadata, is_verified)
                VALUES ($1, $2, 0.95, $3, true)
                RETURNING id
            """, node['domain_id'],
                f"üî¨ –ö–†–û–°–°-–î–û–ú–ï–ù–ù–ê–Ø –ì–ò–ü–û–¢–ï–ó–ê: {hypothesis}",
                json.dumps({
                    "source": "cross_domain_linker",
                    "parents": [str(node['id']), str(random_node['id'])],
                    "source_domain": node['domain'],
                    "target_domain": random_node['domain']
                })
            )
            
            # –ü—É–±–ª–∏–∫—É–µ–º —Å–æ–±—ã—Ç–∏–µ —á–µ—Ä–µ–∑ streaming –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—É
            if self.producer:
                await self.producer.publish_insight(
                    content=hypothesis,
                    source_domain=node['domain'],
                    target_domain=random_node['domain'],
                    hypothesis=hypothesis,
                    confidence=0.95,
                    parent_knowledge_ids=[str(node['id']), str(random_node['id'])],
                    metadata={"knowledge_id": str(knowledge_id)}
                )
            
            logger.info(f"üí° Created cross-domain insight: {node['domain']} ‚Üî {random_node['domain']}")
        
        # –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π
        await pool.execute("""
            UPDATE knowledge_nodes 
            SET metadata = metadata || '{"orchestrated": "true"}'::jsonb 
            WHERE id = $1
        """, node['id'])
    
    async def _run_curiosity_engine(self, pool: asyncpg.Pool):
        """–ù–∞—Ö–æ–¥–∏—Ç '–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–µ –ø—É—Å—Ç—ã–Ω–∏' –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –∑–∞–¥–∞—á–∏."""
        
        # –ò—â–µ–º –¥–æ–º–µ–Ω—ã —Å –º–∞–ª—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∑–Ω–∞–Ω–∏–π
        deserts = await pool.fetch("""
            SELECT d.id, d.name, count(k.id) as node_count
            FROM domains d 
            LEFT JOIN knowledge_nodes k ON d.id = k.domain_id
            GROUP BY d.id, d.name 
            HAVING count(k.id) < 50 
               OR max(k.created_at) < NOW() - INTERVAL '48 hours'
        """)
        
        victoria_id = await pool.fetchval("SELECT id FROM experts WHERE name = '–í–∏–∫—Ç–æ—Ä–∏—è'")
        
        for desert in deserts:
            logger.info(f"üèúÔ∏è Curiosity Engine: Domain '{desert['name']}' needs attention")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
            expert_count = await pool.fetchval(
                "SELECT count(*) FROM experts WHERE department = $1",
                desert['name']
            )
            
            if expert_count == 0:
                logger.info(f"üë§ Recruiting expert for {desert['name']}...")
                try:
                    subprocess.run(
                        ["/root/knowledge_os/venv/bin/python",
                         "/root/knowledge_os/app/expert_generator.py",
                         desert['name']],
                        timeout=60
                    )
                except Exception as e:
                    logger.warning(f"Expert generation failed: {e}")
                continue
            
            # –°–æ–∑–¥–∞—ë–º –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫—É—é –∑–∞–¥–∞—á—É
            curiosity_task = (
                f"–ü—Ä–æ–≤–µ–¥–∏ –≥–ª—É–±–æ–∫–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –∏ —Ç—Ä–µ–Ω–¥–æ–≤ 2026 "
                f"–≤ –æ–±–ª–∞—Å—Ç–∏ {desert['name']}. –ù–∞–π–¥–∏ 3 –ø—Ä–æ—Ä—ã–≤–Ω—ã—Ö –∏–Ω—Å–∞–π—Ç–∞."
            )
            
            # –ù–∞—Ö–æ–¥–∏–º —ç–∫—Å–ø–µ—Ä—Ç–∞
            assignee = await pool.fetchrow(
                "SELECT id, name FROM experts WHERE department = $1 ORDER BY RANDOM() LIMIT 1",
                desert['name']
            )
            
            if assignee and victoria_id:
                task_id = await pool.fetchval("""
                    INSERT INTO tasks (title, description, status, assignee_expert_id, creator_expert_id, metadata)
                    VALUES ($1, $2, 'pending', $3, $4, $5)
                    RETURNING id
                """,
                    f"üî• –°–†–û–ß–ù–û–ï –ò–°–°–õ–ï–î–û–í–ê–ù–ò–ï: {desert['name']}",
                    curiosity_task,
                    assignee['id'],
                    victoria_id,
                    json.dumps({"reason": "curiosity_engine_starvation", "domain": desert['name']})
                )
                
                # –ü—É–±–ª–∏–∫—É–µ–º —Å–æ–±—ã—Ç–∏–µ
                if self.producer and task_id:
                    await self.producer.publish_task_created(
                        task_id=str(task_id),
                        title=f"–°–†–û–ß–ù–û–ï –ò–°–°–õ–ï–î–û–í–ê–ù–ò–ï: {desert['name']}",
                        description=curiosity_task,
                        assignee_expert_id=str(assignee['id']),
                        assignee_name=assignee['name'],
                        creator_expert_id=str(victoria_id) if victoria_id else None,
                        priority="high",
                        metadata={"source": "curiosity_engine"}
                    )
                    
                    logger.info(f"üìã Created research task {task_id} for {assignee['name']}")
    
    async def start_continuous(self, interval_seconds: int = 300):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—É—é –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—é."""
        logger.info(f"üöÄ Starting continuous orchestration (interval: {interval_seconds}s)")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º consumer –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ insight —Å–æ–±—ã—Ç–∏–π
        consumer_task = asyncio.create_task(self.insight_consumer.start())
        
        try:
            while True:
                try:
                    await self.run_orchestration_cycle()
                except Exception as e:
                    logger.error(f"Orchestration cycle error: {e}")
                
                await asyncio.sleep(interval_seconds)
        finally:
            consumer_task.cancel()
            await self.insight_consumer.stop()
    
    async def close(self):
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è."""
        if self.producer:
            await self.producer.close()
        
        if self.stream_manager:
            await self.stream_manager.close()
        
        global _pool
        if _pool:
            await _pool.close()
            _pool = None
        
        logger.info("StreamingOrchestrator closed")


async def main():
    """Entry point."""
    import argparse
    
    parser = argparse.ArgumentParser(description='Streaming Orchestrator for Knowledge OS')
    parser.add_argument('--once', action='store_true', help='Run single cycle and exit')
    parser.add_argument('--interval', type=int, default=300, help='Interval between cycles (seconds)')
    args = parser.parse_args()
    
    orchestrator = StreamingOrchestrator()
    
    try:
        await orchestrator.initialize()
        
        if args.once:
            await orchestrator.run_orchestration_cycle()
        else:
            await orchestrator.start_continuous(interval_seconds=args.interval)
    except KeyboardInterrupt:
        logger.info("Interrupted by user")
    finally:
        await orchestrator.close()


if __name__ == "__main__":
    asyncio.run(main())
