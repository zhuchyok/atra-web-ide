"""
Auto Model Manager –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∑–∞–≥—Ä—É–∑–∫–∏/–≤—ã–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è.
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—Ä–µ–º—è –¥–Ω—è –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –º–æ–¥–µ–ª–∏.
"""

import asyncio
import os
import logging
import httpx
from typing import Dict, List, Optional
from datetime import datetime, time
from enum import Enum

logger = logging.getLogger(__name__)

# –ò–º–ø–æ—Ä—Ç—ã —Å fallback
try:
    from model_memory_manager import get_memory_manager, ModelMemoryManager
except ImportError:
    get_memory_manager = None
    ModelMemoryManager = None

class TimeOfDay(Enum):
    """–í—Ä–µ–º—è –¥–Ω—è –¥–ª—è –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–µ–π"""
    MORNING = "morning"  # 6:00 - 12:00
    AFTERNOON = "afternoon"  # 12:00 - 18:00
    EVENING = "evening"  # 18:00 - 22:00
    NIGHT = "night"  # 22:00 - 6:00

class AutoModelManager:
    """
    –ê–≤—Ç–æ–Ω–æ–º–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –º–æ–¥–µ–ª–µ–π —Å —É–º–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–æ–π –ø–æ –≤—Ä–µ–º–µ–Ω–∏.
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç/–≤—ã–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è.
    """
    
    def __init__(self, ollama_url: str = "http://localhost:11434"):
        self.ollama_url = ollama_url
        self.memory_manager = get_memory_manager(ollama_url) if get_memory_manager else None
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –¥–Ω—è
        self.model_configs = {
            TimeOfDay.MORNING: {
                "priority_models": ["qwen2.5-coder:32b"],  # MLX –º–æ–¥–µ–ª—å (Mac Studio) - Coding —É—Ç—Ä–æ–º
                "fallback_models": ["phi3.5:3.8b"],  # Ollama –º–æ–¥–µ–ª—å (Mac Studio)
                "unload_models": ["qwen2.5-coder:32b"]
            },
            TimeOfDay.AFTERNOON: {
                "priority_models": ["qwen2.5-coder:32b", "phi3.5:3.8b"],  # MLX + Ollama –º–æ–¥–µ–ª–∏ (Mac Studio)
                "fallback_models": ["tinyllama:1.1b-chat-v1.0-q4_0"],
                "unload_models": []
            },
            TimeOfDay.EVENING: {
                "priority_models": ["phi3.5:3.8b", "qwen2.5-coder:32b"],
                "fallback_models": ["phi3:mini-4k-instruct-q4_k_m"],
                "unload_models": []
            },
            TimeOfDay.NIGHT: {
                "priority_models": ["tinyllama:1.1b-chat-v1.0-q4_0"],  # –¢–æ–ª—å–∫–æ –ª–µ–≥–∫–∏–µ –º–æ–¥–µ–ª–∏ –Ω–æ—á—å—é
                "fallback_models": [],
                "unload_models": ["qwen2.5-coder:32b"]
            }
        }
        
        self._running = False
        self._monitor_task: Optional[asyncio.Task] = None
    
    def get_time_of_day(self) -> TimeOfDay:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –¥–Ω—è"""
        current_hour = datetime.now().hour
        
        if 6 <= current_hour < 12:
            return TimeOfDay.MORNING
        elif 12 <= current_hour < 18:
            return TimeOfDay.AFTERNOON
        elif 18 <= current_hour < 22:
            return TimeOfDay.EVENING
        else:
            return TimeOfDay.NIGHT
    
    async def get_loaded_models(self) -> List[str]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            async with httpx.AsyncClient(timeout=5.0) as client:
                response = await client.get(f"{self.ollama_url}/api/tags")
                if response.status_code == 200:
                    data = response.json()
                    return [model['name'] for model in data.get('models', [])]
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {e}")
        return []
    
    async def load_model(self, model_name: str) -> bool:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ Ollama API"""
        try:
            logger.info(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {model_name}...")
            async with httpx.AsyncClient(timeout=60.0) as client:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ generate –∑–∞–ø—Ä–æ—Å
                response = await client.post(
                    f"{self.ollama_url}/api/generate",
                    json={
                        "model": model_name,
                        "prompt": "test",
                        "stream": False
                    },
                    timeout=60.0
                )
                if response.status_code == 200:
                    logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å {model_name} –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                    return True
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ {model_name}: {e}")
        return False
    
    async def unload_model(self, model_name: str) -> bool:
        """–í—ã–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å (–ø–æ–º–µ—Ç–∏—Ç—å –∫–∞–∫ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—É—é)"""
        if self.memory_manager:
            return await self.memory_manager.unload_model(model_name)
        return False
    
    async def optimize_models_for_time(self):
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –Ω–∞–±–æ—Ä –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –¥–Ω—è"""
        time_of_day = self.get_time_of_day()
        config = self.model_configs[time_of_day]
        
        logger.info(f"üïê –¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –¥–Ω—è: {time_of_day.value}")
        
        loaded_models = await self.get_loaded_models()
        
        # –í—ã–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω—É–∂–Ω—ã –≤ —ç—Ç–æ –≤—Ä–µ–º—è
        for model_to_unload in config.get("unload_models", []):
            if model_to_unload in loaded_models:
                logger.info(f"‚è∞ –í—ã–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å {model_to_unload} (–Ω–µ –Ω—É–∂–Ω–∞ –≤ {time_of_day.value})")
                await self.unload_model(model_to_unload)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
        for priority_model in config.get("priority_models", []):
            if priority_model not in loaded_models:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—É—é –ø–∞–º—è—Ç—å –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π
                if self.memory_manager:
                    available_mb = await self.memory_manager.get_available_memory_mb()
                    if available_mb < 200:  # MIN_FREE_MEMORY_MB
                        logger.warning(f"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ {priority_model} ({available_mb}MB)")
                        continue
                
                logger.info(f"‚è∞ –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—É—é –º–æ–¥–µ–ª—å {priority_model} –¥–ª—è {time_of_day.value}")
                await self.load_model(priority_model)
    
    async def monitor_and_optimize(self, check_interval: int = 3600):
        """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π"""
        self._running = True
        logger.info("üîç –ó–∞–ø—É—â–µ–Ω –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –º–æ–¥–µ–ª–µ–π")
        
        last_time_of_day = None
        
        while self._running:
            try:
                current_time_of_day = self.get_time_of_day()
                
                # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–∏ —Å–º–µ–Ω–µ –≤—Ä–µ–º–µ–Ω–∏ –¥–Ω—è
                if current_time_of_day != last_time_of_day:
                    logger.info(f"üîÑ –°–º–µ–Ω–∞ –≤—Ä–µ–º–µ–Ω–∏ –¥–Ω—è: {last_time_of_day.value if last_time_of_day else 'start'} -> {current_time_of_day.value}")
                    await self.optimize_models_for_time()
                    last_time_of_day = current_time_of_day
                
                await asyncio.sleep(check_interval)
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –≤ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–µ –º–æ–¥–µ–ª–µ–π: {e}")
                await asyncio.sleep(check_interval)
    
    def start_monitoring(self, check_interval: int = 3600):
        """–ó–∞–ø—É—Å—Ç–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –º–æ–¥–µ–ª–µ–π"""
        if not self._running:
            self._monitor_task = asyncio.create_task(self.monitor_and_optimize(check_interval))
    
    def stop_monitoring(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –º–æ–¥–µ–ª–µ–π"""
        self._running = False
        if self._monitor_task:
            self._monitor_task.cancel()

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
_auto_model_manager: Optional[AutoModelManager] = None

def get_auto_model_manager(ollama_url: str = "http://localhost:11434") -> AutoModelManager:
    """–ü–æ–ª—É—á–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä AutoModelManager"""
    global _auto_model_manager
    if _auto_model_manager is None:
        _auto_model_manager = AutoModelManager(ollama_url)
    return _auto_model_manager

