#!/usr/bin/env python3
"""
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—ã—Å–æ–∫–æ–ª–∏–∫–≤–∏–¥–Ω—ã—Ö –∑–Ω–∞–Ω–∏–π.
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –∑–Ω–∞–Ω–∏—è –∏ —Å–æ–∑–¥–∞–µ—Ç –∑–∞–¥–∞—á–∏ –¥–ª—è –∏—Ö –≤–Ω–µ–¥—Ä–µ–Ω–∏—è/—É–ª—É—á—à–µ–Ω–∏—è.
"""
import asyncio
import os
import json
import asyncpg
from datetime import datetime, timezone
from typing import List, Dict, Optional
import logging

logger = logging.getLogger(__name__)

# –ü–æ—Ä–æ–≥–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–¥–∞—á
MIN_LIQUIDITY_FOR_TASK = 2.0  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π liquidity_score –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–¥–∞—á–∏
MIN_USAGE_COUNT = 3  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–π
TOP_N_FOR_ANALYSIS = 20  # –¢–æ–ø-N —É–∑–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

# –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏
LIQUIDITY_PRIORITY_THRESHOLDS = {
    "urgent": 10.0,   # –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å
    "high": 5.0,      # –í—ã—Å–æ–∫–∞—è –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å
    "medium": 2.0,    # –°—Ä–µ–¥–Ω—è—è –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å
    "low": 1.0        # –ù–∏–∑–∫–∞—è –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å (–Ω–æ –≤—ã—à–µ –º–∏–Ω–∏–º—É–º–∞)
}


class LiquidityTaskGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∑–∞–¥–∞—á –Ω–∞ –æ—Å–Ω–æ–≤–µ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏ –∑–Ω–∞–Ω–∏–π"""
    
    def __init__(self, db_url: str = None):
        self.db_url = db_url
    
    async def get_pool(self):
        """–ü–æ–ª—É—á–∏—Ç—å –ø—É–ª –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π –∫ –ë–î"""
        if self.db_url:
            return await asyncpg.create_pool(self.db_url, min_size=1, max_size=5)
        else:
            from evaluator import get_pool
            return await get_pool()
    
    def calculate_priority(self, liquidity_score: float, usage_count: int) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∑–∞–¥–∞—á–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏.
        
        Args:
            liquidity_score: –õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å –∑–Ω–∞–Ω–∏—è
            usage_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–π
        
        Returns:
            –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: urgent, high, medium, low
        """
        if liquidity_score >= LIQUIDITY_PRIORITY_THRESHOLDS["urgent"] or usage_count >= 50:
            return "urgent"
        elif liquidity_score >= LIQUIDITY_PRIORITY_THRESHOLDS["high"] or usage_count >= 20:
            return "high"
        elif liquidity_score >= LIQUIDITY_PRIORITY_THRESHOLDS["medium"] or usage_count >= 10:
            return "medium"
        else:
            return "low"
    
    def generate_actionable_insights(self, content: str, usage_count: int, domain: str) -> List[str]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç actionable insights –∏–∑ –ø–æ–ø—É–ª—è—Ä–Ω–æ–≥–æ –∑–Ω–∞–Ω–∏—è.
        
        Args:
            content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —É–∑–ª–∞ –∑–Ω–∞–Ω–∏–π
            usage_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–π
            domain: –î–æ–º–µ–Ω –∑–Ω–∞–Ω–∏—è
        
        Returns:
            –°–ø–∏—Å–æ–∫ actionable insights
        """
        insights = []
        
        # –ï—Å–ª–∏ –∑–Ω–∞–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —á–∞—Å—Ç–æ, –æ–Ω–æ —Ç—Ä–µ–±—É–µ—Ç –≤–Ω–µ–¥—Ä–µ–Ω–∏—è
        if usage_count >= 20:
            insights.append(f"–ü–æ–ø—É–ª—è—Ä–Ω–æ–µ –∑–Ω–∞–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è {usage_count} —Ä–∞–∑ - —Ç—Ä–µ–±—É–µ—Ç –≤–Ω–µ–¥—Ä–µ–Ω–∏—è –≤ –ø—Ä–æ—Ü–µ—Å—Å—ã")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π/–ø—Ä–∞–∫—Ç–∏–∫
        action_keywords = ['—Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å', '–≤–Ω–µ–¥—Ä–∏—Ç—å', '—Å–æ–∑–¥–∞—Ç—å', '–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å', '–ø—Ä–∏–º–µ–Ω–∏—Ç—å', '–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å']
        if any(keyword in content.lower() for keyword in action_keywords):
            insights.append(f"–°–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è –≤–Ω–µ–¥—Ä–µ–Ω–∏—è –≤ –¥–æ–º–µ–Ω–µ {domain}")
        
        # –ï—Å–ª–∏ –≤—ã—Å–æ–∫–∏–π usage_count, –∑–Ω–∞–Ω–∏–µ —Ü–µ–Ω–Ω–æ –∏ –µ–≥–æ –Ω—É–∂–Ω–æ —Ä–∞–∑–≤–∏–≤–∞—Ç—å
        if usage_count >= 10:
            insights.append(f"–í—ã—Å–æ–∫–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å ({usage_count} –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–π) - —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∏ —É–ª—É—á—à–µ–Ω–∏–µ")
        
        # –ï—Å–ª–∏ –Ω–µ—Ç insights, —Å–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–π
        if not insights:
            insights.append(f"–ü–æ–ø—É–ª—è—Ä–Ω–æ–µ –∑–Ω–∞–Ω–∏–µ —Ç—Ä–µ–±—É–µ—Ç –∞–Ω–∞–ª–∏–∑–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –≤–Ω–µ–¥—Ä–µ–Ω–∏—è –≤ –ø—Ä–æ—Ü–µ—Å—Å—ã")
        
        return insights
    
    async def analyze_high_liquidity_knowledge(self) -> List[Dict]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—ã—Å–æ–∫–æ–ª–∏–∫–≤–∏–¥–Ω—ã–µ –∑–Ω–∞–Ω–∏—è –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–¥–∞—á.
        
        Returns:
            –°–ø–∏—Å–æ–∫ –∑–Ω–∞–Ω–∏–π —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏
        """
        try:
            pool = await self.get_pool()
        except Exception as e:
            logger.error(f"Error getting pool: {e}")
            return []
        
        async with pool.acquire() as conn:
            # –ù–∞—Ö–æ–¥–∏–º –≤—ã—Å–æ–∫–æ–ª–∏–∫–≤–∏–¥–Ω—ã–µ –∑–Ω–∞–Ω–∏—è
            knowledge_candidates = await conn.fetch("""
                SELECT 
                    k.id,
                    k.content,
                    k.usage_count,
                    k.confidence_score,
                    d.name as domain,
                    (k.usage_count * k.confidence_score) as liquidity_score,
                    k.metadata->>'expert' as expert,
                    k.metadata->>'implemented' as implemented,
                    k.created_at
                FROM knowledge_nodes k
                JOIN domains d ON k.domain_id = d.id
                WHERE k.usage_count >= $1
                AND (k.metadata->>'implemented' IS NULL OR k.metadata->>'implemented' = 'false')
                ORDER BY (k.usage_count * k.confidence_score) DESC, k.usage_count DESC
                LIMIT $2
            """, MIN_USAGE_COUNT, TOP_N_FOR_ANALYSIS)
            
            candidates = []
            for kn in knowledge_candidates:
                liquidity_score = float(kn['liquidity_score'] or 0)
                if liquidity_score >= MIN_LIQUIDITY_FOR_TASK:
                    candidates.append({
                        "id": str(kn['id']),
                        "content": kn['content'],
                        "usage_count": kn['usage_count'],
                        "confidence_score": kn['confidence_score'],
                        "domain": kn['domain'],
                        "liquidity_score": liquidity_score,
                        "expert": kn['expert'],
                        "created_at": kn['created_at']
                    })
            
        try:
            await pool.close()
        except:
            pass
        return candidates
    
    async def create_task_for_knowledge(self, knowledge: Dict) -> Optional[str]:
        """
        –°–æ–∑–¥–∞–µ—Ç –∑–∞–¥–∞—á—É –¥–ª—è –≤–Ω–µ–¥—Ä–µ–Ω–∏—è/—É–ª—É—á—à–µ–Ω–∏—è –∑–Ω–∞–Ω–∏—è.
        
        Args:
            knowledge: –î–∞–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        
        Returns:
            ID —Å–æ–∑–¥–∞–Ω–Ω–æ–π –∑–∞–¥–∞—á–∏ –∏–ª–∏ None
        """
        try:
            pool = await self.get_pool()
        except Exception as e:
            logger.error(f"Error getting pool: {e}")
            return None
        
        async with pool.acquire() as conn:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å–æ–∑–¥–∞–Ω–∞ –ª–∏ —É–∂–µ –∑–∞–¥–∞—á–∞ –¥–ª—è —ç—Ç–æ–≥–æ –∑–Ω–∞–Ω–∏—è
            existing_task = await conn.fetchval("""
                SELECT id FROM tasks
                WHERE metadata->>'knowledge_node_id' = $1
                AND status IN ('pending', 'in_progress')
                LIMIT 1
            """, knowledge['id'])
            
            if existing_task:
                logger.debug(f"Task already exists for knowledge {knowledge['id']}")
                try:
                    await pool.close()
                except:
                    pass
                return None
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–æ–º–µ–Ω
            domain_id = await conn.fetchval("SELECT id FROM domains WHERE name = $1", knowledge['domain'])
            if not domain_id:
                domain_id = await conn.fetchval("SELECT id FROM domains ORDER BY id LIMIT 1")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —ç–∫—Å–ø–µ—Ä—Ç–∞ –¥–ª—è –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –∑–∞–¥–∞—á–∏
            assignee_id = None
            if knowledge['expert']:
                assignee_id = await conn.fetchval("SELECT id FROM experts WHERE name = $1", knowledge['expert'])
            
            if not assignee_id:
                # –ë–µ—Ä–µ–º —ç–∫—Å–ø–µ—Ä—Ç–∞ –¥–æ–º–µ–Ω–∞
                assignee = await conn.fetchrow("""
                    SELECT id FROM experts 
                    WHERE department = $1
                    ORDER BY RANDOM() 
                    LIMIT 1
                """, knowledge['domain'])
                assignee_id = assignee['id'] if assignee else None
            
            if not assignee_id:
                # –ë–µ—Ä–µ–º –í–∏–∫—Ç–æ—Ä–∏—è–∏—é –∫–∞–∫ –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤–∞—Ä–∏–∞–Ω—Ç
                assignee_id = await conn.fetchval("SELECT id FROM experts WHERE name = '–í–∏–∫—Ç–æ—Ä–∏—è'")
            
            # –ù–∞—Ö–æ–¥–∏–º —Å–æ–∑–¥–∞—Ç–µ–ª—è –∑–∞–¥–∞—á–∏
            creator_id = await conn.fetchval("SELECT id FROM experts WHERE name = '–í–∏–∫—Ç–æ—Ä–∏—è'")
            if not creator_id:
                creator_id = assignee_id
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
            priority = self.calculate_priority(knowledge['liquidity_score'], knowledge['usage_count'])
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º actionable insights
            insights = self.generate_actionable_insights(
                knowledge['content'],
                knowledge['usage_count'],
                knowledge['domain']
            )
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏
            task_title = f"üíé –í–Ω–µ–¥—Ä–∏—Ç—å: {knowledge['content'][:60]}..."
            
            actionable_text = "\n".join([f"- {insight}" for insight in insights])
            task_description = f"""–ü–æ–ø—É–ª—è—Ä–Ω–æ–µ –∑–Ω–∞–Ω–∏–µ —Ç—Ä–µ–±—É–µ—Ç –≤–Ω–µ–¥—Ä–µ–Ω–∏—è/—É–ª—É—á—à–µ–Ω–∏—è

–ú–µ—Ç—Ä–∏–∫–∏ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏:
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {knowledge['usage_count']} —Ä–∞–∑
- –õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å: {knowledge['liquidity_score']:.2f}
- Confidence: {knowledge['confidence_score']}

–î–æ–º–µ–Ω: {knowledge['domain']}

–ó–Ω–∞–Ω–∏–µ:
{knowledge['content'][:500]}...

–î–µ–π—Å—Ç–≤–∏—è:
{actionable_text}

–ò—Å—Ç–æ—á–Ω–∏–∫: –ê–Ω–∞–ª–∏–∑ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏ –∑–Ω–∞–Ω–∏–π (knowledge_node_id: {knowledge['id']})"""
            
            # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á—É
            task_id = await conn.fetchval("""
                INSERT INTO tasks (
                    title, description, status, priority,
                    assignee_expert_id, creator_expert_id, domain_id,
                    metadata
                )
                VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
                RETURNING id
            """, 
                task_title,
                task_description,
                'pending',
                priority,
                assignee_id,
                creator_id,
                domain_id,
                json.dumps({
                    "source": "liquidity_task_generator",
                    "knowledge_node_id": knowledge['id'],
                    "liquidity_score": knowledge['liquidity_score'],
                    "usage_count": knowledge['usage_count'],
                    "created_at": datetime.now(timezone.utc).isoformat()
                })
            )
            
            logger.info(f"‚úÖ Created task {task_id} for knowledge {knowledge['id']} (priority: {priority}, liquidity: {knowledge['liquidity_score']:.2f})")
            
            # –ü–æ–º–µ—á–∞–µ–º –∑–Ω–∞–Ω–∏–µ –∫–∞–∫ –∏–º–µ—é—â–µ–µ –∑–∞–¥–∞—á—É –¥–ª—è –≤–Ω–µ–¥—Ä–µ–Ω–∏—è
            try:
                await conn.execute("""
                    UPDATE knowledge_nodes
                    SET metadata = metadata || jsonb_build_object(
                        'task_created_for_implementation', true,
                        'task_id', $1,
                        'task_created_at', $2
                    )
                    WHERE id = $3
                """, str(task_id), datetime.now(timezone.utc).isoformat(), knowledge['id'])
            except Exception as e:
                logger.debug(f"Could not update metadata for knowledge {knowledge['id']}: {e}")
            
        try:
            await pool.close()
        except:
            pass
        return str(task_id)
    
    async def process_high_liquidity_knowledge(self) -> Dict[str, int]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—ã—Å–æ–∫–æ–ª–∏–∫–≤–∏–¥–Ω—ã–µ –∑–Ω–∞–Ω–∏—è –∏ —Å–æ–∑–¥–∞–µ—Ç –∑–∞–¥–∞—á–∏.
        
        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        stats = {
            "analyzed": 0,
            "tasks_created": 0,
            "skipped": 0,
            "errors": 0
        }
        
        try:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—ã—Å–æ–∫–æ–ª–∏–∫–≤–∏–¥–Ω—ã–µ –∑–Ω–∞–Ω–∏—è
            candidates = await self.analyze_high_liquidity_knowledge()
            stats["analyzed"] = len(candidates)
            
            logger.info(f"üìä Found {len(candidates)} high-liquidity knowledge candidates")
            
            for knowledge in candidates:
                try:
                    task_id = await self.create_task_for_knowledge(knowledge)
                    if task_id:
                        stats["tasks_created"] += 1
                    else:
                        stats["skipped"] += 1
                except Exception as e:
                    logger.error(f"‚ùå Error creating task for knowledge {knowledge['id']}: {e}")
                    stats["errors"] += 1
                    import traceback
                    traceback.print_exc()
        
        except Exception as e:
            logger.error(f"‚ùå Error processing high-liquidity knowledge: {e}")
            stats["errors"] += 1
            import traceback
            traceback.print_exc()
        
        return stats


async def process_liquidity_tasks():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—ã—Å–æ–∫–æ–ª–∏–∫–≤–∏–¥–Ω—ã—Ö –∑–Ω–∞–Ω–∏–π"""
    generator = LiquidityTaskGenerator()
    stats = await generator.process_high_liquidity_knowledge()
    
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏ –∑–Ω–∞–Ω–∏–π:")
    print(f"   –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {stats['analyzed']}")
    print(f"   –°–æ–∑–¥–∞–Ω–æ –∑–∞–¥–∞—á: {stats['tasks_created']}")
    print(f"   –ü—Ä–æ–ø—É—â–µ–Ω–æ: {stats['skipped']}")
    print(f"   –û—à–∏–±–æ–∫: {stats['errors']}")
    
    return stats


if __name__ == "__main__":
    asyncio.run(process_liquidity_tasks())

