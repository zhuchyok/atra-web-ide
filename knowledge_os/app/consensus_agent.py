"""
Consensus Agent - –ú–µ—Ö–∞–Ω–∏–∑–º –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞ –¥–ª—è –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º
–û—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ CONSENSAGENT (2025) –∏ Aegean (2025)
"""

import os
import asyncio
import logging
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timezone
from collections import Counter
from ai_core import FactExtractor, ContextSwapper

logger = logging.getLogger(__name__)

OLLAMA_URL = os.getenv('OLLAMA_BASE_URL', 'http://localhost:11434')


@dataclass
class AgentResponse:
    """–û—Ç–≤–µ—Ç –∞–≥–µ–Ω—Ç–∞"""
    agent_name: str
    response: str
    confidence: float = 0.5
    reasoning: Optional[str] = None
    timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))


@dataclass
class ConsensusResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞"""
    final_answer: str
    consensus_score: float
    agreement_level: float
    agent_responses: List[AgentResponse]
    sycophancy_detected: bool = False
    iterations: int = 0


class ConsensusAgent:
    """
    Consensus Agent - –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞ –º–µ–∂–¥—É –∞–≥–µ–Ω—Ç–∞–º–∏
    
    –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:
    1. Sycophancy mitigation (CONSENSAGENT)
    2. Quorum convergence (Aegean-style)
    3. Dynamic prompt refinement
    """
    
    def __init__(
        self,
        model_name: str = "phi3.5:3.8b",
        ollama_url: str = OLLAMA_URL,
        quorum_threshold: float = 0.67,  # 67% –¥–ª—è –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞
        max_iterations: int = 5
    ):
        self.model_name = model_name
        self.ollama_url = ollama_url
        self.quorum_threshold = quorum_threshold
        self.max_iterations = max_iterations
    
    async def reach_consensus(
        self,
        agents: List[str],
        question: str,
        initial_context: Optional[Dict] = None
    ) -> ConsensusResult:
        """
        –î–æ—Å—Ç–∏—á—å –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞ –º–µ–∂–¥—É –∞–≥–µ–Ω—Ç–∞–º–∏
        
        Args:
            agents: –°–ø–∏—Å–æ–∫ –∞–≥–µ–Ω—Ç–æ–≤
            question: –í–æ–ø—Ä–æ—Å –¥–ª—è –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞
            initial_context: –ù–∞—á–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞
        """
        logger.info(f"ü§ù –ù–∞—á–∏–Ω–∞—é –∫–æ–Ω—Å–µ–Ω—Å—É—Å –º–µ–∂–¥—É {len(agents)} –∞–≥–µ–Ω—Ç–∞–º–∏: {question[:80]}")
        
        agent_responses: List[AgentResponse] = []
        iterations = 0
        previous_responses: List[List[AgentResponse]] = []
        
        while iterations < self.max_iterations:
            iterations += 1
            logger.info(f"üîÑ –ò—Ç–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞ {iterations}/{self.max_iterations}")
            
            # 1. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç—ã –∞–≥–µ–Ω—Ç–æ–≤
            current_responses = await self._collect_responses(
                agents, question, initial_context, previous_responses
            )
            
            agent_responses = current_responses
            previous_responses.append(current_responses)
            
            # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º sycophancy
            sycophancy_detected = self._detect_sycophancy(current_responses)
            
            # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º quorum convergence (Aegean-style)
            consensus_reached, consensus_answer = self._check_quorum_convergence(
                current_responses
            )
            
            if consensus_reached:
                logger.info(f"‚úÖ –ö–æ–Ω—Å–µ–Ω—Å—É—Å –¥–æ—Å—Ç–∏–≥–Ω—É—Ç –Ω–∞ –∏—Ç–µ—Ä–∞—Ü–∏–∏ {iterations}")
                break
            
            # 4. –ï—Å–ª–∏ –Ω–µ—Ç –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞ –∏ –µ—Å—Ç—å sycophancy - —É—Ç–æ—á–Ω—è–µ–º –ø—Ä–æ–º–ø—Ç—ã
            if sycophancy_detected and iterations < self.max_iterations:
                logger.info("‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ sycophancy, —É—Ç–æ—á–Ω—è—é –ø—Ä–æ–º–ø—Ç—ã...")
                # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ —É—Ç–æ—á–Ω–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–æ–≤ (CONSENSAGENT)
                initial_context = await self._refine_prompts(
                    question, current_responses, initial_context
                )
        
        # 5. –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        final_answer, consensus_score = self._synthesize_final_answer(agent_responses)
        agreement_level = self._calculate_agreement_level(agent_responses)
        
        return ConsensusResult(
            final_answer=final_answer,
            consensus_score=consensus_score,
            agreement_level=agreement_level,
            agent_responses=agent_responses,
            sycophancy_detected=sycophancy_detected,
            iterations=iterations
        )
    
    async def _collect_responses(
        self,
        agents: List[str],
        question: str,
        context: Optional[Dict],
        previous_responses: List[List[AgentResponse]]
    ) -> List[AgentResponse]:
        """–°–æ–±—Ä–∞—Ç—å –æ—Ç–≤–µ—Ç—ã –æ—Ç –∞–≥–µ–Ω—Ç–æ–≤"""
        # [SINGULARITY 14.2] Pre-process history with FactExtractor if needed
        if previous_responses and sum(len(r.response) for round in previous_responses for r in round) > 3000:
            logger.info("‚úÇÔ∏è [CONSENSUS] History too long, extracting facts for next round...")
            extractor = FactExtractor()
            all_prev = "\n".join([f"{r.agent_name}: {r.response}" for round in previous_responses for r in round])
            summary = await extractor.extract_facts(all_prev, context_description="Consensus history")
            # –ó–∞–º–µ–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –Ω–∞ —Å—É–º–º–∞—Ä–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é (—É–ø—Ä–æ—â–µ–Ω–Ω–æ –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞)
            # –í —Ä–µ–∞–ª—å–Ω–æ–π –ª–æ–≥–∏–∫–µ –º–æ–∂–Ω–æ –±—ã–ª–æ –±—ã —Å–æ–∑–¥–∞—Ç—å —Ñ–∏–∫—Ç–∏–≤–Ω—ã–π —Ä–∞—É–Ω–¥ —Å summary
            context = context or {}
            context["history_summary"] = summary

        # –°—Ç—Ä–æ–∏–º –ø—Ä–æ–º–ø—Ç —Å —É—á–µ—Ç–æ–º –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤ (–¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è sycophancy)
        base_prompt = self._build_consensus_prompt(question, context, previous_responses)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        tasks = []
        for agent in agents:
            # –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
            agent_prompt = f"{base_prompt}\n\n–¢–´ - {agent}. –î–∞–π –°–í–û–ï –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ–µ –º–Ω–µ–Ω–∏–µ, –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–π –¥—Ä—É–≥–∏—Ö."
            task = self._generate_agent_response(agent, agent_prompt)
            tasks.append(task)
        
        responses = await asyncio.gather(*tasks, return_exceptions=True)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º AgentResponse –æ–±—ä–µ–∫—Ç—ã
        agent_responses = []
        for agent, response in zip(agents, responses):
            if isinstance(response, Exception):
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—Ç–≤–µ—Ç–∞ –æ—Ç {agent}: {response}")
                continue
            
            agent_response = AgentResponse(
                agent_name=agent,
                response=response.get("response", ""),
                confidence=response.get("confidence", 0.5),
                reasoning=response.get("reasoning")
            )
            agent_responses.append(agent_response)
        
        return agent_responses
    
    def _detect_sycophancy(self, responses: List[AgentResponse]) -> bool:
        """–û–±–Ω–∞—Ä—É–∂–∏—Ç—å sycophancy (–ø–æ–¥–¥–∞–∫–∏–≤–∞–Ω–∏–µ)"""
        if len(responses) < 2:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Å–ª–∏—à–∫–æ–º –ø–æ—Ö–æ–∂–∏–µ –æ—Ç–≤–µ—Ç—ã
        response_texts = [r.response.lower().strip() for r in responses]
        
        # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ –æ—Ç–≤–µ—Ç—ã —Å–ª–∏—à–∫–æ–º –ø–æ—Ö–æ–∂–∏ (>80% —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)
        similarities = []
        for i, resp1 in enumerate(response_texts):
            for j, resp2 in enumerate(response_texts[i+1:], i+1):
                similarity = self._calculate_similarity(resp1, resp2)
                similarities.append(similarity)
        
        if similarities:
            avg_similarity = sum(similarities) / len(similarities)
            # –ï—Å–ª–∏ —Å—Ä–µ–¥–Ω—è—è –ø–æ—Ö–æ–∂–µ—Å—Ç—å > 0.8 - –≤–æ–∑–º–æ–∂–Ω–∞ sycophancy
            return avg_similarity > 0.8
        
        return False
    
    def _check_quorum_convergence(
        self,
        responses: List[AgentResponse]
    ) -> Tuple[bool, Optional[str]]:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å quorum convergence (Aegean-style)"""
        if not responses:
            return False, None
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ—Ö–æ–∂–∏–µ –æ—Ç–≤–µ—Ç—ã
        answer_groups = {}
        for resp in responses:
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ—Ç–≤–µ—Ç –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
            normalized = self._normalize_answer(resp.response)
            
            if normalized not in answer_groups:
                answer_groups[normalized] = []
            answer_groups[normalized].append(resp)
        
        # –ù–∞—Ö–æ–¥–∏–º –≥—Ä—É–ø–ø—É —Å –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ–º
        max_group_size = max(len(group) for group in answer_groups.values())
        total_agents = len(responses)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º quorum threshold
        if max_group_size / total_agents >= self.quorum_threshold:
            # –ù–∞—Ö–æ–¥–∏–º –æ—Ç–≤–µ—Ç –≥—Ä—É–ø–ø—ã –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞
            for normalized, group in answer_groups.items():
                if len(group) == max_group_size:
                    # –ë–µ—Ä–µ–º –æ—Ç–≤–µ—Ç —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
                    best_response = max(group, key=lambda r: r.confidence)
                    return True, best_response.response
        
        return False, None
    
    async def _refine_prompts(
        self,
        question: str,
        responses: List[AgentResponse],
        context: Optional[Dict]
    ) -> Dict:
        """–£—Ç–æ—á–Ω–∏—Ç—å –ø—Ä–æ–º–ø—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π (CONSENSAGENT)"""
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç—ã –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É—Ç–æ—á–Ω–µ–Ω–∏—è
        prompt = f"""–ù–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤ –∞–≥–µ–Ω—Ç–æ–≤, —Å–æ–∑–¥–∞–π —É—Ç–æ—á–Ω–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –≥—Ä—É–ø–ø–æ–≤–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è:

–í–û–ü–†–û–°: {question}

–û–¢–í–ï–¢–´ –ê–ì–ï–ù–¢–û–í:
"""
        for i, resp in enumerate(responses, 1):
            prompt += f"\n{i}. {resp.agent_name}: {resp.response[:200]}\n"
        
        prompt += """
–°–æ–∑–¥–∞–π —É—Ç–æ—á–Ω–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç, –∫–æ—Ç–æ—Ä—ã–π:
1. –ü–æ–æ—â—Ä—è–µ—Ç –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ–µ –º—ã—à–ª–µ–Ω–∏–µ
2. –¢—Ä–µ–±—É–µ—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
3. –ò–∑–±–µ–≥–∞–µ—Ç –ø—Ä–æ—Å—Ç–æ–≥–æ —Å–æ–≥–ª–∞—Å–∏—è —Å –¥—Ä—É–≥–∏–º–∏

–£–¢–û–ß–ù–ï–ù–ù–´–ô –ü–†–û–ú–ü–¢:"""
        
        refined = await self._generate_response(prompt)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        if context is None:
            context = {}
        
        context["refined_prompt"] = refined
        context["anti_sycophancy"] = True
        
        return context
    
    def _synthesize_final_answer(self, responses: List[AgentResponse]) -> Tuple[str, float]:
        """–°–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç"""
        if not responses:
            return "–ù–µ—Ç –æ—Ç–≤–µ—Ç–æ–≤", 0.0
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –ø–æ—Ö–æ–∂–µ—Å—Ç–∏
        answer_groups = {}
        for resp in responses:
            normalized = self._normalize_answer(resp.response)
            if normalized not in answer_groups:
                answer_groups[normalized] = []
            answer_groups[normalized].append(resp)
        
        # –í—ã–±–∏—Ä–∞–µ–º –≥—Ä—É–ø–ø—É –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞
        largest_group = max(answer_groups.values(), key=len)
        
        # –ë–µ—Ä–µ–º –æ—Ç–≤–µ—Ç —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
        best_response = max(largest_group, key=lambda r: r.confidence)
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º consensus score
        consensus_score = len(largest_group) / len(responses)
        
        return best_response.response, consensus_score
    
    def _calculate_agreement_level(self, responses: List[AgentResponse]) -> float:
        """–†–∞—Å—Å—á–∏—Ç–∞—Ç—å —É—Ä–æ–≤–µ–Ω—å —Å–æ–≥–ª–∞—Å–∏—è"""
        if len(responses) < 2:
            return 1.0
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç—ã
        answer_groups = {}
        for resp in responses:
            normalized = self._normalize_answer(resp.response)
            if normalized not in answer_groups:
                answer_groups[normalized] = 0
            answer_groups[normalized] += 1
        
        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥—Ä—É–ø–ø–∞
        max_group_size = max(answer_groups.values())
        agreement = max_group_size / len(responses)
        
        return agreement
    
    def _build_consensus_prompt(
        self,
        question: str,
        context: Optional[Dict],
        previous_responses: List[List[AgentResponse]]
    ) -> str:
        """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –ø—Ä–æ–º–ø—Ç –¥–ª—è –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞"""
        # [SINGULARITY 14.2] Use FactExtractor for previous responses to save context
        history_text = ""
        if previous_responses:
            history_text = "–ü–†–ï–î–´–î–£–©–ò–ï –û–¢–í–ï–¢–´ (–¥–ª—è —Å–ø—Ä–∞–≤–∫–∏, –ù–ï –ø–æ–≤—Ç–æ—Ä—è–π –∏—Ö):\n"
            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –æ—Ç–≤–µ—Ç—ã –≤ –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç
            all_prev = ""
            for round_responses in previous_responses:
                for resp in round_responses:
                    all_prev += f"- {resp.agent_name}: {resp.response}\n"
            
            # –ï—Å–ª–∏ –∏—Å—Ç–æ—Ä–∏—è —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∞—è, —Å–∂–∏–º–∞–µ–º –µ—ë
            if len(all_prev) > 2000:
                import asyncio
                extractor = FactExtractor()
                # –í —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–º –º–µ—Ç–æ–¥–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º loop.run_until_complete –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ –æ–±—Ä–µ–∑–∞–µ–º, 
                # –Ω–æ –ª—É—á—à–µ —Å–¥–µ–ª–∞—Ç—å –º–µ—Ç–æ–¥ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–º –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ-–æ–±—Ä–∞–±–æ—Ç–∫—É.
                # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –∑–¥–µ—Å—å –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—Ä–µ–∑–∫—É + –ø–æ–º–µ—Ç–∫—É, —Ç–∞–∫ –∫–∞–∫ _build_consensus_prompt –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –∏–∑ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ _collect_responses
                history_text += "[–°–ñ–ê–¢–û] " + all_prev[:1000] + "..."
            else:
                history_text += all_prev

        prompt = f"""–¢—ã —É—á–∞—Å—Ç–≤—É–µ—à—å –≤ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–∏ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞ –ø–æ —Å–ª–µ–¥—É—é—â–µ–º—É –≤–æ–ø—Ä–æ—Å—É:

–í–û–ü–†–û–°: {question}

"""
        
        if context:
            prompt += f"–ö–û–ù–¢–ï–ö–°–¢: {context}\n\n"
        
        if history_text:
            prompt += history_text + "\n"
        
        prompt += """–í–ê–ñ–ù–û:
- –î–∞–π –°–í–û–ï –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ–µ –º–Ω–µ–Ω–∏–µ
- –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –≤–æ–ø—Ä–æ—Å
- –ù–ï –ø—Ä–æ—Å—Ç–æ —Å–æ–≥–ª–∞—à–∞–π—Å—è —Å –¥—Ä—É–≥–∏–º–∏
- –û–±–æ—Å–Ω—É–π —Å–≤–æ–π –æ—Ç–≤–µ—Ç

–¢–í–û–ô –û–¢–í–ï–¢:"""
        
        return prompt
    
    def _normalize_answer(self, answer: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        # –ü—Ä–æ—Å—Ç–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è: lowercase, —É–±—Ä–∞—Ç—å –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é, –ø–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤
        normalized = answer.lower().strip()
        # –£–±–∏—Ä–∞–µ–º –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        import re
        normalized = re.sub(r'[^\w\s]', '', normalized)
        return normalized[:100]
    
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """–†–∞—Å—Å—á–∏—Ç–∞—Ç—å –ø–æ—Ö–æ–∂–µ—Å—Ç—å –¥–≤—É—Ö —Ç–µ–∫—Å—Ç–æ–≤"""
        # –ü—Ä–æ—Å—Ç–∞—è –º–µ—Ç—Ä–∏–∫–∞: Jaccard similarity
        words1 = set(text1.split())
        words2 = set(text2.split())
        
        if not words1 and not words2:
            return 1.0
        
        intersection = len(words1 & words2)
        union = len(words1 | words2)
        
        return intersection / union if union > 0 else 0.0

    @staticmethod
    def _confidence_from_response_length(response: str) -> float:
        """
        –û—Ü–µ–Ω–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –ø–æ –¥–ª–∏–Ω–µ –æ—Ç–≤–µ—Ç–∞ (—ç–≤—Ä–∏—Å—Ç–∏–∫–∞).
        –ü—É—Å—Ç–æ–π/–æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç ‚Äî –Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å, —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—ã–π ‚Äî –≤—ã—à–µ.
        """
        if not response or not response.strip():
            return 0.0
        n = len(response.strip())
        if n < 20:
            return 0.25
        if n < 100:
            return 0.4
        if n < 300:
            return 0.55
        if n < 600:
            return 0.7
        if n < 1200:
            return 0.82
        return min(0.95, 0.82 + (n - 1200) / 8000)
    
    async def _generate_agent_response(self, agent_name: str, prompt: str) -> Dict:
        """–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç –∞–≥–µ–Ω—Ç–∞"""
        import httpx
        
        try:
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.post(
                    f"{self.ollama_url}/api/generate",
                    json={
                        "model": self.model_name,
                        "prompt": prompt,
                        "stream": False,
                        "options": {
                            "temperature": 0.7,
                            "num_predict": 1024
                        }
                    }
                )
                
                if response.status_code == 200:
                    result = response.json().get('response', '')
                    confidence = self._confidence_from_response_length(result)
                    return {
                        "response": result,
                        "confidence": confidence,
                        "reasoning": None
                    }
                else:
                    return {"response": "", "confidence": 0.0}
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            return {"response": "", "confidence": 0.0}
    
    async def _generate_response(self, prompt: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å"""
        import httpx
        
        try:
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.post(
                    f"{self.ollama_url}/api/generate",
                    json={
                        "model": self.model_name,
                        "prompt": prompt,
                        "stream": False
                    }
                )
                
                if response.status_code == 200:
                    return response.json().get('response', '')
                else:
                    return ""
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
            return ""


async def main():
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
    consensus = ConsensusAgent(quorum_threshold=0.67)
    try:
        from app.expert_services import get_all_expert_names
        agents = get_all_expert_names(max_count=10)
    except ImportError:
        agents = ["–í–∏–∫—Ç–æ—Ä–∏—è", "–í–µ—Ä–æ–Ω–∏–∫–∞", "–ò–≥–æ—Ä—å", "–°–µ—Ä–≥–µ–π", "–î–º–∏—Ç—Ä–∏–π"]
    
    result = await consensus.reach_consensus(
        agents=agents,
        question="–ö–∞–∫–æ–π –ª—É—á—à–∏–π –ø–æ–¥—Ö–æ–¥ –∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö?"
    )
    
    print("–†–µ–∑—É–ª—å—Ç–∞—Ç –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞:")
    print(f"  –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç: {result.final_answer[:200]}...")
    print(f"  Consensus score: {result.consensus_score:.2f}")
    print(f"  Agreement level: {result.agreement_level:.2f}")
    print(f"  Sycophancy detected: {result.sycophancy_detected}")
    print(f"  Iterations: {result.iterations}")


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    asyncio.run(main())
