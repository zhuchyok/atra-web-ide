#!/usr/bin/env python3
"""
–ú–æ–¥—É–ª—å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–µ–±–∞—Ç–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–¥–∞—á –¥–ª—è –≤–Ω–µ–¥—Ä–µ–Ω–∏—è.
–ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –∑–Ω–∞–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–µ–±–∞—Ç–æ–≤.
–£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ –≤–∞–∂–Ω—ã—Ö –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞—Ö.
"""
import asyncio
import os
import re
import json
import asyncpg
from datetime import datetime, timezone
from typing import List, Dict, Optional, Tuple
import logging

logger = logging.getLogger(__name__)

DB_URL = os.getenv("DATABASE_URL", "postgresql://admin:secret@localhost:5432/knowledge_os")

# –ü–æ—Ä–æ–≥–∏ –¥–ª—è –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤
PRIORITY_THRESHOLDS = {
    "urgent": 0.9,  # –ï—Å–ª–∏ 90% —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ —Å–æ–≥–ª–∞—Å–Ω—ã - —Å—Ä–æ—á–Ω–æ
    "high": 0.75,   # 75% —Å–æ–≥–ª–∞—Å–Ω—ã - –≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
    "medium": 0.6,  # 60% —Å–æ–≥–ª–∞—Å–Ω—ã - —Å—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
    "low": 0.4      # 40% —Å–æ–≥–ª–∞—Å–Ω—ã - –Ω–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
}

# –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π consensus_score –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–¥–∞—á–∏ (—Å–Ω–∏–∂–µ–Ω –¥–ª—è –±–æ–ª–µ–µ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–¥–∞—á)
MIN_CONSENSUS_FOR_TASK = 0.5

# –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π consensus_score –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
MIN_CONSENSUS_FOR_NOTIFICATION = 0.75


class DebateProcessor:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–µ–±–∞—Ç–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤"""
    
    def __init__(self, db_url: str = None):
        self.db_url = db_url
    
    async def get_pool(self):
        """–ü–æ–ª—É—á–∏—Ç—å –ø—É–ª –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π –∫ –ë–î (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ—Ç –∂–µ –º–µ—Ç–æ–¥, —á—Ç–æ –∏ evaluator)"""
        if self.db_url:
            return await asyncpg.create_pool(self.db_url, min_size=1, max_size=3)
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º get_pool –∏–∑ evaluator –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            from evaluator import get_pool
            pool = await get_pool()
            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –ø—É–ª –ø—Ä–∞–≤–∏–ª—å–Ω–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω
            return pool
    
    async def analyze_debate_consensus(self, debate_id: str) -> Optional[Dict]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–Ω—Å–µ–Ω—Å—É—Å –≤ –¥–µ–±–∞—Ç–µ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏.
        
        Returns:
            Dict —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏: consensus_score, priority, actionable_insights
        """
        pool = await self.get_pool()
        async with pool.acquire() as conn:
            debate = await conn.fetchrow("""
                SELECT id, knowledge_node_id, expert_ids, topic, consensus_summary, created_at
                FROM expert_discussions
                WHERE id = $1
            """, debate_id)
            
            if not debate:
                return None
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º consensus_summary
            consensus_text = debate['consensus_summary'] or ""
            
            # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –≤ –¥–µ–±–∞—Ç–µ
            expert_count = len(debate['expert_ids']) if debate['expert_ids'] else 2
            
            # –ë–∞–∑–æ–≤—ã–π score –æ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ)
            expert_score = min(expert_count / 3.0, 1.0)  # –ú–∞–∫—Å–∏–º—É–º 3 —ç–∫—Å–ø–µ—Ä—Ç–∞ = 1.0
            
            # Score –æ—Ç –¥–ª–∏–Ω—ã –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞ (—á–µ–º –±–æ–ª—å—à–µ, —Ç–µ–º –ª—É—á—à–µ –æ–±—Å—É–∂–¥–µ–Ω–∏–µ)
            consensus_length = len(consensus_text)
            length_score = min(consensus_length / 500.0, 0.4)  # –ú–∞–∫—Å–∏–º—É–º 0.4 –∑–∞ –¥–ª–∏–Ω—É (500+ —Å–∏–º–≤–æ–ª–æ–≤)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –±–æ–Ω—É—Å –µ—Å–ª–∏ –∫–æ–Ω—Å–µ–Ω—Å—É—Å —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ —Å–ª–æ–≤–∞
            positive_indicators = ['—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è', '–≤–∞–∂–Ω–æ', '–∫—Ä–∏—Ç–∏—á–Ω–æ', '–Ω–µ–æ–±—Ö–æ–¥–∏–º–æ', '—Å—Ä–æ—á–Ω–æ', '–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç', 
                                 '—Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å', '–≤–Ω–µ–¥—Ä–∏—Ç—å', '—Å–æ–∑–¥–∞—Ç—å', '—Ä–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å', '–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å', '—É–ª—É—á—à–∏—Ç—å']
            positive_bonus = 0.0
            if any(indicator in consensus_text.lower() for indicator in positive_indicators):
                positive_bonus = 0.2
            
            # –ë–æ–Ω—É—Å –∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å (–Ω–∞–ª–∏—á–∏–µ –º–∞—Ä–∫–µ—Ä–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤)
            structure_bonus = 0.0
            if 'üßê' in consensus_text or '**' in consensus_text or len(consensus_text.split('\n\n')) > 2:
                structure_bonus = 0.1
            
            # –ò—Ç–æ–≥–æ–≤—ã–π score (–±–æ–ª–µ–µ –≥–∏–±–∫–∏–π)
            base_score = min(expert_score + length_score + positive_bonus + structure_bonus, 1.0)
            
            # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π score –¥–ª—è –¥–µ–±–∞—Ç–æ–≤ —Å —Ö–æ—Ä–æ—à–∏–º –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º
            if consensus_length > 200 and expert_count >= 2:
                base_score = max(base_score, 0.5)  # –ú–∏–Ω–∏–º—É–º 0.5 –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–µ–±–∞—Ç–æ–≤
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
            priority = "low"
            if base_score >= PRIORITY_THRESHOLDS["urgent"]:
                priority = "urgent"
            elif base_score >= PRIORITY_THRESHOLDS["high"]:
                priority = "high"
            elif base_score >= PRIORITY_THRESHOLDS["medium"]:
                priority = "medium"
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º actionable insights
            actionable_insights = self._extract_actionable_insights(consensus_text)
            
            return {
                "debate_id": str(debate['id']),
                "knowledge_node_id": str(debate['knowledge_node_id']) if debate['knowledge_node_id'] else None,
                "consensus_score": base_score,
                "priority": priority,
                "expert_count": expert_count,
                "actionable_insights": actionable_insights,
                "topic": debate['topic'],
                "consensus_summary": consensus_text
            }
    
    def _extract_actionable_insights(self, consensus_text: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç actionable insights –∏–∑ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞ (Singularity 10.0: —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π Prompt Engineer)"""
        insights = []
        seen = set()

        # –ì–ª–∞–≥–æ–ª—ã –¥–µ–π—Å—Ç–≤–∏—è (—Ä—É—Å—Å–∫–∏–π + –∞–Ω–≥–ª–∏–π—Å–∫–∏–π)
        action_verbs = [
            '—Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å', '–≤–Ω–µ–¥—Ä–∏—Ç—å', '—Å–æ–∑–¥–∞—Ç—å', '—Ä–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å', '–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å', '—É–ª—É—á—à–∏—Ç—å', '–¥–æ–±–∞–≤–∏—Ç—å',
            '–≤–Ω–µ–¥—Ä—è—Ç—å', '—Å–æ–∑–¥–∞–≤–∞—Ç—å', '—Ä–∞–∑—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å', '–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å', '—É–ª—É—á—à–∞—Ç—å', '–¥–æ–±–∞–≤–ª—è—Ç—å',
            '—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è', '—Å–ª–µ–¥—É–µ—Ç', '–Ω–µ–æ–±—Ö–æ–¥–∏–º–æ', '–Ω—É–∂–Ω–æ', '–≤–∞–∂–Ω–æ',
            'implement', 'create', 'add', 'improve', 'optimize', 'develop', 'recommend'
        ]
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è actionable —Ñ—Ä–∞–∑
        action_patterns = ['‚Üí', '->', ':', '‚Äî', '‚Ä¢', '- ', '1.', '2.', '—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è', 'action', 'task']

        def normalize(s: str) -> str:
            return s.strip()[:500]

        sentences = re.split(r'[.!?\n]+', consensus_text)
        for sentence in sentences:
            s = sentence.strip()
            if len(s) < 20:
                continue
            s_lower = s.lower()
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–ª–∞–≥–æ–ª–æ–≤ –¥–µ–π—Å—Ç–≤–∏—è
            if any(verb in s_lower for verb in action_verbs):
                n = normalize(s)
                if n and n not in seen:
                    seen.add(n)
                    insights.append(n)
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ (—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, —Å–ø–∏—Å–∫–∏)
            elif any(p in s_lower for p in action_patterns) and len(s) > 30:
                n = normalize(s)
                if n and n not in seen:
                    seen.add(n)
                    insights.append(n)

        return insights[:5]  # –ú–∞–∫—Å–∏–º—É–º 5 –∏–Ω—Å–∞–π—Ç–æ–≤ (—Ä–∞—Å—à–∏—Ä–µ–Ω–æ —Å 3)
    
    async def create_task_from_debate(self, debate_id: str, analysis: Dict) -> Optional[str]:
        """
        –°–æ–∑–¥–∞–µ—Ç –∑–∞–¥–∞—á—É –¥–ª—è –≤–Ω–µ–¥—Ä–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–µ–±–∞—Ç–∞.
        
        Returns:
            ID —Å–æ–∑–¥–∞–Ω–Ω–æ–π –∑–∞–¥–∞—á–∏ –∏–ª–∏ None
        """
        if analysis['consensus_score'] < MIN_CONSENSUS_FOR_TASK:
            logger.info(f"Debate {debate_id} consensus_score too low ({analysis['consensus_score']:.2f}), skipping task creation")
            return None
        
        pool = await self.get_pool()
        async with pool.acquire() as conn:
            # –ü–æ–ª—É—á–∞–µ–º –∑–Ω–∞–Ω–∏–µ, —Å–≤—è–∑–∞–Ω–Ω–æ–µ —Å –¥–µ–±–∞—Ç–æ–º
            knowledge = None
            if analysis['knowledge_node_id']:
                knowledge = await conn.fetchrow("""
                    SELECT id, content, domain_id, metadata
                    FROM knowledge_nodes
                    WHERE id = $1
                """, analysis['knowledge_node_id'])
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–æ–º–µ–Ω –∑–∞–¥–∞—á–∏
            domain_id = knowledge['domain_id'] if knowledge else None
            if not domain_id:
                domain_id = await conn.fetchval("SELECT id FROM domains WHERE name = 'General' LIMIT 1")
                if not domain_id:
                    domain_id = await conn.fetchval("SELECT id FROM domains ORDER BY id LIMIT 1")
            
            # –ù–∞—Ö–æ–¥–∏–º —ç–∫—Å–ø–µ—Ä—Ç–∞ –¥–ª—è –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –∑–∞–¥–∞—á–∏
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞ –∏–∑ –¥–µ–±–∞—Ç–∞ –∏–ª–∏ —ç–∫—Å–ø–µ—Ä—Ç–∞, —Å–æ–∑–¥–∞–≤—à–µ–≥–æ –∑–Ω–∞–Ω–∏–µ
            assignee_id = None
            if analysis['knowledge_node_id'] and knowledge:
                original_expert = knowledge.get('metadata', {}).get('expert')
                if original_expert:
                    try:
                        from app.expert_aliases import resolve_expert_name_for_db
                        resolved_expert = resolve_expert_name_for_db(original_expert)
                    except ImportError:
                        resolved_expert = original_expert
                    assignee_id = await conn.fetchval("SELECT id FROM experts WHERE name = $1", resolved_expert)
            
            if not assignee_id:
                # –ë–µ—Ä–µ–º —ç–∫—Å–ø–µ—Ä—Ç–∞ –¥–æ–º–µ–Ω–∞
                assignee = await conn.fetchrow("""
                    SELECT id FROM experts 
                    WHERE department = (SELECT name FROM domains WHERE id = $1)
                    ORDER BY RANDOM() 
                    LIMIT 1
                """, domain_id)
                assignee_id = assignee['id'] if assignee else None
            
            if not assignee_id:
                # –ë–µ—Ä–µ–º –í–∏–∫—Ç–æ—Ä–∏—è–∏—é –∫–∞–∫ –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤–∞—Ä–∏–∞–Ω—Ç
                assignee_id = await conn.fetchval("SELECT id FROM experts WHERE name = '–í–∏–∫—Ç–æ—Ä–∏—è'")
            
            # –ù–∞—Ö–æ–¥–∏–º —Å–æ–∑–¥–∞—Ç–µ–ª—è –∑–∞–¥–∞—á–∏ (–í–∏–∫—Ç–æ—Ä–∏—è)
            creator_id = await conn.fetchval("SELECT id FROM experts WHERE name = '–í–∏–∫—Ç–æ—Ä–∏—è'")
            if not creator_id:
                creator_id = assignee_id
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏
            task_title = f"üí° –í–Ω–µ–¥—Ä–∏—Ç—å: {analysis['topic'][:60]}"
            
            actionable_text = "\n".join([f"- {insight}" for insight in analysis['actionable_insights']])
            task_description = f"""–ö–æ–Ω—Å–µ–Ω—Å—É—Å —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ (score: {analysis['consensus_score']:.2f}, priority: {analysis['priority']})

–ö–æ–Ω—Å–µ–Ω—Å—É—Å:
{analysis['consensus_summary']}

–î–µ–π—Å—Ç–≤–∏—è –¥–ª—è –≤–Ω–µ–¥—Ä–µ–Ω–∏—è:
{actionable_text if actionable_text else '–¢—Ä–µ–±—É–µ—Ç—Å—è –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞ –∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –ø–ª–∞–Ω–∞ –≤–Ω–µ–¥—Ä–µ–Ω–∏—è.'}

–ò—Å—Ç–æ—á–Ω–∏–∫: –î–µ–±–∞—Ç —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ (debate_id: {debate_id})"""
            
            # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á—É
            task_id = await conn.fetchval("""
                INSERT INTO tasks (
                    title, description, status, priority,
                    assignee_expert_id, creator_expert_id, domain_id,
                    metadata
                )
                VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
                RETURNING id
            """, 
                task_title,
                task_description,
                'pending',
                analysis['priority'],
                assignee_id,
                creator_id,
                domain_id,
                json.dumps({
                    "source": "debate_processor",
                    "debate_id": debate_id,
                    "knowledge_node_id": analysis['knowledge_node_id'],
                    "consensus_score": analysis['consensus_score'],
                    "created_at": datetime.now(timezone.utc).isoformat()
                })
            )
            
            logger.info(f"‚úÖ Created task {task_id} from debate {debate_id} (priority: {analysis['priority']})")
            return str(task_id)
    
    async def prioritize_knowledge_from_debate(self, debate_id: str, analysis: Dict) -> bool:
        """
        –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä—É–µ—Ç –∑–Ω–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–µ–±–∞—Ç–∞.
        –û–±–Ω–æ–≤–ª—è–µ—Ç priority –≤ knowledge_nodes.
        
        Returns:
            True –µ—Å–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ
        """
        if not analysis['knowledge_node_id']:
            return False
        
        pool = await self.get_pool()
        async with pool.acquire() as conn:
            # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º –∏–∑ –¥–µ–±–∞—Ç–∞
            await conn.execute("""
                UPDATE knowledge_nodes
                SET metadata = metadata || jsonb_build_object(
                    'debate_priority', $1::text,
                    'debate_consensus_score', $2::numeric,
                    'debate_id', $3::text,
                    'prioritized_at', $4::text
                )
                WHERE id = $5::uuid
            """, 
                str(analysis['priority']),
                float(analysis['consensus_score']),
                str(debate_id),
                datetime.now(timezone.utc).isoformat(),
                str(analysis['knowledge_node_id'])
            )
            
            logger.info(f"‚úÖ Prioritized knowledge {analysis['knowledge_node_id']} from debate {debate_id} (priority: {analysis['priority']})")
            return True
    
    async def send_notification_for_important_consensus(self, debate_id: str, analysis: Dict) -> bool:
        """
        –°–æ–∑–¥–∞–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –≤–∞–∂–Ω–æ–º –∫–æ–Ω—Å–µ–Ω—Å—É—Å–µ.
        
        Returns:
            True –µ—Å–ª–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–æ
        """
        if analysis['consensus_score'] < MIN_CONSENSUS_FOR_NOTIFICATION:
            return False
        
        pool = await self.get_pool()
        async with pool.acquire() as conn:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ—Ç –ª–∏ —É–∂–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –¥–ª—è —ç—Ç–æ–≥–æ –¥–µ–±–∞—Ç–∞
            # –ï—Å–ª–∏ –µ—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∞ metadata, –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ –Ω–µ–π
            has_metadata = await conn.fetchval("""
                SELECT EXISTS (
                    SELECT 1 FROM information_schema.columns 
                    WHERE table_name = 'notifications' 
                    AND column_name = 'metadata'
                )
            """)
            
            if has_metadata:
                existing = await conn.fetchval("""
                    SELECT COUNT(*) FROM notifications
                    WHERE metadata->>'debate_id' = $1
                """, debate_id)
            else:
                # –ï—Å–ª–∏ metadata –Ω–µ—Ç, –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ —Å–æ–æ–±—â–µ–Ω–∏—é
                existing = await conn.fetchval("""
                    SELECT COUNT(*) FROM notifications
                    WHERE message LIKE $1
                """, f"%debate_id: {debate_id}%")
            
            if existing > 0:
                return False  # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ
            
            # –°–æ–∑–¥–∞–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
            notification_message = f"""üéØ –í–ê–ñ–ù–´–ô –ö–û–ù–°–ï–ù–°–£–° –≠–ö–°–ü–ï–†–¢–û–í

–¢–µ–º–∞: {analysis['topic']}

–ö–æ–Ω—Å–µ–Ω—Å—É—Å (score: {analysis['consensus_score']:.2f}, –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {analysis['priority']}):
{analysis['consensus_summary'][:300]}...

üí° –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Å–æ–∑–¥–∞—Ç—å –∑–∞–¥–∞—á—É –¥–ª—è –≤–Ω–µ–¥—Ä–µ–Ω–∏—è."""
            
            # –°–æ–∑–¥–∞–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ (—Ç–∞–±–ª–∏—Ü–∞ notifications: id, message, sent, created_at)
            await conn.execute("""
                INSERT INTO notifications (message, sent)
                VALUES ($1, FALSE)
            """, notification_message)
            
            logger.info(f"üì¢ Sent notification for important consensus from debate {debate_id}")
            return True
    
    async def process_new_debates(self) -> Dict[str, int]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –Ω–æ–≤—ã–µ –¥–µ–±–∞—Ç—ã (–±–µ–∑ –æ–±—Ä–∞–±–æ—Ç–∫–∏).
        
        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–¥–∏–Ω –ø—É–ª –¥–ª—è –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
        if not hasattr(self, '_pool') or self._pool is None:
            self._pool = await self.get_pool()
        
        pool = self._pool
        stats = {
            "processed": 0,
            "tasks_created": 0,
            "knowledge_prioritized": 0,
            "notifications_sent": 0,
            "errors": 0
        }
        
        try:
            async with pool.acquire() as conn:
                # –ù–∞—Ö–æ–¥–∏–º –¥–µ–±–∞—Ç—ã –±–µ–∑ –æ–±—Ä–∞–±–æ—Ç–∫–∏
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ metadata
                has_metadata = await conn.fetchval("""
                    SELECT EXISTS (
                        SELECT 1 FROM information_schema.columns 
                        WHERE table_name = 'expert_discussions' 
                        AND column_name = 'metadata'
                    )
                """)
            
            if has_metadata:
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–µ–±–∞—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –∏–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –±–æ–ª–µ–µ 7 –¥–Ω–µ–π –Ω–∞–∑–∞–¥
                debates = await conn.fetch("""
                    SELECT id, knowledge_node_id
                    FROM expert_discussions
                    WHERE (metadata->>'processed' IS NULL OR metadata->>'processed' = 'false' 
                           OR (metadata->>'processed_at' IS NOT NULL 
                               AND (metadata->>'processed_at')::timestamp < NOW() - INTERVAL '7 days'))
                    ORDER BY created_at DESC
                    LIMIT 100
                """)
            else:
                # –ï—Å–ª–∏ metadata –Ω–µ—Ç, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –¥–µ–±–∞—Ç—ã
                debates = await conn.fetch("""
                    SELECT id, knowledge_node_id
                    FROM expert_discussions
                    ORDER BY created_at DESC
                    LIMIT 100
                """)
            
            logger.info(f"üìä Found {len(debates)} new debates to process")
            
            for debate in debates:
                try:
                    debate_id = str(debate['id'])
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–µ–±–∞—Ç
                    analysis = await self.analyze_debate_consensus(debate_id)
                    if not analysis:
                        continue
                    
                    stats["processed"] += 1
                    
                    # –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä—É–µ–º –∑–Ω–∞–Ω–∏–µ
                    if analysis['knowledge_node_id']:
                        if await self.prioritize_knowledge_from_debate(debate_id, analysis):
                            stats["knowledge_prioritized"] += 1
                    
                    # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á—É –¥–ª—è –≤–Ω–µ–¥—Ä–µ–Ω–∏—è
                    task_id = await self.create_task_from_debate(debate_id, analysis)
                    if task_id:
                        stats["tasks_created"] += 1
                    
                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –≤–∞–∂–Ω–æ–º –∫–æ–Ω—Å–µ–Ω—Å—É—Å–µ
                    if await self.send_notification_for_important_consensus(debate_id, analysis):
                        stats["notifications_sent"] += 1
                    
                    # –ü–æ–º–µ—á–∞–µ–º –¥–µ–±–∞—Ç –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π (–µ—Å–ª–∏ –µ—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∞ metadata)
                    if has_metadata:
                        await conn.execute("""
                            UPDATE expert_discussions
                            SET metadata = COALESCE(metadata, '{}'::jsonb) || jsonb_build_object(
                                'processed', true,
                                'processed_at', $1,
                                'consensus_score', $2,
                                'priority', $3
                            )
                            WHERE id = $4
                        """, 
                            datetime.now(timezone.utc).isoformat(),
                            analysis['consensus_score'],
                            analysis['priority'],
                            debate['id']
                        )
                    
                except Exception as e:
                    logger.error(f"‚ùå Error processing debate {debate['id']}: {e}")
                    stats["errors"] += 1
                    import traceback
                    traceback.print_exc()
        except Exception as e:
            logger.error(f"‚ùå Critical error in process_new_debates: {e}")
            stats["errors"] += 1
        
        # –ù–µ –∑–∞–∫—Ä—ã–≤–∞–µ–º –ø—É–ª, —Ç–∞–∫ –∫–∞–∫ –æ–Ω –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –ø–æ–≤—Ç–æ—Ä–Ω–æ
        return stats


async def process_all_debates():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—Å–µ—Ö –¥–µ–±–∞—Ç–æ–≤"""
    processor = DebateProcessor()
    stats = await processor.process_new_debates()
    
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–µ–±–∞—Ç–æ–≤:")
    print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –¥–µ–±–∞—Ç–æ–≤: {stats['processed']}")
    print(f"   –°–æ–∑–¥–∞–Ω–æ –∑–∞–¥–∞—á: {stats['tasks_created']}")
    print(f"   –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –∑–Ω–∞–Ω–∏–π: {stats['knowledge_prioritized']}")
    print(f"   –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π: {stats['notifications_sent']}")
    print(f"   –û—à–∏–±–æ–∫: {stats['errors']}")
    
    return stats


if __name__ == "__main__":
    asyncio.run(process_all_debates())

