"""
Batch Processor
–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –≤ –æ–¥–∏–Ω –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤
"""

import asyncio
import logging
import time
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime, timezone

logger = logging.getLogger(__name__)

@dataclass
class BatchRequest:
    """–ó–∞–ø—Ä–æ—Å –≤ batch"""
    prompt: str
    category: Optional[str]
    expert_name: str
    timestamp: float
    callback: Any  # Callback –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞

class BatchProcessor:
    """
    Batch Processor –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤.
    """
    
    def __init__(self, batch_size: int = 5, batch_timeout: float = 2.0):
        """
        Args:
            batch_size: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä batch
            batch_timeout: Timeout –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è batch (—Å–µ–∫—É–Ω–¥—ã)
        """
        self.batch_size = batch_size
        self.batch_timeout = batch_timeout
        self.batch_queue: List[BatchRequest] = []
        self._lock = asyncio.Lock()
        self._processing = False
    
    async def add_request(
        self,
        prompt: str,
        category: Optional[str],
        expert_name: str
    ) -> str:
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –≤ batch –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç.
        
        Args:
            prompt: –ü—Ä–æ–º–ø—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            category: –ö–∞—Ç–µ–≥–æ—Ä–∏—è –∑–∞–¥–∞—á–∏
            expert_name: –ò–º—è —ç–∫—Å–ø–µ—Ä—Ç–∞
        
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        # –°–æ–∑–¥–∞–µ–º callback –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        result_future = asyncio.Future()
        
        request = BatchRequest(
            prompt=prompt,
            category=category,
            expert_name=expert_name,
            timestamp=time.time(),
            callback=result_future
        )
        
        async with self._lock:
            self.batch_queue.append(request)
            
            # –ï—Å–ª–∏ batch –∑–∞–ø–æ–ª–Ω–µ–Ω, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ä–∞–∑—É
            if len(self.batch_queue) >= self.batch_size:
                await self._process_batch()
            else:
                # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —á–µ—Ä–µ–∑ timeout –µ—Å–ª–∏ –µ—â–µ –Ω–µ –∑–∞–ø—É—â–µ–Ω–∞
                if not self._processing:
                    self._processing = True
                    asyncio.create_task(self._process_batch_after_timeout())
        
        # –ñ–¥–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        return await result_future
    
    async def _process_batch_after_timeout(self):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç batch –ø–æ—Å–ª–µ timeout"""
        await asyncio.sleep(self.batch_timeout)
        async with self._lock:
            if self.batch_queue:
                await self._process_batch()
            self._processing = False
    
    async def _process_batch(self):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π batch"""
        if not self.batch_queue:
            return
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–ø—Ä–æ—Å—ã –∏–∑ –æ—á–µ—Ä–µ–¥–∏
        requests = self.batch_queue[:self.batch_size]
        self.batch_queue = self.batch_queue[self.batch_size:]
        
        logger.info(f"üì¶ [BATCH] Processing {len(requests)} requests in batch")
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ø–æ—Ö–æ–∂–∏–µ –∑–∞–ø—Ä–æ—Å—ã
        combined_prompt = self._combine_requests(requests)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        # (–∑–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–µ—Ä–µ–∑ ai_core)
        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º ai_core –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            from ai_core import run_smart_agent_async
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å
            combined_result = await run_smart_agent_async(
                combined_prompt,
                expert_name=requests[0].expert_name,
                category=requests[0].category
            )
            
            # –†–∞–∑–¥–µ–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞—Ç–Ω–æ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
            results = self._split_results(combined_result, len(requests))
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —á–µ—Ä–µ–∑ callbacks
            for i, request in enumerate(requests):
                if i < len(results):
                    if not request.callback.done():
                        request.callback.set_result(results[i])
                else:
                    if not request.callback.done():
                        request.callback.set_result("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ batch")
        except Exception as e:
            logger.error(f"‚ùå [BATCH] Error processing batch: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É –≤—Å–µ–º –∑–∞–ø—Ä–æ—Å–∞–º
            for request in requests:
                if not request.callback.done():
                    request.callback.set_exception(e)
    
    def _combine_requests(self, requests: List[BatchRequest]) -> str:
        """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å—ã –≤ –æ–¥–∏–Ω –ø—Ä–æ–º–ø—Ç (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤)"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤
        combined = "–û–±—Ä–∞–±–æ—Ç–∞–π –∑–∞–ø—Ä–æ—Å—ã:\n"
        for i, request in enumerate(requests, 1):
            # –£–±–∏—Ä–∞–µ–º –∏–∑–±—ã—Ç–æ—á–Ω—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏
            combined += f"{i}. {request.prompt}\n"
        combined += "\n–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:\n1: ...\n2: ...\n"
        return combined
    
    def _split_results(self, combined_result: str, count: int) -> List[str]:
        """–†–∞–∑–¥–µ–ª—è–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã"""
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –∏—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã "–û—Ç–≤–µ—Ç N:"
        results = []
        lines = combined_result.split('\n')
        current_answer = []
        answer_num = 1
        
        for line in lines:
            if f"–û—Ç–≤–µ—Ç {answer_num}:" in line or f"–û—Ç–≤–µ—Ç {answer_num} " in line:
                if current_answer:
                    results.append('\n'.join(current_answer))
                    current_answer = []
                answer_num += 1
                # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫—É –±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞
                clean_line = line.split(':', 1)[-1].strip()
                if clean_line:
                    current_answer.append(clean_line)
            else:
                if current_answer or line.strip():
                    current_answer.append(line)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –æ—Ç–≤–µ—Ç
        if current_answer:
            results.append('\n'.join(current_answer))
        
        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–¥–µ–ª–∏—Ç—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –≤—Å–µ—Ö
        if len(results) != count:
            logger.warning(f"‚ö†Ô∏è [BATCH] Could not split result into {count} parts, using same result for all")
            results = [combined_result] * count
        
        return results[:count]

# Singleton instance
_batch_processor_instance = None

async def get_batch_processor(batch_size: int = 5, batch_timeout: float = 2.0) -> BatchProcessor:
    """–ü–æ–ª—É—á–∞–µ—Ç singleton instance batch processor"""
    global _batch_processor_instance
    if _batch_processor_instance is None:
        _batch_processor_instance = BatchProcessor(batch_size=batch_size, batch_timeout=batch_timeout)
    return _batch_processor_instance

