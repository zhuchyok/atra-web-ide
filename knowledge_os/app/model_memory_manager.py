"""
Model Memory Manager –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ.
–£–ø—Ä–∞–≤–ª—è–µ—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π –∑–∞–≥—Ä—É–∑–∫–æ–π/–≤—ã–≥—Ä—É–∑–∫–æ–π –º–æ–¥–µ–ª–µ–π, –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º –ø–∞–º—è—Ç–∏,
–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ—á–∏—Å—Ç–∫–æ–π –ø—Ä–∏ –Ω–µ—Ö–≤–∞—Ç–∫–µ —Ä–µ—Å—É—Ä—Å–æ–≤.
"""

import asyncio
import os
import logging
import psutil
import httpx
from typing import Dict, List, Optional, Tuple
from datetime import datetime, timedelta
from enum import Enum

logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
MIN_FREE_MEMORY_MB = 200  # –ú–∏–Ω–∏–º—É–º —Å–≤–æ–±–æ–¥–Ω–æ–π –ø–∞–º—è—Ç–∏ –≤ MB
MODEL_UNLOAD_TIMEOUT = 300  # –í—Ä–µ–º—è –¥–æ –≤—ã–≥—Ä—É–∑–∫–∏ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–π –º–æ–¥–µ–ª–∏ (—Å–µ–∫—É–Ω–¥—ã)
MEMORY_CHECK_INTERVAL = 30  # –ò–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–∞–º—è—Ç–∏ (—Å–µ–∫—É–Ω–¥—ã)

class ModelState(Enum):
    """–°–æ—Å—Ç–æ—è–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
    LOADED = "loaded"
    UNLOADED = "unloaded"
    LOADING = "loading"
    UNLOADING = "unloading"

def _default_ollama_url() -> str:
    """URL Ollama: –≤ Docker localhost –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º host.docker.internal."""
    is_docker = os.path.exists('/.dockerenv') or os.getenv('DOCKER_CONTAINER', 'false').lower() == 'true'
    if is_docker:
        return os.getenv('OLLAMA_BASE_URL') or os.getenv('OLLAMA_API_URL') or 'http://host.docker.internal:11434'
    return os.getenv('OLLAMA_BASE_URL') or os.getenv('OLLAMA_API_URL') or 'http://localhost:11434'


class ModelMemoryManager:
    """
    –ú–µ–Ω–µ–¥–∂–µ—Ä –ø–∞–º—è—Ç–∏ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª—è–º–∏ Ollama.
    –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–≥—Ä—É–∂–∞–µ—Ç –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏.
    """
    
    def __init__(self, ollama_url: str = None):
        self.ollama_url = ollama_url or _default_ollama_url()
        self.model_states: Dict[str, ModelState] = {}
        self.model_last_used: Dict[str, datetime] = {}
        self.model_memory_usage: Dict[str, int] = {}  # MB
        self._running = False
        self._monitor_task: Optional[asyncio.Task] = None
        
    async def get_available_memory_mb(self) -> int:
        """–ü–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω—É—é –ø–∞–º—è—Ç—å –≤ MB"""
        try:
            memory = psutil.virtual_memory()
            return memory.available // (1024 * 1024)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–∞–º—è—Ç–∏: {e}")
            return 0
    
    async def get_loaded_models(self) -> List[str]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            async with httpx.AsyncClient(timeout=5.0) as client:
                response = await client.get(f"{self.ollama_url}/api/tags")
                if response.status_code == 200:
                    data = response.json()
                    return [model['name'] for model in data.get('models', [])]
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {e}")
        return []
    
    async def unload_model(self, model_name: str) -> bool:
        """–í—ã–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å –∏–∑ –ø–∞–º—è—Ç–∏"""
        try:
            logger.info(f"üîÑ –í—ã–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {model_name} –∏–∑ –ø–∞–º—è—Ç–∏...")
            async with httpx.AsyncClient(timeout=30.0) as client:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º Ollama API –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏
                # Ollama –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –Ω–µ—Ö–≤–∞—Ç–∫–µ –ø–∞–º—è—Ç–∏,
                # –Ω–æ –º—ã –º–æ–∂–µ–º —è–≤–Ω–æ –∑–∞–ø—Ä–æ—Å–∏—Ç—å —á–µ—Ä–µ–∑ /api/generate —Å stream=false
                # –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ –ø–æ–¥–æ–∂–¥–∞—Ç—å, –ø–æ–∫–∞ Ollama —Å–∞–º –≤—ã–≥—Ä—É–∑–∏—Ç
                
                # –î–ª—è —è–≤–Ω–æ–π –≤—ã–≥—Ä—É–∑–∫–∏ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:
                # response = await client.post(
                #     f"{self.ollama_url}/api/generate",
                #     json={"model": model_name, "prompt": "", "stream": False},
                #     timeout=1.0
                # )
                # –ù–æ –ª—É—á—à–µ –ø—Ä–æ—Å—Ç–æ –ø–æ–º–µ—Ç–∏—Ç—å –º–æ–¥–µ–ª—å –∫–∞–∫ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—É—é
                
                self.model_states[model_name] = ModelState.UNLOADED
                if model_name in self.model_last_used:
                    del self.model_last_used[model_name]
                if model_name in self.model_memory_usage:
                    del self.model_memory_usage[model_name]
                
                logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å {model_name} –≤—ã–≥—Ä—É–∂–µ–Ω–∞")
                return True
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ {model_name}: {e}")
            return False
    
    async def mark_model_used(self, model_name: str):
        """–ü–æ–º–µ—Ç–∏—Ç—å –º–æ–¥–µ–ª—å –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑—É–µ–º—É—é"""
        self.model_last_used[model_name] = datetime.now()
        self.model_states[model_name] = ModelState.LOADED
    
    async def cleanup_unused_models(self) -> int:
        """–û—á–∏—Å—Ç–∏—Ç—å –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏"""
        current_time = datetime.now()
        unloaded_count = 0
        
        for model_name, last_used in list(self.model_last_used.items()):
            time_since_use = (current_time - last_used).total_seconds()
            
            if time_since_use > MODEL_UNLOAD_TIMEOUT:
                logger.info(f"‚è∞ –ú–æ–¥–µ–ª—å {model_name} –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∞—Å—å {time_since_use:.0f} —Å–µ–∫—É–Ω–¥, –≤—ã–≥—Ä—É–∂–∞–µ–º...")
                await self.unload_model(model_name)
                unloaded_count += 1
        
        return unloaded_count
    
    async def emergency_memory_cleanup(self) -> bool:
        """–≠–∫—Å—Ç—Ä–µ–Ω–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –ø—Ä–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π –Ω–µ—Ö–≤–∞—Ç–∫–µ"""
        available_mb = await self.get_available_memory_mb()
        
        if available_mb < MIN_FREE_MEMORY_MB:
            logger.warning(f"üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ù–ï–•–í–ê–¢–ö–ê –ü–ê–ú–Ø–¢–ò: {available_mb}MB —Å–≤–æ–±–æ–¥–Ω–æ (–º–∏–Ω–∏–º—É–º {MIN_FREE_MEMORY_MB}MB)")
            
            # –í—ã–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏
            unloaded = await self.cleanup_unused_models()
            
            # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –Ω–µ—Ö–≤–∞—Ç–∫–∞, –≤—ã–≥—Ä—É–∂–∞–µ–º —Å—Ç–∞—Ä—ã–µ –º–æ–¥–µ–ª–∏
            if await self.get_available_memory_mb() < MIN_FREE_MEMORY_MB:
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
                sorted_models = sorted(
                    self.model_last_used.items(),
                    key=lambda x: x[1]
                )
                
                # –í—ã–≥—Ä—É–∂–∞–µ–º —Å–∞–º—ã–µ —Å—Ç–∞—Ä—ã–µ
                for model_name, _ in sorted_models[:2]:  # –í—ã–≥—Ä—É–∂–∞–µ–º 2 —Å–∞–º—ã–µ —Å—Ç–∞—Ä—ã–µ
                    logger.warning(f"üö® –≠–∫—Å—Ç—Ä–µ–Ω–Ω–∞—è –≤—ã–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {model_name}")
                    await self.unload_model(model_name)
            
            final_available = await self.get_available_memory_mb()
            logger.info(f"‚úÖ –ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {final_available}MB —Å–≤–æ–±–æ–¥–Ω–æ")
            return final_available >= MIN_FREE_MEMORY_MB
        
        return True
    
    async def monitor_memory(self):
        """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–∞–º—è—Ç–∏ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞"""
        self._running = True
        logger.info("üîç –ó–∞–ø—É—â–µ–Ω –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–∞–º—è—Ç–∏ –º–æ–¥–µ–ª–µ–π")
        
        while self._running:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—É—é –ø–∞–º—è—Ç—å
                available_mb = await self.get_available_memory_mb()
                
                # –≠–∫—Å—Ç—Ä–µ–Ω–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π –Ω–µ—Ö–≤–∞—Ç–∫–µ
                if available_mb < MIN_FREE_MEMORY_MB:
                    await self.emergency_memory_cleanup()
                else:
                    # –û–±—ã—á–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –º–æ–¥–µ–ª–µ–π
                    await self.cleanup_unused_models()
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
                loaded_models = await self.get_loaded_models()
                for model in loaded_models:
                    if model not in self.model_states:
                        self.model_states[model] = ModelState.LOADED
                
                await asyncio.sleep(MEMORY_CHECK_INTERVAL)
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –≤ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–µ –ø–∞–º—è—Ç–∏: {e}")
                await asyncio.sleep(MEMORY_CHECK_INTERVAL)
    
    def start_monitoring(self):
        """–ó–∞–ø—É—Å—Ç–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–∞–º—è—Ç–∏"""
        if not self._running:
            self._monitor_task = asyncio.create_task(self.monitor_memory())
    
    def stop_monitoring(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–∞–º—è—Ç–∏"""
        self._running = False
        if self._monitor_task:
            self._monitor_task.cancel()
    
    async def get_actual_model_memory_usage(self) -> Dict[str, float]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª—å—é —á–µ—Ä–µ–∑ –ø—Ä–æ—Ü–µ—Å—Å—ã Ollama"""
        model_memory = {}
        try:
            # –ù–∞—Ö–æ–¥–∏–º –ø—Ä–æ—Ü–µ—Å—Å—ã Ollama
            for proc in psutil.process_iter(['pid', 'name', 'memory_info']):
                try:
                    if 'ollama' in proc.info['name'].lower():
                        memory_mb = proc.info['memory_info'].rss / (1024 * 1024)
                        # –ü—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –º–æ–¥–µ–ª—å –∏–∑ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
                        try:
                            cmdline = ' '.join(proc.cmdline())
                            # –ò—â–µ–º –∏–º—è –º–æ–¥–µ–ª–∏ –≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ
                            for model_name in self.model_states.keys():
                                if model_name in cmdline:
                                    if model_name not in model_memory:
                                        model_memory[model_name] = 0.0
                                    model_memory[model_name] += memory_mb
                        except (psutil.NoSuchProcess, psutil.AccessDenied):
                            pass
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    continue
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏: {e}")
        
        return model_memory
    
    async def get_memory_stats(self) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏"""
        available_mb = await self.get_available_memory_mb()
        loaded_models = await self.get_loaded_models()
        actual_memory_usage = await self.get_actual_model_memory_usage()
        
        return {
            "available_memory_mb": available_mb,
            "min_free_memory_mb": MIN_FREE_MEMORY_MB,
            "loaded_models_count": len(loaded_models),
            "loaded_models": loaded_models,
            "model_states": {k: v.value for k, v in self.model_states.items()},
            "actual_memory_usage_mb": actual_memory_usage,
            "last_used": {
                k: v.isoformat() 
                for k, v in self.model_last_used.items()
            }
        }

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
_memory_manager: Optional[ModelMemoryManager] = None

def get_memory_manager(ollama_url: str = None) -> ModelMemoryManager:
    """–ü–æ–ª—É—á–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä ModelMemoryManager"""
    global _memory_manager
    if _memory_manager is None:
        _memory_manager = ModelMemoryManager(ollama_url)
        _memory_manager.start_monitoring()
    return _memory_manager

