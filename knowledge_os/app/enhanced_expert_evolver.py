"""
Enhanced Expert Evolver: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —ç–≤–æ–ª—é—Ü–∏—è —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏

–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:
- –ú–µ—Ç—Ä–∏–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ (success_rate, response_time, knowledge_quality)
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —ç–≤–æ–ª—é—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫
- –£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
- –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ (—É–≥–ª—É–±–ª–µ–Ω–∏–µ –≤ —É–∑–∫–∏–µ –æ–±–ª–∞—Å—Ç–∏)
"""

import asyncio
import os
import json
import asyncpg
import subprocess
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple  # noqa: F401 - Optional used in evolve_expert_from_insights
from dataclasses import dataclass

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

DB_URL = os.getenv('DATABASE_URL', 'postgresql://admin:secret@localhost:5432/knowledge_os')

# –ü–æ—Ä–æ–≥–∏ –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π
EVOLUTION_THRESHOLD = 0.7  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π success_rate –¥–ª—è —ç–≤–æ–ª—é—Ü–∏–∏
REMOVAL_THRESHOLD = 0.3  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π success_rate –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
SPECIALIZATION_THRESHOLD = 0.8  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π success_rate –¥–ª—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏


@dataclass
class ExpertMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —ç–∫—Å–ø–µ—Ä—Ç–∞"""
    expert_id: str
    name: str
    role: str
    success_rate: float  # –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—à–Ω—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π
    response_time_avg: float  # –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ (–º—Å)
    knowledge_quality: float  # –ö–∞—á–µ—Å—Ç–≤–æ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –∑–Ω–∞–Ω–∏–π (avg confidence)
    task_completion_rate: float  # –ü—Ä–æ—Ü–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
    usage_count: int  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–π
    feedback_avg: float  # –°—Ä–µ–¥–Ω–∏–π feedback score
    knowledge_created: int  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –∑–Ω–∞–Ω–∏–π
    last_activity: Optional[datetime]  # –ü–æ—Å–ª–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å


def run_cursor_agent(prompt: str) -> Optional[str]:
    """–ó–∞–ø—É—Å–∫ Cursor Agent –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
    try:
        env = os.environ.copy()
        result = subprocess.run(
            ['/root/.local/bin/cursor-agent', '--print', prompt],
            capture_output=True, text=True, check=True, timeout=400, env=env
        )
        return result.stdout.strip()
    except Exception as e:
        logger.error(f"Cursor Agent error: {e}")
        return None


class ExpertMetricsCollector:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤"""
    
    def __init__(self, db_url: str = DB_URL):
        self.db_url = db_url
    
    async def collect_metrics(self, expert_id: str) -> Optional[ExpertMetrics]:
        """–°–±–æ—Ä –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫ –¥–ª—è —ç–∫—Å–ø–µ—Ä—Ç–∞"""
        try:
            conn = await asyncpg.connect(self.db_url)
            try:
                # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± —ç–∫—Å–ø–µ—Ä—Ç–µ
                expert = await conn.fetchrow("""
                    SELECT id, name, role, system_prompt, department
                    FROM experts
                    WHERE id = $1
                """, expert_id)
                
                if not expert:
                    return None
                
                # Success rate (–ø—Ä–æ—Ü–µ–Ω—Ç –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö feedback)
                success_rate = await conn.fetchval("""
                    SELECT 
                        CASE 
                            WHEN count(*) = 0 THEN 0.0
                            ELSE count(*) FILTER (WHERE feedback_score > 0)::float / count(*)::float
                        END
                    FROM interaction_logs
                    WHERE expert_id = $1
                      AND feedback_score IS NOT NULL
                      AND created_at > NOW() - INTERVAL '30 days'
                """, expert_id) or 0.0
                
                # –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ (–∏–∑ metadata)
                response_time_avg = await conn.fetchval("""
                    SELECT AVG((metadata->>'response_time_ms')::float)
                    FROM interaction_logs
                    WHERE expert_id = $1
                      AND metadata->>'response_time_ms' IS NOT NULL
                      AND created_at > NOW() - INTERVAL '30 days'
                """, expert_id) or 0.0
                
                # –ö–∞—á–µ—Å—Ç–≤–æ –∑–Ω–∞–Ω–∏–π (—Å—Ä–µ–¥–Ω–∏–π confidence —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –∑–Ω–∞–Ω–∏–π)
                knowledge_quality = await conn.fetchval("""
                    SELECT AVG(confidence_score)
                    FROM knowledge_nodes
                    WHERE metadata->>'expert' = $1
                      AND created_at > NOW() - INTERVAL '30 days'
                """, expert['name']) or 0.0
                
                # Task completion rate
                task_completion_rate = await conn.fetchval("""
                    SELECT 
                        CASE 
                            WHEN count(*) = 0 THEN 0.0
                            ELSE count(*) FILTER (WHERE status = 'completed')::float / count(*)::float
                        END
                    FROM tasks
                    WHERE assignee_expert_id = $1
                      AND created_at > NOW() - INTERVAL '30 days'
                """, expert_id) or 0.0
                
                # Usage count
                usage_count = await conn.fetchval("""
                    SELECT count(*)
                    FROM interaction_logs
                    WHERE expert_id = $1
                      AND created_at > NOW() - INTERVAL '30 days'
                """, expert_id) or 0
                
                # –°—Ä–µ–¥–Ω–∏–π feedback
                feedback_avg = await conn.fetchval("""
                    SELECT AVG(feedback_score)
                    FROM interaction_logs
                    WHERE expert_id = $1
                      AND feedback_score IS NOT NULL
                      AND created_at > NOW() - INTERVAL '30 days'
                """, expert_id) or 0.0
                
                # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –∑–Ω–∞–Ω–∏–π
                knowledge_created = await conn.fetchval("""
                    SELECT count(*)
                    FROM knowledge_nodes
                    WHERE metadata->>'expert' = $1
                      AND created_at > NOW() - INTERVAL '30 days'
                """, expert['name']) or 0
                
                # –ü–æ—Å–ª–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
                last_activity = await conn.fetchval("""
                    SELECT MAX(created_at)
                    FROM interaction_logs
                    WHERE expert_id = $1
                """, expert_id)
                
                return ExpertMetrics(
                    expert_id=str(expert_id),
                    name=expert['name'],
                    role=expert['role'],
                    success_rate=float(success_rate),
                    response_time_avg=float(response_time_avg),
                    knowledge_quality=float(knowledge_quality),
                    task_completion_rate=float(task_completion_rate),
                    usage_count=int(usage_count),
                    feedback_avg=float(feedback_avg),
                    knowledge_created=int(knowledge_created),
                    last_activity=last_activity
                )
            finally:
                await conn.close()
        except Exception as e:
            logger.error(f"Error collecting metrics for expert {expert_id}: {e}")
            return None
    
    async def get_all_experts_metrics(self) -> List[ExpertMetrics]:
        """–°–±–æ—Ä –º–µ—Ç—Ä–∏–∫ –¥–ª—è –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤"""
        try:
            conn = await asyncpg.connect(self.db_url)
            try:
                expert_ids = await conn.fetch("SELECT id FROM experts")
                
                metrics_list = []
                for expert_id in expert_ids:
                    metrics = await self.collect_metrics(expert_id['id'])
                    if metrics:
                        metrics_list.append(metrics)
                
                return metrics_list
            finally:
                await conn.close()
        except Exception as e:
            logger.error(f"Error collecting all metrics: {e}")
            return []


class ExpertEvolver:
    """–ö–ª–∞—Å—Å –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —ç–≤–æ–ª—é—Ü–∏–∏ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤"""
    
    def __init__(self, db_url: str = DB_URL):
        self.db_url = db_url
        self.metrics_collector = ExpertMetricsCollector(db_url)
    
    async def evolve_expert(self, expert_id: str, metrics: ExpertMetrics) -> bool:
        """–≠–≤–æ–ª—é—Ü–∏—è —ç–∫—Å–ø–µ—Ä—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫"""
        try:
            conn = await asyncpg.connect(self.db_url)
            try:
                # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π –ø—Ä–æ–º–ø—Ç
                expert = await conn.fetchrow("""
                    SELECT name, role, system_prompt, version, department
                    FROM experts
                    WHERE id = $1
                """, expert_id)
                
                if not expert:
                    return False
                
                # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç–≤–æ–ª—é—Ü–∏–∏
                feedback_data = await conn.fetch("""
                    SELECT user_query, assistant_response, feedback_score, feedback_text
                    FROM interaction_logs
                    WHERE expert_id = $1
                      AND created_at > NOW() - INTERVAL '7 days'
                    ORDER BY feedback_score DESC NULLS LAST
                    LIMIT 10
                """, expert_id)
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è —ç–≤–æ–ª—é—Ü–∏–∏
                evolution_prompt = f"""
                –í–´ - –ù–ï–ô–†–û–ù–ù–´–ô –ê–†–•–ò–¢–ï–ö–¢–û–† (–£–†–û–í–ï–ù–¨ 5). 
                –¶–ï–õ–¨: –ü—Ä–æ–≤–µ—Å—Ç–∏ —Ä–µ–∫—É—Ä—Å–∏–≤–Ω—É—é —Å–∞–º–æ–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –ª–∏—á–Ω–æ—Å—Ç–∏ –ò–ò-—ç–∫—Å–ø–µ—Ä—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏.
                
                –≠–ö–°–ü–ï–†–¢: {expert['name']} ({expert['role']})
                –¢–ï–ö–£–©–ò–ô –ü–†–û–ú–ü–¢: {expert['system_prompt']}
                
                –ú–ï–¢–†–ò–ö–ò –≠–§–§–ï–ö–¢–ò–í–ù–û–°–¢–ò:
                - Success Rate: {metrics.success_rate:.2%}
                - Response Time: {metrics.response_time_avg:.0f}ms
                - Knowledge Quality: {metrics.knowledge_quality:.2f}
                - Task Completion: {metrics.task_completion_rate:.2%}
                - Usage Count: {metrics.usage_count}
                - Avg Feedback: {metrics.feedback_avg:.2f}
                
                –†–ï–ó–£–õ–¨–¢–ê–¢–´ –†–ê–ë–û–¢–´ –ó–ê –ù–ï–î–ï–õ–Æ:
                {self._format_feedback_data(feedback_data)}
                
                –ó–ê–î–ê–ß–ê: 
                1. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ –∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç–µ —Å–ª–∞–±—ã–µ –º–µ—Å—Ç–∞.
                2. –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π—Ç–µ —É–ª—É—á—à–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞.
                3. –£—Å–∏–ª—å—Ç–µ –æ–±–ª–∞—Å—Ç–∏, –≥–¥–µ –º–µ—Ç—Ä–∏–∫–∏ –Ω–∏–∑–∫–∏–µ.
                4. –°–æ—Ö—Ä–∞–Ω–∏—Ç–µ —Å–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã —ç–∫—Å–ø–µ—Ä—Ç–∞.
                
                –û–¢–í–ï–¢–¨–¢–ï –¢–û–õ–¨–ö–û –¢–ï–ö–°–¢–û–ú –ù–û–í–û–ì–û –ü–†–û–ú–ü–¢–ê.
                """
                
                new_prompt = run_cursor_agent(evolution_prompt)
                
                if new_prompt and len(new_prompt) > 100:
                    new_version = (expert['version'] or 0) + 1
                    
                    await conn.execute("""
                        UPDATE experts 
                        SET system_prompt = $1, 
                            version = $2,
                            metadata = metadata || jsonb_build_object(
                                'last_evolution', NOW(),
                                'prev_prompt', $3,
                                'evolution_metrics', $4
                            )
                        WHERE id = $5
                    """, new_prompt, new_version, expert['system_prompt'], 
                    json.dumps({
                        "success_rate": metrics.success_rate,
                        "response_time": metrics.response_time_avg,
                        "knowledge_quality": metrics.knowledge_quality
                    }), expert_id)
                    
                    logger.info(f"‚ú® Expert {expert['name']} evolved to v{new_version}")
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–±—ã—Ç–∏–µ —ç–≤–æ–ª—é—Ü–∏–∏ (–ø–æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å embedding ‚Äî VERIFICATION ¬ß5, WHATS_NOT_DONE ¬ß4)
                    domain_id = await conn.fetchval("SELECT id FROM domains WHERE name = 'Strategy' LIMIT 1")
                    if not domain_id:
                        domain_id = await conn.fetchval("INSERT INTO domains (name) VALUES ('Strategy') RETURNING id")
                    content_kn = f"üß¨ –≠–í–û–õ–Æ–¶–ò–Ø: {expert['name']} –ø—Ä–æ—à–µ–ª –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é —ç–≤–æ–ª—é—Ü–∏—é –¥–æ v{new_version} –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫ (success_rate: {metrics.success_rate:.2%})."
                    meta_kn = json.dumps({
                        "type": "expert_evolution",
                        "expert": expert['name'],
                        "version": new_version,
                        "metrics": {
                            "success_rate": metrics.success_rate,
                            "response_time": metrics.response_time_avg,
                            "knowledge_quality": metrics.knowledge_quality
                        }
                    })
                    embedding = None
                    try:
                        from semantic_cache import get_embedding
                        embedding = await get_embedding(content_kn[:8000])
                    except Exception:
                        pass
                    if embedding is not None:
                        await conn.execute("""
                            INSERT INTO knowledge_nodes (domain_id, content, confidence_score, metadata, is_verified, embedding)
                            VALUES ($1, $2, 1.0, $3, true, $4::vector)
                        """, domain_id, content_kn, meta_kn, str(embedding))
                    else:
                        await conn.execute("""
                            INSERT INTO knowledge_nodes (domain_id, content, confidence_score, metadata, is_verified)
                            VALUES ($1, $2, 1.0, $3, true)
                        """, domain_id, content_kn, meta_kn)
                    
                    return True
                
                return False
            finally:
                await conn.close()
        except Exception as e:
            logger.error(f"Error evolving expert {expert_id}: {e}")
            return False
    
    async def evolve_expert_from_insights(
        self, conn, expert_id: str, insights_text: str, task_id: Optional[int] = None
    ) -> bool:
        """
        –≠–≤–æ–ª—é—Ü–∏—è –ø—Ä–æ–º–ø—Ç–∞ —ç–∫—Å–ø–µ—Ä—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω—Å–∞–π—Ç–æ–≤ –∏–∑ Knowledge Applicator (–±–µ–∑ –º–µ—Ç—Ä–∏–∫).
        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–¥–∞—á ¬´Prompt evolution from top insights¬ª.
        """
        try:
            expert = await conn.fetchrow("""
                SELECT id, name, role, system_prompt, version, department
                FROM experts
                WHERE id = $1
            """, expert_id)
            if not expert or not (expert["system_prompt"] or "").strip():
                return False
            evolution_prompt = f"""
–í–´ - –ù–ï–ô–†–û–ù–ù–´–ô –ê–†–•–ò–¢–ï–ö–¢–û–†. –¶–ï–õ–¨: –¥–æ–ø–æ–ª–Ω–∏—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —ç–∫—Å–ø–µ—Ä—Ç–∞ –≤–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∏–Ω—Å–∞–π—Ç–∞–º–∏ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π.

–≠–ö–°–ü–ï–†–¢: {expert['name']} ({expert['role']}), –æ—Ç–¥–µ–ª: {expert['department'] or 'General'}.

–¢–ï–ö–£–©–ò–ô SYSTEM PROMPT:
{expert['system_prompt']}

–í–ï–†–ò–§–ò–¶–ò–†–û–í–ê–ù–ù–´–ï –ò–ù–°–ê–ô–¢–´ (–≤–∫–ª—é—á–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –≤ –ø—Ä–æ–º–ø—Ç):
{insights_text[:2500]}

–ó–ê–î–ê–ß–ê: –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –û–ë–ù–û–í–õ–Å–ù–ù–´–ô system_prompt, –∫–æ—Ç–æ—Ä—ã–π —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ª–∏—á–Ω–æ—Å—Ç—å —ç–∫—Å–ø–µ—Ä—Ç–∞ –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç/—É—á–∏—Ç—ã–≤–∞–µ—Ç –∏–Ω—Å–∞–π—Ç—ã –≤—ã—à–µ. –ù–µ —É–¥–∞–ª—è–π —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–∏–ª—å–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏. –û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç–æ–º –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π.
"""
            new_prompt = run_cursor_agent(evolution_prompt)
            if not new_prompt or len(new_prompt.strip()) < 100:
                return False
            new_version = (expert["version"] or 0) + 1
            await conn.execute("""
                UPDATE experts
                SET system_prompt = $1, version = $2,
                    metadata = metadata || jsonb_build_object(
                        'last_evolution', NOW(),
                        'evolution_source', 'insights_task',
                        'evolution_task_id', $3
                    )
                WHERE id = $4
            """, new_prompt.strip(), new_version, task_id, expert_id)
            logger.info("‚ú® Expert %s evolved to v%s from insights task", expert["name"], new_version)
            return True
        except Exception as e:
            logger.warning("evolve_expert_from_insights failed for %s: %s", expert_id, e)
            return False

    def _format_feedback_data(self, feedback_data: List) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö feedback –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞"""
        if not feedback_data:
            return "–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –Ω–µ –±—ã–ª–æ, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ–±—â–∏–µ —Ç—Ä–µ–Ω–¥—ã 2026."
        
        formatted = []
        for f in feedback_data:
            score = f.get('feedback_score', 'N/A')
            text = f.get('feedback_text', '')
            formatted.append(f"Q: {f['user_query'][:200]}\nA: {f['assistant_response'][:200]}\nScore: {score} {text}")
        
        return "\n\n".join(formatted)
    
    async def remove_ineffective_experts(self, metrics_list: List[ExpertMetrics]) -> List[str]:
        """–£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤"""
        removed = []
        
        for metrics in metrics_list:
            # –ö—Ä–∏—Ç–µ—Ä–∏–∏ —É–¥–∞–ª–µ–Ω–∏—è:
            # 1. –ù–∏–∑–∫–∏–π success_rate (< REMOVAL_THRESHOLD)
            # 2. –ù–∏–∑–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (< 5 –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–π –∑–∞ 30 –¥–Ω–µ–π)
            # 3. –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –±–æ–ª–µ–µ 60 –¥–Ω–µ–π
            should_remove = (
                metrics.success_rate < REMOVAL_THRESHOLD and
                metrics.usage_count < 5
            ) or (
                metrics.last_activity and
                (datetime.now() - metrics.last_activity).days > 60
            )
            
            if should_remove:
                try:
                    conn = await asyncpg.connect(self.db_url)
                    try:
                        # –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ –Ω–µ–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –≤–º–µ—Å—Ç–æ —É–¥–∞–ª–µ–Ω–∏—è
                        await conn.execute("""
                            UPDATE experts
                            SET metadata = metadata || jsonb_build_object(
                                'removed_at', NOW(),
                                'removal_reason', 'low_effectiveness',
                                'removal_metrics', $1
                            )
                            WHERE id = $2
                        """, json.dumps({
                            "success_rate": metrics.success_rate,
                            "usage_count": metrics.usage_count,
                            "last_activity": metrics.last_activity.isoformat() if metrics.last_activity else None
                        }), metrics.expert_id)
                        
                        logger.info(f"üóëÔ∏è Marked expert {metrics.name} as inactive (success_rate: {metrics.success_rate:.2%})")
                        removed.append(metrics.expert_id)
                    finally:
                        await conn.close()
                except Exception as e:
                    logger.error(f"Error removing expert {metrics.expert_id}: {e}")
        
        return removed
    
    async def specialize_expert(self, expert_id: str, metrics: ExpertMetrics) -> bool:
        """–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —ç–∫—Å–ø–µ—Ä—Ç–∞ –≤ —É–∑–∫–æ–π –æ–±–ª–∞—Å—Ç–∏"""
        try:
            conn = await asyncpg.connect(self.db_url)
            try:
                # –ù–∞—Ö–æ–¥–∏–º –¥–æ–º–µ–Ω, –≥–¥–µ —ç–∫—Å–ø–µ—Ä—Ç –Ω–∞–∏–±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω
                domain_performance = await conn.fetch("""
                    SELECT 
                        d.name as domain,
                        count(*) as usage_count,
                        avg(il.feedback_score) as avg_feedback
                    FROM interaction_logs il
                    JOIN knowledge_nodes k ON (il.metadata->>'knowledge_id')::uuid = k.id
                    JOIN domains d ON k.domain_id = d.id
                    WHERE il.expert_id = $1
                      AND il.created_at > NOW() - INTERVAL '30 days'
                    GROUP BY d.name
                    ORDER BY avg_feedback DESC, usage_count DESC
                    LIMIT 1
                """, expert_id)
                
                if not domain_performance:
                    return False
                
                best_domain = domain_performance[0]['domain']
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
                expert = await conn.fetchrow("""
                    SELECT name, role, system_prompt, department
                    FROM experts
                    WHERE id = $1
                """, expert_id)
                
                specialization_prompt = f"""
                –í–´ - –ù–ï–ô–†–û–ù–ù–´–ô –ê–†–•–ò–¢–ï–ö–¢–û–†. 
                –¶–ï–õ–¨: –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —ç–∫—Å–ø–µ—Ä—Ç–∞ –≤ —É–∑–∫–æ–π –æ–±–ª–∞—Å—Ç–∏ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏.
                
                –≠–ö–°–ü–ï–†–¢: {expert['name']} ({expert['role']})
                –¢–ï–ö–£–©–ò–ô –ü–†–û–ú–ü–¢: {expert['system_prompt']}
                –û–ë–õ–ê–°–¢–¨ –°–ü–ï–¶–ò–ê–õ–ò–ó–ê–¶–ò–ò: {best_domain}
                
                –ú–ï–¢–†–ò–ö–ò –í –≠–¢–û–ô –û–ë–õ–ê–°–¢–ò:
                - Usage Count: {domain_performance[0]['usage_count']}
                - Avg Feedback: {domain_performance[0]['avg_feedback']:.2f}
                
                –ó–ê–î–ê–ß–ê:
                1. –£–≥–ª—É–±–∏—Ç—å —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—É –≤ –æ–±–ª–∞—Å—Ç–∏ {best_domain}
                2. –î–æ–±–∞–≤–∏—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –∑–Ω–∞–Ω–∏—è –∏ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏
                3. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ–±—â—É—é –∫–æ–º–ø–µ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å
                
                –û–¢–í–ï–¢–¨–¢–ï –¢–û–õ–¨–ö–û –¢–ï–ö–°–¢–û–ú –ù–û–í–û–ì–û –ü–†–û–ú–ü–¢–ê.
                """
                
                new_prompt = run_cursor_agent(specialization_prompt)
                
                if new_prompt and len(new_prompt) > 100:
                    await conn.execute("""
                        UPDATE experts
                        SET system_prompt = $1,
                            department = $2,
                            metadata = metadata || jsonb_build_object(
                                'specialized_at', NOW(),
                                'specialization_domain', $3
                            )
                        WHERE id = $4
                    """, new_prompt, best_domain, best_domain, expert_id)
                    
                    logger.info(f"üéØ Expert {expert['name']} specialized in {best_domain}")
                    return True
                
                return False
            finally:
                await conn.close()
        except Exception as e:
            logger.error(f"Error specializing expert {expert_id}: {e}")
            return False


async def run_enhanced_evolution_cycle():
    """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —ç–≤–æ–ª—é—Ü–∏–∏ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤"""
    logger.info("üß¨ Starting Enhanced Expert Evolution cycle...")
    
    conn = await asyncpg.connect(DB_URL)
    evolver = ExpertEvolver()
    insights_evolved = 0

    try:
        # 0. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á ¬´Prompt evolution from top insights¬ª (Knowledge Applicator ‚Üí –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —ç–≤–æ–ª—é—Ü–∏—è)
        insight_tasks = await conn.fetch("""
            SELECT id, title, description, metadata
            FROM tasks
            WHERE status = 'pending'
              AND metadata->>'source' = 'knowledge_applicator'
              AND (title ILIKE $1 OR title ILIKE $2)
            ORDER BY created_at ASC
            LIMIT 5
        """, "%Prompt evolution%", "%—ç–≤–æ–ª—é—Ü–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤%")
        if insight_tasks:
            logger.info("üì• Processing %d insight-driven prompt evolution task(s)...", len(insight_tasks))
        for task in insight_tasks:
            task_id = task["id"]
            description = (task["description"] or "").strip()
            if len(description) < 50:
                await conn.execute(
                    "UPDATE tasks SET status = 'cancelled', updated_at = NOW() WHERE id = $1",
                    task_id,
                )
                continue
            # –í—ã–±–∏—Ä–∞–µ–º –¥–æ 3 —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ (—Ä–∞–∑–Ω—ã–µ –æ—Ç–¥–µ–ª—ã, –∞–∫—Ç–∏–≤–Ω—ã–µ)
            experts = await conn.fetch("""
                SELECT id FROM experts
                WHERE (is_active IS NULL OR is_active = TRUE)
                  AND system_prompt IS NOT NULL AND LENGTH(TRIM(system_prompt)) > 50
                ORDER BY RANDOM()
                LIMIT 3
            """)
            task_evolved = False
            for row in experts:
                if await evolver.evolve_expert_from_insights(conn, str(row["id"]), description, task_id=task_id):
                    insights_evolved += 1
                    task_evolved = True
                    break
            await conn.execute(
                "UPDATE tasks SET status = 'completed', updated_at = NOW(), result = $2 WHERE id = $1",
                task_id,
                "Insights applied to expert prompt (auto-evolution)." if task_evolved else "No expert updated (LLM unavailable or skip).",
            )
        if insights_evolved:
            logger.info("   Insights ‚Üí prompts: %d expert(s) evolved", insights_evolved)
    finally:
        await conn.close()

    collector = ExpertMetricsCollector()
    
    # –°–æ–±–∏—Ä–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
    metrics_list = await collector.get_all_experts_metrics()
    
    if not metrics_list:
        logger.warning("No experts found for evolution")
        return
    
    logger.info(f"Collected metrics for {len(metrics_list)} experts")
    
    evolved_count = 0
    specialized_count = 0
    removed_count = 0
    
    # 1. –≠–≤–æ–ª—é—Ü–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
    for metrics in metrics_list:
        if metrics.success_rate >= EVOLUTION_THRESHOLD and metrics.usage_count >= 10:
            if await evolver.evolve_expert(metrics.expert_id, metrics):
                evolved_count += 1
    
    # 2. –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—ã—Å–æ–∫–æ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
    for metrics in metrics_list:
        if metrics.success_rate >= SPECIALIZATION_THRESHOLD and metrics.usage_count >= 20:
            if await evolver.specialize_expert(metrics.expert_id, metrics):
                specialized_count += 1
    
    # 3. –£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
    removed = await evolver.remove_ineffective_experts(metrics_list)
    removed_count = len(removed)
    
    logger.info(f"‚úÖ Evolution cycle completed:")
    logger.info(f"   - Evolved: {evolved_count}")
    logger.info(f"   - Specialized: {specialized_count}")
    logger.info(f"   - Removed: {removed_count}")


if __name__ == "__main__":
    asyncio.run(run_enhanced_evolution_cycle())

