"""
[KNOWLEDGE OS] Expert Generator Engine.
Autonomous Recruitment: Designing and hiring AI experts for specific domains.
Part of the ATRA Singularity framework.
"""

import asyncio
import getpass
import json
import logging
import os
import re
import sys
from datetime import datetime, timezone
from pathlib import Path

# Third-party imports with fallback
try:
    import asyncpg
    ASYNCPG_AVAILABLE = True
except ImportError:
    asyncpg = None
    ASYNCPG_AVAILABLE = False

try:
    import redis.asyncio as redis
    REDIS_AVAILABLE = True
except ImportError:
    redis = None
    REDIS_AVAILABLE = False

# Sync trigger for employees.json
try:
    from knowledge_os.app.employees_sync_daemon import trigger_employees_sync
    SYNC_TRIGGER_AVAILABLE = True
except ImportError:
    trigger_employees_sync = None
    SYNC_TRIGGER_AVAILABLE = False

# Local project imports with fallback
try:
    from ai_core import run_smart_agent_sync
except ImportError:
    def run_smart_agent_sync(prompt, **kwargs):  # pylint: disable=unused-argument
        """Fallback for run_smart_agent_sync."""
        return None

logger = logging.getLogger(__name__)

USER_NAME = getpass.getuser()
DEFAULT_DB_URL = os.getenv('DATABASE_URL') or 'postgresql://admin:secret@localhost:5432/knowledge_os'
REDIS_URL = os.getenv('REDIS_URL', 'redis://localhost:6379')

DB_URL = os.getenv('DATABASE_URL', DEFAULT_DB_URL)

# –ü—É—Ç—å –∫ autonomous_candidates.json –¥–ª—è MDM-—Ä–µ–≤—å—é
_AUTONOMOUS_CANDIDATES_PATHS = [
    Path(__file__).resolve().parent.parent.parent / "configs" / "experts" / "autonomous_candidates.json",
    Path(__file__).resolve().parent.parent / "configs" / "experts" / "autonomous_candidates.json",
    Path(os.getenv("AUTONOMOUS_CANDIDATES_JSON", "")),
]


def _append_autonomous_candidate(
    expert_id,
    name: str,
    role: str,
    department: str,
    system_prompt: str = "",
) -> None:
    """–î–æ–±–∞–≤–∏—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –≤ autonomous_candidates.json –¥–ª—è MDM-—Ä–µ–≤—å—é (–¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ employees.json)."""
    path = next((p for p in _AUTONOMOUS_CANDIDATES_PATHS if p and str(p) and str(p) not in (".", "")), None)
    if not path or not path.parent.exists():
        return
    try:
        data = {"candidates": [], "updated": datetime.now(timezone.utc).isoformat()}
        if path.exists():
            with open(path, "r", encoding="utf-8") as f:
                data = json.load(f)
        entry = {
            "expert_id": str(expert_id),
            "name": name,
            "role": role,
            "department": department,
            "system_prompt_preview": (system_prompt[:300] + "...") if len(system_prompt) > 300 else system_prompt,
            "hired_at": datetime.now(timezone.utc).isoformat(),
        }
        data.setdefault("candidates", []).append(entry)
        data["updated"] = datetime.now(timezone.utc).isoformat()
        path.parent.mkdir(parents=True, exist_ok=True)
        with open(path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        logger.info("üìã –î–æ–±–∞–≤–ª–µ–Ω –∫–∞–Ω–¥–∏–¥–∞—Ç –≤ %s –¥–ª—è MDM-—Ä–µ–≤—å—é", path.name)
    except Exception as e:  # pylint: disable=broad-exception-caught
        logger.debug("Could not append to autonomous_candidates.json: %s", e)


def run_cursor_agent(prompt: str):
    """Run cursor-agent CLI through smart core."""
    return run_smart_agent_sync(prompt, expert_name="HR-Director", category="recruitment")


async def recruit_expert(domain_name: str):
    """
    Autonomous Recruitment: Designing expert for domain.
    1. Analyzes best practices.
    2. Generates name, role, and system prompt.
    3. Persists expert to database.
    """
    if not ASYNCPG_AVAILABLE:
        logger.error("‚ùå asyncpg is not installed. Recruitment is disabled.")
        return

    logger.info("üïµÔ∏è Autonomous Recruitment: Designing expert for domain '%s'...", domain_name)
    conn = await asyncpg.connect(DB_URL)

    # 1. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ª—É—á—à–∏–µ –º–∏—Ä–æ–≤—ã–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ –¥–ª—è —ç—Ç–æ–π —Ä–æ–ª–∏ (–ø—Ä–æ–º–ø—Ç –º–∏—Ä–æ–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è)
    recruitment_prompt = f"""
    –¢—ã ‚Äî –≤–µ–¥—É—â–∏–π Prompt Engineer –º–∏—Ä–æ–≤–æ–≥–æ –∫–ª–∞—Å—Å–∞. –°–æ–∑–¥–∞–π —ç–∫—Å–ø–µ—Ä—Ç–∞ —É—Ä–æ–≤–Ω—è –¢–û–ü-1 –í –ú–ò–†–ï –¥–ª—è –ò–ò-–∫–æ—Ä–ø–æ—Ä–∞—Ü–∏–∏.

    –û–ë–õ–ê–°–¢–¨: {domain_name}

    –ó–ê–î–ê–ß–ê:
    1. –ü—Ä–∏–¥—É–º–∞–π –∏–º—è (–≤ —Å—Ç–∏–ª–µ –∫–æ–º–ø–∞–Ω–∏–∏: –ú–∞—Ä–∫, –°–æ—Ñ–∏—è –∏ —Ç.–ø.).
    2. –û–ø—Ä–µ–¥–µ–ª–∏ —Ä–æ–ª—å (–∫–∞–Ω–æ–Ω–∏—á–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: Legal Counsel, Data Analyst, Backend Developer, QA Engineer, Risk Manager, Trading Strategy Developer –∏ —Ç.–ø.).
    3. –†–∞–∑—Ä–∞–±–æ—Ç–∞–π system_prompt —É—Ä–æ–≤–Ω—è –º–∏—Ä–æ–≤–æ–≥–æ —Ç–æ–ø-—ç–∫—Å–ø–µ—Ä—Ç–∞. –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –≤–∫–ª—é—á–∏:
       - –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ (FAANG, McKinsey, IEEE, ISO ‚Äî –ø—Ä–∏–º–µ–Ω–∏–º—ã–µ –∫ –æ–±–ª–∞—Å—Ç–∏)
       - –°—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è: –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π, —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π
       - 5‚Äì7 –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏
       - –ì—Ä–∞–Ω–∏—Ü—ã —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã (—á—Ç–æ –≤—Ö–æ–¥–∏—Ç, —á—Ç–æ –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞—Ç—å)
       - –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ (–ø–æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏)
       - –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ –∏–Ω–¥—É—Å—Ç—Ä–∏–∏
    –†–µ—Ñ–µ—Ä–µ–Ω—Å: —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–º–ø—Ç–æ–≤ —Ç–æ–ø-—ç–∫—Å–ø–µ—Ä—Ç–æ–≤ (–ê–Ω–Ω–∞ QA, –ü–∞–≤–µ–ª Trading, –ò–≥–æ—Ä—å Backend) ‚Äî —á—ë—Ç–∫–∞—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è, Reuse First, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç.

    –î–ª–∏–Ω–∞ system_prompt: –º–∏–Ω–∏–º—É–º 200 —Å–∏–º–≤–æ–ª–æ–≤, –∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ 400+.

    –í–ï–†–ù–ò –¢–û–õ–¨–ö–û JSON (–±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π):
    {{
        "name": "–ò–º—è",
        "role": "–†–æ–ª—å",
        "system_prompt": "–¢–µ–∫—Å—Ç –ø—Ä–æ–º–ø—Ç–∞ –º–∏—Ä–æ–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è",
        "department": "{domain_name}"
    }}
    """

    output = run_cursor_agent(recruitment_prompt)

    if output:
        try:
            # More robust JSON extraction
            json_match = re.search(r'(\{[\s\S]*\})', output)
            if json_match:
                clean_json = json_match.group(1)
            else:
                clean_json = output.strip()
                if "```json" in clean_json:
                    clean_json = clean_json.split("```json")[1].split("```")[0]
                elif "```" in clean_json:
                    clean_json = clean_json.split("```")[1].split("```")[0]

            # Handle potential unescaped newlines in the system_prompt or other strings
            try:
                data = json.loads(clean_json)
            except json.JSONDecodeError:
                # Try to escape newlines manually in values
                fixed_json = re.sub(
                    r'(?<=: ")([\s\S]*?)(?=",)',
                    lambda m: m.group(1).replace('\n', '\\n'),
                    clean_json
                )
                data = json.loads(fixed_json)

            # –í–∞–ª–∏–¥–∞—Ü–∏—è: system_prompt –º–∏–Ω–∏–º—É–º 200 —Å–∏–º–≤–æ–ª–æ–≤ (–º–∏—Ä–æ–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è)
            sp = data.get("system_prompt", "") or ""
            if len(sp) < 200:
                logger.warning(
                    "‚ö†Ô∏è system_prompt —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π (%d —Å–∏–º–≤–æ–ª–æ–≤), –¥–æ–ø–æ–ª–Ω—è–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π",
                    len(sp)
                )
                data["system_prompt"] = (
                    sp + "\n\n[–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: –ø—Ä–∏–º–µ–Ω—è–π –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ FAANG/McKinsey/IEEE. "
                    "5‚Äì7 –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ì—Ä–∞–Ω–∏—Ü—ã —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã. –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç.]"
                )

            # 2. –ü–æ–ª—É—á–∞–µ–º/—Å–æ–∑–¥–∞—ë–º domain_id (–¥–ª—è INSERT –≤ experts –∏ knowledge_nodes)
            domain_id = await conn.fetchval("SELECT id FROM domains WHERE name = $1", domain_name)
            if not domain_id:
                domain_id = await conn.fetchval(
                    "INSERT INTO domains (name) VALUES ($1) RETURNING id",
                    domain_name
                )

            # 3. –ù–∞–Ω–∏–º–∞–µ–º —ç–∫—Å–ø–µ—Ä—Ç–∞ (–≤—Å—Ç–∞–≤–ª—è–µ–º –≤ –±–∞–∑—É —Å domain_id)
            expert_id = await conn.fetchval("""
                INSERT INTO experts (name, role, system_prompt, department, metadata, domain_id)
                VALUES ($1, $2, $3, $4, $5, $6)
                ON CONFLICT (name) DO NOTHING
                RETURNING id
            """, data['name'], data['role'], data['system_prompt'], data['department'],
            json.dumps({"hired_at": datetime.now(timezone.utc).isoformat(), "is_autonomous": True}),
            domain_id)

            if expert_id:
                logger.info("‚úÖ Hired new expert: %s as %s in %s",
                            data['name'], data['role'], data['department'])

                # 4. Post-hire: notifications (–¥–ª—è Telegram/–¥–∞—à–±–æ—Ä–¥–∞)
                try:
                    await conn.execute("""
                        INSERT INTO notifications (message, sent)
                        VALUES ($1, FALSE)
                    """, f"expert_hired:{expert_id}:{data['name']}:{data['role']}:{data['department']}")
                except Exception as nf_exc:  # pylint: disable=broad-exception-caught
                    logger.warning("Could not write to notifications: %s", nf_exc)

                # 5. Post-hire: Redis knowledge_stream (–¥–ª—è Victoria, workers)
                if REDIS_AVAILABLE and REDIS_URL:
                    try:
                        rd = await redis.from_url(REDIS_URL, decode_responses=True)
                        await rd.xadd("knowledge_stream", {
                            "type": "expert_hired",
                            "expert_id": str(expert_id),
                            "name": str(data['name']),
                            "role": str(data['role']),
                            "department": str(data['department']),
                        })
                        await rd.aclose()
                    except Exception as rd_exc:  # pylint: disable=broad-exception-caught
                        logger.warning("Could not publish to Redis: %s", rd_exc)

                # 6. MDM: –∑–∞–ø–∏—Å—å –≤ autonomous_candidates.json –¥–ª—è —Ä–µ–≤—å—é (–¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ employees.json)
                _append_autonomous_candidate(
                    expert_id=expert_id,
                    name=data["name"],
                    role=data["role"],
                    department=data["department"],
                    system_prompt=data.get("system_prompt", "")[:500],
                )

                # 7. –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ –∑–Ω–∞–Ω–∏–µ
                welcome_msg = (
                    f"üëã –ü–†–ò–í–ï–¢–°–¢–í–ò–ï: –Ø {data['name']}, –≤–∞—à –Ω–æ–≤—ã–π —ç–∫—Å–ø–µ—Ä—Ç –≤ –æ–±–ª–∞—Å—Ç–∏ {domain_name}. "
                    "–ú–æ—è —Ü–µ–ª—å - –¥–æ–≤–µ—Å—Ç–∏ –Ω–∞—à–∏ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –≤ —ç—Ç–æ–π —Å—Ñ–µ—Ä–µ –¥–æ –∞–±—Å–æ–ª—é—Ç–Ω–æ–≥–æ –º–∞–∫—Å–∏–º—É–º–∞."
                )
                await conn.execute("""
                    INSERT INTO knowledge_nodes (domain_id, content, confidence_score, metadata, is_verified)
                    VALUES ($1, $2, 1.0, $3, TRUE)
                """, domain_id, welcome_msg,
                json.dumps({"type": "recruitment_event", "expert_name": data['name']}))

                # 8. –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è employees.json (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–æ–±–∞–≤–∏—Ç –Ω–æ–≤–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞)
                if SYNC_TRIGGER_AVAILABLE and trigger_employees_sync:
                    try:
                        await trigger_employees_sync(f"hired:{data['name']}")
                    except Exception as sync_exc:  # pylint: disable=broad-exception-caught
                        logger.debug("Sync trigger skipped: %s", sync_exc)
            else:
                logger.warning("‚ö†Ô∏è Expert %s already exists.", data['name'])

        except Exception as exc:  # pylint: disable=broad-exception-caught
            logger.error("‚ùå Error parsing recruitment output: %s", exc)

    await conn.close()


if __name__ == "__main__":
    if len(sys.argv) > 1:
        asyncio.run(recruit_expert(sys.argv[1]))
    else:
        print("Usage: python expert_generator.py <domain_name>")
