"""
ReCAP Framework - Recursive Context-Aware Reasoning and Planning
–û—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ Meta ReCAP: +32% —É–ª—É—á—à–µ–Ω–∏–µ –Ω–∞ multi-step reasoning
"""

import os
import asyncio
import logging
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timezone
from enum import Enum

logger = logging.getLogger(__name__)

OLLAMA_URL = os.getenv('OLLAMA_BASE_URL', 'http://localhost:11434')
# –§–∞–∑–∞ 3 –ø–ª–∞–Ω–∞ ¬´–õ–æ–≥–∏–∫–∞ –º—ã—Å–ª–∏¬ª: —á–µ–∫–ø–æ–∏–Ω—Ç—ã —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏ –∏ –ø–µ—Ä–µ—Å–º–æ—Ç—Ä –ø–ª–∞–Ω–∞
VICTORIA_REFLECTION_ENABLED = os.getenv('VICTORIA_REFLECTION_ENABLED', 'true').lower() in ('1', 'true', 'yes')
VICTORIA_MAX_PLAN_REVISIONS = max(0, min(3, int(os.getenv('VICTORIA_MAX_PLAN_REVISIONS', '1'))))


class PlanningLevel(Enum):
    """–£—Ä–æ–≤–Ω–∏ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è"""
    HIGH_LEVEL = "high_level"  # –í—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
    MID_LEVEL = "mid_level"   # –°—Ä–µ–¥–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å
    LOW_LEVEL = "low_level"   # –î–µ—Ç–∞–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ


@dataclass
class PlanStep:
    """–û–¥–∏–Ω —à–∞–≥ –ø–ª–∞–Ω–∞"""
    step_id: int
    description: str
    level: PlanningLevel
    dependencies: List[int] = field(default_factory=list)
    status: str = "pending"  # pending, executing, completed, failed
    result: Optional[Any] = None
    context: Dict = field(default_factory=dict)


@dataclass
class ReCAPPlan:
    """–ü–ª–∞–Ω ReCAP"""
    goal: str
    high_level_steps: List[PlanStep] = field(default_factory=list)
    mid_level_steps: List[PlanStep] = field(default_factory=list)
    low_level_steps: List[PlanStep] = field(default_factory=list)
    context_history: List[Dict] = field(default_factory=list)
    current_step: Optional[int] = None


class ReCAPFramework:
    """
    ReCAP Framework - Recursive Context-Aware Reasoning and Planning
    
    –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:
    1. Plan-ahead decomposition - –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è –∑–∞–¥–∞—á–∏ –Ω–∞ —É—Ä–æ–≤–Ω–∏
    2. Structured context re-injection - —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ä–µ–∏–Ω—ä–µ–∫—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    3. Memory-efficient execution - —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
    """
    
    def __init__(
        self,
        model_name: str = "phi3.5:3.8b",
        ollama_url: str = OLLAMA_URL,
        reflection_enabled: bool = VICTORIA_REFLECTION_ENABLED,
        max_plan_revisions: int = VICTORIA_MAX_PLAN_REVISIONS,
    ):
        self.model_name = model_name
        self.ollama_url = ollama_url
        self.reflection_enabled = reflection_enabled
        self.max_plan_revisions = max_plan_revisions
    
    async def solve(
        self,
        goal: str,
        initial_context: Optional[Dict] = None
    ) -> Dict:
        """
        –†–µ—à–∏—Ç—å –∑–∞–¥–∞—á—É –∏—Å–ø–æ–ª—å–∑—É—è ReCAP Framework
        
        Args:
            goal: –¶–µ–ª—å –∑–∞–¥–∞—á–∏
            initial_context: –ù–∞—á–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç —Å –ø–ª–∞–Ω–æ–º –∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ–º
        """
        logger.info(f"üöÄ ReCAP: –ù–∞—á–∏–Ω–∞—é —Ä–µ—à–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏: {goal[:80]}")
        context = dict(initial_context) if initial_context else {}
        revision_count = 0

        while True:
            # 1. Plan-ahead decomposition (–ø—Ä–∏ –ø–µ—Ä–µ—Å–º–æ—Ç—Ä–µ ‚Äî —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø—Ä–µ–¥—ã–¥—É—â–µ–π –Ω–µ—É–¥–∞—á–∏)
            plan = await self._decompose_goal(goal, context if context else None)

            # 2. Structured context re-injection –∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ (—Å —á–µ–∫–ø–æ–∏–Ω—Ç–∞–º–∏ —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏)
            results, should_replan, failure_info = await self._execute_plan(plan, revision_count)

            if should_replan and failure_info and revision_count < self.max_plan_revisions:
                revision_count += 1
                context["previous_plan_failure"] = failure_info
                logger.info(f"üîÑ ReCAP: –ø–µ—Ä–µ—Å–º–æ—Ç—Ä –ø–ª–∞–Ω–∞ (–ø–æ–ø—ã—Ç–∫–∞ {revision_count}), –ø—Ä–∏—á–∏–Ω–∞: {failure_info.get('reason', '')[:100]}")
                continue

            # 3. –°–∏–Ω—Ç–µ–∑ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            final_result = await self._synthesize_result(plan, results)
            return {
                "goal": goal,
                "plan": plan,
                "results": results,
                "final_result": final_result,
                "method": "recap",
                "plan_revisions": revision_count,
            }
    
    async def _decompose_goal(
        self,
        goal: str,
        context: Optional[Dict]
    ) -> ReCAPPlan:
        """–î–µ–∫–æ–º–ø–æ–∑–∏—Ä–æ–≤–∞—Ç—å —Ü–µ–ª—å –Ω–∞ —É—Ä–æ–≤–Ω–∏ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è"""
        
        # 1. High-level planning
        high_level_prompt = self._build_high_level_prompt(goal, context)
        high_level_response = await self._generate_response(high_level_prompt)
        high_level_steps = self._parse_planning_steps(high_level_response, PlanningLevel.HIGH_LEVEL)
        
        logger.info(f"üìã High-level: {len(high_level_steps)} —à–∞–≥–æ–≤")
        
        # 2. Mid-level planning –¥–ª—è –∫–∞–∂–¥–æ–≥–æ high-level —à–∞–≥–∞
        mid_level_steps = []
        for hl_step in high_level_steps:
            mid_prompt = self._build_mid_level_prompt(goal, hl_step, context)
            mid_response = await self._generate_response(mid_prompt)
            mid_steps = self._parse_planning_steps(mid_response, PlanningLevel.MID_LEVEL, parent_id=hl_step.step_id)
            mid_level_steps.extend(mid_steps)
            hl_step.dependencies = [s.step_id for s in mid_steps]
        
        logger.info(f"üìã Mid-level: {len(mid_level_steps)} —à–∞–≥–æ–≤")
        
        # 3. Low-level planning –¥–ª—è –∫–∞–∂–¥–æ–≥–æ mid-level —à–∞–≥–∞
        low_level_steps = []
        for ml_step in mid_level_steps:
            low_prompt = self._build_low_level_prompt(goal, ml_step, context)
            low_response = await self._generate_response(low_prompt)
            low_steps = self._parse_planning_steps(low_response, PlanningLevel.LOW_LEVEL, parent_id=ml_step.step_id)
            low_level_steps.extend(low_steps)
            ml_step.dependencies = [s.step_id for s in low_steps]
        
        logger.info(f"üìã Low-level: {len(low_level_steps)} —à–∞–≥–æ–≤")
        
        return ReCAPPlan(
            goal=goal,
            high_level_steps=high_level_steps,
            mid_level_steps=mid_level_steps,
            low_level_steps=low_level_steps
        )
    
    def _is_step_failed_or_empty(self, result: Any) -> bool:
        """–§–∞–∑–∞ 3: —Å—á–∏—Ç–∞—Ç—å —à–∞–≥ –ø—Ä–æ–≤–∞–ª—å–Ω—ã–º –ø—Ä–∏ –ø—É—Å—Ç–æ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –∏–ª–∏ —è–≤–Ω–æ–π –æ—à–∏–±–∫–µ."""
        if result is None:
            return True
        s = (str(result) or "").strip().lower()
        if not s:
            return True
        for kw in ("–æ—à–∏–±–∫–∞", "error", "failed", "–Ω–µ —É–¥–∞–ª–æ—Å—å", "–Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å", "exception"):
            if kw in s:
                return True
        return False

    async def _should_revise_plan(
        self, goal: str, plan_summary: str, step_description: str, step_result: Any
    ) -> Tuple[bool, str]:
        """–§–∞–∑–∞ 3: –æ–¥–∏–Ω –≤—ã–∑–æ–≤ LLM ‚Äî –ø–µ—Ä–µ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–ª–∞–Ω? –¥–∞/–Ω–µ—Ç –∏ –ø—Ä–∏—á–∏–Ω–∞. –ü—Ä–∏ –æ—à–∏–±–∫–µ ‚Äî (False, '')."""
        try:
            import httpx
            prompt = f"""–ó–∞–¥–∞—á–∞: {goal[:300]}
–ü–ª–∞–Ω (–∫—Ä–∞—Ç–∫–æ): {plan_summary[:400]}
–®–∞–≥, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–æ–≤–∞–ª–∏–ª—Å—è –∏–ª–∏ –¥–∞–ª –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {step_description[:200]}
–†–µ–∑—É–ª—å—Ç–∞—Ç —à–∞–≥–∞: {str(step_result)[:300]}

–ù—É–∂–Ω–æ –ª–∏ –ø–µ—Ä–µ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–ª–∞–Ω —Å —É—á—ë—Ç–æ–º —ç—Ç–æ–≥–æ –ø—Ä–æ–≤–∞–ª–∞? –û—Ç–≤–µ—Ç—å —Å—Ç—Ä–æ–≥–æ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π: –î–ê <–ø—Ä–∏—á–∏–Ω–∞> –∏–ª–∏ –ù–ï–¢."""
            async with httpx.AsyncClient(timeout=15.0) as client:
                r = await client.post(
                    f"{self.ollama_url}/api/generate",
                    json={"model": self.model_name, "prompt": prompt, "stream": False, "options": {"num_predict": 150}}
                )
                if r.status_code != 200:
                    return False, ""
                text = (r.json().get("response") or "").strip().upper()
                if "–î–ê" in text[:10] or text.startswith("YES"):
                    reason = text.replace("–î–ê", "").replace("YES", "").strip()[:200]
                    return True, reason or "–ø—Ä–æ–≤–∞–ª —à–∞–≥–∞"
                return False, ""
        except Exception as e:
            logger.debug("ReCAP _should_revise_plan: %s", e)
            return False, ""

    async def _execute_plan(
        self, plan: ReCAPPlan, revision_count: int = 0
    ) -> Tuple[Dict[int, Any], bool, Optional[Dict]]:
        """–í—ã–ø–æ–ª–Ω–∏—Ç—å –ø–ª–∞–Ω —Å structured context re-injection. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (results, should_replan, failure_info)."""
        results: Dict[int, Any] = {}
        context_history: List[Dict] = []
        plan_summary = "; ".join(s.description[:80] for s in plan.low_level_steps[:8])

        for hl_step in plan.high_level_steps:
            context = self._build_context(plan, hl_step, context_history, results=results)
            mid_steps = [s for s in plan.mid_level_steps if s.step_id in hl_step.dependencies]

            for ml_step in mid_steps:
                ml_context = self._build_context(
                    plan, ml_step, context_history, parent_context=context, results=results
                )
                low_steps = [s for s in plan.low_level_steps if s.step_id in ml_step.dependencies]

                for ll_step in low_steps:
                    ll_context = self._build_context(
                        plan, ll_step, context_history,
                        parent_context=ml_context,
                        grandparent_context=context,
                        results=results
                    )
                    result = await self._execute_step(ll_step, ll_context)
                    results[ll_step.step_id] = result
                    ll_step.result = result

                    if self._is_step_failed_or_empty(result) and self.reflection_enabled and revision_count < self.max_plan_revisions:
                        revise, reason = await self._should_revise_plan(
                            plan.goal, plan_summary, ll_step.description, result
                        )
                        if revise:
                            ll_step.status = "failed"
                            failure_info = {
                                "step_id": ll_step.step_id,
                                "step_description": ll_step.description,
                                "result": str(result)[:500],
                                "reason": reason or "–ø—Ä–æ–≤–∞–ª —à–∞–≥–∞",
                            }
                            return results, True, failure_info

                    ll_step.status = "completed"
                    context_history.append({
                        "step_id": ll_step.step_id,
                        "level": ll_step.level.value,
                        "context": ll_context,
                        "result": result,
                        "timestamp": datetime.now(timezone.utc)
                    })

                ml_result = self._aggregate_results([results[s.step_id] for s in low_steps])
                results[ml_step.step_id] = ml_result
                ml_step.status = "completed"
                ml_step.result = ml_result

            hl_result = self._aggregate_results([results[s.step_id] for s in mid_steps])
            results[hl_step.step_id] = hl_result
            hl_step.status = "completed"
            hl_step.result = hl_result

        return results, False, None
    
    def _build_context(
        self,
        plan: ReCAPPlan,
        step: PlanStep,
        context_history: List[Dict],
        parent_context: Optional[Dict] = None,
        grandparent_context: Optional[Dict] = None,
        results: Optional[Dict[int, Any]] = None
    ) -> Dict:
        """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å —Ä–µ–∏–Ω—ä–µ–∫—Ü–∏–µ–π.

        –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω results (—Å–ª–æ–≤–∞—Ä—å step_id -> —Ä–µ–∑—É–ª—å—Ç–∞—Ç), –≤ –±–ª–æ–∫ dependencies
        –ø–æ–¥—Å—Ç–∞–≤–ª—è—é—Ç—Å—è —Ä–µ–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö —à–∞–≥–æ–≤; –∏–Ω–∞—á–µ ‚Äî "pending".
        """
        context = {
            "goal": plan.goal,
            "current_step": step.description,
            "step_level": step.level.value,
            "step_id": step.step_id
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        if parent_context:
            context["parent_context"] = parent_context
        
        if grandparent_context:
            context["grandparent_context"] = grandparent_context
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é (—Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —à–∞–≥–æ–≤ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–∞–º—è—Ç–∏)
        relevant_history = context_history[-5:]  # Memory-efficient: —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5
        context["recent_history"] = relevant_history
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (—Ä–µ–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ results, –µ—Å–ª–∏ –µ—Å—Ç—å)
        if step.dependencies:
            context["dependencies"] = [
                {
                    "step_id": dep_id,
                    "result": results.get(dep_id, "pending") if results is not None else "pending"
                }
                for dep_id in step.dependencies
            ]
        
        return context
    
    async def _execute_step(self, step: PlanStep, context: Dict) -> Any:
        """–í—ã–ø–æ–ª–Ω–∏—Ç—å –æ–¥–∏–Ω —à–∞–≥ –ø–ª–∞–Ω–∞"""
        logger.info(f"üîÑ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —à–∞–≥–∞ {step.step_id}: {step.description[:50]}")
        
        # –°—Ç—Ä–æ–∏–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        prompt = f"""–í—ã–ø–æ–ª–Ω–∏ —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥ –ø–ª–∞–Ω–∞:

–®–ê–ì: {step.description}
–ö–û–ù–¢–ï–ö–°–¢: {context}

–í—ã–ø–æ–ª–Ω–∏ –¥–µ–π—Å—Ç–≤–∏–µ –∏ –≤–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç."""
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å
        result = await self._generate_response(prompt)
        
        return result
    
    def _aggregate_results(self, results: List[Any]) -> Any:
        """–ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —à–∞–≥–æ–≤"""
        # –ü—Ä–æ—Å—Ç–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è - –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if not results:
            return None
        
        if len(results) == 1:
            return results[0]
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        aggregated = "\n".join([str(r) for r in results])
        return aggregated
    
    async def _synthesize_result(self, plan: ReCAPPlan, results: Dict[int, Any]) -> str:
        """–°–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑ –≤—Å–µ—Ö —à–∞–≥–æ–≤"""
        # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã high-level —à–∞–≥–æ–≤
        high_level_results = [
            results[step.step_id]
            for step in plan.high_level_steps
            if step.step_id in results
        ]
        
        # –°—Ç—Ä–æ–∏–º –ø—Ä–æ–º–ø—Ç –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞
        prompt = f"""–°–∏–Ω—Ç–µ–∑–∏—Ä—É–π —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–ª–∞–Ω–∞:

–¶–ï–õ–¨: {plan.goal}

–†–ï–ó–£–õ–¨–¢–ê–¢–´ –í–´–°–û–ö–û–£–†–û–í–ù–ï–í–´–• –®–ê–ì–û–í:
"""
        for i, (step, result) in enumerate(zip(plan.high_level_steps, high_level_results), 1):
            prompt += f"\n{i}. {step.description}\n   –†–µ–∑—É–ª—å—Ç–∞—Ç: {result}\n"
        
        prompt += "\n–§–ò–ù–ê–õ–¨–ù–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢:"
        
        final_result = await self._generate_response(prompt)
        return final_result
    
    def _build_high_level_prompt(self, goal: str, context: Optional[Dict]) -> str:
        """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –ø—Ä–æ–º–ø—Ç –¥–ª—è high-level –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è"""
        prompt = f"""–†–∞–∑–±–µ–π –∑–∞–¥–∞—á—É –Ω–∞ –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–µ —à–∞–≥–∏ (3-5 —à–∞–≥–æ–≤):

–ó–ê–î–ê–ß–ê: {goal}

"""
        if context:
            prev = context.get("previous_plan_failure")
            if isinstance(prev, dict):
                prompt += f"–ü–†–ï–î–´–î–£–©–ê–Ø –ü–û–ü–´–¢–ö–ê –ù–ï –£–î–ê–õ–ê–°–¨ (—É—á—Ç–∏ –ø—Ä–∏ –Ω–æ–≤–æ–º –ø–ª–∞–Ω–µ): —à–∞–≥ ¬´{prev.get('step_description', '')[:150]}¬ª ‚Äî {prev.get('reason', '–ø—Ä–æ–≤–∞–ª')}. –ò–∑–±–µ–≥–∞–π –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è.\n\n"
            prompt += f"–ö–û–ù–¢–ï–ö–°–¢: {context}\n\n"
        
        prompt += """–°–æ–∑–¥–∞–π –ø–ª–∞–Ω –∏–∑ –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã—Ö —à–∞–≥–æ–≤. –ö–∞–∂–¥—ã–π —à–∞–≥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å:
1. –ß–µ—Ç–∫–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω
2. –ù–µ–∑–∞–≤–∏—Å–∏–º –æ—Ç –¥—Ä—É–≥–∏—Ö (–≥–¥–µ –≤–æ–∑–º–æ–∂–Ω–æ)
3. –í–µ–¥–µ—Ç –∫ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—é —Ü–µ–ª–∏

–§–û–†–ú–ê–¢:
1. [–û–ø–∏—Å–∞–Ω–∏–µ —à–∞–≥–∞ 1]
2. [–û–ø–∏—Å–∞–Ω–∏–µ —à–∞–≥–∞ 2]
...

–í–´–°–û–ö–û–£–†–û–í–ù–ï–í–´–ô –ü–õ–ê–ù:"""
        
        return prompt
    
    def _build_mid_level_prompt(self, goal: str, high_level_step: PlanStep, context: Optional[Dict]) -> str:
        """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –ø—Ä–æ–º–ø—Ç –¥–ª—è mid-level –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è"""
        prompt = f"""–†–∞–∑–±–µ–π –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π —à–∞–≥ –Ω–∞ —Å—Ä–µ–¥–Ω–∏–µ —à–∞–≥–∏ (2-4 —à–∞–≥–∞):

–¶–ï–õ–¨: {goal}
–í–´–°–û–ö–û–£–†–û–í–ù–ï–í–´–ô –®–ê–ì: {high_level_step.description}

"""
        if context:
            prompt += f"–ö–û–ù–¢–ï–ö–°–¢: {context}\n\n"
        
        prompt += """–°–æ–∑–¥–∞–π —Å—Ä–µ–¥–Ω–∏–µ —à–∞–≥–∏ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç—Ç–æ–≥–æ –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤–æ–≥–æ —à–∞–≥–∞.

–§–û–†–ú–ê–¢:
1. [–û–ø–∏—Å–∞–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ —à–∞–≥–∞ 1]
2. [–û–ø–∏—Å–∞–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ —à–∞–≥–∞ 2]
...

–°–†–ï–î–ù–ò–ï –®–ê–ì–ò:"""
        
        return prompt
    
    def _build_low_level_prompt(self, goal: str, mid_level_step: PlanStep, context: Optional[Dict]) -> str:
        """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –ø—Ä–æ–º–ø—Ç –¥–ª—è low-level –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è"""
        prompt = f"""–†–∞–∑–±–µ–π —Å—Ä–µ–¥–Ω–∏–π —à–∞–≥ –Ω–∞ –¥–µ—Ç–∞–ª—å–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è (1-3 –¥–µ–π—Å—Ç–≤–∏—è):

–¶–ï–õ–¨: {goal}
–°–†–ï–î–ù–ò–ô –®–ê–ì: {mid_level_step.description}

"""
        if context:
            prompt += f"–ö–û–ù–¢–ï–ö–°–¢: {context}\n\n"
        
        prompt += """–°–æ–∑–¥–∞–π –¥–µ—Ç–∞–ª—å–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç—Ç–æ–≥–æ —Å—Ä–µ–¥–Ω–µ–≥–æ —à–∞–≥–∞.

–§–û–†–ú–ê–¢:
1. [–î–µ—Ç–∞–ª—å–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ 1]
2. [–î–µ—Ç–∞–ª—å–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ 2]
...

–î–ï–¢–ê–õ–¨–ù–´–ï –î–ï–ô–°–¢–í–ò–Ø:"""
        
        return prompt
    
    def _parse_planning_steps(
        self,
        response: str,
        level: PlanningLevel,
        parent_id: Optional[int] = None
    ) -> List[PlanStep]:
        """–ü–∞—Ä—Å–∏—Ç—å —à–∞–≥–∏ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑ –æ—Ç–≤–µ—Ç–∞"""
        import re
        
        steps = []
        # –ò—â–µ–º –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —à–∞–≥–∏
        pattern = r'(\d+)\.\s*(.+?)(?=\d+\.|$)'
        matches = re.finditer(pattern, response, re.DOTALL)
        
        step_id_base = {
            PlanningLevel.HIGH_LEVEL: 1000,
            PlanningLevel.MID_LEVEL: 2000,
            PlanningLevel.LOW_LEVEL: 3000
        }.get(level, 0)
        
        for i, match in enumerate(matches, 1):
            step_num = int(match.group(1))
            description = match.group(2).strip()
            
            step = PlanStep(
                step_id=step_id_base + i,
                description=description,
                level=level
            )
            
            if parent_id:
                step.dependencies = [parent_id]
            
            steps.append(step)
        
        return steps
    
    async def _generate_response(self, prompt: str, max_tokens: int = 2048) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å"""
        import httpx
        
        try:
            async with httpx.AsyncClient(timeout=120.0) as client:
                response = await client.post(
                    f"{self.ollama_url}/api/generate",
                    json={
                        "model": self.model_name,
                        "prompt": prompt,
                        "stream": False,
                        "options": {
                            "temperature": 0.5,
                            "num_predict": max_tokens
                        }
                    }
                )
                
                if response.status_code == 200:
                    return response.json().get('response', '')
                else:
                    logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {response.status_code}")
                    return ""
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ –º–æ–¥–µ–ª–∏: {e}")
            return ""


async def main():
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
    framework = ReCAPFramework(model_name="phi3.5:3.8b")
    
    result = await framework.solve(
        "–°–æ–∑–¥–∞–π —Å–∏—Å—Ç–µ–º—É –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"
    )
    
    print("–†–µ–∑—É–ª—å—Ç–∞—Ç ReCAP:")
    print(f"–¶–µ–ª—å: {result['goal']}")
    print(f"High-level —à–∞–≥–æ–≤: {len(result['plan'].high_level_steps)}")
    print(f"Mid-level —à–∞–≥–æ–≤: {len(result['plan'].mid_level_steps)}")
    print(f"Low-level —à–∞–≥–æ–≤: {len(result['plan'].low_level_steps)}")
    print(f"\n–§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:\n{result['final_result']}")


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    asyncio.run(main())
