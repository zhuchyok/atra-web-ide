import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import os
from datetime import datetime, timezone, timedelta
from database_service import fetch_data

def format_msk(dt):
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç datetime –≤ –º–æ—Å–∫–æ–≤—Å–∫–æ–µ –≤—Ä–µ–º—è (UTC+3)."""
    if dt is None:
        return "N/A"
    if dt.tzinfo is None:
        dt = dt.replace(tzinfo=timezone.utc)
    msk_dt = dt.astimezone(timezone(timedelta(hours=3)))
    return msk_dt.strftime('%d.%m.%Y %H:%M')

def render_data_tab():
    """–í–∫–ª–∞–¥–∫–∞ –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç (RAG) –∏ –ö–∞—á–µ—Å—Ç–≤–æ –ó–Ω–∞–Ω–∏–π."""
    tabs = st.tabs(["üìö AI Research KB", "üìä –¶–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å", "üß† –ö–∞—Ä—Ç–∞ –†–∞–∑—É–º–∞", "üîç –†–µ–≤–∏–∑–∏—è", "ü§ù –°–∏–Ω—Ç–µ–∑ –ó–Ω–∞–Ω–∏–π", "üé® Canvas"])
    
    with tabs[0]:
        render_ai_research_kb()
    with tabs[1]:
        render_data_health()
    with tabs[2]:
        render_mindmap()
    with tabs[3]:
        render_revision()
    with tabs[4]:
        render_synthesis_hub()
    with tabs[5]:
        render_canvas_mode()

def render_canvas_mode():
    """üé® Canvas Mode –¥–ª—è Web IDE (–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã)."""
    st.subheader("üé® Canvas Mode: –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã")
    st.markdown("–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞, –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏ —Å—Ö–µ–º –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏.")
    
    col_chat, col_canvas = st.columns([1, 1])
    
    with col_chat:
        st.markdown("### üí¨ –ß–∞—Ç —Å –í–∏–∫—Ç–æ—Ä–∏–µ–π")
        st.info("–ó–¥–µ—Å—å –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–π –¥–∏–∞–ª–æ–≥.")
        st.text_area("–í–∞—à–∞ –∫–æ–º–∞–Ω–¥–∞", placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: '–£–ª—É—á—à–∏ –∞–ª–≥–æ—Ä–∏—Ç–º RAG'...", height=100)
        st.button("–û—Ç–ø—Ä–∞–≤–∏—Ç—å")
        
    with col_canvas:
        st.markdown("### üñºÔ∏è –ê—Ä—Ç–µ—Ñ–∞–∫—Ç: `rag_optimizer.py`")
        # –ò–º–∏—Ç–∞—Ü–∏—è Canvas
        st.code("""
def optimize_rag(query, nodes):
    # [CANARY] –ù–æ–≤–∞—è –ª–æ–≥–∏–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    filtered = [n for n in nodes if n.score > 0.85]
    return filtered
        """, language="python")
        
        st.markdown("---")
        st.markdown("**üõ†Ô∏è –ë—ã—Å—Ç—Ä—ã–µ –¥–µ–π—Å—Ç–≤–∏—è:**")
        c1, c2, c3 = st.columns(3)
        if c1.button("üß™ –¢–µ—Å—Ç (–ê–Ω–Ω–∞)"):
            st.toast("–ê–Ω–Ω–∞ –∑–∞–ø—É—Å–∫–∞–µ—Ç —Ç–µ—Å—Ç—ã –≤ –ü–µ—Å–æ—á–Ω–∏—Ü–µ...")
        if c2.button("üõ°Ô∏è –°–µ–∫—å—é—Ä–∏—Ç–∏ (–ú–∞–∫—Å–∏–º)"):
            st.toast("–ú–∞–∫—Å–∏–º –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ–¥...")
        if c3.button("üíæ –í –±–∞–∑—É (–ï–ª–µ–Ω–∞)"):
            st.toast("–ï–ª–µ–Ω–∞ –æ–±–Ω–æ–≤–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é...")

def render_synthesis_hub():
    """ü§ù –•–∞–± –°–∏–Ω—Ç–µ–∑–∞ –ó–Ω–∞–Ω–∏–π (Knowledge Synthesis Hub)."""
    st.subheader("ü§ù –•–∞–± –°–∏–Ω—Ç–µ–∑–∞ –ó–Ω–∞–Ω–∏–π")
    st.markdown("–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –º–Ω–µ–Ω–∏–π –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –µ–¥–∏–Ω–æ–≥–æ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞.")
    
    col_q, col_ex = st.columns([2, 1])
    with col_q:
        topic = st.text_input("–¢–µ–º–∞ –¥–ª—è –æ–±—Å—É–∂–¥–µ–Ω–∏—è", placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: '–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è PostgreSQL –¥–ª—è 100–∫ RPS'")
        question = st.text_area("–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –≤–æ–ø—Ä–æ—Å", placeholder="–ö–∞–∫ –ª—É—á—à–µ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –ø—É–ª —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –∏ –∏–Ω–¥–µ–∫—Å—ã?")
    
    with col_ex:
        experts_list = fetch_data("SELECT name FROM experts ORDER BY name")
        expert_names = [e['name'] for e in experts_list] if experts_list else ["–í–∏–∫—Ç–æ—Ä–∏—è", "–ò–≥–æ—Ä—å", "–†–æ–º–∞–Ω", "–ê–Ω–Ω–∞"]
        selected_experts = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ (3-5)", expert_names, default=expert_names[:3])
    
    if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –°–∏–Ω—Ç–µ–∑ –ö–æ–Ω—Å–µ–Ω—Å—É—Å–∞"):
        if not topic or not question or len(selected_experts) < 2:
            st.error("–ó–∞–ø–æ–ª–Ω–∏—Ç–µ —Ç–µ–º—É, –≤–æ–ø—Ä–æ—Å –∏ –≤—ã–±–µ—Ä–∏—Ç–µ –º–∏–Ω–∏–º—É–º 2 —ç–∫—Å–ø–µ—Ä—Ç–æ–≤.")
        else:
            with st.spinner("–≠–∫—Å–ø–µ—Ä—Ç—ã –æ–±—Å—É–∂–¥–∞—é—Ç –ø—Ä–æ–±–ª–µ–º—É..."):
                try:
                    # –ò–º–∏—Ç–∞—Ü–∏—è –≤—ã–∑–æ–≤–∞ ConsensusAgent (–≤ –±—É–¥—É—â–µ–º ‚Äî —Ä–µ–∞–ª—å–Ω—ã–π –≤—ã–∑–æ–≤ —á–µ—Ä–µ–∑ API)
                    # –î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º Victoria Enhanced
                    from app.victoria_enhanced import VictoriaEnhanced
                    victoria = VictoriaEnhanced()
                    
                    prompt = f"""–¢—ã –≤—ã—Å—Ç—É–ø–∞–µ—à—å –∫–∞–∫ –•–∞–± –°–∏–Ω—Ç–µ–∑–∞ –ó–Ω–∞–Ω–∏–π. 
                    –ü—Ä–æ–≤–µ–¥–∏ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–±—Å—É–∂–¥–µ–Ω–∏–µ –º–µ–∂–¥—É —ç–∫—Å–ø–µ—Ä—Ç–∞–º–∏: {', '.join(selected_experts)}.
                    –¢–ï–ú–ê: {topic}
                    –í–û–ü–†–û–°: {question}
                    
                    –í–´–î–ê–ô –ò–¢–û–ì–û–í–´–ô –ö–û–ù–°–ï–ù–°–£–° –ò –£–†–û–í–ï–ù–¨ –°–û–ì–õ–ê–°–ò–Ø (–≤ %).
                    """
                    
                    result = victoria.solve_sync(prompt, method="consensus") if hasattr(victoria, 'solve_sync') else victoria.solve(prompt, method="extended_thinking")
                    # –ï—Å–ª–∏ result ‚Äî –∫–æ—Ä—É—Ç–∏–Ω–∞, –Ω—É–∂–Ω–æ –µ—ë –¥–æ–∂–¥–∞—Ç—å—Å—è (–≤ Streamlit —ç—Ç–æ —Å–ª–æ–∂–Ω–æ –±–µ–∑ asyncio.run)
                    # –ù–æ victoria_enhanced.py –æ–±—ã—á–Ω–æ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π. –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–≥–ª—É—à–∫—É –¥–ª—è UI, –µ—Å–ª–∏ –Ω–µ –º–æ–∂–µ–º –≤—ã–∑–≤–∞—Ç—å –Ω–∞–ø—Ä—è–º—É—é.
                    
                    st.success("‚úÖ –ö–æ–Ω—Å–µ–Ω—Å—É—Å –¥–æ—Å—Ç–∏–≥–Ω—É—Ç!")
                    
                    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —É—Ä–æ–≤–Ω—è —Å–æ–≥–ª–∞—Å–∏—è
                    agreement = 85 # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
                    st.write(f"**–£—Ä–æ–≤–µ–Ω—å —Å–æ–≥–ª–∞—Å–∏—è —ç–∫—Å–ø–µ—Ä—Ç–æ–≤:** {agreement}%")
                    st.progress(agreement / 100)
                    
                    st.markdown("### üìú –ï–¥–∏–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –∫–æ—Ä–ø–æ—Ä–∞—Ü–∏–∏")
                    st.info("–≠—Ç–æ —Ä–µ—à–µ–Ω–∏–µ —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–∞–∑—É–º–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤.")
                    # –ó–¥–µ—Å—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ç–µ–∫—Å—Ç –∏–∑ result
                    st.write("–°–æ–≥–ª–∞—Å–Ω–æ –º–Ω–µ–Ω–∏—é —ç–∫—Å–ø–µ—Ä—Ç–æ–≤, –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è 100–∫ RPS –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –≤–Ω–µ–¥—Ä–∏—Ç—å PgBouncer –≤ —Ä–µ–∂–∏–º–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å shared_buffers –¥–æ 25% RAM –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü –ø–æ –¥–∞—Ç–µ.")
                    
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞: {e}")

def render_ai_research_kb():
    """üìö AI Research Knowledge Base (–ù–æ–≤–æ–µ!)."""
    st.subheader("üìö –ë–∞–∑–∞ –ú—É–¥—Ä–æ—Å—Ç–∏ (AI Research)")
    st.markdown("–ú–∏—Ä–æ–≤—ã–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ –∏ –ø—Ä–æ–º–ø—Ç—ã Anthropic, OpenAI, Google, Perplexity.")
    
    search_ai = st.text_input("üîç –ü–æ–∏—Å–∫ –ø–æ AI Research", placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: 'Claude Code error handling'...")
    
    if search_ai:
        # –ü–æ–∏—Å–∫ –ø–æ –¥–æ–º–µ–Ω—É AI Research
        results = fetch_data("""
            SELECT content, metadata->>'file_path' as path, confidence_score
            FROM knowledge_nodes 
            WHERE (content ILIKE %s OR metadata->>'file_path' ILIKE %s)
            AND domain_id = (SELECT id FROM domains WHERE name = 'AI Research')
            ORDER BY confidence_score DESC LIMIT 10
        """, (f"%{search_ai}%", f"%{search_ai}%"))
        
        if results:
            for r in results:
                with st.expander(f"üìÑ {r['path']} (Conf: {r['confidence_score']:.2f})"):
                    st.markdown(r['content'])
        else:
            st.info("–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ AI Research.")
    else:
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ
        st.markdown("### –ü–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–∞—Ö–æ–¥–∫–∏")
        latest = fetch_data("""
            SELECT content, metadata->>'file_path' as path, created_at
            FROM knowledge_nodes 
            WHERE domain_id = (SELECT id FROM domains WHERE name = 'AI Research')
            ORDER BY created_at DESC LIMIT 5
        """)
        if latest:
            for l in latest:
                st.caption(f"üìå {l['path']} - {format_msk(l['created_at']).split()[0]}")
                st.markdown(f"{(l['content'] or '')[:200]}...")
        else:
            st.info("–ë–∞–∑–∞ AI Research –ø–æ–∫–∞ –ø—É—Å—Ç–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏.")

def render_data_health():
    """üìä –¶–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö (Knowledge OS Health)."""
    st.subheader("üìä –ó–¥–æ—Ä–æ–≤—å–µ –ë–∞–∑—ã –ó–Ω–∞–Ω–∏–π")
    try:
        stats = fetch_data("""
            SELECT 
                COUNT(*) as total,
                COUNT(*) FILTER (WHERE embedding IS NULL) as missing_embeddings,
                COUNT(*) FILTER (WHERE confidence_score < 0.3) as low_confidence
            FROM knowledge_nodes
        """)
        if stats and stats[0]:
            s = stats[0]
            c1, c2, c3 = st.columns(3)
            c1.metric("–í—Å–µ–≥–æ —É–∑–ª–æ–≤", s['total'])
            c2.metric("–ë–µ–∑ –≤–µ–∫—Ç–æ—Ä–æ–≤", s['missing_embeddings'], delta_color="inverse")
            c3.metric("–ù–∏–∑–∫–∏–π Conf", s['low_confidence'], delta_color="inverse")
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∞—É–¥–∏—Ç–∞ –¥–∞–Ω–Ω—ã—Ö: {e}")

def render_mindmap():
    """üß† –ö–∞—Ä—Ç–∞ —Ä–∞–∑—É–º–∞ –∫–æ—Ä–ø–æ—Ä–∞—Ü–∏–∏ (–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–∞—Ñ–∞)."""
    st.subheader("üß† –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ì—Ä–∞—Ñ –ó–Ω–∞–Ω–∏–π")
    
    try:
        import networkx as nx
        import traceback
        from database_service import fetch_data
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–≤—è–∑–∏ –Ω–∞–ø—Ä—è–º—É—é –∏–∑ knowledge_links (fallback –µ—Å–ª–∏ view –ø—É—Å—Ç)
        links = fetch_data("""
            SELECT 
                COALESCE(NULLIF(LEFT(k1.content, 50), ''), 'Node ' || k1.id::text) as source_content, 
                COALESCE(NULLIF(LEFT(k2.content, 50), ''), 'Node ' || k2.id::text) as target_content, 
                l.link_type,
                COALESCE(d1.name, 'Unknown') as source_domain,
                COALESCE(d2.name, 'Unknown') as target_domain
            FROM knowledge_links l
            JOIN knowledge_nodes k1 ON l.source_node_id = k1.id
            JOIN knowledge_nodes k2 ON l.target_node_id = k2.id
            LEFT JOIN domains d1 ON k1.domain_id = d1.id
            LEFT JOIN domains d2 ON k2.domain_id = d2.id
            ORDER BY l.created_at DESC
            LIMIT 50
        """)
        
        if not links:
            st.info("–°–≤—è–∑–∏ –º–µ–∂–¥—É —É–∑–ª–∞–º–∏ –∑–Ω–∞–Ω–∏–π –ø–æ–∫–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∏–ª–∏ –æ–Ω–∏ —É—Å—Ç–∞—Ä–µ–ª–∏ (orphaned). –ó–∞–ø—É—Å—Ç–∏—Ç–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ª–∏–Ω–∫–æ–≤–∞–Ω–∏–µ (Cross-domain Linker).")
            return

        # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ
        G = nx.Graph()
        
        for link in links:
            source = link['source_content']
            target = link['target_content']
            G.add_edge(source, target, type=link['link_type'])
            
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ Plotly (—Ç–∞–∫ –∫–∞–∫ streamlit-agraph –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)
        pos = nx.spring_layout(G, k=0.5, iterations=50)
        
        edge_x = []
        edge_y = []
        for edge in G.edges():
            x0, y0 = pos[edge[0]]
            x1, y1 = pos[edge[1]]
            edge_x.extend([x0, x1, None])
            edge_y.extend([y0, y1, None])

        edge_trace = go.Scatter(
            x=edge_x, y=edge_y,
            line=dict(width=0.5, color='#888'),
            hoverinfo='none',
            mode='lines')

        node_x = []
        node_y = []
        node_text = []
        for node in G.nodes():
            x, y = pos[node]
            node_x.append(x)
            node_y.append(y)
            node_text.append(node)

        node_trace = go.Scatter(
            x=node_x, y=node_y,
            mode='markers+text',
            hoverinfo='text',
            text=node_text,
            textposition="bottom center",
            marker=dict(
                showscale=True,
                colorscale='YlGnBu',
                reversescale=True,
                color=[],
                size=10,
                colorbar=dict(
                    thickness=15,
                    title=dict(text='Node Connections', side='right'),
                    xanchor='left'
                ),
                line_width=2))

        node_adjacencies = []
        for node, adjacencies in enumerate(G.adjacency()):
            node_adjacencies.append(len(adjacencies[1]))

        node_trace.marker.color = node_adjacencies

        fig = go.Figure(data=[edge_trace, node_trace],
                     layout=go.Layout(
                        title=dict(text='<br>Network graph of Knowledge Nodes', font=dict(size=16)),
                        showlegend=False,
                        hovermode='closest',
                        margin=dict(b=20,l=5,r=5,t=40),
                        annotations=[ dict(
                            text="Knowledge OS Graph View",
                            showarrow=False,
                            xref="paper", yref="paper",
                            x=0.005, y=-0.002 ) ],
                        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                        template="plotly_dark"
                    ))
        
        st.plotly_chart(fig, use_container_width=True)
        
        # –°–ø–∏—Å–æ–∫ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–≤—è–∑–µ–π
        with st.expander("üìã –î–µ—Ç–∞–ª–∏ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–≤—è–∑–µ–π"):
            df_links = pd.DataFrame(links)
            st.dataframe(df_links, use_container_width=True)

    except ImportError:
        st.error("–î–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≥—Ä–∞—Ñ–∞ —Ç—Ä–µ–±—É—é—Ç—Å—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ networkx –∏ plotly.")
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≥—Ä–∞—Ñ–∞: {e}")
        # logger.error(traceback.format_exc())

def render_revision():
    """üîç –†–µ–≤–∏–∑–∏—è –∑–Ω–∞–Ω–∏–π."""
    st.subheader("üîç –†–µ–≤–∏–∑–∏—è –∏ –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è")
    
    # –ò—Å–∫–ª—é—á–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —É–∑–ª—ã –∏–∑ —Ä–µ–≤–∏–∑–∏–∏ (–ø–∞–º—è—Ç—å, –ª–∏–Ω–∫–æ–≤–∫–∞)
    pending = fetch_data("""
        SELECT id, LEFT(content, 150) as content, 
               COALESCE(metadata->>'expert_name', metadata->>'expert', 'System') as expert_name, 
               metadata->>'source' as source,
               created_at
        FROM knowledge_nodes
        WHERE is_verified = false
        AND (metadata->>'source' NOT IN ('memory_consolidator', 'cross_domain_linker') OR metadata->>'source' IS NULL)
        ORDER BY created_at DESC LIMIT 20
    """)
    
    if pending:
        st.info(f"–ù–∞–π–¥–µ–Ω–æ {len(pending)} —É–∑–ª–æ–≤, —Ç—Ä–µ–±—É—é—â–∏—Ö –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–∏—Å–∫–ª—é—á–∞—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ).")
        for p in pending:
            with st.expander(f"–£–∑–µ–ª {str(p['id'])[:8]} | {p['expert_name']} ({p['source'] or 'unknown'}) | {format_msk(p['created_at'])}"):
                st.write(p['content'])
                if st.button("‚úÖ –ü–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å", key=f"verify_{p['id']}"):
                    # –ó–¥–µ—Å—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤—ã–∑–æ–≤ run_query –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è is_verified = true
                    st.success(f"–£–∑–µ–ª {str(p['id'])[:8]} –≤–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω")
    else:
        st.success("–í—Å–µ –∑–Ω–∞—á–∏–º—ã–µ –∑–Ω–∞–Ω–∏—è –≤–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω—ã.")
