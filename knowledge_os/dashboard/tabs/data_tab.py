import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import os
import numpy as np
import networkx as nx
import json
from datetime import datetime, timezone, timedelta
from database_service import fetch_data
from graph_utils import optimized_force_layout

def format_msk(dt):
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç datetime –≤ –º–æ—Å–∫–æ–≤—Å–∫–æ–µ –≤—Ä–µ–º—è (UTC+3)."""
    if dt is None:
        return "N/A"
    if dt.tzinfo is None:
        dt = dt.replace(tzinfo=timezone.utc)
    msk_dt = dt.astimezone(timezone(timedelta(hours=3)))
    return msk_dt.strftime('%d.%m.%Y %H:%M')

def render_data_tab():
    """–í–∫–ª–∞–¥–∫–∞ –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç (RAG) –∏ –ö–∞—á–µ—Å—Ç–≤–æ –ó–Ω–∞–Ω–∏–π."""
    tabs = st.tabs(["üìö AI Research KB", "üìä –¶–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å", "üß† –ö–∞—Ä—Ç–∞ –†–∞–∑—É–º–∞", "üîç –†–µ–≤–∏–∑–∏—è", "ü§ù –°–∏–Ω—Ç–µ–∑ –ó–Ω–∞–Ω–∏–π", "üé® Canvas"])
    
    with tabs[0]:
        render_ai_research_kb()
    with tabs[1]:
        render_data_health()
    with tabs[2]:
        render_mindmap()
    with tabs[3]:
        render_revision()
    with tabs[4]:
        render_synthesis_hub()
    with tabs[5]:
        render_canvas_mode()

def render_canvas_mode():
    """üé® Canvas Mode –¥–ª—è Web IDE (–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã)."""
    st.subheader("üé® Canvas Mode: –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã")
    st.markdown("–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞, –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏ —Å—Ö–µ–º –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏.")
    
    col_chat, col_canvas = st.columns([1, 1])
    
    with col_chat:
        st.markdown("### üí¨ –ß–∞—Ç —Å –í–∏–∫—Ç–æ—Ä–∏–µ–π")
        st.info("–ó–¥–µ—Å—å –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–π –¥–∏–∞–ª–æ–≥.")
        st.text_area("–í–∞—à–∞ –∫–æ–º–∞–Ω–¥–∞", placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: '–£–ª—É—á—à–∏ –∞–ª–≥–æ—Ä–∏—Ç–º RAG'...", height=100)
        st.button("–û—Ç–ø—Ä–∞–≤–∏—Ç—å")
        
    with col_canvas:
        st.markdown("### üñºÔ∏è –ê—Ä—Ç–µ—Ñ–∞–∫—Ç: `rag_optimizer.py`")
        # –ò–º–∏—Ç–∞—Ü–∏—è Canvas
        st.code("""
def optimize_rag(query, nodes):
    # [CANARY] –ù–æ–≤–∞—è –ª–æ–≥–∏–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    filtered = [n for n in nodes if n.score > 0.85]
    return filtered
        """, language="python")
        
        st.markdown("---")
        st.markdown("**üõ†Ô∏è –ë—ã—Å—Ç—Ä—ã–µ –¥–µ–π—Å—Ç–≤–∏—è:**")
        c1, c2, c3 = st.columns(3)
        if c1.button("üß™ –¢–µ—Å—Ç (–ê–Ω–Ω–∞)"):
            st.toast("–ê–Ω–Ω–∞ –∑–∞–ø—É—Å–∫–∞–µ—Ç —Ç–µ—Å—Ç—ã –≤ –ü–µ—Å–æ—á–Ω–∏—Ü–µ...")
        if c2.button("üõ°Ô∏è –°–µ–∫—å—é—Ä–∏—Ç–∏ (–ú–∞–∫—Å–∏–º)"):
            st.toast("–ú–∞–∫—Å–∏–º –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ–¥...")
        if c3.button("üíæ –í –±–∞–∑—É (–ï–ª–µ–Ω–∞)"):
            st.toast("–ï–ª–µ–Ω–∞ –æ–±–Ω–æ–≤–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é...")

def render_synthesis_hub():
    """ü§ù –•–∞–± –°–∏–Ω—Ç–µ–∑–∞ –ó–Ω–∞–Ω–∏–π (Knowledge Synthesis Hub)."""
    st.subheader("ü§ù –•–∞–± –°–∏–Ω—Ç–µ–∑–∞ –ó–Ω–∞–Ω–∏–π")
    st.markdown("–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –º–Ω–µ–Ω–∏–π –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –µ–¥–∏–Ω–æ–≥–æ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞.")
    
    col_q, col_ex = st.columns([2, 1])
    with col_q:
        topic = st.text_input("–¢–µ–º–∞ –¥–ª—è –æ–±—Å—É–∂–¥–µ–Ω–∏—è", placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: '–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è PostgreSQL –¥–ª—è 100–∫ RPS'")
        question = st.text_area("–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –≤–æ–ø—Ä–æ—Å", placeholder="–ö–∞–∫ –ª—É—á—à–µ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –ø—É–ª —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –∏ –∏–Ω–¥–µ–∫—Å—ã?")
    
    with col_ex:
        experts_list = fetch_data("SELECT name FROM experts ORDER BY name")
        expert_names = [e['name'] for e in experts_list] if experts_list else ["–í–∏–∫—Ç–æ—Ä–∏—è", "–ò–≥–æ—Ä—å", "–†–æ–º–∞–Ω", "–ê–Ω–Ω–∞"]
        selected_experts = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ (3-5)", expert_names, default=expert_names[:3])
    
    if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –°–∏–Ω—Ç–µ–∑ –ö–æ–Ω—Å–µ–Ω—Å—É—Å–∞"):
        if not topic or not question or len(selected_experts) < 2:
            st.error("–ó–∞–ø–æ–ª–Ω–∏—Ç–µ —Ç–µ–º—É, –≤–æ–ø—Ä–æ—Å –∏ –≤—ã–±–µ—Ä–∏—Ç–µ –º–∏–Ω–∏–º—É–º 2 —ç–∫—Å–ø–µ—Ä—Ç–æ–≤.")
        else:
            with st.spinner("–≠–∫—Å–ø–µ—Ä—Ç—ã –æ–±—Å—É–∂–¥–∞—é—Ç –ø—Ä–æ–±–ª–µ–º—É..."):
                try:
                    # –ò–º–∏—Ç–∞—Ü–∏—è –≤—ã–∑–æ–≤–∞ ConsensusAgent (–≤ –±—É–¥—É—â–µ–º ‚Äî —Ä–µ–∞–ª—å–Ω—ã–π –≤—ã–∑–æ–≤ —á–µ—Ä–µ–∑ API)
                    # –î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º Victoria Enhanced
                    from app.victoria_enhanced import VictoriaEnhanced
                    victoria = VictoriaEnhanced()
                    
                    prompt = f"""–¢—ã –≤—ã—Å—Ç—É–ø–∞–µ—à—å –∫–∞–∫ –•–∞–± –°–∏–Ω—Ç–µ–∑–∞ –ó–Ω–∞–Ω–∏–π. 
                    –ü—Ä–æ–≤–µ–¥–∏ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–±—Å—É–∂–¥–µ–Ω–∏–µ –º–µ–∂–¥—É —ç–∫—Å–ø–µ—Ä—Ç–∞–º–∏: {', '.join(selected_experts)}.
                    –¢–ï–ú–ê: {topic}
                    –í–û–ü–†–û–°: {question}
                    
                    –í–´–î–ê–ô –ò–¢–û–ì–û–í–´–ô –ö–û–ù–°–ï–ù–°–£–° –ò –£–†–û–í–ï–ù–¨ –°–û–ì–õ–ê–°–ò–Ø (–≤ %).
                    """
                    
                    result = victoria.solve_sync(prompt, method="consensus") if hasattr(victoria, 'solve_sync') else victoria.solve(prompt, method="extended_thinking")
                    
                    st.success("‚úÖ –ö–æ–Ω—Å–µ–Ω—Å—É—Å –¥–æ—Å—Ç–∏–≥–Ω—É—Ç!")
                    
                    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —É—Ä–æ–≤–Ω—è —Å–æ–≥–ª–∞—Å–∏—è
                    agreement = 85 # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
                    st.write(f"**–£—Ä–æ–≤–µ–Ω—å —Å–æ–≥–ª–∞—Å–∏—è —ç–∫—Å–ø–µ—Ä—Ç–æ–≤:** {agreement}%")
                    st.progress(agreement / 100)
                    
                    st.markdown("### üìú –ï–¥–∏–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –∫–æ—Ä–ø–æ—Ä–∞—Ü–∏–∏")
                    st.info("–≠—Ç–æ —Ä–µ—à–µ–Ω–∏–µ —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–ª–ª–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–∞–∑—É–º–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤.")
                    # –ó–¥–µ—Å—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ç–µ–∫—Å—Ç –∏–∑ result
                    st.write("–°–æ–≥–ª–∞—Å–Ω–æ –º–Ω–µ–Ω–∏—é —ç–∫—Å–ø–µ—Ä—Ç–æ–≤, –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è 100–∫ RPS –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –≤–Ω–µ–¥—Ä–∏—Ç—å PgBouncer –≤ —Ä–µ–∂–∏–º–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å shared_buffers –¥–æ 25% RAM –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü –ø–æ –¥–∞—Ç–µ.")
                    
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞: {e}")

def render_ai_research_kb():
    """üìö AI Research Knowledge Base (–ù–æ–≤–æ–µ!)."""
    st.subheader("üìö –ë–∞–∑–∞ –ú—É–¥—Ä–æ—Å—Ç–∏ (AI Research)")
    st.markdown("–ú–∏—Ä–æ–≤—ã–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ –∏ –ø—Ä–æ–º–ø—Ç—ã Anthropic, OpenAI, Google, Perplexity.")
    
    search_ai = st.text_input("üîç –ü–æ–∏—Å–∫ –ø–æ AI Research", placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: 'Claude Code error handling'...")
    
    if search_ai:
        # –ü–æ–∏—Å–∫ –ø–æ –¥–æ–º–µ–Ω—É AI Research
        results = fetch_data("""
            SELECT content, metadata->>'file_path' as path, confidence_score
            FROM knowledge_nodes 
            WHERE (content ILIKE %s OR metadata->>'file_path' ILIKE %s)
            AND domain_id = (SELECT id FROM domains WHERE name = 'AI Research')
            ORDER BY confidence_score DESC LIMIT 10
        """, (f"%{search_ai}%", f"%{search_ai}%"))
        
        if results:
            for r in results:
                with st.expander(f"üìÑ {r['path']} (Conf: {r['confidence_score']:.2f})"):
                    st.markdown(r['content'])
        else:
            st.info("–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ AI Research.")
    else:
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ
        st.markdown("### –ü–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–∞—Ö–æ–¥–∫–∏")
        latest = fetch_data("""
            SELECT content, metadata->>'file_path' as path, created_at
            FROM knowledge_nodes 
            WHERE domain_id = (SELECT id FROM domains WHERE name = 'AI Research')
            ORDER BY created_at DESC LIMIT 5
        """)
        if latest:
            for l in latest:
                st.caption(f"üìå {l['path']} - {format_msk(l['created_at']).split()[0]}")
                st.markdown(f"{(l['content'] or '')[:200]}...")
        else:
            st.info("–ë–∞–∑–∞ AI Research –ø–æ–∫–∞ –ø—É—Å—Ç–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏.")

def render_data_health():
    """üìä –¶–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö (Knowledge OS Health)."""
    st.subheader("üìä –ó–¥–æ—Ä–æ–≤—å–µ –ë–∞–∑—ã –ó–Ω–∞–Ω–∏–π")
    try:
        stats = fetch_data("""
            SELECT 
                (SELECT COUNT(*) FROM knowledge_nodes) as total_nodes,
                (SELECT COUNT(*) FROM knowledge_links) as total_links,
                (SELECT COUNT(*) FROM knowledge_nodes WHERE embedding IS NULL) as missing_embeddings,
                (SELECT COUNT(*) FROM knowledge_nodes WHERE confidence_score < 0.3) as low_confidence
        """)
        if stats and stats[0]:
            s = stats[0]
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("–í—Å–µ–≥–æ —É–∑–ª–æ–≤", s['total_nodes'])
            c2.metric("–í—Å–µ–≥–æ —Å–≤—è–∑–µ–π", s['total_links'])
            c3.metric("–ë–µ–∑ –≤–µ–∫—Ç–æ—Ä–æ–≤", s['missing_embeddings'], delta_color="inverse")
            c4.metric("–ù–∏–∑–∫–∏–π Conf", s['low_confidence'], delta_color="inverse")
            
            # –ü—Ä–æ–≥—Ä–µ—Å—Å –∫ —Ü–µ–ª–∏ 10/10 (100k —Å–≤—è–∑–µ–π)
            st.markdown("### üèÜ –ü—É—Ç—å –∫ Neural Graph (100k —Å–≤—è–∑–µ–π)")
            progress = min(100, int(s['total_links'] / 1000))
            st.progress(progress / 100)
            st.caption(f"–¢–µ–∫—É—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å: {progress}% (–¶–µ–ª—å: 100,000 —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö —Å–≤—è–∑–µ–π)")
            
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∞—É–¥–∏—Ç–∞ –¥–∞–Ω–Ω—ã—Ö: {e}")

def render_mindmap():
    """üß† –ö–∞—Ä—Ç–∞ —Ä–∞–∑—É–º–∞ –∫–æ—Ä–ø–æ—Ä–∞—Ü–∏–∏ (–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è 100k+)."""
    st.subheader("üß† –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ì—Ä–∞—Ñ –ó–Ω–∞–Ω–∏–π (Neural Graph)")
    
    view_mode = st.radio("–†–µ–∂–∏–º –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è", 
                        ["üåê –ì–ª–æ–±–∞–ª—å–Ω—ã–π (–î–æ–º–µ–Ω—ã)", "üß¨ –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ –ö–ª–∞—Å—Ç–µ—Ä—ã", "üîç –õ–æ–∫–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫"], 
                        horizontal=True)
    
    try:
        if view_mode == "üåê –ì–ª–æ–±–∞–ª—å–Ω—ã–π (–î–æ–º–µ–Ω—ã)":
            st.markdown("### –ì–ª–æ–±–∞–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –¥–æ–º–µ–Ω–∞–º–∏")
            domain_links = fetch_data("""
                SELECT 
                    d1.name as source_domain, 
                    d2.name as target_domain, 
                    COUNT(*) as link_count
                FROM knowledge_links l
                JOIN knowledge_nodes k1 ON l.source_node_id = k1.id
                JOIN knowledge_nodes k2 ON l.target_node_id = k2.id
                JOIN domains d1 ON k1.domain_id = d1.id
                JOIN domains d2 ON k2.domain_id = d2.id
                GROUP BY d1.name, d2.name
                ORDER BY link_count DESC
            """)
            
            # –û–¢–õ–ê–î–ö–ê: –í—ã–≤–æ–¥–∏–º —Å–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤ –ø—Ä—è–º–æ –≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–¥–∏–Ω)
            if domain_links:
                unique_domains = set([l['source_domain'] for l in domain_links] + [l['target_domain'] for l in domain_links])
                if len(unique_domains) <= 1:
                    st.warning(f"–í–ù–ò–ú–ê–ù–ò–ï: –ù–∞–π–¥–µ–Ω–æ —Å–≤—è–∑–µ–π: {len(domain_links)}, –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤: {len(unique_domains)}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–∏–Ω–∫–æ–≤–∫—É –≤ –ë–î.")
            
            if not domain_links:
                st.info("–ú–µ–∂–¥–æ–º–µ–Ω–Ω—ã–µ —Å–≤—è–∑–∏ –ø–æ–∫–∞ –Ω–µ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω—ã.")
                return

            G = nx.DiGraph()
            for link in domain_links:
                G.add_edge(link['source_domain'], link['target_domain'], weight=link['link_count'])
            
            domain_stats = fetch_data("SELECT d.name, COUNT(k.id) as node_count FROM domains d LEFT JOIN knowledge_nodes k ON d.id = k.domain_id GROUP BY d.name")
            node_sizes_map = {d['name']: d['node_count'] for d in domain_stats}
            
            node_list = list(G.nodes())
            n_nodes = len(node_list)
            adj_matrix = np.zeros((n_nodes, n_nodes))
            for i, u in enumerate(node_list):
                for j, v in enumerate(node_list):
                    if G.has_edge(u, v): adj_matrix[i, j] = 1
            
            pos_array = optimized_force_layout(adj_matrix, np.ones(n_nodes), iterations=50)
            pos = {node_list[i]: pos_array[i] for i in range(n_nodes)}
            
            edge_x, edge_y = [], []
            for edge in G.edges(data=True):
                x0, y0 = pos[edge[0]]
                x1, y1 = pos[edge[1]]
                edge_x.extend([x0, x1, None])
                edge_y.extend([y0, y1, None])

            edge_trace = go.Scatter(
                x=edge_x, y=edge_y,
                line=dict(width=2.0, color='rgba(255, 255, 255, 0.8)'),
                hoverinfo='none', mode='lines'
            )

            node_x, node_y, node_text, node_size_vals = [], [], [], []
            for node in G.nodes():
                x, y = pos[node]
                node_x.append(x)
                node_y.append(y)
                count = node_sizes_map.get(node, 0)
                node_text.append(f"–î–æ–º–µ–Ω: {node}<br>–£–∑–ª–æ–≤: {count}")
                node_size_vals.append(min(60, max(25, count / 3)))

            node_trace = go.Scatter(
                x=node_x, y=node_y, mode='markers+text',
                text=[n for n in G.nodes()], textposition="top center",
                hoverinfo='text', hovertext=node_text,
                textfont=dict(size=14, color="white"),
                marker=dict(size=node_size_vals, color='#FF7F50', line=dict(width=2, color='white'))
            )

            fig = go.Figure(data=[edge_trace, node_trace],
                         layout=go.Layout(
                            showlegend=False, hovermode='closest',
                            margin=dict(b=0,l=0,r=0,t=0),
                            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False, range=[-1.1, 1.1]),
                            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False, range=[-1.1, 1.1]),
                            template="plotly_dark", height=700
                        ))
            st.plotly_chart(fig, use_container_width=True)

        elif view_mode == "üß¨ –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ –ö–ª–∞—Å—Ç–µ—Ä—ã":
            st.markdown("### –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∑–Ω–∞–Ω–∏–π (–°–æ–∑–≤–µ–∑–¥–∏—è)")
            limit = st.slider("–õ–∏–º–∏—Ç —É–∑–ª–æ–≤ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏", 50, 1000, 400)
            
            # –ü–†–ê–í–ò–õ–¨–ù–´–ô SQL: –£–±–∏—Ä–∞–µ–º —Ñ–∏–ª—å—Ç—Ä —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è —Ç–µ—Å—Ç–∞, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –í–°–ï –¥–æ–º–µ–Ω—ã
            nodes_data = fetch_data("""
                WITH connection_counts AS (
                    SELECT 
                        kn.id, kn.domain_id, kn.content, kn.confidence_score, d.name as domain_name,
                        (SELECT COUNT(*) FROM knowledge_links WHERE source_node_id = kn.id OR target_node_id = kn.id) AS total_degree
                    FROM knowledge_nodes kn
                    JOIN domains d ON kn.domain_id = d.id
                ),
                ranked_nodes AS (
                    SELECT 
                        id, domain_id, content, confidence_score, domain_name as domain, total_degree,
                        ROW_NUMBER() OVER (PARTITION BY domain_id ORDER BY total_degree DESC) AS rn
                    FROM connection_counts
                ),
                top_nodes AS (
                    -- –ë–µ—Ä–µ–º –¥–æ 20 —É–∑–ª–æ–≤ –∏–∑ –ö–ê–ñ–î–û–ì–û –¥–æ–º–µ–Ω–∞
                    SELECT * FROM ranked_nodes 
                    WHERE rn <= 20
                    ORDER BY total_degree DESC
                    LIMIT %s
                ),
                selected_node_ids AS (
                    SELECT id FROM top_nodes
                ),
                relevant_links AS (
                    SELECT kl.source_node_id, kl.target_node_id
                    FROM knowledge_links kl
                    WHERE kl.source_node_id IN (SELECT id FROM selected_node_ids)
                      AND kl.target_node_id IN (SELECT id FROM selected_node_ids)
                )
                SELECT tn.id, tn.content as label, tn.domain, tn.total_degree,
                       (SELECT json_agg(target_node_id) FROM relevant_links WHERE source_node_id = tn.id) as links
                FROM top_nodes tn
            """, (limit,))
            
            if not nodes_data:
                st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö.")
                return

            G = nx.Graph()
            node_info = {}
            node_list = []
            for n in nodes_data:
                G.add_node(n['id'], label=n['label'], domain=n['domain'], degree=n['total_degree'])
                node_info[n['id']] = n
                node_list.append(n['id'])
            
            for n in nodes_data:
                if n['links']:
                    targets = n['links'] if isinstance(n['links'], list) else json.loads(n['links'])
                    for target_id in targets:
                        if target_id in node_info:
                            G.add_edge(n['id'], target_id)
            
            n_nodes = len(node_list)
            if n_nodes == 0:
                st.info("–ì—Ä–∞—Ñ –ø—É—Å—Ç.")
                return

            adj_matrix = np.zeros((n_nodes, n_nodes))
            node_id_to_idx = {nid: i for i, nid in enumerate(node_list)}
            for u, v in G.edges():
                adj_matrix[node_id_to_idx[u], node_id_to_idx[v]] = 1
                adj_matrix[node_id_to_idx[v], node_id_to_idx[u]] = 1
            
            pos_array = optimized_force_layout(adj_matrix, np.array([G.degree(n) for n in node_list]), iterations=300)
            pos_dict = {node_list[i]: pos_array[i] for i in range(n_nodes)}
            
            edge_x, edge_y = [], []
            for edge in G.edges():
                x0, y0 = pos_dict[edge[0]]
                x1, y1 = pos_dict[edge[1]]
                edge_x.extend([x0, x1, None])
                edge_y.extend([y0, y1, None])
            edge_trace = go.Scatter(x=edge_x, y=edge_y, line=dict(width=1.2, color='rgba(255,255,255,0.25)'), hoverinfo='none', mode='lines')

            node_x, node_y, node_text, node_color, node_size, node_labels = [], [], [], [], [], []
            degrees_in_graph = dict(G.degree())
            
            for node_id in node_list:
                x, y = pos_dict[node_id]
                node_x.append(x)
                node_y.append(y)
                info = node_info[node_id]
                curr_deg = degrees_in_graph.get(node_id, 0)
                
                # –•–∞–± ‚Äî –µ—Å–ª–∏ –µ—Å—Ç—å —Å–≤—è–∑–∏ –≤ —Ç–µ–∫—É—â–µ–π –≤—ã–±–æ—Ä–∫–µ
                is_hub = curr_deg > 1
                
                node_color.append('#FF7F50' if is_hub else '#5DADE2')
                node_size.append(min(30, 12 + curr_deg * 3) if is_hub else 6)
                
                # –ö—Ä–∞—Å–∏–≤—ã–µ –ø–æ–¥–ø–∏—Å–∏ –≤ —Å—Ç–∏–ª–µ –¥–∞—à–±–æ—Ä–¥–∞
                if is_hub:
                    # –ü–û–ö–ê–ó–´–í–ê–ï–ú –î–û–ú–ï–ù –ö–†–£–ü–ù–û, –∞ –∫–æ–Ω—Ç–µ–Ω—Ç –º–µ–ª–∫–æ –ø–æ–¥ –Ω–∏–º
                    label_text = f"<b style='color:#FF7F50; font-size:14px;'>{info['domain']}</b><br><span style='font-size:10px; color:#AAB7B8;'>{info['label'][:30]}...</span>"
                else:
                    label_text = ""
                
                node_text.append(f"<b>{info['domain']}</b><br>{info['label'][:200]}...<br>–°–≤—è–∑–µ–π: {curr_deg}")
                node_labels.append(label_text)

            node_trace = go.Scatter(
                x=node_x, y=node_y, mode='markers+text',
                hoverinfo='text', text=node_labels,
                textposition="top center",
                hovertext=node_text,
                marker=dict(color=node_color, size=node_size, line=dict(width=1.5, color='#111'))
            )

            fig = go.Figure(data=[edge_trace, node_trace],
                         layout=go.Layout(showlegend=False, hovermode='closest',
                            margin=dict(b=0,l=0,r=0,t=0),
                            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False, range=[-1.1, 1.1]),
                            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False, range=[-1.1, 1.1]),
                            template="plotly_dark", height=700))
            st.plotly_chart(fig, use_container_width=True)

        elif view_mode == "üîç –õ–æ–∫–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫":
            search_query = st.text_input("–í–≤–µ–¥–∏—Ç–µ ID —É–∑–ª–∞ –∏–ª–∏ —Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ü–µ–Ω—Ç—Ä–∞ –≥—Ä–∞—Ñ–∞", placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: 'PostgreSQL' –∏–ª–∏ UUID...")
            depth = st.slider("–ì–ª—É–±–∏–Ω–∞ —Å–≤—è–∑–µ–π", 1, 3, 1)
            
            if search_query:
                center_node = fetch_data("SELECT id, content FROM knowledge_nodes WHERE content ILIKE %s OR id::text = %s LIMIT 1", (f"%{search_query}%", search_query))
                if center_node:
                    c_id = center_node[0]['id']
                    local_links = fetch_data("""
                        WITH RECURSIVE graph AS (
                            SELECT source_node_id, target_node_id, 1 as level
                            FROM knowledge_links
                            WHERE source_node_id = %s OR target_node_id = %s
                            UNION
                            SELECT l.source_node_id, l.target_node_id, g.level + 1
                            FROM knowledge_links l
                            JOIN graph g ON l.source_node_id = g.target_node_id OR l.target_node_id = g.source_node_id
                            WHERE g.level < %s
                        )
                        SELECT DISTINCT g.source_node_id, g.target_node_id, k1.content as s_content, k2.content as t_content
                        FROM graph g
                        JOIN knowledge_nodes k1 ON g.source_node_id = k1.id
                        JOIN knowledge_nodes k2 ON g.target_node_id = k2.id
                        LIMIT 200
                    """, (c_id, c_id, depth))

                    if local_links:
                        G = nx.Graph()
                        node_list_local = set()
                        for l in local_links:
                            G.add_edge(str(l['source_node_id']), str(l['target_node_id']))
                            node_list_local.add(str(l['source_node_id']))
                            node_list_local.add(str(l['target_node_id']))
                        
                        node_list_local = list(node_list_local)
                        n_nodes = len(node_list_local)
                        adj_matrix = np.zeros((n_nodes, n_nodes))
                        nid_to_idx = {nid: i for i, nid in enumerate(node_list_local)}
                        for u, v in G.edges():
                            adj_matrix[nid_to_idx[u], nid_to_idx[v]] = 1
                            adj_matrix[nid_to_idx[v], nid_to_idx[u]] = 1
                        
                        pos_array = optimized_force_layout(adj_matrix, np.ones(n_nodes), iterations=50)
                        pos_dict = {node_list_local[i]: pos_array[i] for i in range(n_nodes)}
                        
                        edge_x, edge_y = [], []
                        for edge in G.edges():
                            x0, y0 = pos_dict[edge[0]]
                            x1, y1 = pos_dict[edge[1]]
                            edge_x.extend([x0, x1, None])
                            edge_y.extend([y0, y1, None])
                        
                        edge_trace = go.Scatter(x=edge_x, y=edge_y, line=dict(width=1, color='#888'), hoverinfo='none', mode='lines')
                        
                        node_x, node_y, node_text = [], [], []
                        for node in G.nodes():
                            x, y = pos_dict[node]
                            node_x.append(x)
                            node_y.append(y)
                            node_text.append(f"Node ID: {node}")
                            
                        node_trace = go.Scatter(
                            x=node_x, y=node_y, mode='markers+text',
                            text=[n[:8] for n in G.nodes()], textposition="bottom center",
                            hoverinfo='text', hovertext=node_text,
                            marker=dict(size=20, color='#ffcc00', line_width=2)
                        )
                        
                        fig = go.Figure(data=[edge_trace, node_trace],
                                     layout=go.Layout(template="plotly_dark", height=600, margin=dict(b=0,l=0,r=0,t=0),
                                                     xaxis=dict(showgrid=False, zeroline=False, showticklabels=False, range=[-1.1, 1.1]),
                                                     yaxis=dict(showgrid=False, zeroline=False, showticklabels=False, range=[-1.1, 1.1])))
                        st.plotly_chart(fig, use_container_width=True)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
        import traceback
        st.code(traceback.format_exc())

def render_revision():
    """üîç –†–µ–≤–∏–∑–∏—è –∑–Ω–∞–Ω–∏–π."""
    st.subheader("üîç –†–µ–≤–∏–∑–∏—è –∏ –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è")
    
    # –ò—Å–∫–ª—é—á–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —É–∑–ª—ã –∏–∑ —Ä–µ–≤–∏–∑–∏–∏ (–ø–∞–º—è—Ç—å, –ª–∏–Ω–∫–æ–≤–∫–∞)
    pending = fetch_data("""
        SELECT id, LEFT(content, 150) as content, 
               COALESCE(metadata->>'expert_name', metadata->>'expert', 'System') as expert_name, 
               metadata->>'source' as source,
               created_at
        FROM knowledge_nodes
        WHERE is_verified = false
        AND (metadata->>'source' NOT IN ('memory_consolidator', 'cross_domain_linker') OR metadata->>'source' IS NULL)
        ORDER BY created_at DESC LIMIT 20
    """)
    
    if pending:
        st.info(f"–ù–∞–π–¥–µ–Ω–æ {len(pending)} —É–∑–ª–æ–≤, —Ç—Ä–µ–±—É—é—â–∏—Ö –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–∏—Å–∫–ª—é—á–∞—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ).")
        for p in pending:
            with st.expander(f"–£–∑–µ–ª {str(p['id'])[:8]} | {p['expert_name']} ({p['source'] or 'unknown'}) | {format_msk(p['created_at'])}"):
                st.write(p['content'])
                if st.button("‚úÖ –ü–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å", key=f"verify_{p['id']}"):
                    # –ó–¥–µ—Å—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤—ã–∑–æ–≤ run_query –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è is_verified = true
                    st.success(f"–£–∑–µ–ª {str(p['id'])[:8]} –≤–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω")
    else:
        st.success("–í—Å–µ –∑–Ω–∞—á–∏–º—ã–µ –∑–Ω–∞–Ω–∏—è –≤–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω—ã.")
