#!/usr/bin/env python3
"""
ü§ñ –ò–ò-–û–ü–¢–ò–ú–ò–ó–ê–¢–û–† STOP LOSS –£–†–û–í–ù–ï–ô
–ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è SL –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤

–ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ AITakeProfitOptimizer, –Ω–æ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —É—Ä–æ–≤–Ω–µ–π —Å—Ç–æ–ø-–ª–æ—Å—Å–∞
"""

import json
import logging
import os
from typing import Dict, List, Any

import numpy as np
import pandas as pd

logger = logging.getLogger(__name__)

class AIStopLossOptimizer:
    """–ò–ò-—Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ Stop Loss —É—Ä–æ–≤–Ω–µ–π"""

    def __init__(self, data_dir: str = "ai_sl_data"):
        self.data_dir = data_dir
        os.makedirs(data_dir, exist_ok=True)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ SL
        self.sl_effectiveness = self._load_sl_effectiveness()

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è ML –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        self.all_patterns = self._load_all_patterns()

        # –ö—ç—à –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ –∫ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        self.pattern_cache = {}
        self.cache_timestamp = None

        # –í–µ—Å–∞ –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤
        self.factor_weights = {
            'volatility': 0.35,      # –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å (–±–æ–ª–µ–µ –≤–∞–∂–Ω–æ –¥–ª—è SL)
            'trend_strength': 0.2,   # –°–∏–ª–∞ —Ç—Ä–µ–Ω–¥–∞
            'volume_profile': 0.15,  # –ü—Ä–æ—Ñ–∏–ª—å –æ–±—ä–µ–º–∞
            'support_resistance': 0.2, # –£—Ä–æ–≤–Ω–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏/—Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è
            'pattern_similarity': 0.3  # –ü–æ—Ö–æ–∂–µ—Å—Ç—å –Ω–∞ —É—Å–ø–µ—à–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        }

        logger.info("ü§ñ –ò–ò-–æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä SL –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        if self.all_patterns:
            logger.info("üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ %d –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è ML –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ SL", len(self.all_patterns))

    def _load_sl_effectiveness(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫—É—é —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å SL –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–∏–º–≤–æ–ª–∞"""
        file_path = os.path.join(self.data_dir, "sl_effectiveness.json")

        if os.path.exists(file_path):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.error("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ SL: %s", e)

        return {}

    def _load_all_patterns(self) -> List[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è ML –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        try:
            # –ü—Ä–æ–±—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø—É—Ç–µ–π
            paths = [
                "ai_learning_data/trading_patterns.json",
                "../ai_learning_data/trading_patterns.json",
                "trading_patterns.json"
            ]

            for path in paths:
                if os.path.exists(path):
                    with open(path, 'r', encoding='utf-8') as f:
                        patterns = json.load(f)
                        logger.info("üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ %d –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏–∑ %s –¥–ª—è SL", len(patterns), path)
                        return patterns

            logger.warning("‚ö†Ô∏è –§–∞–π–ª trading_patterns.json –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
            return []

        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è SL: %s", e)
            return []

    def _save_sl_effectiveness(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å SL"""
        file_path = os.path.join(self.data_dir, "sl_effectiveness.json")

        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(self.sl_effectiveness, f, indent=2, ensure_ascii=False)
            logger.debug("üíæ –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å SL —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ SL: %s", e)

    def calculate_volatility_factor(self, df: pd.DataFrame, current_index: int) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ñ–∞–∫—Ç–æ—Ä –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è SL"""
        try:
            if current_index < 20:
                return 1.0

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º ATR –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
            if 'atr' in df.columns:
                atr = df['atr'].iloc[current_index]
                current_price = df['close'].iloc[current_index]

                if pd.notna(atr) and current_price > 0:
                    atr_pct = (atr / current_price) * 100

                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å: –Ω–∏–∑–∫–∞—è (<1%) = 0.8x, –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è (1-3%) = 1.0x, –≤—ã—Å–æ–∫–∞—è (>3%) = 1.3x
                    if atr_pct < 1.0:
                        return 0.8  # –£–∂–µ—Å—Ç–æ—á–∞–µ–º SL –ø—Ä–∏ –Ω–∏–∑–∫–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
                    elif atr_pct > 3.0:
                        return 1.3  # –û—Å–ª–∞–±–ª—è–µ–º SL –ø—Ä–∏ –≤—ã—Å–æ–∫–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
                    else:
                        return 1.0

            return 1.0

        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ —Ñ–∞–∫—Ç–æ—Ä–∞ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è SL: %s", e)
            return 1.0

    def find_similar_patterns_for_sl(self, symbol: str, side: str, df: pd.DataFrame,
                                     current_index: int, top_n: int = 100) -> List[Dict[str, Any]]:
        """
        –ù–∞—Ö–æ–¥–∏—Ç –ø–æ—Ö–æ–∂–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ SL
        
        Args:
            symbol: –°–∏–º–≤–æ–ª
            side: LONG –∏–ª–∏ SHORT
            df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            current_index: –¢–µ–∫—É—â–∏–π –∏–Ω–¥–µ–∫—Å
            top_n: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª—É—á—à–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ –ø–æ—Ö–æ–∂–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Å –æ—Ü–µ–Ω–∫–æ–π —Å—Ö–æ–∂–µ—Å—Ç–∏
        """
        if not self.all_patterns:
            return []

        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—É—â–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
            current_indicators = self._extract_current_indicators(df, current_index)
            if not current_indicators:
                return []

            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ —Å–∏–º–≤–æ–ª—É –∏ —Å—Ç–æ—Ä–æ–Ω–µ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
            relevant_patterns = []
            for pattern in self.all_patterns:
                pattern_symbol = pattern.get('symbol', '')
                pattern_side = pattern.get('signal_type', '').upper()

                # –£—á–∏—Ç—ã–≤–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ç–æ–≥–æ –∂–µ —Å–∏–º–≤–æ–ª–∞ –∏–ª–∏ –≤—Å–µ—Ö —Å–∏–º–≤–æ–ª–æ–≤ –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –º–∞–ª–æ
                if pattern_symbol == symbol or len(self.all_patterns) < 50:
                    if pattern_side == side.upper() or not pattern_side:
                        relevant_patterns.append(pattern)

            if not relevant_patterns:
                return []

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞
            similarities = []
            for pattern in relevant_patterns:
                pattern_indicators = pattern.get('indicators', {})
                similarity = self._calculate_pattern_similarity(current_indicators, pattern_indicators)

                similarities.append({
                    'pattern': pattern,
                    'similarity': similarity
                })

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å—Ö–æ–∂–µ—Å—Ç–∏ –∏ –±–µ—Ä–µ–º —Ç–æ–ø-N
            similarities.sort(key=lambda x: x['similarity'], reverse=True)
            top_patterns = similarities[:top_n]

            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result = []
            for item in top_patterns:
                pattern = item['pattern']
                pattern['similarity_score'] = item['similarity']
                result.append(pattern)

            return result

        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è SL: %s", e)
            return []

    def _extract_current_indicators(self, df: pd.DataFrame, current_index: int) -> Dict[str, float]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—É—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤"""
        try:
            if current_index >= len(df):
                return {}

            indicators = {}
            row = df.iloc[current_index]

            # –°–ø–∏—Å–æ–∫ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            indicator_keys = ['rsi', 'ema_7', 'ema_25', 'macd', 'bb_width', 'volume', 'atr']

            for key in indicator_keys:
                if key in df.columns:
                    value = row[key]
                    if pd.notna(value) and np.isfinite(value):
                        indicators[key] = float(value)

            return indicators

        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è SL: %s", e)
            return {}

    def _calculate_pattern_similarity(self, indicators1: Dict[str, float],
                                     indicators2: Dict[str, float]) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç—å –º–µ–∂–¥—É –¥–≤—É–º—è –Ω–∞–±–æ—Ä–∞–º–∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤"""
        if not indicators1 or not indicators2:
            return 0.0

        try:
            similarities = []
            weights = {'rsi': 0.25, 'ema_7': 0.2, 'ema_25': 0.2, 'macd': 0.15,
                      'bb_width': 0.1, 'volume': 0.05, 'atr': 0.05}

            for key, weight in weights.items():
                if key in indicators1 and key in indicators2:
                    val1 = indicators1[key]
                    val2 = indicators2[key]

                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
                    if key == 'rsi':
                        val1_norm = val1 / 100.0
                        val2_norm = val2 / 100.0
                    elif key == 'volume':
                        val1_norm = min(val1 / 1000000.0, 1.0)
                        val2_norm = min(val2 / 1000000.0, 1.0)
                    elif key == 'atr':
                        val1_norm = min(val1 / 100.0, 1.0)
                        val2_norm = min(val2 / 100.0, 1.0)
                    else:
                        val1_norm = min(abs(val1), 100.0) / 100.0
                        val2_norm = min(abs(val2), 100.0) / 100.0

                    similarity = 1.0 - abs(val1_norm - val2_norm)
                    similarities.append(similarity * weight)

            return sum(similarities) if similarities else 0.0

        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è SL: %s", e)
            return 0.0

    def calculate_optimal_sl_from_patterns(self, similar_patterns: List[Dict[str, Any]],
                                          side: str = "long") -> float:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π SL –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Ö–æ–∂–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        
        Args:
            similar_patterns: –°–ø–∏—Å–æ–∫ –ø–æ—Ö–æ–∂–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            side: LONG –∏–ª–∏ SHORT
            
        Returns:
            –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π SL –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
        """
        if not similar_patterns:
            return 2.0  # –î–µ—Ñ–æ–ª—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ

        try:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø–∞—Ç—Ç–µ—Ä–Ω—ã, –≥–¥–µ SL —Å—Ä–∞–±–æ—Ç–∞–ª (–±—ã–ª–∏ —É–±—ã—Ç–∫–∏)
            sl_patterns = []
            for p in similar_patterns:
                exit_reason = p.get('exit_reason', '').upper()
                sl_pct = p.get('stop_loss_pct')

                # –£—á–∏—Ç—ã–≤–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≥–¥–µ SL —Å—Ä–∞–±–æ—Ç–∞–ª –∏–ª–∏ –≥–¥–µ –±—ã–ª SL —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
                if exit_reason in ['SL', 'STOP_LOSS'] or (sl_pct and sl_pct > 0):
                    sl_patterns.append(p)

            # –ï—Å–ª–∏ –Ω–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Å–æ SL, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ —É–±—ã—Ç–æ—á–Ω—ã–µ
            if not sl_patterns:
                sl_patterns = [p for p in similar_patterns if p.get('result') == 'LOSS']

            if not sl_patterns:
                return 2.0

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π SL –Ω–∞ –æ—Å–Ω–æ–≤–µ —É—Å–ø–µ—à–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ (–≥–¥–µ SL –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª)
            # –∏ –Ω–µ—É—Å–ø–µ—à–Ω—ã—Ö (–≥–¥–µ SL —Å—Ä–∞–±–æ—Ç–∞–ª)
            successful_patterns = [p for p in similar_patterns if p.get('result') == 'WIN']
            failed_patterns = [p for p in similar_patterns if p.get('result') == 'LOSS']

            optimal_sl = 2.0

            if failed_patterns:
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —É–±—ã—Ç–∫–∏ - SL –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –º–µ–Ω—å—à–µ —Å—Ä–µ–¥–Ω–µ–≥–æ —É–±—ã—Ç–∫–∞
                losses = []
                for p in failed_patterns:
                    profit_pct = p.get('profit_pct', 0)
                    if profit_pct < 0:
                        losses.append(abs(profit_pct))

                if losses:
                    # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π SL = 80% –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ —É–±—ã—Ç–∫–∞ (–Ω–æ –Ω–µ –º–µ–Ω—å—à–µ 1%)
                    avg_loss = np.mean(losses)
                    optimal_sl = max(1.0, min(5.0, avg_loss * 0.8))

            if successful_patterns:
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω—ã–µ - SL –Ω–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–∏—à–∫–æ–º —Ç–µ—Å–Ω—ã–º
                # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–æ—Å–∞–¥–∫—É –≤ —É—Å–ø–µ—à–Ω—ã—Ö —Å–¥–µ–ª–∫–∞—Ö
                drawdowns = []
                for p in successful_patterns:
                    max_dd = p.get('max_drawdown', 0)
                    if max_dd > 0:
                        drawdowns.append(max_dd)

                if drawdowns:
                    # SL –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –±–æ–ª—å—à–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ—Å–∞–¥–∫–∏ –≤ —É—Å–ø–µ—à–Ω—ã—Ö —Å–¥–µ–ª–∫–∞—Ö
                    max_dd = np.max(drawdowns)
                    optimal_sl = max(optimal_sl, max_dd * 1.2)

            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑—É–º–Ω—ã–º–∏ –ø—Ä–µ–¥–µ–ª–∞–º–∏: 0.8% - 8%
            optimal_sl = np.clip(optimal_sl, 0.8, 8.0)

            logger.debug("üéØ ML-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è SL: %.2f%% (–Ω–∞ –æ—Å–Ω–æ–≤–µ %d –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: "
                        "%d —É—Å–ø–µ—à–Ω—ã—Ö, %d —É–±—ã—Ç–æ—á–Ω—ã—Ö)",
                        optimal_sl, len(similar_patterns),
                        len(successful_patterns), len(failed_patterns))

            return float(optimal_sl)

        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ SL: %s", e)
            return 2.0

    def calculate_ai_optimized_sl(self, symbol: str, side: str, df: pd.DataFrame,
                                 current_index: int, base_sl: float = 2.0) -> float:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –ò–ò-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π SL –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞
        
        Args:
            symbol: –¢–æ—Ä–≥–æ–≤—ã–π —Å–∏–º–≤–æ–ª
            side: LONG –∏–ª–∏ SHORT
            df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ —Å–≤–µ—á–µ–π
            current_index: –¢–µ–∫—É—â–∏–π –∏–Ω–¥–µ–∫—Å —Å–≤–µ—á–∏
            base_sl: –ë–∞–∑–æ–≤—ã–π SL –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
            
        Returns:
            –ò–ò-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π SL –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
        """
        try:
            # 1. –§–∞–∫—Ç–æ—Ä –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
            volatility_factor = self.calculate_volatility_factor(df, current_index)

            # 2. –ù–∞—Ö–æ–¥–∏–º –ø–æ—Ö–æ–∂–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            similar_patterns = self.find_similar_patterns_for_sl(symbol, side, df, current_index, top_n=100)

            # 3. –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π SL –∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            pattern_sl = self.calculate_optimal_sl_from_patterns(similar_patterns, side)

            # 4. –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º: –±–∞–∑–æ–≤—ã–π SL + –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ + –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
            if similar_patterns:
                # –ï—Å–ª–∏ –µ—Å—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö –∫–∞–∫ –æ—Å–Ω–æ–≤—É
                ai_sl = pattern_sl * volatility_factor
            else:
                # –ï—Å–ª–∏ –Ω–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤, –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –±–∞–∑–æ–≤—ã–π SL
                ai_sl = base_sl * volatility_factor

            # 5. –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑—É–º–Ω—ã–º–∏ –ø—Ä–µ–¥–µ–ª–∞–º–∏: 0.8% - 8%
            ai_sl = max(0.8, min(8.0, ai_sl))

            logger.debug("ü§ñ –ò–ò SL: –±–∞–∑–æ–≤—ã–π=%.2f%%, –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å=%.2fx, "
                        "–ø–∞—Ç—Ç–µ—Ä–Ω—ã=%.2f%%, –∏—Ç–æ–≥–æ–≤—ã–π=%.2f%%",
                        base_sl, volatility_factor, pattern_sl, ai_sl)

            return float(ai_sl)

        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –ò–ò-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ SL: %s", e)
            return base_sl

    def update_sl_effectiveness(self, symbol: str, side: str, sl_pct: float,
                               sl_hit: bool, profit_pct: float):
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å SL –¥–ª—è —Å–∏–º–≤–æ–ª–∞
        
        Args:
            symbol: –°–∏–º–≤–æ–ª
            side: LONG –∏–ª–∏ SHORT
            sl_pct: –ü—Ä–æ—Ü–µ–Ω—Ç SL
            sl_hit: –°—Ä–∞–±–æ—Ç–∞–ª –ª–∏ SL
            profit_pct: –ü—Ä–∏–±—ã–ª—å/—É–±—ã—Ç–æ–∫ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
        """
        try:
            key = f"{symbol}_{side}"

            if key not in self.sl_effectiveness:
                self.sl_effectiveness[key] = {
                    'total_trades': 0,
                    'sl_hits': 0,
                    'sl_misses': 0,
                    'avg_loss_on_sl': [],
                    'avg_profit_on_miss': []
                }

            data = self.sl_effectiveness[key]
            data['total_trades'] += 1

            if sl_hit:
                data['sl_hits'] += 1
                if profit_pct < 0:
                    data['avg_loss_on_sl'].append(abs(profit_pct))
                    # –•—Ä–∞–Ω–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 100 –∑–Ω–∞—á–µ–Ω–∏–π
                    data['avg_loss_on_sl'] = data['avg_loss_on_sl'][-100:]
            else:
                data['sl_misses'] += 1
                if profit_pct > 0:
                    data['avg_profit_on_miss'].append(profit_pct)
                    # –•—Ä–∞–Ω–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 100 –∑–Ω–∞—á–µ–Ω–∏–π
                    data['avg_profit_on_miss'] = data['avg_profit_on_miss'][-100:]

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
            self._save_sl_effectiveness()

        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ SL: %s", e)


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞
_AI_SL_OPTIMIZER = None  # pylint: disable=invalid-name

def get_ai_sl_optimizer() -> AIStopLossOptimizer:
    """–ü–æ–ª—É—á–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä AI SL –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞"""
    global _AI_SL_OPTIMIZER  # pylint: disable=invalid-name
    if _AI_SL_OPTIMIZER is None:
        _AI_SL_OPTIMIZER = AIStopLossOptimizer()
    return _AI_SL_OPTIMIZER
