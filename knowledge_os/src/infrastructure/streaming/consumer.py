"""
Event Consumer - –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π –∏–∑ Redis Streams.

–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç:
- Consumer Groups –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
- At-least-once –¥–æ—Å—Ç–∞–≤–∫—É
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π recovery –∑–∞–≤–∏—Å—à–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
- Graceful shutdown
"""

import logging
import asyncio
from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import Callable, List, Optional, Dict, Any, Awaitable
import redis.asyncio as redis
import signal
import uuid

from .events import BaseEvent, deserialize_event, EventType

logger = logging.getLogger(__name__)


@dataclass
class ConsumerConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è consumer."""
    
    stream_name: str
    group_name: str
    consumer_name: str = ""  # Auto-generated if empty
    batch_size: int = 10
    block_ms: int = 5000  # –í—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
    claim_idle_ms: int = 60000  # –í—Ä–µ–º—è –¥–ª—è claim –∑–∞–≤–∏—Å—à–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
    max_retries: int = 3
    ack_after_process: bool = True  # ACK –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏


class ConsumerGroup:
    """
    –ü—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç consumer group —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏.
    """
    
    def __init__(self, name: str, stream_name: str):
        self.name = name
        self.stream_name = stream_name
        self.consumers: List[str] = []
        self.processed_count = 0
        self.failed_count = 0


EventHandler = Callable[[BaseEvent, Dict[str, Any]], Awaitable[bool]]


class EventConsumer:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π consumer –¥–ª—è —á—Ç–µ–Ω–∏—è —Å–æ–±—ã—Ç–∏–π –∏–∑ Redis Streams.
    
    –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
        consumer = EventConsumer(
            redis_url="redis://localhost:6379",
            config=ConsumerConfig(
                stream_name="knowledge_stream",
                group_name="knowledge_processors",
            )
        )
        
        @consumer.on_event(EventType.KNOWLEDGE_CREATED)
        async def handle_knowledge(event: KnowledgeEvent, raw_data: dict):
            print(f"New knowledge: {event.content}")
            return True  # ACK message
        
        await consumer.start()
    """
    
    def __init__(
        self,
        redis_url: str = "redis://localhost:6379",
        config: Optional[ConsumerConfig] = None
    ):
        self.redis_url = redis_url
        self.config = config or ConsumerConfig(
            stream_name="knowledge_stream",
            group_name="knowledge_processors"
        )
        
        # Generate unique consumer name if not provided
        if not self.config.consumer_name:
            self.config.consumer_name = f"consumer-{uuid.uuid4().hex[:8]}"
        
        self._redis: Optional[redis.Redis] = None
        self._running = False
        self._handlers: Dict[EventType, List[EventHandler]] = {}
        self._default_handler: Optional[EventHandler] = None
        
        # Metrics
        self.processed_count = 0
        self.failed_count = 0
        self.last_message_id: Optional[str] = None
    
    async def connect(self) -> None:
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Redis."""
        self._redis = await redis.from_url(
            self.redis_url,
            decode_responses=True,
            socket_connect_timeout=5,
            socket_timeout=10
        )
        
        try:
            await self._redis.ping()
            logger.info(f"‚úÖ Consumer '{self.config.consumer_name}' connected to Redis")
        except redis.ConnectionError as e:
            logger.error(f"Failed to connect: {e}")
            raise
        
        # Ensure consumer group exists
        try:
            await self._redis.xgroup_create(
                self.config.stream_name,
                self.config.group_name,
                id="$",
                mkstream=True
            )
            logger.info(f"Created consumer group '{self.config.group_name}'")
        except redis.ResponseError as e:
            if "BUSYGROUP" not in str(e):
                raise
    
    def on_event(self, event_type: EventType) -> Callable:
        """
        Decorator –¥–ª—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ —Å–æ–±—ã—Ç–∏—è.
        
        @consumer.on_event(EventType.KNOWLEDGE_CREATED)
        async def handle(event, raw_data):
            return True
        """
        def decorator(func: EventHandler) -> EventHandler:
            if event_type not in self._handlers:
                self._handlers[event_type] = []
            self._handlers[event_type].append(func)
            logger.debug(f"Registered handler for {event_type.value}")
            return func
        return decorator
    
    def set_default_handler(self, handler: EventHandler) -> None:
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –≤—Å–µ—Ö —Å–æ–±—ã—Ç–∏–π."""
        self._default_handler = handler
    
    def add_handler(self, event_type: EventType, handler: EventHandler) -> None:
        """–ü—Ä–æ–≥—Ä–∞–º–º–Ω–∞—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞."""
        if event_type not in self._handlers:
            self._handlers[event_type] = []
        self._handlers[event_type].append(handler)
    
    async def _process_message(
        self,
        message_id: str,
        message_data: Dict[str, str]
    ) -> bool:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ."""
        try:
            event = deserialize_event(message_data)
            
            # –ù–∞—Ö–æ–¥–∏–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
            handlers = self._handlers.get(event.event_type, [])
            if not handlers and self._default_handler:
                handlers = [self._default_handler]
            
            if not handlers:
                logger.warning(
                    f"No handler for event type {event.event_type.value}, ACKing anyway"
                )
                return True
            
            # –í—ã–∑—ã–≤–∞–µ–º –≤—Å–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
            success = True
            for handler in handlers:
                try:
                    result = await handler(event, message_data)
                    if not result:
                        success = False
                except Exception as e:
                    logger.error(f"Handler error for {event.event_type.value}: {e}")
                    success = False
            
            return success
            
        except Exception as e:
            logger.error(f"Failed to process message {message_id}: {e}")
            return False
    
    async def _claim_pending_messages(self) -> List[tuple]:
        """–ó–∞–±–∏—Ä–∞–µ—Ç –∑–∞–≤–∏—Å—à–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –æ—Ç –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã—Ö consumers."""
        if not self._redis:
            return []
        
        try:
            result = await self._redis.xautoclaim(
                self.config.stream_name,
                self.config.group_name,
                self.config.consumer_name,
                min_idle_time=self.config.claim_idle_ms,
                count=self.config.batch_size
            )
            messages = result[1] if len(result) > 1 else []
            if messages:
                logger.info(f"üîÑ Claimed {len(messages)} pending messages")
            return messages
        except Exception as e:
            logger.warning(f"Failed to claim pending messages: {e}")
            return []
    
    async def _read_new_messages(self) -> List[tuple]:
        """–ß–∏—Ç–∞–µ—Ç –Ω–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ stream."""
        if not self._redis:
            return []
        
        try:
            # > –æ–∑–Ω–∞—á–∞–µ—Ç —á–∏—Ç–∞—Ç—å —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è —ç—Ç–æ–≥–æ consumer
            result = await self._redis.xreadgroup(
                groupname=self.config.group_name,
                consumername=self.config.consumer_name,
                streams={self.config.stream_name: ">"},
                count=self.config.batch_size,
                block=self.config.block_ms
            )
            
            if result:
                # result = [(stream_name, [(msg_id, fields), ...])]
                return result[0][1]
            return []
            
        except Exception as e:
            logger.error(f"Failed to read messages: {e}")
            return []
    
    async def _ack_message(self, message_id: str) -> bool:
        """–ü–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É —Å–æ–æ–±—â–µ–Ω–∏—è."""
        if not self._redis:
            return False
        
        try:
            await self._redis.xack(
                self.config.stream_name,
                self.config.group_name,
                message_id
            )
            return True
        except Exception as e:
            logger.warning(f"Failed to ACK message {message_id}: {e}")
            return False
    
    async def start(self) -> None:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç consumer loop.
        –ë–ª–æ–∫–∏—Ä—É—é—â–∏–π –º–µ—Ç–æ–¥ - –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –¥–æ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏.
        """
        await self.connect()
        self._running = True
        
        logger.info(
            f"üöÄ Consumer '{self.config.consumer_name}' started "
            f"(stream: {self.config.stream_name}, group: {self.config.group_name})"
        )
        
        while self._running:
            try:
                # 1. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –∑–∞–±—Ä–∞—Ç—å –∑–∞–≤–∏—Å—à–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
                pending_messages = await self._claim_pending_messages()
                
                # 2. –ó–∞—Ç–µ–º —á–∏—Ç–∞–µ–º –Ω–æ–≤—ã–µ
                new_messages = await self._read_new_messages()
                
                all_messages = pending_messages + new_messages
                
                for message_id, message_data in all_messages:
                    self.last_message_id = message_id
                    
                    success = await self._process_message(message_id, message_data)
                    
                    if success:
                        self.processed_count += 1
                        if self.config.ack_after_process:
                            await self._ack_message(message_id)
                    else:
                        self.failed_count += 1
                        # –ù–µ ACK–∞–µ–º - —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–µ—Ç—Å—è –≤ pending
                        logger.warning(
                            f"Message {message_id} processing failed, "
                            "will be redelivered"
                        )
                
            except asyncio.CancelledError:
                logger.info("Consumer cancelled, shutting down...")
                break
            except Exception as e:
                logger.error(f"Consumer loop error: {e}")
                await asyncio.sleep(1)  # Backoff before retry
        
        await self.stop()
    
    async def stop(self) -> None:
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç consumer."""
        self._running = False
        
        if self._redis:
            await self._redis.close()
            self._redis = None
        
        logger.info(
            f"Consumer '{self.config.consumer_name}' stopped. "
            f"Processed: {self.processed_count}, Failed: {self.failed_count}"
        )
    
    def get_stats(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É consumer."""
        return {
            "consumer_name": self.config.consumer_name,
            "stream": self.config.stream_name,
            "group": self.config.group_name,
            "running": self._running,
            "processed_count": self.processed_count,
            "failed_count": self.failed_count,
            "last_message_id": self.last_message_id,
        }


class MultiStreamConsumer:
    """
    Consumer –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö streams –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ.
    –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π –∏–∑ —Ä–∞–∑–Ω—ã—Ö streams.
    """
    
    def __init__(
        self,
        redis_url: str = "redis://localhost:6379",
        consumer_name: Optional[str] = None
    ):
        self.redis_url = redis_url
        self.consumer_name = consumer_name or f"multi-consumer-{uuid.uuid4().hex[:8]}"
        self._consumers: Dict[str, EventConsumer] = {}
        self._tasks: List[asyncio.Task] = []
        self._running = False
    
    def add_stream(
        self,
        stream_name: str,
        group_name: str,
        handlers: Optional[Dict[EventType, EventHandler]] = None
    ) -> EventConsumer:
        """–î–æ–±–∞–≤–ª—è–µ—Ç stream –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        config = ConsumerConfig(
            stream_name=stream_name,
            group_name=group_name,
            consumer_name=f"{self.consumer_name}-{stream_name}"
        )
        
        consumer = EventConsumer(self.redis_url, config)
        
        if handlers:
            for event_type, handler in handlers.items():
                consumer.add_handler(event_type, handler)
        
        self._consumers[stream_name] = consumer
        return consumer
    
    async def start(self) -> None:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ consumers –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ."""
        self._running = True
        
        for stream_name, consumer in self._consumers.items():
            task = asyncio.create_task(
                consumer.start(),
                name=f"consumer-{stream_name}"
            )
            self._tasks.append(task)
        
        logger.info(f"üöÄ MultiStreamConsumer started with {len(self._tasks)} streams")
        
        # –ñ–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö tasks
        try:
            await asyncio.gather(*self._tasks)
        except asyncio.CancelledError:
            await self.stop()
    
    async def stop(self) -> None:
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –≤—Å–µ consumers."""
        self._running = False
        
        for task in self._tasks:
            task.cancel()
        
        for consumer in self._consumers.values():
            await consumer.stop()
        
        self._tasks.clear()
        logger.info("MultiStreamConsumer stopped")
