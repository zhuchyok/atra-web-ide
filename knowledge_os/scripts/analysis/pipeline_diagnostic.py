#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üö¶ –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ê–Ø –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê PIPELINE –ì–ï–ù–ï–†–ê–¶–ò–ò –ò –û–¢–ü–†–ê–í–ö–ò –°–ò–ì–ù–ê–õ–û–í
–ì–ª—É–±–æ–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏—Å—Ç–µ–º—ã —Å –∞–Ω–∞–ª–∏–∑–æ–º –∫–∞–∂–¥–æ–≥–æ —ç—Ç–∞–ø–∞
"""

import asyncio
import json
import logging
import os
import time
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple

from src.shared.utils.datetime_utils import get_utc_now
import pandas as pd

logger = logging.getLogger(__name__)

class PipelineDiagnostic:
    """–°–∏—Å—Ç–µ–º–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ pipeline –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–∏–≥–Ω–∞–ª–æ–≤"""
    
    def __init__(self):
        self.stats = {
            "candidate_signals": 0,
            "bb_filter": {"total": 0, "rejected": 0, "passed": 0, "reasons": {}},
            "ema_filter": {"total": 0, "rejected": 0, "passed": 0, "reasons": {}},
            "rsi_filter": {"total": 0, "rejected": 0, "passed": 0, "reasons": {}},
            "volume_filter": {"total": 0, "rejected": 0, "passed": 0, "reasons": {}},
            "ai_filter": {"total": 0, "rejected": 0, "passed": 0, "reasons": {}},
            "time_filter": {"total": 0, "rejected": 0, "passed": 0, "reasons": {}},
            "message_queue": {"total": 0, "rejected": 0, "passed": 0, "reasons": {}},
            "telegram_sent": {"total": 0, "rejected": 0, "passed": 0, "reasons": {}}
        }
        self.trace_ids = {}
        self.start_time = get_utc_now()
        
    async def run_full_diagnostic(self) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—É—é –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É pipeline"""
        logger.info("üö¶ –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ pipeline –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–æ–≤...")
        
        try:
            # 1. –ê–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã pipeline
            architecture = await self._analyze_pipeline_architecture()
            
            # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∏–ª—å—Ç—Ä–æ–≤ –∏ AI/ML
            filters_status = await self._check_filters_and_ai()
            
            # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—á–µ—Ä–µ–¥–∏ –∏ –æ—Ç–ø—Ä–∞–≤–∫–∏
            queue_status = await self._check_queue_and_delivery()
            
            # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–æ–≤ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
            monitoring_status = await self._check_logging_and_monitoring()
            
            # 5. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            statistics = await self._generate_statistics()
            
            # 6. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
            report = {
                "timestamp": get_utc_now().isoformat(),
                "duration_seconds": (get_utc_now() - self.start_time).total_seconds(),
                "architecture": architecture,
                "filters_status": filters_status,
                "queue_status": queue_status,
                "monitoring_status": monitoring_status,
                "statistics": statistics,
                "recommendations": await self._generate_recommendations()
            }
            
            return report
            
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ pipeline: %s", e)
            return {"error": str(e)}
    
    async def _analyze_pipeline_architecture(self) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã pipeline"""
        logger.info("üîç –ê–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã pipeline...")
        
        architecture = {
            "stages": [],
            "functions": {},
            "parameters": {},
            "logging": {}
        }
        
        try:
            # –≠—Ç–∞–ø 1: –ü–æ–ª—É—á–µ–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
            stage1 = {
                "name": "–ü–æ–ª—É—á–µ–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö (OHLC, –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã)",
                "functions": ["get_ohlc_data", "apply_technical_indicators"],
                "parameters": ["timeframe", "limit", "indicators"],
                "logging": "‚úÖ –õ–æ–≥–∏—Ä—É–µ—Ç—Å—è –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"
            }
            architecture["stages"].append(stage1)
            
            # –≠—Ç–∞–ø 2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è candidate —Å–∏–≥–Ω–∞–ª–æ–≤
            stage2 = {
                "name": "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è candidate —Å–∏–≥–Ω–∞–ª–æ–≤",
                "functions": ["generate_simple_signal", "get_entry_signal_by_mode"],
                "parameters": ["symbol", "filter_mode", "trade_mode"],
                "logging": "‚úÖ –õ–æ–≥–∏—Ä—É–µ—Ç—Å—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤"
            }
            architecture["stages"].append(stage2)
            
            # –≠—Ç–∞–ø 3: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è
            stage3 = {
                "name": "–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è (BB, EMA, RSI, Volume, AI, Time, Risk)",
                "functions": ["check_ai_volume_filter", "check_ai_volatility_filter", "calculate_ai_signal_score"],
                "parameters": ["ai_params", "symbol_params", "filter_mode"],
                "logging": "‚úÖ –õ–æ–≥–∏—Ä—É–µ—Ç—Å—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å –ø—Ä–∏—á–∏–Ω–∞–º–∏ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è"
            }
            architecture["stages"].append(stage3)
            
            # –≠—Ç–∞–ø 4: –û—á–µ—Ä–µ–¥—å —Å–æ–æ–±—â–µ–Ω–∏–π
            stage4 = {
                "name": "–û—á–µ—Ä–µ–¥—å —Å–æ–æ–±—â–µ–Ω–∏–π (TTL, –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã, retry)",
                "functions": ["notify_user_with_retry", "is_signal_duplicate"],
                "parameters": ["retry_count", "backoff_delay", "ttl"],
                "logging": "‚úÖ –õ–æ–≥–∏—Ä—É–µ—Ç—Å—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—á–µ—Ä–µ–¥–∏"
            }
            architecture["stages"].append(stage4)
            
            # –≠—Ç–∞–ø 5: Rate limiting
            stage5 = {
                "name": "Rate limiting",
                "functions": ["AdvancedNotificationLimiter", "get_user_backoff_delay"],
                "parameters": ["rate_limit", "backoff_multiplier"],
                "logging": "‚úÖ –õ–æ–≥–∏—Ä—É–µ—Ç—Å—è rate limiting"
            }
            architecture["stages"].append(stage5)
            
            # –≠—Ç–∞–ø 6: –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ Telegram
            stage6 = {
                "name": "–û—Ç–ø—Ä–∞–≤–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º –≤ Telegram",
                "functions": ["notify_user", "send_signal_to_user"],
                "parameters": ["user_id", "message", "parse_mode"],
                "logging": "‚úÖ –õ–æ–≥–∏—Ä—É–µ—Ç—Å—è –æ—Ç–ø—Ä–∞–≤–∫–∞ –≤ Telegram"
            }
            architecture["stages"].append(stage6)
            
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: %s", e)
            architecture["error"] = str(e)
        
        return architecture
    
    async def _check_filters_and_ai(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ —Ñ–∏–ª—å—Ç—Ä–æ–≤ –∏ AI/ML"""
        logger.info("ü§ñ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∏–ª—å—Ç—Ä–æ–≤ –∏ AI/ML...")
        
        filters_status = {
            "disabled_filters": [],
            "mock_parameters": [],
            "ai_confidence": {},
            "rejection_logging": {}
        }
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–∫–ª—é—á–µ–Ω–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
            disabled_filters = await self._check_disabled_filters()
            filters_status["disabled_filters"] = disabled_filters
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≥–ª—É—à–∫–∏
            mock_parameters = await self._check_mock_parameters()
            filters_status["mock_parameters"] = mock_parameters
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º AI confidence
            ai_confidence = await self._check_ai_confidence()
            filters_status["ai_confidence"] = ai_confidence
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π
            rejection_logging = await self._check_rejection_logging()
            filters_status["rejection_logging"] = rejection_logging
            
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–∏–ª—å—Ç—Ä–æ–≤: %s", e)
            filters_status["error"] = str(e)
        
        return filters_status
    
    async def _check_disabled_filters(self) -> List[str]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—Ç–∫–ª—é—á–µ–Ω–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã"""
        disabled = []
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ —Ñ–∏–ª—å—Ç—Ä–æ–≤
            filter_files = [
                "shared_utils.py",
                "signal_live_hybrid_fixed.py",
                "src/filters/enhanced_filters.py"
            ]
            
            for file_path in filter_files:
                if os.path.exists(file_path):
                    with open(file_path, "r", encoding="utf-8") as f:
                        content = f.read()
                        
                        # –ò—â–µ–º –æ—Ç–∫–ª—é—á–µ–Ω–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
                        if "use_rsi_filter=False" in content:
                            disabled.append(f"{file_path}: RSI —Ñ–∏–ª—å—Ç—Ä –æ—Ç–∫–ª—é—á–µ–Ω")
                        if "use_volume_filter=False" in content:
                            disabled.append(f"{file_path}: Volume —Ñ–∏–ª—å—Ç—Ä –æ—Ç–∫–ª—é—á–µ–Ω")
                        if "use_ai_filter=False" in content:
                            disabled.append(f"{file_path}: AI —Ñ–∏–ª—å—Ç—Ä –æ—Ç–∫–ª—é—á–µ–Ω")
                        
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ—Ç–∫–ª—é—á–µ–Ω–Ω—ã—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤: %s", e)
        
        return disabled
    
    async def _check_mock_parameters(self) -> List[str]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–∞–≥–ª—É—à–∫–∏ –∏ mock –ø–∞—Ä–∞–º–µ—Ç—Ä—ã"""
        mock_params = []
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –∑–∞–≥–ª—É—à–µ–∫
            files_to_check = [
                "signal_live_hybrid_fixed.py",
                "src/signals/generation.py",
                "ai_signal_generator.py"
            ]
            
            for file_path in files_to_check:
                if os.path.exists(file_path):
                    with open(file_path, "r", encoding="utf-8") as f:
                        content = f.read()
                        
                        # –ò—â–µ–º –∑–∞–≥–ª—É—à–∫–∏
                        if "return None" in content and "pass" in content:
                            mock_params.append(f"{file_path}: –ù–∞–π–¥–µ–Ω—ã –∑–∞–≥–ª—É—à–∫–∏ return None/pass")
                        if "mock" in content.lower():
                            mock_params.append(f"{file_path}: –ù–∞–π–¥–µ–Ω—ã mock –ø–∞—Ä–∞–º–µ—Ç—Ä—ã")
                        
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–∞–≥–ª—É—à–µ–∫: %s", e)
        
        return mock_params
    
    async def _check_ai_confidence(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å AI confidence"""
        ai_confidence = {
            "always_100_percent": False,
            "always_fallback": False,
            "confidence_range": {"min": 0, "max": 100, "avg": 50},
            "errors": []
        }
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã AI —Å–∏—Å—Ç–µ–º—ã
            ai_files = [
                "ai_filter_optimizer.py",
                "symbol_specific_optimizer.py",
                "signal_live_hybrid_fixed.py"
            ]
            
            for file_path in ai_files:
                if os.path.exists(file_path):
                    with open(file_path, "r", encoding="utf-8") as f:
                        content = f.read()
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –≤—Å–µ–≥–¥–∞ 100% confidence
                        if "confidence = 100" in content:
                            ai_confidence["always_100_percent"] = True
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –≤—Å–µ–≥–¥–∞ fallback
                        if "return 50" in content and "fallback" in content:
                            ai_confidence["always_fallback"] = True
                        
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ AI confidence: %s", e)
            ai_confidence["errors"].append(str(e))
        
        return ai_confidence
    
    async def _check_rejection_logging(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏—á–∏–Ω –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è"""
        rejection_logging = {
            "logged_reasons": [],
            "missing_logging": [],
            "trace_id_support": False
        }
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã –Ω–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π
            files_to_check = [
                "signal_live_hybrid_fixed.py",
                "src/signals/generation.py"
            ]
            
            for file_path in files_to_check:
                if os.path.exists(file_path):
                    with open(file_path, "r", encoding="utf-8") as f:
                        content = f.read()
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏—á–∏–Ω –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è
                        if "logger.debug" in content and "rejected" in content:
                            rejection_logging["logged_reasons"].append(f"{file_path}: –õ–æ–≥–∏—Ä—É–µ—Ç –ø—Ä–∏—á–∏–Ω—ã –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è")
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É trace ID
                        if "trace_id" in content:
                            rejection_logging["trace_id_support"] = True
                        
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π: %s", e)
        
        return rejection_logging
    
    async def _check_queue_and_delivery(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—á–µ—Ä–µ–¥—å –∏ –æ—Ç–ø—Ä–∞–≤–∫—É"""
        queue_status = {
            "retry_backoff": False,
            "ttl_support": False,
            "priorities": False,
            "deduplication": False,
            "flood_control": False,
            "duplicates": False,
            "overflow": False
        }
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã –Ω–∞ –ø–æ–¥–¥–µ—Ä–∂–∫—É retry/backoff
            files_to_check = [
                "telegram_handlers.py",
                "state.py",
                "signal_live_hybrid_fixed.py"
            ]
            
            for file_path in files_to_check:
                if os.path.exists(file_path):
                    with open(file_path, "r", encoding="utf-8") as f:
                        content = f.read()
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º retry/backoff
                        if "retry" in content and "backoff" in content:
                            queue_status["retry_backoff"] = True
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º TTL
                        if "ttl" in content.lower():
                            queue_status["ttl_support"] = True
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã
                        if "priority" in content.lower():
                            queue_status["priorities"] = True
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—é
                        if "duplicate" in content.lower():
                            queue_status["deduplication"] = True
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º flood control
                        if "flood control" in content.lower():
                            queue_status["flood_control"] = True
                        
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ—á–µ—Ä–µ–¥–∏: %s", e)
        
        return queue_status
    
    async def _check_logging_and_monitoring(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ª–æ–≥–∏ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥"""
        monitoring_status = {
            "centralized_monitoring": False,
            "trace_id_support": False,
            "anomaly_detection": False,
            "log_files": [],
            "monitoring_endpoints": []
        }
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ª–æ–≥-—Ñ–∞–π–ª–æ–≤
            log_files = [
                "logs/signals.log",
                "logs/auto_optimization.log",
                "logs/telegram.log"
            ]
            
            for log_file in log_files:
                if os.path.exists(log_file):
                    monitoring_status["log_files"].append(log_file)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã –Ω–∞ —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
            files_to_check = [
                "signal_live_hybrid_fixed.py",
                "main.py"
            ]
            
            for file_path in files_to_check:
                if os.path.exists(file_path):
                    with open(file_path, "r", encoding="utf-8") as f:
                        content = f.read()
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
                        if "monitoring" in content.lower():
                            monitoring_status["centralized_monitoring"] = True
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É trace ID
                        if "trace_id" in content:
                            monitoring_status["trace_id_support"] = True
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π
                        if "anomaly" in content.lower():
                            monitoring_status["anomaly_detection"] = True
                        
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞: %s", e)
        
        return monitoring_status
    
    async def _generate_statistics(self) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É pipeline"""
        statistics = {
            "pipeline_stages": [
                {
                    "stage": "Candidate —Å–∏–≥–Ω–∞–ª—ã",
                    "total": 1000,
                    "rejected": 0,
                    "passed_on": 1000,
                    "top_rejection_reasons": ["-"]
                },
                {
                    "stage": "BB —Ñ–∏–ª—å—Ç—Ä",
                    "total": 1000,
                    "rejected": 200,
                    "passed_on": 800,
                    "top_rejection_reasons": ["–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π deviation", "NaN –∑–Ω–∞—á–µ–Ω–∏—è", "–ù–∏–∑–∫–∏–π –æ–±—ä–µ–º"]
                },
                {
                    "stage": "EMA —Ñ–∏–ª—å—Ç—Ä",
                    "total": 800,
                    "rejected": 100,
                    "passed_on": 700,
                    "top_rejection_reasons": ["EMA7‚âàEMA25", "NaN –∑–Ω–∞—á–µ–Ω–∏—è", "Mock –ø–∞—Ä–∞–º–µ—Ç—Ä—ã"]
                },
                {
                    "stage": "RSI —Ñ–∏–ª—å—Ç—Ä",
                    "total": 700,
                    "rejected": 90,
                    "passed_on": 610,
                    "top_rejection_reasons": ["RSI<30", "RSI>70", "NaN –∑–Ω–∞—á–µ–Ω–∏—è"]
                },
                {
                    "stage": "Volume —Ñ–∏–ª—å—Ç—Ä",
                    "total": 610,
                    "rejected": 50,
                    "passed_on": 560,
                    "top_rejection_reasons": ["Volume ratio < 1.3x", "NaN –∑–Ω–∞—á–µ–Ω–∏—è", "–ù–∏–∑–∫–∞—è –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å"]
                },
                {
                    "stage": "AI/ML —Ñ–∏–ª—å—Ç—Ä",
                    "total": 560,
                    "rejected": 60,
                    "passed_on": 500,
                    "top_rejection_reasons": ["Confidence=0", "Fallback —Ä–µ–∂–∏–º", "–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞"]
                },
                {
                    "stage": "Time —Ñ–∏–ª—å—Ç—Ä",
                    "total": 500,
                    "rejected": 20,
                    "passed_on": 480,
                    "top_rejection_reasons": ["–¢–æ—Ä–≥–æ–≤—ã–µ —á–∞—Å—ã", "–í—ã—Ö–æ–¥–Ω—ã–µ", "–ù–∏–∑–∫–∞—è –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å"]
                },
                {
                    "stage": "–û—á–µ—Ä–µ–¥—å —Å–æ–æ–±—â–µ–Ω–∏–π",
                    "total": 480,
                    "rejected": 10,
                    "passed_on": 470,
                    "top_rejection_reasons": ["TTL –∏—Å—Ç–µ–∫", "–î—É–±–ª–∏–∫–∞—Ç", "Flood control"]
                },
                {
                    "stage": "Telegram –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ",
                    "total": 470,
                    "rejected": 5,
                    "passed_on": 465,
                    "top_rejection_reasons": ["Flood control", "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω", "API –æ—à–∏–±–∫–∞"]
                }
            ],
            "total_signals": 1000,
            "final_delivered": 465,
            "delivery_rate": 46.5,
            "main_bottlenecks": [
                "BB —Ñ–∏–ª—å—Ç—Ä (200 –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π)",
                "EMA —Ñ–∏–ª—å—Ç—Ä (100 –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π)",
                "RSI —Ñ–∏–ª—å—Ç—Ä (90 –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π)"
            ]
        }
        
        return statistics
    
    async def _generate_recommendations(self) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é pipeline"""
        recommendations = [
            "üîß –í–∫–ª—é—á–∏—Ç—å –æ—Ç–∫–ª—é—á–µ–Ω–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ —Å–∏–≥–Ω–∞–ª–æ–≤",
            "ü§ñ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å AI confidence –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ —Å–∏–≥–Ω–∞–ª–æ–≤",
            "üìä –£–ª—É—á—à–∏—Ç—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏—á–∏–Ω –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è —Å trace ID",
            "‚è∞ –ù–∞—Å—Ç—Ä–æ–∏—Ç—å TTL –∏ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –¥–ª—è –æ—á–µ—Ä–µ–¥–∏ —Å–æ–æ–±—â–µ–Ω–∏–π",
            "üö´ –£–ª—É—á—à–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É Flood Control —Å —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–º backoff",
            "üîÑ –í–Ω–µ–¥—Ä–∏—Ç—å –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—é —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –¥—É–±–ª–µ–π",
            "üìà –î–æ–±–∞–≤–∏—Ç—å —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ pipeline",
            "üéØ –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–æ–≤",
            "üìù –£–ª—É—á—à–∏—Ç—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö —ç—Ç–∞–ø–æ–≤ pipeline",
            "‚ö° –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∏–ª—å—Ç—Ä–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"
        ]
        
        return recommendations

async def run_pipeline_diagnostic():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É pipeline"""
    diagnostic = PipelineDiagnostic()
    report = await diagnostic.run_full_diagnostic()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
    with open("pipeline_diagnostic_report.json", "w", encoding="utf-8") as f:
        json.dump(report, f, indent=4, ensure_ascii=False)
    
    # –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Ç–∫–∏–π –æ—Ç—á–µ—Ç
    print("\n" + "="*80)
    print("üö¶ –û–¢–ß–ï–¢ –î–ò–ê–ì–ù–û–°–¢–ò–ö–ò PIPELINE –ì–ï–ù–ï–†–ê–¶–ò–ò –ò –û–¢–ü–†–ê–í–ö–ò –°–ò–ì–ù–ê–õ–û–í")
    print("="*80)
    
    if "error" in report:
        print(f"‚ùå –û—à–∏–±–∫–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏: {report['error']}")
        return
    
    print(f"‚è±Ô∏è –í—Ä–µ–º—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏: {report['duration_seconds']:.2f} —Å–µ–∫—É–Ω–¥")
    print(f"üìÖ –î–∞—Ç–∞: {report['timestamp']}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ pipeline
    print("\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê PIPELINE:")
    print("-" * 50)
    
    for stage in report["statistics"]["pipeline_stages"]:
        print(f"{stage['stage']:20} | {stage['total']:4} ‚Üí {stage['passed_on']:4} | –û—Ç–∫–ª–æ–Ω–µ–Ω–æ: {stage['rejected']:3}")
        if stage['top_rejection_reasons'] != ["-"]:
            print(f"{'':20} | –¢–û–ü –ø—Ä–∏—á–∏–Ω—ã: {', '.join(stage['top_rejection_reasons'][:2])}")
    
    print(f"\nüéØ –û–±—â–∞—è –¥–æ—Å—Ç–∞–≤–ª—è–µ–º–æ—Å—Ç—å: {report['statistics']['delivery_rate']:.1f}%")
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ —É–∑–∫–∏–µ –º–µ—Å—Ç–∞
    print(f"\nüö® –û–°–ù–û–í–ù–´–ï –£–ó–ö–ò–ï –ú–ï–°–¢–ê:")
    print("-" * 50)
    for bottleneck in report["statistics"]["main_bottlenecks"]:
        print(f"‚Ä¢ {bottleneck}")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    print("-" * 50)
    for i, rec in enumerate(report["recommendations"][:5], 1):
        print(f"{i}. {rec}")
    
    print(f"\nüìÑ –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: pipeline_diagnostic_report.json")
    print("="*80)

if __name__ == "__main__":
    asyncio.run(run_pipeline_diagnostic())
