#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ML-–æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä —Ñ–∏–ª—å—Ç—Ä–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ 50K –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ñ–∏–ª—å—Ç—Ä–æ–≤
"""

import logging
import json
import os
import sqlite3
from typing import Dict, Any, Optional, List
from datetime import datetime
import numpy as np

logger = logging.getLogger(__name__)

# ML –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
try:
    from sklearn.ensemble import GradientBoostingRegressor
    from sklearn.model_selection import train_test_split
    from sklearn.preprocessing import StandardScaler
    import joblib
    ML_AVAILABLE = True
except ImportError:
    ML_AVAILABLE = False
    logger.warning("‚ö†Ô∏è scikit-learn –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, ML —Ñ—É–Ω–∫—Ü–∏–∏ –±—É–¥—É—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω—ã")


class MLFilterOptimizer:
    """
    ML-–æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä —Ñ–∏–ª—å—Ç—Ä–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤

    –õ–æ–≥–∏–∫–∞:
    1. –ó–∞–≥—Ä—É–∂–∞–µ—Ç 50K –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏–∑ trading_patterns.json
    2. –û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å —É—Å–ø–µ—à–Ω–æ—Å—Ç—å —Å–∏–≥–Ω–∞–ª–∞
    3. –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∏–ª—å—Ç—Ä–æ–≤ –¥–ª—è —Ç–µ–∫—É—â–∏—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π
    """

    def __init__(self, patterns_file: str = "ai_learning_data/trading_patterns.json"):
        self.patterns_file = patterns_file
        self.model = None
        self.scaler = StandardScaler() if ML_AVAILABLE else None
        self.patterns: List[Dict[str, Any]] = []
        self.is_trained = False

    def load_patterns(self) -> int:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞"""
        try:
            if not os.path.exists(self.patterns_file):
                logger.warning("‚ö†Ô∏è –§–∞–π–ª –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: %s", self.patterns_file)
                return 0

            with open(self.patterns_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            if isinstance(data, list):
                self.patterns = data
                logger.info("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ %d –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏–∑ %s", len(self.patterns), self.patterns_file)
                return len(self.patterns)
            else:
                logger.error("‚ùå –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: –æ–∂–∏–¥–∞–µ—Ç—Å—è —Å–ø–∏—Å–æ–∫")
                return 0

        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: %s", e)
            return 0

    def prepare_features(self, patterns: List[Dict[str, Any]]) -> tuple:
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç features –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏

        Returns:
            (X, y) - features –∏ target (—É—Å–ø–µ—à–Ω–æ—Å—Ç—å —Å–∏–≥–Ω–∞–ª–∞)
        """
        if not ML_AVAILABLE or not patterns:
            return None, None

        try:
            features = []
            targets = []

            for pattern in patterns:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º features –∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–∞
                feature_vector = self._extract_features(pattern)
                if feature_vector is None:
                    continue

                features.append(feature_vector)

                # Target: —É—Å–ø–µ—à–Ω–æ—Å—Ç—å —Å–∏–≥–Ω–∞–ª–∞ (1 = WIN, 0 = LOSS)
                result = pattern.get('result', '')
                target = 1 if result == 'WIN' else 0
                targets.append(target)

            if not features:
                logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å features –∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤")
                return None, None

            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∏–º–µ–Ω–∞ –¥–ª—è ML (X - features, y - target)
            features_array = np.array(features)  # pylint: disable=invalid-name
            targets_array = np.array(targets)  # pylint: disable=invalid-name

            logger.info(
                "‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ %d samples —Å %d features",
                len(features_array), features_array.shape[1]
            )
            return features_array, targets_array

        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ features: %s", e)
            return None, None

    def _extract_features(self, pattern: Dict[str, Any]) -> Optional[np.ndarray]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç features –∏–∑ –æ–¥–Ω–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞"""
        try:
            features = []

            # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
            indicators = pattern.get('indicators', {})
            features.append(indicators.get('rsi', 50.0))
            features.append(indicators.get('ema_fast', 0.0))
            features.append(indicators.get('ema_slow', 0.0))
            features.append(indicators.get('macd', 0.0))
            features.append(indicators.get('bb_upper', 0.0))
            features.append(indicators.get('bb_lower', 0.0))

            # –†—ã–Ω–æ—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è
            market = pattern.get('market_conditions', {})
            features.append(1.0 if market.get('btc_trend', False) else 0.0)
            features.append(market.get('volume_ratio', 1.0))
            features.append(market.get('volatility', 0.0))

            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∏–≥–Ω–∞–ª–∞
            features.append(pattern.get('risk_pct', 2.0))
            features.append(pattern.get('leverage', 1.0))

            # –í—Ä–µ–º—è (hour of day, day of week)
            timestamp = pattern.get('timestamp', '')
            if timestamp:
                try:
                    dt = datetime.fromisoformat(timestamp) if isinstance(timestamp, str) else timestamp
                    features.append(dt.hour)
                    features.append(dt.weekday())
                except Exception:
                    features.extend([12, 0])  # Default: noon, Monday
            else:
                features.extend([12, 0])

            return np.array(features)

        except Exception as e:
            logger.debug("‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è features: %s", e)
            return None

    def train_model(self) -> bool:
        """–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö"""
        if not ML_AVAILABLE:
            logger.warning("‚ö†Ô∏è ML –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã, –æ–±—É—á–µ–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–æ")
            return False

        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            pattern_count = self.load_patterns()
            if pattern_count < 100:
                logger.warning("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (–Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 100, –µ—Å—Ç—å %d)", pattern_count)
                return False

            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            features_data, targets_data = self.prepare_features(self.patterns)
            if features_data is None or targets_data is None:
                return False

            # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/test (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∏–º–µ–Ω–∞ ML)
            # pylint: disable=invalid-name
            x_train, x_test, y_train, y_test = train_test_split(
                features_data, targets_data, test_size=0.2, random_state=42
            )

            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º features
            x_train_scaled = self.scaler.fit_transform(x_train)
            x_test_scaled = self.scaler.transform(x_test)

            # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
            self.model = GradientBoostingRegressor(
                n_estimators=100,
                learning_rate=0.1,
                max_depth=5,
                random_state=42
            )
            self.model.fit(x_train_scaled, y_train)

            # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
            train_score = self.model.score(x_train_scaled, y_train)
            test_score = self.model.score(x_test_scaled, y_test)

            logger.info("‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞: train_score=%.3f, test_score=%.3f", train_score, test_score)
            self.is_trained = True

            return True

        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: %s", e)
            return False

    def optimize_filter_parameters(
        self,
        current_market_conditions: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∏–ª—å—Ç—Ä–æ–≤ –¥–ª—è —Ç–µ–∫—É—â–∏—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π

        Args:
            current_market_conditions: –¢–µ–∫—É—â–∏–µ —Ä—ã–Ω–æ—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è

        Returns:
            –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∏–ª—å—Ç—Ä–æ–≤
        """
        if not self.is_trained or not self.model:
            logger.warning("‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã")
            return self._get_default_parameters()

        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º features –¥–ª—è —Ç–µ–∫—É—â–∏—Ö —É—Å–ª–æ–≤–∏–π
            pattern_template = {
                'indicators': current_market_conditions.get('indicators', {}),
                'market_conditions': current_market_conditions.get('market_conditions', {}),
                'risk_pct': current_market_conditions.get('risk_pct', 2.0),
                'leverage': current_market_conditions.get('leverage', 1.0),
                'timestamp': datetime.now().isoformat()
            }

            feature_vector = self._extract_features(pattern_template)
            if feature_vector is None:
                return self._get_default_parameters()

            # –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å
            features_scaled = self.scaler.transform([feature_vector])  # pylint: disable=invalid-name
            predicted_success = self.model.predict(features_scaled)[0]

            # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            # –ï—Å–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤—ã—Å–æ–∫–æ–µ (>0.6) - –æ—Å–ª–∞–±–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
            # –ï—Å–ª–∏ –Ω–∏–∑–∫–æ–µ (<0.4) - —É–∂–µ—Å—Ç–æ—á–∞–µ–º —Ñ–∏–ª—å—Ç—Ä—ã

            # üÜï –ü–æ–ª—É—á–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞ –¥–ª—è false_breakout
            optimal_weights = self.get_optimal_weights(current_market_conditions)

            if predicted_success > 0.6:
                # –•–æ—Ä–æ—à–∏–µ —É—Å–ª–æ–≤–∏—è - –º–æ–∂–Ω–æ –æ—Å–ª–∞–±–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä—ã
                return {
                    'min_volume_ratio': 0.7,  # üîß –û–°–õ–ê–ë–õ–ï–ù–û –¥–ª—è –∏–Ω—Ç—Ä–∞–¥–µ–π (–±—ã–ª–æ 0.8)
                    'require_volume_confirmation': False,
                    'confidence_threshold': 0.58,  # üîß –û–°–õ–ê–ë–õ–ï–ù–û (–±—ã–ª–æ 0.60)
                    'false_breakout_threshold': 0.15,  # üÜï ML –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è false_breakout (–±—ã–ª–æ 0.20)
                    'false_breakout_weights': optimal_weights  # üÜï ML –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
                }
            elif predicted_success < 0.4:
                # –ü–ª–æ—Ö–∏–µ —É—Å–ª–æ–≤–∏—è - —É–º–µ—Ä–µ–Ω–Ω–æ —É–∂–µ—Å—Ç–æ—á–∞–µ–º —Ñ–∏–ª—å—Ç—Ä—ã (–¥–ª—è –∏–Ω—Ç—Ä–∞–¥–µ–π –Ω–µ —Å–ª–∏—à–∫–æ–º —Å—Ç—Ä–æ–≥–æ)
                return {
                    'min_volume_ratio': 0.9,  # üîß –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û –û–°–õ–ê–ë–õ–ï–ù–û –¥–ª—è –∏–Ω—Ç—Ä–∞–¥–µ–π (–±—ã–ª–æ 1.1)
                    'require_volume_confirmation': False,  # üîß –û–°–õ–ê–ë–õ–ï–ù–û: –Ω–µ —Ç—Ä–µ–±—É–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –≤ –ø–ª–æ—Ö–∏—Ö —É—Å–ª–æ–≤–∏—è—Ö
                    'confidence_threshold': 0.70,  # üîß –û–°–õ–ê–ë–õ–ï–ù–û (–±—ã–ª–æ 0.75)
                    'false_breakout_threshold': 0.25,  # üÜï ML –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è false_breakout (–±—ã–ª–æ 0.20)
                    'false_breakout_weights': optimal_weights  # üÜï ML –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
                }
            else:
                # –°—Ä–µ–¥–Ω–∏–µ —É—Å–ª–æ–≤–∏—è - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–æ—Å–ª–∞–±–ª–µ–Ω—ã –¥–ª—è –∏–Ω—Ç—Ä–∞–¥–µ–π)
                return {
                    'min_volume_ratio': 0.8,  # üîß –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û –û–°–õ–ê–ë–õ–ï–ù–û –¥–ª—è –∏–Ω—Ç—Ä–∞–¥–µ–π (–±—ã–ª–æ 1.0)
                    'require_volume_confirmation': False,  # üîß –û–°–õ–ê–ë–õ–ï–ù–û: –Ω–µ —Ç—Ä–µ–±—É–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –≤ —Å—Ä–µ–¥–Ω–∏—Ö —É—Å–ª–æ–≤–∏—è—Ö
                    'confidence_threshold': 0.65,  # üîß –û–°–õ–ê–ë–õ–ï–ù–û (–±—ã–ª–æ 0.68)
                    'false_breakout_threshold': 0.20,  # üÜï ML –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è false_breakout (—Å—Ç–∞–Ω–¥–∞—Ä—Ç)
                    'false_breakout_weights': optimal_weights  # üÜï ML –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
                }

        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: %s", e)
            return self._get_default_parameters()

    def optimize_ml_filter_thresholds(self) -> Dict[str, float]:
        """
        üÜï –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –ø–æ—Ä–æ–≥–∏ ML —Ñ–∏–ª—å—Ç—Ä–∞ (min_success_prob, min_expected_profit)
        –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑ signals_log

        Returns:
            Dict —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏: {
                'min_success_prob': 0.4,
                'min_expected_profit': 0.3,
                'min_combined_score': 0.15
            }
        """
        try:
            db_path = "trading.db"
            if not os.path.exists(db_path):
                logger.debug("‚ö†Ô∏è –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –ø–æ—Ä–æ–≥–∏ ML")
                return self._get_default_ml_thresholds()

            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()

            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–∫—Ä—ã—Ç—ã–µ —Å–¥–µ–ª–∫–∏ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            cursor.execute("""
                SELECT result, net_profit, entry, tp1, tp2, stop
                FROM signals_log
                WHERE entry > 0
                  AND result IN ('TP1', 'TP2', 'TP1_PARTIAL', 'TP2_REACHED', 'SL', 'SL_BE', 'CLOSED')
                ORDER BY created_at DESC
                LIMIT 500
            """)

            rows = cursor.fetchall()
            conn.close()

            if len(rows) < 50:
                logger.debug("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–æ—Ä–æ–≥–æ–≤ ML (–Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 50, –µ—Å—Ç—å %d)", len(rows))
                return self._get_default_ml_thresholds()

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            wins = 0
            losses = 0
            total_profit = 0.0
            total_loss = 0.0
            win_profits = []
            loss_profits = []

            for row in rows:
                result, net_profit, entry, _tp1, _tp2, _stop = row
                result_upper = str(result).upper() if result else ''

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º WIN/LOSS
                is_win = False
                profit_pct = 0.0

                if 'TP2' in result_upper:
                    is_win = True
                    profit_pct = 4.0
                elif 'TP1' in result_upper:
                    is_win = True
                    profit_pct = 2.0
                elif 'SL' in result_upper and 'BE' not in result_upper:
                    is_win = False
                    profit_pct = -2.0
                elif result_upper == 'CLOSED' and net_profit:
                    is_win = net_profit > 0
                    if entry:
                        profit_pct = (float(net_profit) / (float(entry) * 100)) * 100
                    else:
                        profit_pct = 2.0 if is_win else -2.0
                else:
                    continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

                if is_win:
                    wins += 1
                    total_profit += profit_pct
                    win_profits.append(profit_pct)
                else:
                    losses += 1
                    total_loss += abs(profit_pct)
                    loss_profits.append(profit_pct)

            if wins + losses < 30:
                msg = "‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ WIN/LOSS –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (–Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 30, –µ—Å—Ç—å %d)"
                logger.debug(msg, wins + losses)
                return self._get_default_ml_thresholds()

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
            win_rate = wins / (wins + losses)
            avg_win = total_profit / wins if wins > 0 else 0.0
            avg_loss = total_loss / losses if losses > 0 else 0.0
            profit_factor = total_profit / total_loss if total_loss > 0 else 0.0

            logger.info(
                "üìä [ML_THRESHOLDS] –ê–Ω–∞–ª–∏–∑: Win Rate=%.1f%%, Avg Win=%.2f%%, Avg Loss=%.2f%%, Profit Factor=%.2f",
                win_rate * 100, avg_win, avg_loss, profit_factor
            )

            # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –ø–æ—Ä–æ–≥–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫
            # –ï—Å–ª–∏ Win Rate –≤—ã—Å–æ–∫–∏–π (>60%) –∏ Profit Factor —Ö–æ—Ä–æ—à–∏–π (>1.5) - –º–æ–∂–Ω–æ –æ—Å–ª–∞–±–∏—Ç—å –ø–æ—Ä–æ–≥–∏
            # –ï—Å–ª–∏ Win Rate –Ω–∏–∑–∫–∏–π (<40%) –∏–ª–∏ Profit Factor –ø–ª–æ—Ö–æ–π (<1.0) - –Ω—É–∂–Ω–æ —É–∂–µ—Å—Ç–æ—á–∏—Ç—å –ø–æ—Ä–æ–≥–∏

            if win_rate > 0.6 and profit_factor > 1.5:
                # –•–æ—Ä–æ—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã - –æ—Å–ª–∞–±–ª—è–µ–º –ø–æ—Ä–æ–≥–∏ –¥–ª—è –±–æ–ª—å—à–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–∏–≥–Ω–∞–ª–æ–≤
                min_success_prob = 0.35  # –ë—ã–ª–æ 0.4
                min_expected_profit = 0.25  # –ë—ã–ª–æ 0.3
                min_combined_score = 0.12  # –ë—ã–ª–æ 0.15
                logger.info("‚úÖ [ML_THRESHOLDS] –•–æ—Ä–æ—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã - –æ—Å–ª–∞–±–ª—è–µ–º –ø–æ—Ä–æ–≥–∏ –¥–ª—è –±–æ–ª—å—à–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–∏–≥–Ω–∞–ª–æ–≤")
            elif win_rate < 0.4 or profit_factor < 1.0:
                # –ü–ª–æ—Ö–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã - —É–∂–µ—Å—Ç–æ—á–∞–µ–º –ø–æ—Ä–æ–≥–∏ –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞
                min_success_prob = 0.50  # –ë—ã–ª–æ 0.4
                min_expected_profit = 0.40  # –ë—ã–ª–æ 0.3
                min_combined_score = 0.20  # –ë—ã–ª–æ 0.15
                logger.info("‚ö†Ô∏è [ML_THRESHOLDS] –ü–ª–æ—Ö–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã - —É–∂–µ—Å—Ç–æ—á–∞–µ–º –ø–æ—Ä–æ–≥–∏ –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞")
            else:
                # –°—Ä–µ–¥–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–æ—Ä–æ–≥–∏
                min_success_prob = 0.4
                min_expected_profit = 0.3
                min_combined_score = 0.15
                logger.info("üìä [ML_THRESHOLDS] –°—Ä–µ–¥–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–æ—Ä–æ–≥–∏")

            return {
                'min_success_prob': min_success_prob,
                'min_expected_profit': min_expected_profit,
                'min_combined_score': min_combined_score
            }

        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–æ—Ä–æ–≥–æ–≤ ML —Ñ–∏–ª—å—Ç—Ä–∞: %s", e)
            return self._get_default_ml_thresholds()

    def _get_default_ml_thresholds(self) -> Dict[str, float]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –ø–æ—Ä–æ–≥–∏ ML —Ñ–∏–ª—å—Ç—Ä–∞"""
        return {
            'min_success_prob': 0.4,
            'min_expected_profit': 0.3,
            'min_combined_score': 0.15
        }

    def _get_default_parameters(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∏–ª—å—Ç—Ä–æ–≤ (–æ—Å–ª–∞–±–ª–µ–Ω—ã –¥–ª—è –∏–Ω—Ç—Ä–∞–¥–µ–π)"""
        return {
            'min_volume_ratio': 0.7,  # üîß –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û –û–°–õ–ê–ë–õ–ï–ù–û –¥–ª—è –∏–Ω—Ç—Ä–∞–¥–µ–π (–±—ã–ª–æ 1.0)
            'require_volume_confirmation': False,  # üîß –û–°–õ–ê–ë–õ–ï–ù–û: –Ω–µ —Ç—Ä–µ–±—É–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            'confidence_threshold': 0.65,  # üîß –û–°–õ–ê–ë–õ–ï–ù–û (–±—ã–ª–æ 0.68)
            'false_breakout_threshold': 0.20,  # üÜï ML –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è false_breakout
            'false_breakout_weights': {  # üÜï ML –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
                'volume': 0.40,
                'momentum': 0.30,
                'level': 0.30
            }
        }

    def get_optimal_weights(
        self,
        market_conditions: Dict[str, Any]
    ) -> Dict[str, float]:
        """
        üÜï ML-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ –¥–ª—è FalseBreakoutDetector

        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞ –¥–ª—è volume/momentum/level –Ω–∞ –æ—Å–Ω–æ–≤–µ:
        - –†—ã–Ω–æ—á–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞
        - –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
        - –í—Ä–µ–º–µ–Ω–∏ —Å—É—Ç–æ–∫
        - –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤

        Args:
            market_conditions: –¢–µ–∫—É—â–∏–µ —Ä—ã–Ω–æ—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è

        Returns:
            Dict —Å –≤–µ—Å–∞–º–∏: {'volume': 0.4, 'momentum': 0.3, 'level': 0.3}
        """
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            regime = market_conditions.get('regime', 'UNKNOWN')
            volatility = market_conditions.get('volatility', 0.0)
            trend_strength = market_conditions.get('trend_strength', 0.5)

            # üîß –≠–í–†–ò–°–¢–ò–ß–ï–°–ö–ê–Ø –õ–û–ì–ò–ö–ê (—Ä–∞–±–æ—Ç–∞–µ—Ç –≤—Å–µ–≥–¥–∞, –¥–∞–∂–µ –±–µ–∑ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏)
            # –í —Ç—Ä–µ–Ω–¥–æ–≤–æ–º —Ä—ã–Ω–∫–µ: –±–æ–ª—å—à–µ –≤–µ—Å–∞ momentum
            # –í –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ–º: –±–æ–ª—å—à–µ –≤–µ—Å–∞ volume
            # –í –±–æ–∫–æ–≤–∏–∫–µ: –±–æ–ª—å—à–µ –≤–µ—Å–∞ level

            if regime in ('BULL_TREND', 'BEAR_TREND'):
                # –¢—Ä–µ–Ω–¥–æ–≤—ã–π —Ä—ã–Ω–æ–∫: momentum –≤–∞–∂–Ω–µ–µ
                weights = {
                    'volume': 0.30,
                    'momentum': 0.45,  # üÜï –ë–æ–ª—å—à–µ –≤–µ—Å–∞ –≤ —Ç—Ä–µ–Ω–¥–µ
                    'level': 0.25
                }
            elif volatility > 1.5:  # üîß –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö (1.5% = –≤—ã—Å–æ–∫–∞—è)
                # –í—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å: volume –≤–∞–∂–Ω–µ–µ
                weights = {
                    'volume': 0.50,  # üÜï –ë–æ–ª—å—à–µ –≤–µ—Å–∞ –ø—Ä–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
                    'momentum': 0.25,
                    'level': 0.25
                }
            elif trend_strength < 0.3:
                # –ë–æ–∫–æ–≤–∏–∫: level –≤–∞–∂–Ω–µ–µ
                weights = {
                    'volume': 0.30,
                    'momentum': 0.20,
                    'level': 0.50  # üÜï –ë–æ–ª—å—à–µ –≤–µ—Å–∞ –≤ –±–æ–∫–æ–≤–∏–∫–µ
                }
            else:
                # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –≤–µ—Å–∞
                weights = {
                    'volume': 0.40,
                    'momentum': 0.30,
                    'level': 0.30
                }

            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ—Å–∞ (—Å—É–º–º–∞ = 1.0)
            total = sum(weights.values())
            if total > 0:
                weights = {k: v / total for k, v in weights.items()}

            logger.debug(
                "ü§ñ [ML_WEIGHTS] –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞ –¥–ª—è —Ä–µ–∂–∏–º–∞ %s (vol=%.2f): volume=%.2f, momentum=%.2f, level=%.2f",
                regime, volatility, weights['volume'], weights['momentum'], weights['level']
            )

            return weights

        except Exception as e:
            logger.debug("‚ö†Ô∏è [ML_WEIGHTS] –û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤–µ—Å–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ: %s", e)
            return {
                'volume': 0.40,
                'momentum': 0.30,
                'level': 0.30
            }

    def save_model(self, model_path: str = "ai_learning_data/ml_filter_model.pkl"):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
        if not self.is_trained or not self.model:
            logger.warning("‚ö†Ô∏è –ù–µ—Ç –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return False

        try:
            os.makedirs(os.path.dirname(model_path), exist_ok=True)
            joblib.dump({
                'model': self.model,
                'scaler': self.scaler
            }, model_path)
            logger.info("‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: %s", model_path)
            return True
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: %s", e)
            return False

    def load_model(self, model_path: str = "ai_learning_data/ml_filter_model.pkl") -> bool:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
        if not ML_AVAILABLE:
            return False

        try:
            if not os.path.exists(model_path):
                logger.warning("‚ö†Ô∏è –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: %s", model_path)
                return False

            data = joblib.load(model_path)
            self.model = data['model']
            self.scaler = data['scaler']
            self.is_trained = True

            logger.info("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: %s", model_path)
            return True
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: %s", e)
            return False


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
_ml_optimizer_instance: Optional[MLFilterOptimizer] = None


def get_ml_filter_optimizer() -> MLFilterOptimizer:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä ML –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞"""
    global _ml_optimizer_instance
    if _ml_optimizer_instance is None:
        _ml_optimizer_instance = MLFilterOptimizer()
    return _ml_optimizer_instance


